[
    {
        "id": "http://arxiv.org/abs/cs/9905014v1",
        "title": "Hierarchical Reinforcement Learning with the MAXQ Value Function\n  Decomposition",
        "summary": "  This paper presents the MAXQ approach to hierarchical reinforcement learning\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\nof smaller MDPs and decomposing the value function of the target MDP into an\nadditive combination of the value functions of the smaller MDPs. The paper\ndefines the MAXQ hierarchy, proves formal results on its representational\npower, and establishes five conditions for the safe use of state abstractions.\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\nthat it converges wih probability 1 to a kind of locally-optimal policy known\nas a recursively optimal policy, even in the presence of the five kinds of\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\nthrough a series of experiments in three domains and shows experimentally that\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\nvalue function has an important benefit: it makes it possible to compute and\nexecute an improved, non-hierarchical policy via a procedure similar to the\npolicy improvement step of policy iteration. The paper demonstrates the\neffectiveness of this non-hierarchical execution experimentally. Finally, the\npaper concludes with a comparison to related work and a discussion of the\ndesign tradeoffs in hierarchical reinforcement learning.\n",
        "published": "1999-05-21T14:26:07Z",
        "pdf_link": "http://arxiv.org/pdf/cs/9905014v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/9905015v1",
        "title": "State Abstraction in MAXQ Hierarchical Reinforcement Learning",
        "summary": "  Many researchers have explored methods for hierarchical reinforcement\nlearning (RL) with temporal abstractions, in which abstract actions are defined\nthat can perform many primitive actions before terminating. However, little is\nknown about learning with state abstractions, in which aspects of the state\nspace are ignored. In previous work, we developed the MAXQ method for\nhierarchical RL. In this paper, we define five conditions under which state\nabstraction can be combined with the MAXQ value function decomposition. We\nprove that the MAXQ-Q learning algorithm converges under these conditions and\nshow experimentally that state abstraction is important for the successful\napplication of MAXQ-Q learning.\n",
        "published": "1999-05-21T14:49:39Z",
        "pdf_link": "http://arxiv.org/pdf/cs/9905015v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0001004v1",
        "title": "Multiplicative Algorithm for Orthgonal Groups and Independent Component\n  Analysis",
        "summary": "  The multiplicative Newton-like method developed by the author et al. is\nextended to the situation where the dynamics is restricted to the orthogonal\ngroup. A general framework is constructed without specifying the cost function.\nThough the restriction to the orthogonal groups makes the problem somewhat\ncomplicated, an explicit expression for the amount of individual jumps is\nobtained. This algorithm is exactly second-order-convergent. The global\ninstability inherent in the Newton method is remedied by a\nLevenberg-Marquardt-type variation. The method thus constructed can readily be\napplied to the independent component analysis. Its remarkable performance is\nillustrated by a numerical simulation.\n",
        "published": "2000-01-07T06:20:53Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0001004v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0002006v1",
        "title": "Multiplicative Nonholonomic/Newton -like Algorithm",
        "summary": "  We construct new algorithms from scratch, which use the fourth order cumulant\nof stochastic variables for the cost function. The multiplicative updating rule\nhere constructed is natural from the homogeneous nature of the Lie group and\nhas numerous merits for the rigorous treatment of the dynamics. As one\nconsequence, the second order convergence is shown. For the cost function,\nfunctions invariant under the componentwise scaling are choosen. By identifying\npoints which can be transformed to each other by the scaling, we assume that\nthe dynamics is in a coset space. In our method, a point can move toward any\ndirection in this coset. Thus, no prewhitening is required.\n",
        "published": "2000-02-09T06:44:28Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0002006v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0009001v3",
        "title": "Complexity analysis for algorithmically simple strings",
        "summary": "  Given a reference computer, Kolmogorov complexity is a well defined function\non all binary strings. In the standard approach, however, only the asymptotic\nproperties of such functions are considered because they do not depend on the\nreference computer. We argue that this approach can be more useful if it is\nrefined to include an important practical case of simple binary strings.\nKolmogorov complexity calculus may be developed for this case if we restrict\nthe class of available reference computers. The interesting problem is to\ndefine a class of computers which is restricted in a {\\it natural} way modeling\nthe real-life situation where only a limited class of computers is physically\navailable to us. We give an example of what such a natural restriction might\nlook like mathematically, and show that under such restrictions some error\nterms, even logarithmic in complexity, can disappear from the standard\ncomplexity calculus.\n  Keywords: Kolmogorov complexity; Algorithmic information theory.\n",
        "published": "2000-09-05T18:54:58Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0009001v3"
    },
    {
        "id": "http://arxiv.org/abs/cs/0009007v1",
        "title": "Robust Classification for Imprecise Environments",
        "summary": "  In real-world environments it usually is difficult to specify target\noperating conditions precisely, for example, target misclassification costs.\nThis uncertainty makes building robust classification systems problematic. We\nshow that it is possible to build a hybrid classifier that will perform at\nleast as well as the best available classifier for any target conditions. In\nsome cases, the performance of the hybrid actually can surpass that of the best\nknown classifier. This robust performance extends across a wide variety of\ncomparison frameworks, including the optimization of metrics such as accuracy,\nexpected cost, lift, precision, recall, and workforce utilization. The hybrid\nalso is efficient to build, to store, and to update. The hybrid is based on a\nmethod for the comparison of classifier performance that is robust to imprecise\nclass distributions and misclassification costs. The ROC convex hull (ROCCH)\nmethod combines techniques from ROC analysis, decision analysis and\ncomputational geometry, and adapts them to the particulars of analyzing learned\nclassifiers. The method is efficient and incremental, minimizes the management\nof classifier performance data, and allows for clear visual comparisons and\nsensitivity analyses. Finally, we point to empirical evidence that a robust\nhybrid classifier indeed is needed for many real-world problems.\n",
        "published": "2000-09-13T21:09:47Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0009007v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0011032v1",
        "title": "Top-down induction of clustering trees",
        "summary": "  An approach to clustering is presented that adapts the basic top-down\ninduction of decision trees method towards clustering. To this aim, it employs\nthe principles of instance based learning. The resulting methodology is\nimplemented in the TIC (Top down Induction of Clustering trees) system for\nfirst order clustering. The TIC system employs the first order logical decision\ntree representation of the inductive logic programming system Tilde. Various\nexperiments with TIC are presented, in both propositional and relational\ndomains.\n",
        "published": "2000-11-21T21:51:01Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0011032v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0011044v1",
        "title": "Scaling Up Inductive Logic Programming by Learning from Interpretations",
        "summary": "  When comparing inductive logic programming (ILP) and attribute-value learning\ntechniques, there is a trade-off between expressive power and efficiency.\nInductive logic programming techniques are typically more expressive but also\nless efficient. Therefore, the data sets handled by current inductive logic\nprogramming systems are small according to general standards within the data\nmining community. The main source of inefficiency lies in the assumption that\nseveral examples may be related to each other, so they cannot be handled\nindependently.\n  Within the learning from interpretations framework for inductive logic\nprogramming this assumption is unnecessary, which allows to scale up existing\nILP algorithms. In this paper we explain this learning setting in the context\nof relational databases. We relate the setting to propositional data mining and\nto the classical ILP setting, and show that learning from interpretations\ncorresponds to learning from multiple relations and thus extends the\nexpressiveness of propositional learning, while maintaining its efficiency to a\nlarge extent (which is not the case in the classical ILP setting).\n  As a case study, we present two alternative implementations of the ILP system\nTilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which\nloads all data in main memory, and Tilde-LDS, which loads the examples one by\none. We experimentally compare the implementations, showing Tilde-LDS can\nhandle large data sets (in the order of 100,000 examples or 100 MB) and indeed\nscales up linearly in the number of examples.\n",
        "published": "2000-11-29T12:14:50Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0011044v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0103003v1",
        "title": "Learning Policies with External Memory",
        "summary": "  In order for an agent to perform well in partially observable domains, it is\nusually necessary for actions to depend on the history of observations. In this\npaper, we explore a {\\it stigmergic} approach, in which the agent's actions\ninclude the ability to set and clear bits in an external memory, and the\nexternal memory is included as part of the input to the agent. In this case, we\nneed to learn a reactive policy in a highly non-Markovian domain. We explore\ntwo algorithms: SARSA(\\lambda), which has had empirical success in partially\nobservable domains, and VAPS, a new algorithm due to Baird and Moore, with\nconvergence guarantees in partially observable domains. We compare the\nperformance of these two algorithms on benchmark problems.\n",
        "published": "2001-03-02T01:55:46Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0103003v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0110036v1",
        "title": "Efficient algorithms for decision tree cross-validation",
        "summary": "  Cross-validation is a useful and generally applicable technique often\nemployed in machine learning, including decision tree induction. An important\ndisadvantage of straightforward implementation of the technique is its\ncomputational overhead. In this paper we show that, for decision trees, the\ncomputational overhead of cross-validation can be reduced significantly by\nintegrating the cross-validation with the normal decision tree induction\nprocess. We discuss how existing decision tree algorithms can be adapted to\nthis aim, and provide an analysis of the speedups these adaptations may yield.\nThe analysis is supported by experimental results.\n",
        "published": "2001-10-17T15:45:23Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0110036v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0211003v1",
        "title": "Evaluation of the Performance of the Markov Blanket Bayesian Classifier\n  Algorithm",
        "summary": "  The Markov Blanket Bayesian Classifier is a recently-proposed algorithm for\nconstruction of probabilistic classifiers. This paper presents an empirical\ncomparison of the MBBC algorithm with three other Bayesian classifiers: Naive\nBayes, Tree-Augmented Naive Bayes and a general Bayesian network. All of these\nare implemented using the K2 framework of Cooper and Herskovits. The\nclassifiers are compared in terms of their performance (using simple accuracy\nmeasures and ROC curves) and speed, on a range of standard benchmark data sets.\nIt is concluded that MBBC is competitive in terms of speed and accuracy with\nthe other algorithms considered.\n",
        "published": "2002-11-01T18:09:56Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0211003v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0211007v1",
        "title": "Approximating Incomplete Kernel Matrices by the em Algorithm",
        "summary": "  In biological data, it is often the case that observed data are available\nonly for a subset of samples. When a kernel matrix is derived from such data,\nwe have to leave the entries for unavailable samples as missing. In this paper,\nwe make use of a parametric model of kernel matrices, and estimate missing\nentries by fitting the model to existing entries. The parametric model is\ncreated as a set of spectral variants of a complete kernel matrix derived from\nanother information source. For model fitting, we adopt the em algorithm based\non the information geometry of positive definite matrices. We will report\npromising results on bacteria clustering experiments using two marker\nsequences: 16S and gyrB.\n",
        "published": "2002-11-07T07:21:58Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0211007v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0309015v1",
        "title": "Reliable and Efficient Inference of Bayesian Networks from Sparse Data\n  by Statistical Learning Theory",
        "summary": "  To learn (statistical) dependencies among random variables requires\nexponentially large sample size in the number of observed random variables if\nany arbitrary joint probability distribution can occur.\n  We consider the case that sparse data strongly suggest that the probabilities\ncan be described by a simple Bayesian network, i.e., by a graph with small\nin-degree \\Delta. Then this simple law will also explain further data with high\nconfidence. This is shown by calculating bounds on the VC dimension of the set\nof those probability measures that correspond to simple graphs. This allows to\nselect networks by structural risk minimization and gives reliability bounds on\nthe error of the estimated joint measure without (in contrast to a previous\npaper) any prior assumptions on the set of possible joint measures.\n  The complexity for searching the optimal Bayesian networks of in-degree\n\\Delta increases only polynomially in the number of random varibales for\nconstant \\Delta and the optimal joint measure associated with a given graph can\nbe found by convex optimization.\n",
        "published": "2003-09-10T13:56:41Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0309015v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0311042v1",
        "title": "Toward Attribute Efficient Learning Algorithms",
        "summary": "  We make progress on two important problems regarding attribute efficient\nlearnability.\n  First, we give an algorithm for learning decision lists of length $k$ over\n$n$ variables using $2^{\\tilde{O}(k^{1/3})} \\log n$ examples and time\n$n^{\\tilde{O}(k^{1/3})}$. This is the first algorithm for learning decision\nlists that has both subexponential sample complexity and subexponential running\ntime in the relevant parameters. Our approach establishes a relationship\nbetween attribute efficient learning and polynomial threshold functions and is\nbased on a new construction of low degree, low weight polynomial threshold\nfunctions for decision lists. For a wide range of parameters our construction\nmatches a 1994 lower bound due to Beigel for the ODDMAXBIT predicate and gives\nan essentially optimal tradeoff between polynomial threshold function degree\nand weight.\n  Second, we give an algorithm for learning an unknown parity function on $k$\nout of $n$ variables using $O(n^{1-1/k})$ examples in time polynomial in $n$.\nFor $k=o(\\log n)$ this yields a polynomial time algorithm with sample\ncomplexity $o(n)$. This is the first polynomial time algorithm for learning\nparity on a superconstant number of variables with sublinear sample complexity.\n",
        "published": "2003-11-27T05:34:04Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0311042v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0312004v1",
        "title": "Improving spam filtering by combining Naive Bayes with simple k-nearest\n  neighbor searches",
        "summary": "  Using naive Bayes for email classification has become very popular within the\nlast few months. They are quite easy to implement and very efficient. In this\npaper we want to present empirical results of email classification using a\ncombination of naive Bayes and k-nearest neighbor searches. Using this\ntechnique we show that the accuracy of a Bayes filter can be improved slightly\nfor a high number of features and significantly for a small number of features.\n",
        "published": "2003-11-30T20:41:18Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0312004v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0401005v1",
        "title": "About Unitary Rating Score Constructing",
        "summary": "  It is offered to pool test points of different subjects and different aspects\nof the same subject together in order to get the unitary rating score, by the\nway of nonlinear transformation of indicator points in accordance with Zipf's\ndistribution. It is proposed to use the well-studied distribution of\nIntellectuality Quotient IQ as the reference distribution for latent variable\n\"progress in studies\".\n",
        "published": "2004-01-08T07:50:51Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0401005v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0412003v1",
        "title": "Mining Heterogeneous Multivariate Time-Series for Learning Meaningful\n  Patterns: Application to Home Health Telecare",
        "summary": "  For the last years, time-series mining has become a challenging issue for\nresearchers. An important application lies in most monitoring purposes, which\nrequire analyzing large sets of time-series for learning usual patterns. Any\ndeviation from this learned profile is then considered as an unexpected\nsituation. Moreover, complex applications may involve the temporal study of\nseveral heterogeneous parameters. In that paper, we propose a method for mining\nheterogeneous multivariate time-series for learning meaningful patterns. The\nproposed approach allows for mixed time-series -- containing both pattern and\nnon-pattern data -- such as for imprecise matches, outliers, stretching and\nglobal translating of patterns instances in time. We present the early results\nof our approach in the context of monitoring the health status of a person at\nhome. The purpose is to build a behavioral profile of a person by analyzing the\ntime variations of several quantitative or qualitative parameters recorded\nthrough a provision of sensors installed in the home.\n",
        "published": "2004-12-01T16:32:49Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0412003v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0502016v1",
        "title": "Stability Analysis for Regularized Least Squares Regression",
        "summary": "  We discuss stability for a class of learning algorithms with respect to noisy\nlabels. The algorithms we consider are for regression, and they involve the\nminimization of regularized risk functionals, such as L(f) := 1/N sum_i\n(f(x_i)-y_i)^2+ lambda ||f||_H^2. We shall call the algorithm `stable' if, when\ny_i is a noisy version of f*(x_i) for some function f* in H, the output of the\nalgorithm converges to f* as the regularization term and noise simultaneously\nvanish. We consider two flavors of this problem, one where a data set of N\npoints remains fixed, and the other where N -> infinity. For the case where N\n-> infinity, we give conditions for convergence to f_E (the function which is\nthe expectation of y(x) for each x), as lambda -> 0. For the fixed N case, we\ndescribe the limiting 'non-noisy', 'non-regularized' function f*, and give\nconditions for convergence. In the process, we develop a set of tools for\ndealing with functionals such as L(f), which are applicable to many other\nproblems in learning theory.\n",
        "published": "2005-02-03T19:54:02Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0502016v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0504001v1",
        "title": "Probabilistic and Team PFIN-type Learning: General Properties",
        "summary": "  We consider the probability hierarchy for Popperian FINite learning and study\nthe general properties of this hierarchy. We prove that the probability\nhierarchy is decidable, i.e. there exists an algorithm that receives p_1 and\np_2 and answers whether PFIN-type learning with the probability of success p_1\nis equivalent to PFIN-type learning with the probability of success p_2.\n  To prove our result, we analyze the topological structure of the probability\nhierarchy. We prove that it is well-ordered in descending ordering and\norder-equivalent to ordinal epsilon_0. This shows that the structure of the\nhierarchy is very complicated.\n  Using similar methods, we also prove that, for PFIN-type learning, team\nlearning and probabilistic learning are of the same power.\n",
        "published": "2005-03-31T23:04:28Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0504001v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0506004v4",
        "title": "Non-asymptotic calibration and resolution",
        "summary": "  We analyze a new algorithm for probability forecasting of binary observations\non the basis of the available data, without making any assumptions about the\nway the observations are generated. The algorithm is shown to be well\ncalibrated and to have good resolution for long enough sequences of\nobservations and for a suitable choice of its parameter, a kernel on the\nCartesian product of the forecast space $[0,1]$ and the data space. Our main\nresults are non-asymptotic: we establish explicit inequalities, shown to be\ntight, for the performance of the algorithm.\n",
        "published": "2005-06-01T14:03:20Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0506004v4"
    },
    {
        "id": "http://arxiv.org/abs/cs/0506007v2",
        "title": "Defensive forecasting for linear protocols",
        "summary": "  We consider a general class of forecasting protocols, called \"linear\nprotocols\", and discuss several important special cases, including multi-class\nforecasting. Forecasting is formalized as a game between three players:\nReality, whose role is to generate observations; Forecaster, whose goal is to\npredict the observations; and Skeptic, who tries to make money on any lack of\nagreement between Forecaster's predictions and the actual observations. Our\nmain mathematical result is that for any continuous strategy for Skeptic in a\nlinear protocol there exists a strategy for Forecaster that does not allow\nSkeptic's capital to grow. This result is a meta-theorem that allows one to\ntransform any continuous law of probability in a linear protocol into a\nforecasting strategy whose predictions are guaranteed to satisfy this law. We\napply this meta-theorem to a weak law of large numbers in Hilbert spaces to\nobtain a version of the K29 prediction algorithm for linear protocols and show\nthat this version also satisfies the attractive properties of proper\ncalibration and resolution under a suitable choice of its kernel parameter,\nwith no assumptions about the way the data is generated.\n",
        "published": "2005-06-02T13:26:43Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0506007v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0506057v2",
        "title": "About one 3-parameter Model of Testing",
        "summary": "  This article offers a 3-parameter model of testing, with 1) the difference\nbetween the ability level of the examinee and item difficulty; 2) the examinee\ndiscrimination and 3) the item discrimination as model parameters.\n",
        "published": "2005-06-14T04:00:38Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0506057v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0506085v1",
        "title": "On the Job Training",
        "summary": "  We propose a new framework for building and evaluating machine learning\nalgorithms. We argue that many real-world problems require an agent which must\nquickly learn to respond to demands, yet can continue to perform and respond to\nnew training throughout its useful life. We give a framework for how such\nagents can be built, describe several metrics for evaluating them, and show\nthat subtle changes in system construction can significantly affect agent\nperformance.\n",
        "published": "2005-06-22T21:21:13Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0506085v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0507033v2",
        "title": "Multiresolution Kernels",
        "summary": "  We present in this work a new methodology to design kernels on data which is\nstructured with smaller components, such as text, images or sequences. This\nmethodology is a template procedure which can be applied on most kernels on\nmeasures and takes advantage of a more detailed \"bag of components\"\nrepresentation of the objects. To obtain such a detailed description, we\nconsider possible decompositions of the original bag into a collection of\nnested bags, following a prior knowledge on the objects' structure. We then\nconsider these smaller bags to compare two objects both in a detailed\nperspective, stressing local matches between the smaller bags, and in a global\nor coarse perspective, by considering the entire bag. This multiresolution\napproach is likely to be best suited for tasks where the coarse approach is not\nprecise enough, and where a more subtle mixture of both local and global\nsimilarities is necessary to compare objects. The approach presented here would\nnot be computationally tractable without a factorization trick that we\nintroduce before presenting promising results on an image retrieval task.\n",
        "published": "2005-07-13T05:45:28Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0507033v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0507044v1",
        "title": "Defensive Universal Learning with Experts",
        "summary": "  This paper shows how universal learning can be achieved with expert advice.\nTo this aim, we specify an experts algorithm with the following\ncharacteristics: (a) it uses only feedback from the actions actually chosen\n(bandit setup), (b) it can be applied with countably infinite expert classes,\nand (c) it copes with losses that may grow in time appropriately slowly. We\nprove loss bounds against an adaptive adversary. From this, we obtain a master\nalgorithm for \"reactive\" experts problems, which means that the master's\nactions may influence the behavior of the adversary. Our algorithm can\nsignificantly outperform standard experts algorithms on such problems. Finally,\nwe combine it with a universal expert class. The resulting universal learner\nperforms -- in a certain sense -- almost as well as any computable strategy,\nfor any online decision problem. We also specify the (worst-case) convergence\nspeed, which is very slow.\n",
        "published": "2005-07-18T14:33:56Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0507044v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0507062v1",
        "title": "FPL Analysis for Adaptive Bandits",
        "summary": "  A main problem of \"Follow the Perturbed Leader\" strategies for online\ndecision problems is that regret bounds are typically proven against oblivious\nadversary. In partial observation cases, it was not clear how to obtain\nperformance guarantees against adaptive adversary, without worsening the\nbounds. We propose a conceptually simple argument to resolve this problem.\nUsing this, a regret bound of O(t^(2/3)) for FPL in the adversarial multi-armed\nbandit problem is shown. This bound holds for the common FPL variant using only\nthe observations from designated exploration rounds. Using all observations\nallows for the stronger bound of O(t^(1/2)), matching the best bound known so\nfar (and essentially the known lower bound) for adversarial bandits.\nSurprisingly, this variant does not even need explicit exploration, it is\nself-stabilizing. However the sampling probabilities have to be either\nexternally provided or approximated to sufficient accuracy, using O(t^2 log t)\nsamples in each step.\n",
        "published": "2005-07-26T05:00:27Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0507062v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0509055v1",
        "title": "Learning Optimal Augmented Bayes Networks",
        "summary": "  Naive Bayes is a simple Bayesian classifier with strong independence\nassumptions among the attributes. This classifier, desipte its strong\nindependence assumptions, often performs well in practice. It is believed that\nrelaxing the independence assumptions of a naive Bayes classifier may improve\nthe classification accuracy of the resulting structure. While finding an\noptimal unconstrained Bayesian Network (for most any reasonable scoring\nmeasure) is an NP-hard problem, it is possible to learn in polynomial time\noptimal networks obeying various structural restrictions. Several authors have\nexamined the possibilities of adding augmenting arcs between attributes of a\nNaive Bayes classifier. Friedman, Geiger and Goldszmidt define the TAN\nstructure in which the augmenting arcs form a tree on the attributes, and\npresent a polynomial time algorithm that learns an optimal TAN with respect to\nMDL score. Keogh and Pazzani define Augmented Bayes Networks in which the\naugmenting arcs form a forest on the attributes (a collection of trees, hence a\nrelaxation of the stuctural restriction of TAN), and present heuristic search\nmethods for learning good, though not optimal, augmenting arc sets. The\nauthors, however, evaluate the learned structure only in terms of observed\nmisclassification error and not against a scoring metric, such as MDL. In this\npaper, we present a simple, polynomial time greedy algorithm for learning an\noptimal Augmented Bayes Network with respect to MDL score.\n",
        "published": "2005-09-19T04:57:26Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0509055v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0510038v4",
        "title": "Learning Unions of $ω(1)$-Dimensional Rectangles",
        "summary": "  We consider the problem of learning unions of rectangles over the domain\n$[b]^n$, in the uniform distribution membership query learning setting, where\nboth b and n are \"large\". We obtain poly$(n, \\log b)$-time algorithms for the\nfollowing classes:\n  - poly$(n \\log b)$-way Majority of $O(\\frac{\\log(n \\log b)} {\\log \\log(n \\log\nb)})$-dimensional rectangles.\n  - Union of poly$(\\log(n \\log b))$ many $O(\\frac{\\log^2 (n \\log b)} {(\\log\n\\log(n \\log b) \\log \\log \\log (n \\log b))^2})$-dimensional rectangles.\n  - poly$(n \\log b)$-way Majority of poly$(n \\log b)$-Or of disjoint\n$O(\\frac{\\log(n \\log b)} {\\log \\log(n \\log b)})$-dimensional rectangles.\n  Our main algorithmic tool is an extension of Jackson's boosting- and\nFourier-based Harmonic Sieve algorithm [Jackson 1997] to the domain $[b]^n$,\nbuilding on work of [Akavia, Goldwasser, Safra 2003]. Other ingredients used to\nobtain the results stated above are techniques from exact learning [Beimel,\nKushilevitz 1998] and ideas from recent work on learning augmented $AC^{0}$\ncircuits [Jackson, Klivans, Servedio 2002] and on representing Boolean\nfunctions as thresholds of parities [Klivans, Servedio 2001].\n",
        "published": "2005-10-14T19:26:34Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0510038v4"
    },
    {
        "id": "http://arxiv.org/abs/cs/0511058v2",
        "title": "On-line regression competitive with reproducing kernel Hilbert spaces",
        "summary": "  We consider the problem of on-line prediction of real-valued labels, assumed\nbounded in absolute value by a known constant, of new objects from known\nlabeled objects. The prediction algorithm's performance is measured by the\nsquared deviation of the predictions from the actual labels. No stochastic\nassumptions are made about the way the labels and objects are generated.\nInstead, we are given a benchmark class of prediction rules some of which are\nhoped to produce good predictions. We show that for a wide range of\ninfinite-dimensional benchmark classes one can construct a prediction algorithm\nwhose cumulative loss over the first N examples does not exceed the cumulative\nloss of any prediction rule in the class plus O(sqrt(N)); the main differences\nfrom the known results are that we do not impose any upper bound on the norm of\nthe considered prediction rules and that we achieve an optimal leading term in\nthe excess loss of our algorithm. If the benchmark class is \"universal\" (dense\nin the class of continuous functions on each compact set), this provides an\non-line non-stochastic analogue of universally consistent prediction in\nnon-parametric statistics. We use two proof techniques: one is based on the\nAggregating Algorithm and the other on the recently developed method of\ndefensive forecasting.\n",
        "published": "2005-11-15T17:13:50Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0511058v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0511088v1",
        "title": "Bounds on Query Convergence",
        "summary": "  The problem of finding an optimum using noisy evaluations of a smooth cost\nfunction arises in many contexts, including economics, business, medicine,\nexperiment design, and foraging theory. We derive an asymptotic bound E[ (x_t -\nx*)^2 ] >= O(1/sqrt(t)) on the rate of convergence of a sequence (x_0, x_1,\n>...) generated by an unbiased feedback process observing noisy evaluations of\nan unknown quadratic function maximised at x*. The bound is tight, as the proof\nleads to a simple algorithm which meets it. We further establish a bound on the\ntotal regret, E[ sum_{i=1..t} (x_i - x*)^2 ] >= O(sqrt(t)) These bounds may\nimpose practical limitations on an agent's performance, as O(eps^-4) queries\nare made before the queries converge to x* with eps accuracy.\n",
        "published": "2005-11-25T15:57:56Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0511088v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0512050v1",
        "title": "Preference Learning in Terminology Extraction: A ROC-based approach",
        "summary": "  A key data preparation step in Text Mining, Term Extraction selects the\nterms, or collocation of words, attached to specific concepts. In this paper,\nthe task of extracting relevant collocations is achieved through a supervised\nlearning algorithm, exploiting a few collocations manually labelled as\nrelevant/irrelevant. The candidate terms are described along 13 standard\nstatistical criteria measures. From these examples, an evolutionary learning\nalgorithm termed Roger, based on the optimization of the Area under the ROC\ncurve criterion, extracts an order on the candidate terms. The robustness of\nthe approach is demonstrated on two real-world domain applications, considering\ndifferent domains (biology and human resources) and different languages\n(English and French).\n",
        "published": "2005-12-13T13:25:57Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0512050v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0512059v2",
        "title": "Competing with wild prediction rules",
        "summary": "  We consider the problem of on-line prediction competitive with a benchmark\nclass of continuous but highly irregular prediction rules. It is known that if\nthe benchmark class is a reproducing kernel Hilbert space, there exists a\nprediction algorithm whose average loss over the first N examples does not\nexceed the average loss of any prediction rule in the class plus a \"regret\nterm\" of O(N^(-1/2)). The elements of some natural benchmark classes, however,\nare so irregular that these classes are not Hilbert spaces. In this paper we\ndevelop Banach-space methods to construct a prediction algorithm with a regret\nterm of O(N^(-1/p)), where p is in [2,infty) and p-2 reflects the degree to\nwhich the benchmark class fails to be a Hilbert space.\n",
        "published": "2005-12-14T20:03:30Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0512059v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0601044v1",
        "title": "Genetic Programming, Validation Sets, and Parsimony Pressure",
        "summary": "  Fitness functions based on test cases are very common in Genetic Programming\n(GP). This process can be assimilated to a learning task, with the inference of\nmodels from a limited number of samples. This paper is an investigation on two\nmethods to improve generalization in GP-based learning: 1) the selection of the\nbest-of-run individuals using a three data sets methodology, and 2) the\napplication of parsimony pressure in order to reduce the complexity of the\nsolutions. Results using GP in a binary classification setup show that while\nthe accuracy on the test sets is preserved, with less variances compared to\nbaseline results, the mean tree size obtained with the tested methods is\nsignificantly reduced.\n",
        "published": "2006-01-11T15:39:16Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0601044v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0601087v1",
        "title": "Processing of Test Matrices with Guessing Correction",
        "summary": "  It is suggested to insert into test matrix 1s for correct responses, 0s for\nresponse refusals, and negative corrective elements for incorrect responses.\nWith the classical test theory approach test scores of examinees and items are\ncalculated traditionally as sums of matrix elements, organized in rows and\ncolumns. Correlation coefficients are estimated using correction coefficients.\nIn item response theory approach examinee and item logits are estimated using\nmaximum likelihood method and probabilities of all matrix elements.\n",
        "published": "2006-01-20T05:40:44Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0601087v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0602062v1",
        "title": "Learning rational stochastic languages",
        "summary": "  Given a finite set of words w1,...,wn independently drawn according to a\nfixed unknown distribution law P called a stochastic language, an usual goal in\nGrammatical Inference is to infer an estimate of P in some class of\nprobabilistic models, such as Probabilistic Automata (PA). Here, we study the\nclass of rational stochastic languages, which consists in stochastic languages\nthat can be generated by Multiplicity Automata (MA) and which strictly includes\nthe class of stochastic languages generated by PA. Rational stochastic\nlanguages have minimal normal representation which may be very concise, and\nwhose parameters can be efficiently estimated from stochastic samples. We\ndesign an efficient inference algorithm DEES which aims at building a minimal\nnormal representation of the target. Despite the fact that no recursively\nenumerable class of MA computes exactly the set of rational stochastic\nlanguages over Q, we show that DEES strongly identifies tis set in the limit.\nWe study the intermediary MA output by DEES and show that they compute rational\nseries which converge absolutely to one and which can be used to provide\nstochastic languages which closely estimate the target.\n",
        "published": "2006-02-17T08:57:44Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0602062v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0605040v1",
        "title": "General Discounting versus Average Reward",
        "summary": "  Consider an agent interacting with an environment in cycles. In every\ninteraction cycle the agent is rewarded for its performance. We compare the\naverage reward U from cycle 1 to m (average value) with the future discounted\nreward V from cycle k to infinity (discounted value). We consider essentially\narbitrary (non-geometric) discount sequences and arbitrary reward sequences\n(non-MDP environments). We show that asymptotically U for m->infinity and V for\nk->infinity are equal, provided both limits exist. Further, if the effective\nhorizon grows linearly with k or faster, then existence of the limit of U\nimplies that the limit of V exists. Conversely, if the effective horizon grows\nlinearly with k or slower, then existence of the limit of V implies that the\nlimit of U exists.\n",
        "published": "2006-05-09T10:39:03Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0605040v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0606077v1",
        "title": "On Sequence Prediction for Arbitrary Measures",
        "summary": "  Suppose we are given two probability measures on the set of one-way infinite\nfinite-alphabet sequences and consider the question when one of the measures\npredicts the other, that is, when conditional probabilities converge (in a\ncertain sense) when one of the measures is chosen to generate the sequence.\nThis question may be considered a refinement of the problem of sequence\nprediction in its most general formulation: for a given class of probability\nmeasures, does there exist a measure which predicts all of the measures in the\nclass? To address this problem, we find some conditions on local absolute\ncontinuity which are sufficient for prediction and which generalize several\ndifferent notions which are known to be sufficient for prediction. We also\nformulate some open questions to outline a direction for finding the conditions\non classes of measures for which prediction is possible.\n",
        "published": "2006-06-16T16:33:23Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0606077v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0606093v1",
        "title": "Predictions as statements and decisions",
        "summary": "  Prediction is a complex notion, and different predictors (such as people,\ncomputer programs, and probabilistic theories) can pursue very different goals.\nIn this paper I will review some popular kinds of prediction and argue that the\ntheory of competitive on-line learning can benefit from the kinds of prediction\nthat are now foreign to it.\n",
        "published": "2006-06-22T04:31:51Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0606093v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0607047v1",
        "title": "PAC Classification based on PAC Estimates of Label Class Distributions",
        "summary": "  A standard approach in pattern classification is to estimate the\ndistributions of the label classes, and then to apply the Bayes classifier to\nthe estimates of the distributions in order to classify unlabeled examples. As\none might expect, the better our estimates of the label class distributions,\nthe better the resulting classifier will be. In this paper we make this\nobservation precise by identifying risk bounds of a classifier in terms of the\nquality of the estimates of the label class distributions. We show how PAC\nlearnability relates to estimates of the distributions that have a PAC\nguarantee on their $L_1$ distance from the true distribution, and we bound the\nincrease in negative log likelihood risk in terms of PAC bounds on the\nKL-divergence. We give an inefficient but general-purpose smoothing method for\nconverting an estimated distribution that is good under the $L_1$ metric into a\ndistribution that is good under the KL-divergence.\n",
        "published": "2006-07-11T13:52:39Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0607047v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0607067v1",
        "title": "Competing with stationary prediction strategies",
        "summary": "  In this paper we introduce the class of stationary prediction strategies and\nconstruct a prediction algorithm that asymptotically performs as well as the\nbest continuous stationary strategy. We make mild compactness assumptions but\nno stochastic assumptions about the environment. In particular, no assumption\nof stationarity is made about the environment, and the stationarity of the\nconsidered strategies only means that they do not depend explicitly on time; we\nargue that it is natural to consider only stationary strategies even for highly\nnon-stationary environments.\n",
        "published": "2006-07-13T15:52:04Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0607067v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0607085v2",
        "title": "Using Pseudo-Stochastic Rational Languages in Probabilistic Grammatical\n  Inference",
        "summary": "  In probabilistic grammatical inference, a usual goal is to infer a good\napproximation of an unknown distribution P called a stochastic language. The\nestimate of P stands in some class of probabilistic models such as\nprobabilistic automata (PA). In this paper, we focus on probabilistic models\nbased on multiplicity automata (MA). The stochastic languages generated by MA\nare called rational stochastic languages; they strictly include stochastic\nlanguages generated by PA; they also admit a very concise canonical\nrepresentation. Despite the fact that this class is not recursively enumerable,\nit is efficiently identifiable in the limit by using the algorithm DEES,\nintroduced by the authors in a previous paper. However, the identification is\nnot proper and before the convergence of the algorithm, DEES can produce MA\nthat do not define stochastic languages. Nevertheless, it is possible to use\nthese MA to define stochastic languages. We show that they belong to a broader\nclass of rational series, that we call pseudo-stochastic rational languages.\nThe aim of this paper is twofold. First we provide a theoretical study of\npseudo-stochastic rational languages, the languages output by DEES, showing for\nexample that this class is decidable within polynomial time. Second, we have\ncarried out a lot of experiments in order to compare DEES to classical\ninference algorithms such as ALERGIA and MDI. They show that DEES outperforms\nthem in most cases.\n",
        "published": "2006-07-18T07:21:51Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0607085v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0607096v1",
        "title": "Logical settings for concept learning from incomplete examples in First\n  Order Logic",
        "summary": "  We investigate here concept learning from incomplete examples. Our first\npurpose is to discuss to what extent logical learning settings have to be\nmodified in order to cope with data incompleteness. More precisely we are\ninterested in extending the learning from interpretations setting introduced by\nL. De Raedt that extends to relational representations the classical\npropositional (or attribute-value) concept learning from examples framework. We\nare inspired here by ideas presented by H. Hirsh in a work extending the\nVersion space inductive paradigm to incomplete data. H. Hirsh proposes to\nslightly modify the notion of solution when dealing with incomplete examples: a\nsolution has to be a hypothesis compatible with all pieces of information\nconcerning the examples. We identify two main classes of incompleteness. First,\nuncertainty deals with our state of knowledge concerning an example. Second,\ngeneralization (or abstraction) deals with what part of the description of the\nexample is sufficient for the learning purpose. These two main sources of\nincompleteness can be mixed up when only part of the useful information is\nknown. We discuss a general learning setting, referred to as \"learning from\npossibilities\" that formalizes these ideas, then we present a more specific\nlearning setting, referred to as \"assumption-based learning\" that cope with\nexamples which uncertainty can be reduced when considering contextual\ninformation outside of the proper description of the examples. Assumption-based\nlearning is illustrated on a recent work concerning the prediction of a\nconsensus secondary structure common to a set of RNA sequences.\n",
        "published": "2006-07-20T14:52:08Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0607096v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0607110v1",
        "title": "A Theory of Probabilistic Boosting, Decision Trees and Matryoshki",
        "summary": "  We present a theory of boosting probabilistic classifiers. We place ourselves\nin the situation of a user who only provides a stopping parameter and a\nprobabilistic weak learner/classifier and compare three types of boosting\nalgorithms: probabilistic Adaboost, decision tree, and tree of trees of ... of\ntrees, which we call matryoshka. \"Nested tree,\" \"embedded tree\" and \"recursive\ntree\" are also appropriate names for this algorithm, which is one of our\ncontributions. Our other contribution is the theoretical analysis of the\nalgorithms, in which we give training error bounds. This analysis suggests that\nthe matryoshka leverages probabilistic weak classifiers more efficiently than\nsimple decision trees.\n",
        "published": "2006-07-25T15:57:56Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0607110v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0607134v1",
        "title": "Leading strategies in competitive on-line prediction",
        "summary": "  We start from a simple asymptotic result for the problem of on-line\nregression with the quadratic loss function: the class of continuous\nlimited-memory prediction strategies admits a \"leading prediction strategy\",\nwhich not only asymptotically performs at least as well as any continuous\nlimited-memory strategy but also satisfies the property that the excess loss of\nany continuous limited-memory strategy is determined by how closely it imitates\nthe leading strategy. More specifically, for any class of prediction strategies\nconstituting a reproducing kernel Hilbert space we construct a leading\nstrategy, in the sense that the loss of any prediction strategy whose norm is\nnot too large is determined by how closely it imitates the leading strategy.\nThis result is extended to the loss functions given by Bregman divergences and\nby strictly proper scoring rules.\n",
        "published": "2006-07-27T22:11:07Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0607134v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0607136v1",
        "title": "Competing with Markov prediction strategies",
        "summary": "  Assuming that the loss function is convex in the prediction, we construct a\nprediction strategy universal for the class of Markov prediction strategies,\nnot necessarily continuous. Allowing randomization, we remove the requirement\nof convexity.\n",
        "published": "2006-07-28T21:45:41Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0607136v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0608033v1",
        "title": "A Study on Learnability for Rigid Lambek Grammars",
        "summary": "  We present basic notions of Gold's \"learnability in the limit\" paradigm,\nfirst presented in 1967, a formalization of the cognitive process by which a\nnative speaker gets to grasp the underlying grammar of his/her own native\nlanguage by being exposed to well formed sentences generated by that grammar.\nThen we present Lambek grammars, a formalism issued from categorial grammars\nwhich, although not as expressive as needed for a full formalization of natural\nlanguages, is particularly suited to easily implement a natural interface\nbetween syntax and semantics. In the last part of this work, we present a\nlearnability result for Rigid Lambek grammars from structured examples.\n",
        "published": "2006-08-06T16:10:05Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0608033v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0609007v1",
        "title": "A Massive Local Rules Search Approach to the Classification Problem",
        "summary": "  An approach to the classification problem of machine learning, based on\nbuilding local classification rules, is developed. The local rules are\nconsidered as projections of the global classification rules to the event we\nwant to classify. A massive global optimization algorithm is used for\noptimization of quality criterion. The algorithm, which has polynomial\ncomplexity in typical case, is used to find all high--quality local rules. The\nother distinctive feature of the algorithm is the integration of attributes\nlevels selection (for ordered attributes) with rules searching and original\nconflicting rules resolution strategy. The algorithm is practical; it was\ntested on a number of data sets from UCI repository, and a comparison with the\nother predicting techniques is presented.\n",
        "published": "2006-09-03T21:30:03Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0609007v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0609045v1",
        "title": "Metric entropy in competitive on-line prediction",
        "summary": "  Competitive on-line prediction (also known as universal prediction of\nindividual sequences) is a strand of learning theory avoiding making any\nstochastic assumptions about the way the observations are generated. The\npredictor's goal is to compete with a benchmark class of prediction rules,\nwhich is often a proper Banach function space. Metric entropy provides a\nunifying framework for competitive on-line prediction: the numerous known upper\nbounds on the metric entropy of various compact sets in function spaces readily\nimply bounds on the performance of on-line prediction strategies. This paper\ndiscusses strengths and limitations of the direct approach to competitive\non-line prediction via metric entropy, including comparisons to other\napproaches.\n",
        "published": "2006-09-09T11:31:01Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0609045v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0609093v1",
        "title": "PAC Learning Mixtures of Axis-Aligned Gaussians with No Separation\n  Assumption",
        "summary": "  We propose and analyze a new vantage point for the learning of mixtures of\nGaussians: namely, the PAC-style model of learning probability distributions\nintroduced by Kearns et al. Here the task is to construct a hypothesis mixture\nof Gaussians that is statistically indistinguishable from the actual mixture\ngenerating the data; specifically, the KL-divergence should be at most epsilon.\n  In this scenario, we give a poly(n/epsilon)-time algorithm that learns the\nclass of mixtures of any constant number of axis-aligned Gaussians in\nn-dimensional Euclidean space. Our algorithm makes no assumptions about the\nseparation between the means of the Gaussians, nor does it have any dependence\non the minimum mixing weight. This is in contrast to learning results known in\nthe ``clustering'' model, where such assumptions are unavoidable.\n  Our algorithm relies on the method of moments, and a subalgorithm developed\nin previous work by the authors (FOCS 2005) for a discrete mixture-learning\nproblem.\n",
        "published": "2006-09-16T14:43:27Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0609093v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0611011v1",
        "title": "Hedging predictions in machine learning",
        "summary": "  Recent advances in machine learning make it possible to design efficient\nprediction algorithms for data sets with huge numbers of parameters. This paper\ndescribes a new technique for \"hedging\" the predictions output by many such\nalgorithms, including support vector machines, kernel ridge regression, kernel\nnearest neighbours, and by many other state-of-the-art methods. The hedged\npredictions for the labels of new objects include quantitative measures of\ntheir own accuracy and reliability. These measures are provably valid under the\nassumption of randomness, traditional in machine learning: the objects and\ntheir labels are assumed to be generated independently from the same\nprobability distribution. In particular, it becomes possible to control (up to\nstatistical fluctuations) the number of erroneous predictions by selecting a\nsuitable confidence level. Validity being achieved automatically, the remaining\ngoal of hedged prediction is efficiency: taking full account of the new\nobjects' features and other available information to produce as accurate\npredictions as possible. This can be done successfully using the powerful\nmachinery of modern machine learning.\n",
        "published": "2006-11-02T18:44:49Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0611011v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0611145v1",
        "title": "A Unified View of TD Algorithms; Introducing Full-Gradient TD and\n  Equi-Gradient Descent TD",
        "summary": "  This paper addresses the issue of policy evaluation in Markov Decision\nProcesses, using linear function approximation. It provides a unified view of\nalgorithms such as TD(lambda), LSTD(lambda), iLSTD, residual-gradient TD. It is\nasserted that they all consist in minimizing a gradient function and differ by\nthe form of this function and their means of minimizing it. Two new schemes are\nintroduced in that framework: Full-gradient TD which uses a generalization of\nthe principle introduced in iLSTD, and EGD TD, which reduces the gradient by\nsuccessive equi-gradient descents. These three algorithms form a new\nintermediate family with the interesting property of making much better use of\nthe samples than TD while keeping a gradient descent scheme, which is useful\nfor complexity issues and optimistic policy iteration.\n",
        "published": "2006-11-29T00:00:57Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0611145v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0703062v1",
        "title": "Bandit Algorithms for Tree Search",
        "summary": "  Bandit based methods for tree search have recently gained popularity when\napplied to huge trees, e.g. in the game of go (Gelly et al., 2006). The UCT\nalgorithm (Kocsis and Szepesvari, 2006), a tree search method based on Upper\nConfidence Bounds (UCB) (Auer et al., 2002), is believed to adapt locally to\nthe effective smoothness of the tree. However, we show that UCT is too\n``optimistic'' in some cases, leading to a regret O(exp(exp(D))) where D is the\ndepth of the tree. We propose alternative bandit algorithms for tree search.\nFirst, a modification of UCT using a confidence sequence that scales\nexponentially with the horizon depth is proven to have a regret O(2^D\n\\sqrt{n}), but does not adapt to possible smoothness in the tree. We then\nanalyze Flat-UCB performed on the leaves and provide a finite regret bound with\nhigh probability. Then, we introduce a UCB-based Bandit Algorithm for Smooth\nTrees which takes into account actual smoothness of the rewards for performing\nefficient ``cuts'' of sub-optimal branches with high confidence. Finally, we\npresent an incremental tree search version which applies when the full tree is\ntoo big (possibly infinite) to be entirely represented and show that with high\nprobability, essentially only the optimal branches is indefinitely developed.\nWe illustrate these methods on a global optimization problem of a Lipschitz\nfunction, given noisy data.\n",
        "published": "2007-03-13T08:53:41Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0703062v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0703125v1",
        "title": "Intrinsic dimension of a dataset: what properties does one expect?",
        "summary": "  We propose an axiomatic approach to the concept of an intrinsic dimension of\na dataset, based on a viewpoint of geometry of high-dimensional structures. Our\nfirst axiom postulates that high values of dimension be indicative of the\npresence of the curse of dimensionality (in a certain precise mathematical\nsense). The second axiom requires the dimension to depend smoothly on a\ndistance between datasets (so that the dimension of a dataset and that of an\napproximating principal manifold would be close to each other). The third axiom\nis a normalization condition: the dimension of the Euclidean $n$-sphere $\\s^n$\nis $\\Theta(n)$. We give an example of a dimension function satisfying our\naxioms, even though it is in general computationally unfeasible, and discuss a\ncomputationally cheap function satisfying most but not all of our axioms (the\n``intrinsic dimensionality'' of Ch\\'avez et al.)\n",
        "published": "2007-03-25T01:19:14Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0703125v1"
    },
    {
        "id": "http://arxiv.org/abs/0704.1274v1",
        "title": "Parametric Learning and Monte Carlo Optimization",
        "summary": "  This paper uncovers and explores the close relationship between Monte Carlo\nOptimization of a parametrized integral (MCO), Parametric machine-Learning\n(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\ncontributions. First, we prove that MCO is mathematically identical to a broad\nclass of PL problems. This identity potentially provides a new application\ndomain for all broadly applicable PL techniques: MCO. Second, we introduce\nimmediate sampling, a new version of the Probability Collectives (PC) algorithm\nfor blackbox optimization. Immediate sampling transforms the original BO\nproblem into an MCO problem. Accordingly, by combining these first two\ncontributions, we can apply all PL techniques to BO. In our third contribution\nwe validate this way of improving BO by demonstrating that cross-validation and\nbagging improve immediate sampling. Finally, conventional MC and MCO procedures\nignore the relationship between the sample point locations and the associated\nvalues of the integrand; only the values of the integrand at those locations\nare considered. We demonstrate that one can exploit the sample location\ninformation using PL techniques, for example by forming a fit of the sample\nlocations to the associated values of the integrand. This provides an\nadditional way to apply PL techniques to improve MCO.\n",
        "published": "2007-04-10T17:01:07Z",
        "pdf_link": "http://arxiv.org/pdf/0704.1274v1"
    },
    {
        "id": "http://arxiv.org/abs/0704.2668v1",
        "title": "Supervised Feature Selection via Dependence Estimation",
        "summary": "  We introduce a framework for filtering features that employs the\nHilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence\nbetween the features and the labels. The key idea is that good features should\nmaximise such dependence. Feature selection for various supervised learning\nproblems (including classification and regression) is unified under this\nframework, and the solutions can be approximated using a backward-elimination\nalgorithm. We demonstrate the usefulness of our method on both artificial and\nreal world datasets.\n",
        "published": "2007-04-20T08:26:29Z",
        "pdf_link": "http://arxiv.org/pdf/0704.2668v1"
    },
    {
        "id": "http://arxiv.org/abs/0705.1585v1",
        "title": "HMM Speaker Identification Using Linear and Non-linear Merging\n  Techniques",
        "summary": "  Speaker identification is a powerful, non-invasive and in-expensive biometric\ntechnique. The recognition accuracy, however, deteriorates when noise levels\naffect a specific band of frequency. In this paper, we present a sub-band based\nspeaker identification that intends to improve the live testing performance.\nEach frequency sub-band is processed and classified independently. We also\ncompare the linear and non-linear merging techniques for the sub-bands\nrecognizer. Support vector machines and Gaussian Mixture models are the\nnon-linear merging techniques that are investigated. Results showed that the\nsub-band based method used with linear merging techniques enormously improved\nthe performance of the speaker identification over the performance of wide-band\nrecognizers when tested live. A live testing improvement of 9.78% was achieved\n",
        "published": "2007-05-11T04:54:54Z",
        "pdf_link": "http://arxiv.org/pdf/0705.1585v1"
    },
    {
        "id": "http://arxiv.org/abs/0706.3679v1",
        "title": "Scale-sensitive Psi-dimensions: the Capacity Measures for Classifiers\n  Taking Values in R^Q",
        "summary": "  Bounds on the risk play a crucial role in statistical learning theory. They\nusually involve as capacity measure of the model studied the VC dimension or\none of its extensions. In classification, such \"VC dimensions\" exist for models\ntaking values in {0, 1}, {1,..., Q} and R. We introduce the generalizations\nappropriate for the missing case, the one of models with values in R^Q. This\nprovides us with a new guaranteed risk for M-SVMs which appears superior to the\nexisting one.\n",
        "published": "2007-06-25T17:28:57Z",
        "pdf_link": "http://arxiv.org/pdf/0706.3679v1"
    },
    {
        "id": "http://arxiv.org/abs/0707.3390v2",
        "title": "Consistency of the group Lasso and multiple kernel learning",
        "summary": "  We consider the least-square regression problem with regularization by a\nblock 1-norm, i.e., a sum of Euclidean norms over spaces of dimensions larger\nthan one. This problem, referred to as the group Lasso, extends the usual\nregularization by the 1-norm where all spaces have dimension one, where it is\ncommonly referred to as the Lasso. In this paper, we study the asymptotic model\nconsistency of the group Lasso. We derive necessary and sufficient conditions\nfor the consistency of group Lasso under practical assumptions, such as model\nmisspecification. When the linear predictors and Euclidean norms are replaced\nby functions and reproducing kernel Hilbert norms, the problem is usually\nreferred to as multiple kernel learning and is commonly used for learning from\nheterogeneous data sources and for non linear variable selection. Using tools\nfrom functional analysis, and in particular covariance operators, we extend the\nconsistency results to this infinite dimensional case and also propose an\nadaptive scheme to obtain a consistent model estimate, even when the necessary\ncondition required for the non adaptive scheme is not satisfied.\n",
        "published": "2007-07-23T14:35:20Z",
        "pdf_link": "http://arxiv.org/pdf/0707.3390v2"
    },
    {
        "id": "http://arxiv.org/abs/0709.0509v1",
        "title": "Filtering Additive Measurement Noise with Maximum Entropy in the Mean",
        "summary": "  The purpose of this note is to show how the method of maximum entropy in the\nmean (MEM) may be used to improve parametric estimation when the measurements\nare corrupted by large level of noise. The method is developed in the context\non a concrete example: that of estimation of the parameter in an exponential\ndistribution. We compare the performance of our method with the bayesian and\nmaximum likelihood approaches.\n",
        "published": "2007-09-04T19:36:22Z",
        "pdf_link": "http://arxiv.org/pdf/0709.0509v1"
    },
    {
        "id": "http://arxiv.org/abs/0710.0485v2",
        "title": "Prediction with expert advice for the Brier game",
        "summary": "  We show that the Brier game of prediction is mixable and find the optimal\nlearning rate and substitution function for it. The resulting prediction\nalgorithm is applied to predict results of football and tennis matches. The\ntheoretical performance guarantee turns out to be rather tight on these data\nsets, especially in the case of the more extensive tennis data.\n",
        "published": "2007-10-02T10:08:41Z",
        "pdf_link": "http://arxiv.org/pdf/0710.0485v2"
    },
    {
        "id": "http://arxiv.org/abs/0710.2848v1",
        "title": "Consistency of trace norm minimization",
        "summary": "  Regularization by the sum of singular values, also referred to as the trace\nnorm, is a popular technique for estimating low rank rectangular matrices. In\nthis paper, we extend some of the consistency results of the Lasso to provide\nnecessary and sufficient conditions for rank consistency of trace norm\nminimization with the square loss. We also provide an adaptive version that is\nrank consistent even when the necessary condition for the non adaptive version\nis not fulfilled.\n",
        "published": "2007-10-15T15:38:33Z",
        "pdf_link": "http://arxiv.org/pdf/0710.2848v1"
    },
    {
        "id": "http://arxiv.org/abs/0711.3594v1",
        "title": "Clustering with Transitive Distance and K-Means Duality",
        "summary": "  Recent spectral clustering methods are a propular and powerful technique for\ndata clustering. These methods need to solve the eigenproblem whose\ncomputational complexity is $O(n^3)$, where $n$ is the number of data samples.\nIn this paper, a non-eigenproblem based clustering method is proposed to deal\nwith the clustering problem. Its performance is comparable to the spectral\nclustering algorithms but it is more efficient with computational complexity\n$O(n^2)$. We show that with a transitive distance and an observed property,\ncalled K-means duality, our algorithm can be used to handle data sets with\ncomplex cluster shapes, multi-scale clusters, and noise. Moreover, no\nparameters except the number of clusters need to be set in our algorithm.\n",
        "published": "2007-11-22T15:05:35Z",
        "pdf_link": "http://arxiv.org/pdf/0711.3594v1"
    },
    {
        "id": "http://arxiv.org/abs/0711.4452v1",
        "title": "Covariance and PCA for Categorical Variables",
        "summary": "  Covariances from categorical variables are defined using a regular simplex\nexpression for categories. The method follows the variance definition by Gini,\nand it gives the covariance as a solution of simultaneous equations. The\ncalculated results give reasonable values for test data. A method of principal\ncomponent analysis (RS-PCA) is also proposed using regular simplex expressions,\nwhich allows easy interpretation of the principal components. The proposed\nmethods apply to variable selection problem of categorical data USCensus1990\ndata. The proposed methods give appropriate criterion for the variable\nselection problem of categorical\n",
        "published": "2007-11-28T12:05:47Z",
        "pdf_link": "http://arxiv.org/pdf/0711.4452v1"
    },
    {
        "id": "http://arxiv.org/abs/0712.0130v1",
        "title": "On the Relationship between the Posterior and Optimal Similarity",
        "summary": "  For a classification problem described by the joint density $P(\\omega,x)$,\nmodels of $P(\\omega\\eq\\omega'|x,x')$ (the ``Bayesian similarity measure'') have\nbeen shown to be an optimal similarity measure for nearest neighbor\nclassification. This paper analyzes demonstrates several additional properties\nof that conditional distribution. The paper first shows that we can\nreconstruct, up to class labels, the class posterior distribution $P(\\omega|x)$\ngiven $P(\\omega\\eq\\omega'|x,x')$, gives a procedure for recovering the class\nlabels, and gives an asymptotically Bayes-optimal classification procedure. It\nalso shows, given such an optimal similarity measure, how to construct a\nclassifier that outperforms the nearest neighbor classifier and achieves\nBayes-optimal classification rates. The paper then analyzes Bayesian similarity\nin a framework where a classifier faces a number of related classification\ntasks (multitask learning) and illustrates that reconstruction of the class\nposterior distribution is not possible in general. Finally, the paper\nidentifies a distinct class of classification problems using\n$P(\\omega\\eq\\omega'|x,x')$ and shows that using $P(\\omega\\eq\\omega'|x,x')$ to\nsolve those problems is the Bayes optimal solution.\n",
        "published": "2007-12-02T09:38:26Z",
        "pdf_link": "http://arxiv.org/pdf/0712.0130v1"
    },
    {
        "id": "http://arxiv.org/abs/0712.0653v2",
        "title": "Equations of States in Singular Statistical Estimation",
        "summary": "  Learning machines which have hierarchical structures or hidden variables are\nsingular statistical models because they are nonidentifiable and their Fisher\ninformation matrices are singular. In singular statistical models, neither the\nBayes a posteriori distribution converges to the normal distribution nor the\nmaximum likelihood estimator satisfies asymptotic normality. This is the main\nreason why it has been difficult to predict their generalization performances\nfrom trained states. In this paper, we study four errors, (1) Bayes\ngeneralization error, (2) Bayes training error, (3) Gibbs generalization error,\nand (4) Gibbs training error, and prove that there are mathematical relations\namong these errors. The formulas proved in this paper are equations of states\nin statistical estimation because they hold for any true distribution, any\nparametric model, and any a priori distribution. Also we show that Bayes and\nGibbs generalization errors are estimated by Bayes and Gibbs training errors,\nand propose widely applicable information criteria which can be applied to both\nregular and singular statistical models.\n",
        "published": "2007-12-05T05:39:07Z",
        "pdf_link": "http://arxiv.org/pdf/0712.0653v2"
    },
    {
        "id": "http://arxiv.org/abs/0712.2869v1",
        "title": "Density estimation in linear time",
        "summary": "  We consider the problem of choosing a density estimate from a set of\ndistributions F, minimizing the L1-distance to an unknown distribution\n(Devroye, Lugosi 2001). Devroye and Lugosi analyze two algorithms for the\nproblem: Scheffe tournament winner and minimum distance estimate. The Scheffe\ntournament estimate requires fewer computations than the minimum distance\nestimate, but has strictly weaker guarantees than the latter.\n  We focus on the computational aspect of density estimation. We present two\nalgorithms, both with the same guarantee as the minimum distance estimate. The\nfirst one, a modification of the minimum distance estimate, uses the same\nnumber (quadratic in |F|) of computations as the Scheffe tournament. The second\none, called ``efficient minimum loss-weight estimate,'' uses only a linear\nnumber of computations, assuming that F is preprocessed.\n  We also give examples showing that the guarantees of the algorithms cannot be\nimproved and explore randomized algorithms for density estimation.\n",
        "published": "2007-12-18T03:30:05Z",
        "pdf_link": "http://arxiv.org/pdf/0712.2869v1"
    },
    {
        "id": "http://arxiv.org/abs/0712.3402v1",
        "title": "Graph kernels between point clouds",
        "summary": "  Point clouds are sets of points in two or three dimensions. Most kernel\nmethods for learning on sets of points have not yet dealt with the specific\ngeometrical invariances and practical constraints associated with point clouds\nin computer vision and graphics. In this paper, we present extensions of graph\nkernels for point clouds, which allow to use kernel methods for such ob jects\nas shapes, line drawings, or any three-dimensional point clouds. In order to\ndesign rich and numerically efficient kernels with as few free parameters as\npossible, we use kernels between covariance matrices and their factorizations\non graphical models. We derive polynomial time dynamic programming recursions\nand present applications to recognition of handwritten digits and Chinese\ncharacters from few training examples.\n",
        "published": "2007-12-20T13:06:50Z",
        "pdf_link": "http://arxiv.org/pdf/0712.3402v1"
    },
    {
        "id": "http://arxiv.org/abs/0801.1988v1",
        "title": "Online variants of the cross-entropy method",
        "summary": "  The cross-entropy method is a simple but efficient method for global\noptimization. In this paper we provide two online variants of the basic CEM,\ntogether with a proof of convergence.\n",
        "published": "2008-01-14T06:56:42Z",
        "pdf_link": "http://arxiv.org/pdf/0801.1988v1"
    },
    {
        "id": "http://arxiv.org/abs/0801.4061v1",
        "title": "The optimal assignment kernel is not positive definite",
        "summary": "  We prove that the optimal assignment kernel, proposed recently as an attempt\nto embed labeled graphs and more generally tuples of basic data to a Hilbert\nspace, is in fact not always positive definite.\n",
        "published": "2008-01-26T07:32:48Z",
        "pdf_link": "http://arxiv.org/pdf/0801.4061v1"
    },
    {
        "id": "http://arxiv.org/abs/0802.1002v1",
        "title": "New Estimation Procedures for PLS Path Modelling",
        "summary": "  Given R groups of numerical variables X1, ... XR, we assume that each group\nis the result of one underlying latent variable, and that all latent variables\nare bound together through a linear equation system. Moreover, we assume that\nsome explanatory latent variables may interact pairwise in one or more\nequations. We basically consider PLS Path Modelling's algorithm to estimate\nboth latent variables and the model's coefficients. New \"external\" estimation\nschemes are proposed that draw latent variables towards strong group structures\nin a more flexible way. New \"internal\" estimation schemes are proposed to\nenable PLSPM to make good use of variable group complementarity and to deal\nwith interactions. Application examples are given.\n",
        "published": "2008-02-07T15:18:27Z",
        "pdf_link": "http://arxiv.org/pdf/0802.1002v1"
    },
    {
        "id": "http://arxiv.org/abs/0802.1430v2",
        "title": "A New Approach to Collaborative Filtering: Operator Estimation with\n  Spectral Regularization",
        "summary": "  We present a general approach for collaborative filtering (CF) using spectral\nregularization to learn linear operators from \"users\" to the \"objects\" they\nrate. Recent low-rank type matrix completion approaches to CF are shown to be\nspecial cases. However, unlike existing regularization based CF methods, our\napproach can be used to also incorporate information such as attributes of the\nusers or the objects -- a limitation of existing regularization based CF\nmethods. We then provide novel representer theorems that we use to develop new\nestimation methods. We provide learning algorithms based on low-rank\ndecompositions, and test them on a standard CF dataset. The experiments\nindicate the advantages of generalizing the existing regularization based CF\nmethods to incorporate related information about users and objects. Finally, we\nshow that certain multi-task learning methods can be also seen as special cases\nof our proposed approach.\n",
        "published": "2008-02-11T12:55:34Z",
        "pdf_link": "http://arxiv.org/pdf/0802.1430v2"
    },
    {
        "id": "http://arxiv.org/abs/0804.3817v1",
        "title": "Multiple Random Oracles Are Better Than One",
        "summary": "  We study the problem of learning k-juntas given access to examples drawn from\na number of different product distributions. Thus we wish to learn a function f\n: {-1,1}^n -> {-1,1} that depends on k (unknown) coordinates. While the best\nknown algorithms for the general problem of learning a k-junta require running\ntime of n^k * poly(n,2^k), we show that given access to k different product\ndistributions with biases separated by \\gamma>0, the functions may be learned\nin time poly(n,2^k,\\gamma^{-k}). More generally, given access to t <= k\ndifferent product distributions, the functions may be learned in time n^{k/t} *\npoly(n,2^k,\\gamma^{-k}). Our techniques involve novel results in Fourier\nanalysis relating Fourier expansions with respect to different biases and a\ngeneralization of Russo's formula.\n",
        "published": "2008-04-23T23:18:00Z",
        "pdf_link": "http://arxiv.org/pdf/0804.3817v1"
    },
    {
        "id": "http://arxiv.org/abs/0804.4682v1",
        "title": "Introduction to Relational Networks for Classification",
        "summary": "  The use of computational intelligence techniques for classification has been\nused in numerous applications. This paper compares the use of a Multi Layer\nPerceptron Neural Network and a new Relational Network on classifying the HIV\nstatus of women at ante-natal clinics. The paper discusses the architecture of\nthe relational network and its merits compared to a neural network and most\nother computational intelligence classifiers. Results gathered from the study\nindicate comparable classification accuracies as well as revealed relationships\nbetween data features in the classification data. Much higher classification\naccuracies are recommended for future research in the area of HIV\nclassification as well as missing data estimation.\n",
        "published": "2008-04-29T19:25:07Z",
        "pdf_link": "http://arxiv.org/pdf/0804.4682v1"
    },
    {
        "id": "http://arxiv.org/abs/0804.4741v1",
        "title": "The Effect of Structural Diversity of an Ensemble of Classifiers on\n  Classification Accuracy",
        "summary": "  This paper aims to showcase the measure of structural diversity of an\nensemble of 9 classifiers and then map a relationship between this structural\ndiversity and accuracy. The structural diversity was induced by having\ndifferent architectures or structures of the classifiers The Genetical\nAlgorithms (GA) were used to derive the relationship between diversity and the\nclassification accuracy by evolving the classifiers and then picking 9\nclassifiers out on an ensemble of 60 classifiers. It was found that as the\nensemble became diverse the accuracy improved. However at a certain diversity\nmeasure the accuracy began to drop. The Kohavi-Wolpert variance method is used\nto measure the diversity of the ensemble. A method of voting is used to\naggregate the results from each classifier. The lowest error was observed at a\ndiversity measure of 0.16 with a mean square error of 0.274, when taking 0.2024\nas maximum diversity measured. The parameters that were varied were: the number\nof hidden nodes, learning rate and the activation function.\n",
        "published": "2008-04-30T06:07:45Z",
        "pdf_link": "http://arxiv.org/pdf/0804.4741v1"
    },
    {
        "id": "http://arxiv.org/abs/0804.4898v1",
        "title": "A Quadratic Loss Multi-Class SVM",
        "summary": "  Using a support vector machine requires to set two types of hyperparameters:\nthe soft margin parameter C and the parameters of the kernel. To perform this\nmodel selection task, the method of choice is cross-validation. Its\nleave-one-out variant is known to produce an estimator of the generalization\nerror which is almost unbiased. Its major drawback rests in its time\nrequirement. To overcome this difficulty, several upper bounds on the\nleave-one-out error of the pattern recognition SVM have been derived. Among\nthose bounds, the most popular one is probably the radius-margin bound. It\napplies to the hard margin pattern recognition SVM, and by extension to the\n2-norm SVM. In this report, we introduce a quadratic loss M-SVM, the M-SVM^2,\nas a direct extension of the 2-norm SVM to the multi-class case. For this\nmachine, a generalized radius-margin bound is then established.\n",
        "published": "2008-04-30T19:59:56Z",
        "pdf_link": "http://arxiv.org/pdf/0804.4898v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.1156v1",
        "title": "Utilisation des grammaires probabilistes dans les tâches de\n  segmentation et d'annotation prosodique",
        "summary": "  Nous pr\\'esentons dans cette contribution une approche \\`a la fois symbolique\net probabiliste permettant d'extraire l'information sur la segmentation du\nsignal de parole \\`a partir d'information prosodique. Nous utilisons pour ce\nfaire des grammaires probabilistes poss\\'edant une structure hi\\'erarchique\nminimale. La phase de construction des grammaires ainsi que leur pouvoir de\npr\\'ediction sont \\'evalu\\'es qualitativement ainsi que quantitativement.\n  -----\n  Methodologically oriented, the present work sketches an approach for prosodic\ninformation retrieval and speech segmentation, based on both symbolic and\nprobabilistic information. We have recourse to probabilistic grammars, within\nwhich we implement a minimal hierarchical structure. Both the stages of\nprobabilistic grammar building and its testing in prediction are explored and\nquantitatively and qualitatively evaluated.\n",
        "published": "2008-06-06T13:33:31Z",
        "pdf_link": "http://arxiv.org/pdf/0806.1156v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.3537v2",
        "title": "Statistical Learning of Arbitrary Computable Classifiers",
        "summary": "  Statistical learning theory chiefly studies restricted hypothesis classes,\nparticularly those with finite Vapnik-Chervonenkis (VC) dimension. The\nfundamental quantity of interest is the sample complexity: the number of\nsamples required to learn to a specified level of accuracy. Here we consider\nlearning over the set of all computable labeling functions. Since the\nVC-dimension is infinite and a priori (uniform) bounds on the number of samples\nare impossible, we let the learning algorithm decide when it has seen\nsufficient samples to have learned. We first show that learning in this setting\nis indeed possible, and develop a learning algorithm. We then show, however,\nthat bounding sample complexity independently of the distribution is\nimpossible. Notably, this impossibility is entirely due to the requirement that\nthe learning algorithm be computable, and not due to the statistical nature of\nthe problem.\n",
        "published": "2008-06-22T01:28:14Z",
        "pdf_link": "http://arxiv.org/pdf/0806.3537v2"
    },
    {
        "id": "http://arxiv.org/abs/0806.4210v1",
        "title": "Agnostically Learning Juntas from Random Walks",
        "summary": "  We prove that the class of functions g:{-1,+1}^n -> {-1,+1} that only depend\non an unknown subset of k<<n variables (so-called k-juntas) is agnostically\nlearnable from a random walk in time polynomial in n, 2^{k^2}, epsilon^{-k},\nand log(1/delta). In other words, there is an algorithm with the claimed\nrunning time that, given epsilon, delta > 0 and access to a random walk on\n{-1,+1}^n labeled by an arbitrary function f:{-1,+1}^n -> {-1,+1}, finds with\nprobability at least 1-delta a k-junta that is (opt(f)+epsilon)-close to f,\nwhere opt(f) denotes the distance of a closest k-junta to f.\n",
        "published": "2008-06-25T23:18:44Z",
        "pdf_link": "http://arxiv.org/pdf/0806.4210v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.4422v1",
        "title": "Computationally Efficient Estimators for Dimension Reductions Using\n  Stable Random Projections",
        "summary": "  The method of stable random projections is a tool for efficiently computing\nthe $l_\\alpha$ distances using low memory, where $0<\\alpha \\leq 2$ is a tuning\nparameter. The method boils down to a statistical estimation task and various\nestimators have been proposed, based on the geometric mean, the harmonic mean,\nand the fractional power etc.\n  This study proposes the optimal quantile estimator, whose main operation is\nselecting, which is considerably less expensive than taking fractional power,\nthe main operation in previous estimators. Our experiments report that the\noptimal quantile estimator is nearly one order of magnitude more\ncomputationally efficient than previous estimators. For large-scale learning\ntasks in which storing and computing pairwise distances is a serious\nbottleneck, this estimator should be desirable.\n  In addition to its computational advantages, the optimal quantile estimator\nexhibits nice theoretical properties. It is more accurate than previous\nestimators when $\\alpha>1$. We derive its theoretical error bounds and\nestablish the explicit (i.e., no hidden constants) sample complexity bound.\n",
        "published": "2008-06-27T05:19:19Z",
        "pdf_link": "http://arxiv.org/pdf/0806.4422v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.4423v1",
        "title": "On Approximating the Lp Distances for p>2",
        "summary": "  Applications in machine learning and data mining require computing pairwise\nLp distances in a data matrix A. For massive high-dimensional data, computing\nall pairwise distances of A can be infeasible. In fact, even storing A or all\npairwise distances of A in the memory may be also infeasible. This paper\nproposes a simple method for p = 2, 4, 6, ... We first decompose the l_p (where\np is even) distances into a sum of 2 marginal norms and p-1 ``inner products''\nat different orders. Then we apply normal or sub-Gaussian random projections to\napproximate the resultant ``inner products,'' assuming that the marginal norms\ncan be computed exactly by a linear scan. We propose two strategies for\napplying random projections. The basic projection strategy requires only one\nprojection matrix but it is more difficult to analyze, while the alternative\nprojection strategy requires p-1 projection matrices but its theoretical\nanalysis is much easier. In terms of the accuracy, at least for p=4, the basic\nstrategy is always more accurate than the alternative strategy if the data are\nnon-negative, which is common in reality.\n",
        "published": "2008-06-27T05:36:09Z",
        "pdf_link": "http://arxiv.org/pdf/0806.4423v1"
    },
    {
        "id": "http://arxiv.org/abs/0807.0093v1",
        "title": "Graph Kernels",
        "summary": "  We present a unified framework to study graph kernels, special cases of which\ninclude the random walk graph kernel \\citep{GaeFlaWro03,BorOngSchVisetal05},\nmarginalized graph kernel \\citep{KasTsuIno03,KasTsuIno04,MahUedAkuPeretal04},\nand geometric kernel on graphs \\citep{Gaertner02}. Through extensions of linear\nalgebra to Reproducing Kernel Hilbert Spaces (RKHS) and reduction to a\nSylvester equation, we construct an algorithm that improves the time complexity\nof kernel computation from $O(n^6)$ to $O(n^3)$. When the graphs are sparse,\nconjugate gradient solvers or fixed-point iterations bring our algorithm into\nthe sub-cubic domain. Experiments on graphs from bioinformatics and other\napplication domains show that it is often more than a thousand times faster\nthan previous approaches. We then explore connections between diffusion kernels\n\\citep{KonLaf02}, regularization on graphs \\citep{SmoKon03}, and graph kernels,\nand use these connections to propose new graph kernels. Finally, we show that\nrational kernels \\citep{CorHafMoh02,CorHafMoh03,CorHafMoh04} when specialized\nto graphs reduce to the random walk graph kernel.\n",
        "published": "2008-07-01T09:46:14Z",
        "pdf_link": "http://arxiv.org/pdf/0807.0093v1"
    },
    {
        "id": "http://arxiv.org/abs/0807.2983v1",
        "title": "On Probability Distributions for Trees: Representations, Inference and\n  Learning",
        "summary": "  We study probability distributions over free algebras of trees. Probability\ndistributions can be seen as particular (formal power) tree series [Berstel et\nal 82, Esik et al 03], i.e. mappings from trees to a semiring K . A widely\nstudied class of tree series is the class of rational (or recognizable) tree\nseries which can be defined either in an algebraic way or by means of\nmultiplicity tree automata. We argue that the algebraic representation is very\nconvenient to model probability distributions over a free algebra of trees.\nFirst, as in the string case, the algebraic representation allows to design\nlearning algorithms for the whole class of probability distributions defined by\nrational tree series. Note that learning algorithms for rational tree series\ncorrespond to learning algorithms for weighted tree automata where both the\nstructure and the weights are learned. Second, the algebraic representation can\nbe easily extended to deal with unranked trees (like XML trees where a symbol\nmay have an unbounded number of children). Both properties are particularly\nrelevant for applications: nondeterministic automata are required for the\ninference problem to be relevant (recall that Hidden Markov Models are\nequivalent to nondeterministic string automata); nowadays applications for Web\nInformation Extraction, Web Services and document processing consider unranked\ntrees.\n",
        "published": "2008-07-18T14:41:44Z",
        "pdf_link": "http://arxiv.org/pdf/0807.2983v1"
    },
    {
        "id": "http://arxiv.org/abs/0807.4198v2",
        "title": "Positive factor networks: A graphical framework for modeling\n  non-negative sequential data",
        "summary": "  We present a novel graphical framework for modeling non-negative sequential\ndata with hierarchical structure. Our model corresponds to a network of coupled\nnon-negative matrix factorization (NMF) modules, which we refer to as a\npositive factor network (PFN). The data model is linear, subject to\nnon-negativity constraints, so that observation data consisting of an additive\ncombination of individually representable observations is also representable by\nthe network. This is a desirable property for modeling problems in\ncomputational auditory scene analysis, since distinct sound sources in the\nenvironment are often well-modeled as combining additively in the corresponding\nmagnitude spectrogram. We propose inference and learning algorithms that\nleverage existing NMF algorithms and that are straightforward to implement. We\npresent a target tracking example and provide results for synthetic observation\ndata which serve to illustrate the interesting properties of PFNs and motivate\ntheir potential usefulness in applications such as music transcription, source\nseparation, and speech recognition. We show how a target process characterized\nby a hierarchical state transition model can be represented as a PFN. Our\nresults illustrate that a PFN which is defined in terms of a single target\nobservation can then be used to effectively track the states of multiple\nsimultaneous targets. Our results show that the quality of the inferred target\nstates degrades gradually as the observation noise is increased. We also\npresent results for an example in which meaningful hierarchical features are\nextracted from a spectrogram. Such a hierarchical representation could be\nuseful for music transcription and source separation applications. We also\npropose a network for language modeling.\n",
        "published": "2008-07-25T22:50:46Z",
        "pdf_link": "http://arxiv.org/pdf/0807.4198v2"
    },
    {
        "id": "http://arxiv.org/abs/0809.1590v1",
        "title": "When is there a representer theorem? Vector versus matrix regularizers",
        "summary": "  We consider a general class of regularization methods which learn a vector of\nparameters on the basis of linear measurements. It is well known that if the\nregularizer is a nondecreasing function of the inner product then the learned\nvector is a linear combination of the input data. This result, known as the\n{\\em representer theorem}, is at the basis of kernel-based methods in machine\nlearning. In this paper, we prove the necessity of the above condition, thereby\ncompleting the characterization of kernel methods based on regularization. We\nfurther extend our analysis to regularization methods which learn a matrix, a\nproblem which is motivated by the application to multi-task learning. In this\ncontext, we study a more general representer theorem, which holds for a larger\nclass of regularizers. We provide a necessary and sufficient condition for\nthese class of matrix regularizers and highlight them with some concrete\nexamples of practical importance. Our analysis uses basic principles from\nmatrix theory, especially the useful notion of matrix nondecreasing function.\n",
        "published": "2008-09-09T16:11:12Z",
        "pdf_link": "http://arxiv.org/pdf/0809.1590v1"
    },
    {
        "id": "http://arxiv.org/abs/0809.2085v1",
        "title": "Clustered Multi-Task Learning: A Convex Formulation",
        "summary": "  In multi-task learning several related tasks are considered simultaneously,\nwith the hope that by an appropriate sharing of information across tasks, each\ntask may benefit from the others. In the context of learning linear functions\nfor supervised classification or regression, this can be achieved by including\na priori information about the weight vectors associated with the tasks, and\nhow they are expected to be related to each other. In this paper, we assume\nthat tasks are clustered into groups, which are unknown beforehand, and that\ntasks within a group have similar weight vectors. We design a new spectral norm\nthat encodes this a priori assumption, without the prior knowledge of the\npartition of tasks into groups, resulting in a new convex optimization\nformulation for multi-task learning. We show in simulations on synthetic\nexamples and on the IEDB MHC-I binding dataset, that our approach outperforms\nwell-known convex methods for multi-task learning, as well as related non\nconvex methods dedicated to the same problem.\n",
        "published": "2008-09-11T19:01:39Z",
        "pdf_link": "http://arxiv.org/pdf/0809.2085v1"
    },
    {
        "id": "http://arxiv.org/abs/0809.4632v1",
        "title": "Surrogate Learning - An Approach for Semi-Supervised Classification",
        "summary": "  We consider the task of learning a classifier from the feature space\n$\\mathcal{X}$ to the set of classes $\\mathcal{Y} = \\{0, 1\\}$, when the features\ncan be partitioned into class-conditionally independent feature sets\n$\\mathcal{X}_1$ and $\\mathcal{X}_2$. We show the surprising fact that the\nclass-conditional independence can be used to represent the original learning\ntask in terms of 1) learning a classifier from $\\mathcal{X}_2$ to\n$\\mathcal{X}_1$ and 2) learning the class-conditional distribution of the\nfeature set $\\mathcal{X}_1$. This fact can be exploited for semi-supervised\nlearning because the former task can be accomplished purely from unlabeled\nsamples. We present experimental evaluation of the idea in two real world\napplications.\n",
        "published": "2008-09-26T13:47:36Z",
        "pdf_link": "http://arxiv.org/pdf/0809.4632v1"
    },
    {
        "id": "http://arxiv.org/abs/0810.4611v2",
        "title": "Learning Isometric Separation Maps",
        "summary": "  Maximum Variance Unfolding (MVU) and its variants have been very successful\nin embedding data-manifolds in lower dimensional spaces, often revealing the\ntrue intrinsic dimension. In this paper we show how to also incorporate\nsupervised class information into an MVU-like method without breaking its\nconvexity. We call this method the Isometric Separation Map and we show that\nthe resulting kernel matrix can be used as a binary/multiclass Support Vector\nMachine-like method in a semi-supervised (transductive) framework. We also show\nthat the method always finds a kernel matrix that linearly separates the\ntraining data exactly without projecting them in infinite dimensional spaces.\nIn traditional SVMs we choose a kernel and hope that the data become linearly\nseparable in the kernel space. In this paper we show how the hyperplane can be\nchosen ad-hoc and the kernel is trained so that data are always linearly\nseparable. Comparisons with Large Margin SVMs show comparable performance.\n",
        "published": "2008-10-25T15:09:28Z",
        "pdf_link": "http://arxiv.org/pdf/0810.4611v2"
    },
    {
        "id": "http://arxiv.org/abs/0812.1357v1",
        "title": "A Novel Clustering Algorithm Based on Quantum Random Walk",
        "summary": "  The enormous successes have been made by quantum algorithms during the last\ndecade. In this paper, we combine the quantum random walk (QRW) with the\nproblem of data clustering, and develop two clustering algorithms based on the\none dimensional QRW. Then, the probability distributions on the positions\ninduced by QRW in these algorithms are investigated, which also indicates the\npossibility of obtaining better results. Consequently, the experimental results\nhave demonstrated that data points in datasets are clustered reasonably and\nefficiently, and the clustering algorithms are of fast rates of convergence.\nMoreover, the comparison with other algorithms also provides an indication of\nthe effectiveness of the proposed approach.\n",
        "published": "2008-12-07T15:22:27Z",
        "pdf_link": "http://arxiv.org/pdf/0812.1357v1"
    },
    {
        "id": "http://arxiv.org/abs/0812.1869v1",
        "title": "Convex Sparse Matrix Factorizations",
        "summary": "  We present a convex formulation of dictionary learning for sparse signal\ndecomposition. Convexity is obtained by replacing the usual explicit upper\nbound on the dictionary size by a convex rank-reducing term similar to the\ntrace norm. In particular, our formulation introduces an explicit trade-off\nbetween size and sparsity of the decomposition of rectangular matrices. Using a\nlarge set of synthetic examples, we compare the estimation abilities of the\nconvex and non-convex approaches, showing that while the convex formulation has\na single local minimum, this may lead in some cases to performance which is\ninferior to the local minima of the non-convex formulation.\n",
        "published": "2008-12-10T09:00:40Z",
        "pdf_link": "http://arxiv.org/pdf/0812.1869v1"
    },
    {
        "id": "http://arxiv.org/abs/0812.3145v2",
        "title": "Binary Classification Based on Potentials",
        "summary": "  We introduce a simple and computationally trivial method for binary\nclassification based on the evaluation of potential functions. We demonstrate\nthat despite the conceptual and computational simplicity of the method its\nperformance can match or exceed that of standard Support Vector Machine\nmethods.\n",
        "published": "2008-12-16T20:41:06Z",
        "pdf_link": "http://arxiv.org/pdf/0812.3145v2"
    },
    {
        "id": "http://arxiv.org/abs/0812.3465v2",
        "title": "Linearly Parameterized Bandits",
        "summary": "  We consider bandit problems involving a large (possibly infinite) collection\nof arms, in which the expected reward of each arm is a linear function of an\n$r$-dimensional random vector $\\mathbf{Z} \\in \\mathbb{R}^r$, where $r \\geq 2$.\nThe objective is to minimize the cumulative regret and Bayes risk. When the set\nof arms corresponds to the unit sphere, we prove that the regret and Bayes risk\nis of order $\\Theta(r \\sqrt{T})$, by establishing a lower bound for an\narbitrary policy, and showing that a matching upper bound is obtained through a\npolicy that alternates between exploration and exploitation phases. The\nphase-based policy is also shown to be effective if the set of arms satisfies a\nstrong convexity condition. For the case of a general set of arms, we describe\na near-optimal policy whose regret and Bayes risk admit upper bounds of the\nform $O(r \\sqrt{T} \\log^{3/2} T)$.\n",
        "published": "2008-12-18T07:59:33Z",
        "pdf_link": "http://arxiv.org/pdf/0812.3465v2"
    },
    {
        "id": "http://arxiv.org/abs/0812.4952v4",
        "title": "Importance Weighted Active Learning",
        "summary": "  We present a practical and statistically consistent scheme for actively\nlearning binary classifiers under general loss functions. Our algorithm uses\nimportance weighting to correct sampling bias, and by controlling the variance,\nwe are able to give rigorous label complexity bounds for the learning process.\nExperiments on passively labeled data show that this approach reduces the label\ncomplexity required to achieve good predictive performance on many learning\nproblems.\n",
        "published": "2008-12-29T18:29:08Z",
        "pdf_link": "http://arxiv.org/pdf/0812.4952v4"
    },
    {
        "id": "http://arxiv.org/abs/0901.0753v1",
        "title": "Distributed Preemption Decisions: Probabilistic Graphical Model,\n  Algorithm and Near-Optimality",
        "summary": "  Cooperative decision making is a vision of future network management and\ncontrol. Distributed connection preemption is an important example where nodes\ncan make intelligent decisions on allocating resources and controlling traffic\nflows for multi-class service networks. A challenge is that nodal decisions are\nspatially dependent as traffic flows trespass multiple nodes in a network.\nHence the performance-complexity trade-off becomes important, i.e., how\naccurate decisions are versus how much information is exchanged among nodes.\nConnection preemption is known to be NP-complete. Centralized preemption is\noptimal but computationally intractable. Decentralized preemption is\ncomputationally efficient but may result in a poor performance. This work\ninvestigates distributed preemption where nodes decide whether and which flows\nto preempt using only local information exchange with neighbors. We develop,\nbased on the probabilistic graphical models, a near-optimal distributed\nalgorithm. The algorithm is used by each node to make collectively near-optimal\npreemption decisions. We study trade-offs between near-optimal performance and\ncomplexity that corresponds to the amount of information-exchange of the\ndistributed algorithm. The algorithm is validated by both analysis and\nsimulation.\n",
        "published": "2009-01-07T04:36:58Z",
        "pdf_link": "http://arxiv.org/pdf/0901.0753v1"
    },
    {
        "id": "http://arxiv.org/abs/0901.2376v1",
        "title": "A Limit Theorem in Singular Regression Problem",
        "summary": "  In statistical problems, a set of parameterized probability distributions is\nused to estimate the true probability distribution. If Fisher information\nmatrix at the true distribution is singular, then it has been left unknown what\nwe can estimate about the true distribution from random samples. In this paper,\nwe study a singular regression problem and prove a limit theorem which shows\nthe relation between the singular regression problem and two birational\ninvariants, a real log canonical threshold and a singular fluctuation. The\nobtained theorem has an important application to statistics, because it enables\nus to estimate the generalization error from the training error without any\nknowledge of the true probability distribution.\n",
        "published": "2009-01-16T01:00:39Z",
        "pdf_link": "http://arxiv.org/pdf/0901.2376v1"
    },
    {
        "id": "http://arxiv.org/abs/0901.4012v3",
        "title": "Cross-situational and supervised learning in the emergence of\n  communication",
        "summary": "  Scenarios for the emergence or bootstrap of a lexicon involve the repeated\ninteraction between at least two agents who must reach a consensus on how to\nname N objects using H words. Here we consider minimal models of two types of\nlearning algorithms: cross-situational learning, in which the individuals\ndetermine the meaning of a word by looking for something in common across all\nobserved uses of that word, and supervised operant conditioning learning, in\nwhich there is strong feedback between individuals about the intended meaning\nof the words. Despite the stark differences between these learning schemes, we\nshow that they yield the same communication accuracy in the realistic limits of\nlarge N and H, which coincides with the result of the classical occupancy\nproblem of randomly assigning N objects to H words.\n",
        "published": "2009-01-26T15:12:13Z",
        "pdf_link": "http://arxiv.org/pdf/0901.4012v3"
    },
    {
        "id": "http://arxiv.org/abs/0902.1258v1",
        "title": "Extraction de concepts sous contraintes dans des données d'expression\n  de gènes",
        "summary": "  In this paper, we propose a technique to extract constrained formal concepts.\n",
        "published": "2009-02-07T18:01:09Z",
        "pdf_link": "http://arxiv.org/pdf/0902.1258v1"
    },
    {
        "id": "http://arxiv.org/abs/0902.1259v1",
        "title": "Database Transposition for Constrained (Closed) Pattern Mining",
        "summary": "  Recently, different works proposed a new way to mine patterns in databases\nwith pathological size. For example, experiments in genome biology usually\nprovide databases with thousands of attributes (genes) but only tens of objects\n(experiments). In this case, mining the \"transposed\" database runs through a\nsmaller search space, and the Galois connection allows to infer the closed\npatterns of the original database. We focus here on constrained pattern mining\nfor those unusual databases and give a theoretical framework for database and\nconstraint transposition. We discuss the properties of constraint transposition\nand look into classical constraints. We then address the problem of generating\nthe closed patterns of the original database satisfying the constraint,\nstarting from those mined in the \"transposed\" database. Finally, we show how to\ngenerate all the patterns satisfying the constraint from the closed ones.\n",
        "published": "2009-02-07T18:01:56Z",
        "pdf_link": "http://arxiv.org/pdf/0902.1259v1"
    },
    {
        "id": "http://arxiv.org/abs/0902.1284v2",
        "title": "Multi-Label Prediction via Compressed Sensing",
        "summary": "  We consider multi-label prediction problems with large output spaces under\nthe assumption of output sparsity -- that the target (label) vectors have small\nsupport. We develop a general theory for a variant of the popular error\ncorrecting output code scheme, using ideas from compressed sensing for\nexploiting this sparsity. The method can be regarded as a simple reduction from\nmulti-label regression problems to binary regression problems. We show that the\nnumber of subproblems need only be logarithmic in the total number of possible\nlabels, making this approach radically more efficient than others. We also\nstate and prove robustness guarantees for this method in the form of regret\ntransform bounds (in general), and also provide a more detailed analysis for\nthe linear prediction setting.\n",
        "published": "2009-02-08T02:30:06Z",
        "pdf_link": "http://arxiv.org/pdf/0902.1284v2"
    },
    {
        "id": "http://arxiv.org/abs/0902.3373v1",
        "title": "Learning rules from multisource data for cardiac monitoring",
        "summary": "  This paper formalises the concept of learning symbolic rules from multisource\ndata in a cardiac monitoring context. Our sources, electrocardiograms and\narterial blood pressure measures, describe cardiac behaviours from different\nviewpoints. To learn interpretable rules, we use an Inductive Logic Programming\n(ILP) method. We develop an original strategy to cope with the dimensionality\nissues caused by using this ILP technique on a rich multisource language. The\nresults show that our method greatly improves the feasibility and the\nefficiency of the process while staying accurate. They also confirm the\nbenefits of using multiple sources to improve the diagnosis of cardiac\narrhythmias.\n",
        "published": "2009-02-19T13:47:53Z",
        "pdf_link": "http://arxiv.org/pdf/0902.3373v1"
    },
    {
        "id": "http://arxiv.org/abs/0902.3846v1",
        "title": "Uniqueness of Low-Rank Matrix Completion by Rigidity Theory",
        "summary": "  The problem of completing a low-rank matrix from a subset of its entries is\noften encountered in the analysis of incomplete data sets exhibiting an\nunderlying factor model with applications in collaborative filtering, computer\nvision and control. Most recent work had been focused on constructing efficient\nalgorithms for exact or approximate recovery of the missing matrix entries and\nproving lower bounds for the number of known entries that guarantee a\nsuccessful recovery with high probability. A related problem from both the\nmathematical and algorithmic point of view is the distance geometry problem of\nrealizing points in a Euclidean space from a given subset of their pairwise\ndistances. Rigidity theory answers basic questions regarding the uniqueness of\nthe realization satisfying a given partial set of distances. We observe that\nbasic ideas and tools of rigidity theory can be adapted to determine uniqueness\nof low-rank matrix completion, where inner products play the role that\ndistances play in rigidity theory. This observation leads to an efficient\nrandomized algorithm for testing both local and global unique completion.\nCrucial to our analysis is a new matrix, which we call the completion matrix,\nthat serves as the analogue of the rigidity matrix.\n",
        "published": "2009-02-23T04:05:48Z",
        "pdf_link": "http://arxiv.org/pdf/0902.3846v1"
    },
    {
        "id": "http://arxiv.org/abs/0902.4127v2",
        "title": "Prediction with expert evaluators' advice",
        "summary": "  We introduce a new protocol for prediction with expert advice in which each\nexpert evaluates the learner's and his own performance using a loss function\nthat may change over time and may be different from the loss functions used by\nthe other experts. The learner's goal is to perform better or not much worse\nthan each expert, as evaluated by that expert, for all experts simultaneously.\nIf the loss functions used by the experts are all proper scoring rules and all\nmixable, we show that the defensive forecasting algorithm enjoys the same\nperformance guarantee as that attainable by the Aggregating Algorithm in the\nstandard setting and known to be optimal. This result is also applied to the\ncase of \"specialist\" (or \"sleeping\") experts. In this case, the defensive\nforecasting algorithm reduces to a simple modification of the Aggregating\nAlgorithm.\n",
        "published": "2009-02-24T11:47:03Z",
        "pdf_link": "http://arxiv.org/pdf/0902.4127v2"
    },
    {
        "id": "http://arxiv.org/abs/0902.4228v1",
        "title": "Multiplicative updates For Non-Negative Kernel SVM",
        "summary": "  We present multiplicative updates for solving hard and soft margin support\nvector machines (SVM) with non-negative kernels. They follow as a natural\nextension of the updates for non-negative matrix factorization. No additional\nparam- eter setting, such as choosing learning, rate is required. Ex- periments\ndemonstrate rapid convergence to good classifiers. We analyze the rates of\nasymptotic convergence of the up- dates and establish tight bounds. We test the\nperformance on several datasets using various non-negative kernels and report\nequivalent generalization errors to that of a standard SVM.\n",
        "published": "2009-02-24T20:38:32Z",
        "pdf_link": "http://arxiv.org/pdf/0902.4228v1"
    },
    {
        "id": "http://arxiv.org/abs/0903.1125v1",
        "title": "Efficient Human Computation",
        "summary": "  Collecting large labeled data sets is a laborious and expensive task, whose\nscaling up requires division of the labeling workload between many teachers.\nWhen the number of classes is large, miscorrespondences between the labels\ngiven by the different teachers are likely to occur, which, in the extreme\ncase, may reach total inconsistency. In this paper we describe how globally\nconsistent labels can be obtained, despite the absence of teacher coordination,\nand discuss the possible efficiency of this process in terms of human labor. We\ndefine a notion of label efficiency, measuring the ratio between the number of\nglobally consistent labels obtained and the number of labels provided by\ndistributed teachers. We show that the efficiency depends critically on the\nratio alpha between the number of data instances seen by a single teacher, and\nthe number of classes. We suggest several algorithms for the distributed\nlabeling problem, and analyze their efficiency as a function of alpha. In\naddition, we provide an upper bound on label efficiency for the case of\ncompletely uncoordinated teachers, and show that efficiency approaches 0 as the\nratio between the number of labels each teacher provides and the number of\nclasses drops (i.e. alpha goes to 0).\n",
        "published": "2009-03-05T22:39:46Z",
        "pdf_link": "http://arxiv.org/pdf/0903.1125v1"
    },
    {
        "id": "http://arxiv.org/abs/0903.2299v3",
        "title": "Differential Contrastive Divergence",
        "summary": "  This paper has been retracted.\n",
        "published": "2009-03-13T13:47:03Z",
        "pdf_link": "http://arxiv.org/pdf/0903.2299v3"
    },
    {
        "id": "http://arxiv.org/abs/0903.2870v2",
        "title": "On $p$-adic Classification",
        "summary": "  A $p$-adic modification of the split-LBG classification method is presented\nin which first clusterings and then cluster centers are computed which locally\nminimise an energy function. The outcome for a fixed dataset is independent of\nthe prime number $p$ with finitely many exceptions. The methods are applied to\nthe construction of $p$-adic classifiers in the context of learning.\n",
        "published": "2009-03-16T22:52:06Z",
        "pdf_link": "http://arxiv.org/pdf/0903.2870v2"
    },
    {
        "id": "http://arxiv.org/abs/0904.0814v1",
        "title": "Stability Analysis and Learning Bounds for Transductive Regression\n  Algorithms",
        "summary": "  This paper uses the notion of algorithmic stability to derive novel\ngeneralization bounds for several families of transductive regression\nalgorithms, both by using convexity and closed-form solutions. Our analysis\nhelps compare the stability of these algorithms. It also shows that a number of\nwidely used transductive regression algorithms are in fact unstable. Finally,\nit reports the results of experiments with local transductive regression\ndemonstrating the benefit of our stability bounds for model selection, for one\nof the algorithms, in particular for determining the radius of the local\nneighborhood used by the algorithm.\n",
        "published": "2009-04-05T20:08:44Z",
        "pdf_link": "http://arxiv.org/pdf/0904.0814v1"
    },
    {
        "id": "http://arxiv.org/abs/0904.2160v1",
        "title": "Inferring Dynamic Bayesian Networks using Frequent Episode Mining",
        "summary": "  Motivation: Several different threads of research have been proposed for\nmodeling and mining temporal data. On the one hand, approaches such as dynamic\nBayesian networks (DBNs) provide a formal probabilistic basis to model\nrelationships between time-indexed random variables but these models are\nintractable to learn in the general case. On the other, algorithms such as\nfrequent episode mining are scalable to large datasets but do not exhibit the\nrigorous probabilistic interpretations that are the mainstay of the graphical\nmodels literature.\n  Results: We present a unification of these two seemingly diverse threads of\nresearch, by demonstrating how dynamic (discrete) Bayesian networks can be\ninferred from the results of frequent episode mining. This helps bridge the\nmodeling emphasis of the former with the counting emphasis of the latter.\nFirst, we show how, under reasonable assumptions on data characteristics and on\ninfluences of random variables, the optimal DBN structure can be computed using\na greedy, local, algorithm. Next, we connect the optimality of the DBN\nstructure with the notion of fixed-delay episodes and their counts of distinct\noccurrences. Finally, to demonstrate the practical feasibility of our approach,\nwe focus on a specific (but broadly applicable) class of networks, called\nexcitatory networks, and show how the search for the optimal DBN structure can\nbe conducted using just information from frequent episodes. Application on\ndatasets gathered from mathematical models of spiking neurons as well as real\nneuroscience datasets are presented.\n  Availability: Algorithmic implementations, simulator codebases, and datasets\nare available from our website at http://neural-code.cs.vt.edu/dbn\n",
        "published": "2009-04-14T17:32:00Z",
        "pdf_link": "http://arxiv.org/pdf/0904.2160v1"
    },
    {
        "id": "http://arxiv.org/abs/0904.3664v1",
        "title": "Introduction to Machine Learning: Class Notes 67577",
        "summary": "  Introduction to Machine learning covering Statistical Inference (Bayes, EM,\nML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),\nand PAC learning (the Formal model, VC dimension, Double Sampling theorem).\n",
        "published": "2009-04-23T11:40:57Z",
        "pdf_link": "http://arxiv.org/pdf/0904.3664v1"
    },
    {
        "id": "http://arxiv.org/abs/0904.4527v1",
        "title": "Limits of Learning about a Categorical Latent Variable under Prior\n  Near-Ignorance",
        "summary": "  In this paper, we consider the coherent theory of (epistemic) uncertainty of\nWalley, in which beliefs are represented through sets of probability\ndistributions, and we focus on the problem of modeling prior ignorance about a\ncategorical random variable. In this setting, it is a known result that a state\nof prior ignorance is not compatible with learning. To overcome this problem,\nanother state of beliefs, called \\emph{near-ignorance}, has been proposed.\nNear-ignorance resembles ignorance very closely, by satisfying some principles\nthat can arguably be regarded as necessary in a state of ignorance, and allows\nlearning to take place. What this paper does, is to provide new and substantial\nevidence that also near-ignorance cannot be really regarded as a way out of the\nproblem of starting statistical inference in conditions of very weak beliefs.\nThe key to this result is focusing on a setting characterized by a variable of\ninterest that is \\emph{latent}. We argue that such a setting is by far the most\ncommon case in practice, and we provide, for the case of categorical latent\nvariables (and general \\emph{manifest} variables) a condition that, if\nsatisfied, prevents learning to take place under prior near-ignorance. This\ncondition is shown to be easily satisfied even in the most common statistical\nproblems. We regard these results as a strong form of evidence against the\npossibility to adopt a condition of prior near-ignorance in real statistical\nproblems.\n",
        "published": "2009-04-29T03:16:20Z",
        "pdf_link": "http://arxiv.org/pdf/0904.4527v1"
    },
    {
        "id": "http://arxiv.org/abs/0904.4608v2",
        "title": "Temporal data mining for root-cause analysis of machine faults in\n  automotive assembly lines",
        "summary": "  Engine assembly is a complex and heavily automated distributed-control\nprocess, with large amounts of faults data logged everyday. We describe an\napplication of temporal data mining for analyzing fault logs in an engine\nassembly plant. Frequent episode discovery framework is a model-free method\nthat can be used to deduce (temporal) correlations among events from the logs\nin an efficient manner. In addition to being theoretically elegant and\ncomputationally efficient, frequent episodes are also easy to interpret in the\nform actionable recommendations. Incorporation of domain-specific information\nis critical to successful application of the method for analyzing fault logs in\nthe manufacturing domain. We show how domain-specific knowledge can be\nincorporated using heuristic rules that act as pre-filters and post-filters to\nfrequent episode discovery. The system described here is currently being used\nin one of the engine assembly plants of General Motors and is planned for\nadaptation in other plants. To the best of our knowledge, this paper presents\nthe first real, large-scale application of temporal data mining in the\nmanufacturing domain. We believe that the ideas presented in this paper can\nhelp practitioners engineer tools for analysis in other similar or related\napplication domains as well.\n",
        "published": "2009-04-29T13:17:31Z",
        "pdf_link": "http://arxiv.org/pdf/0904.4608v2"
    },
    {
        "id": "http://arxiv.org/abs/0905.2347v1",
        "title": "Combining Supervised and Unsupervised Learning for GIS Classification",
        "summary": "  This paper presents a new hybrid learning algorithm for unsupervised\nclassification tasks. We combined Fuzzy c-means learning algorithm and a\nsupervised version of Minimerror to develop a hybrid incremental strategy\nallowing unsupervised classifications. We applied this new approach to a\nreal-world database in order to know if the information contained in unlabeled\nfeatures of a Geographic Information System (GIS), allows to well classify it.\nFinally, we compared our results to a classical supervised classification\nobtained by a multilayer perceptron.\n",
        "published": "2009-05-14T14:59:15Z",
        "pdf_link": "http://arxiv.org/pdf/0905.2347v1"
    },
    {
        "id": "http://arxiv.org/abs/0905.2997v1",
        "title": "Average-Case Active Learning with Costs",
        "summary": "  We analyze the expected cost of a greedy active learning algorithm. Our\nanalysis extends previous work to a more general setting in which different\nqueries have different costs. Moreover, queries may have more than two possible\nresponses and the distribution over hypotheses may be non uniform. Specific\napplications include active learning with label costs, active learning for\nmulticlass and partial label queries, and batch mode active learning. We also\ndiscuss an approximate version of interest when there are very many queries.\n",
        "published": "2009-05-18T23:21:35Z",
        "pdf_link": "http://arxiv.org/pdf/0905.2997v1"
    },
    {
        "id": "http://arxiv.org/abs/0905.4022v1",
        "title": "Transfer Learning Using Feature Selection",
        "summary": "  We present three related ways of using Transfer Learning to improve feature\nselection. The three methods address different problems, and hence share\ndifferent kinds of information between tasks or feature classes, but all three\nare based on the information theoretic Minimum Description Length (MDL)\nprinciple and share the same underlying Bayesian interpretation. The first\nmethod, MIC, applies when predictive models are to be built simultaneously for\nmultiple tasks (``simultaneous transfer'') that share the same set of features.\nMIC allows each feature to be added to none, some, or all of the task models\nand is most beneficial for selecting a small set of predictive features from a\nlarge pool of features, as is common in genomic and biological datasets. Our\nsecond method, TPC (Three Part Coding), uses a similar methodology for the case\nwhen the features can be divided into feature classes. Our third method,\nTransfer-TPC, addresses the ``sequential transfer'' problem in which the task\nto which we want to transfer knowledge may not be known in advance and may have\ndifferent amounts of data than the other tasks. Transfer-TPC is most beneficial\nwhen we want to transfer knowledge between tasks which have unequal amounts of\nlabeled data, for example the data for disambiguating the senses of different\nverbs. We demonstrate the effectiveness of these approaches with experimental\nresults on real world data pertaining to genomics and to Word Sense\nDisambiguation (WSD).\n",
        "published": "2009-05-25T14:29:59Z",
        "pdf_link": "http://arxiv.org/pdf/0905.4022v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.0211v2",
        "title": "Equations of States in Statistical Learning for a Nonparametrizable and\n  Regular Case",
        "summary": "  Many learning machines that have hierarchical structure or hidden variables\nare now being used in information science, artificial intelligence, and\nbioinformatics. However, several learning machines used in such fields are not\nregular but singular statistical models, hence their generalization performance\nis still left unknown. To overcome these problems, in the previous papers, we\nproved new equations in statistical learning, by which we can estimate the\nBayes generalization loss from the Bayes training loss and the functional\nvariance, on the condition that the true distribution is a singularity\ncontained in a learning machine. In this paper, we prove that the same\nequations hold even if a true distribution is not contained in a parametric\nmodel. Also we prove that, the proposed equations in a regular case are\nasymptotically equivalent to the Takeuchi information criterion. Therefore, the\nproposed equations are always applicable without any condition on the unknown\ntrue distribution.\n",
        "published": "2009-06-01T04:47:15Z",
        "pdf_link": "http://arxiv.org/pdf/0906.0211v2"
    },
    {
        "id": "http://arxiv.org/abs/0906.0470v1",
        "title": "An optimal linear separator for the Sonar Signals Classification task",
        "summary": "  The problem of classifying sonar signals from rocks and mines first studied\nby Gorman and Sejnowski has become a benchmark against which many learning\nalgorithms have been tested. We show that both the training set and the test\nset of this benchmark are linearly separable, although with different\nhyperplanes. Moreover, the complete set of learning and test patterns together,\nis also linearly separable. We give the weights that separate these sets, which\nmay be used to compare results found by other algorithms.\n",
        "published": "2009-06-02T11:52:36Z",
        "pdf_link": "http://arxiv.org/pdf/0906.0470v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.2635v1",
        "title": "Bayesian History Reconstruction of Complex Human Gene Clusters on a\n  Phylogeny",
        "summary": "  Clusters of genes that have evolved by repeated segmental duplication present\ndifficult challenges throughout genomic analysis, from sequence assembly to\nfunctional analysis. Improved understanding of these clusters is of utmost\nimportance, since they have been shown to be the source of evolutionary\ninnovation, and have been linked to multiple diseases, including HIV and a\nvariety of cancers. Previously, Zhang et al. (2008) developed an algorithm for\nreconstructing parsimonious evolutionary histories of such gene clusters, using\nonly human genomic sequence data. In this paper, we propose a probabilistic\nmodel for the evolution of gene clusters on a phylogeny, and an MCMC algorithm\nfor reconstruction of duplication histories from genomic sequences in multiple\nspecies. Several projects are underway to obtain high quality BAC-based\nassemblies of duplicated clusters in multiple species, and we anticipate that\nour method will be useful in analyzing these valuable new data sets.\n",
        "published": "2009-06-15T08:43:51Z",
        "pdf_link": "http://arxiv.org/pdf/0906.2635v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.4032v1",
        "title": "Bayesian two-sample tests",
        "summary": "  In this paper, we present two classes of Bayesian approaches to the\ntwo-sample problem. Our first class of methods extends the Bayesian t-test to\ninclude all parametric models in the exponential family and their conjugate\npriors. Our second class of methods uses Dirichlet process mixtures (DPM) of\nsuch conjugate-exponential distributions as flexible nonparametric priors over\nthe unknown distributions.\n",
        "published": "2009-06-22T15:25:23Z",
        "pdf_link": "http://arxiv.org/pdf/0906.4032v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.4663v1",
        "title": "Acquiring Knowledge for Evaluation of Teachers Performance in Higher\n  Education using a Questionnaire",
        "summary": "  In this paper, we present the step by step knowledge acquisition process by\nchoosing a structured method through using a questionnaire as a knowledge\nacquisition tool. Here we want to depict the problem domain as, how to evaluate\nteachers performance in higher education through the use of expert system\ntechnology. The problem is how to acquire the specific knowledge for a selected\nproblem efficiently and effectively from human experts and encode it in the\nsuitable computer format. Acquiring knowledge from human experts in the process\nof expert systems development is one of the most common problems cited till\nyet. This questionnaire was sent to 87 domain experts within all public and\nprivate universities in Pakistani. Among them 25 domain experts sent their\nvaluable opinions. Most of the domain experts were highly qualified, well\nexperienced and highly responsible persons. The whole questionnaire was divided\ninto 15 main groups of factors, which were further divided into 99 individual\nquestions. These facts were analyzed further to give a final shape to the\nquestionnaire. This knowledge acquisition technique may be used as a learning\ntool for further research work.\n",
        "published": "2009-06-25T11:09:39Z",
        "pdf_link": "http://arxiv.org/pdf/0906.4663v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.5151v1",
        "title": "Unsupervised Search-based Structured Prediction",
        "summary": "  We describe an adaptation and application of a search-based structured\nprediction algorithm \"Searn\" to unsupervised learning problems. We show that it\nis possible to reduce unsupervised learning to supervised learning and\ndemonstrate a high-quality unsupervised shift-reduce parsing model. We\nadditionally show a close connection between unsupervised Searn and expectation\nmaximization. Finally, we demonstrate the efficacy of a semi-supervised\nextension. The key idea that enables this is an application of the predict-self\nidea for unsupervised learning.\n",
        "published": "2009-06-28T17:47:22Z",
        "pdf_link": "http://arxiv.org/pdf/0906.5151v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.0453v2",
        "title": "Random DFAs are Efficiently PAC Learnable",
        "summary": "  This paper has been withdrawn due to an error found by Dana Angluin and Lev\nReyzin.\n",
        "published": "2009-07-02T17:54:45Z",
        "pdf_link": "http://arxiv.org/pdf/0907.0453v2"
    },
    {
        "id": "http://arxiv.org/abs/0907.0783v1",
        "title": "Bayesian Multitask Learning with Latent Hierarchies",
        "summary": "  We learn multiple hypotheses for related tasks under a latent hierarchical\nrelationship between tasks. We exploit the intuition that for domain\nadaptation, we wish to share classifier structure, but for multitask learning,\nwe wish to share covariance structure. Our hierarchical model is seen to\nsubsume several previously proposed multitask learning models and performs well\non three distinct real-world data sets.\n",
        "published": "2009-07-04T18:35:52Z",
        "pdf_link": "http://arxiv.org/pdf/0907.0783v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.0808v1",
        "title": "A Bayesian Model for Supervised Clustering with the Dirichlet Process\n  Prior",
        "summary": "  We develop a Bayesian framework for tackling the supervised clustering\nproblem, the generic problem encountered in tasks such as reference matching,\ncoreference resolution, identity uncertainty and record linkage. Our clustering\nmodel is based on the Dirichlet process prior, which enables us to define\ndistributions over the countably infinite sets that naturally arise in this\nproblem. We add supervision to our model by positing the existence of a set of\nunobserved random variables (we call these \"reference types\") that are generic\nacross all clusters. Inference in our framework, which requires integrating\nover infinitely many parameters, is solved using Markov chain Monte Carlo\ntechniques. We present algorithms for both conjugate and non-conjugate priors.\nWe present a simple--but general--parameterization of our model based on a\nGaussian assumption. We evaluate this model on one artificial task and three\nreal-world tasks, comparing it against both unsupervised and state-of-the-art\nsupervised algorithms. Our results show that our model is able to outperform\nother models across a variety of tasks and performance metrics.\n",
        "published": "2009-07-04T22:32:58Z",
        "pdf_link": "http://arxiv.org/pdf/0907.0808v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.1812v1",
        "title": "Fast search for Dirichlet process mixture models",
        "summary": "  Dirichlet process (DP) mixture models provide a flexible Bayesian framework\nfor density estimation. Unfortunately, their flexibility comes at a cost:\ninference in DP mixture models is computationally expensive, even when\nconjugate distributions are used. In the common case when one seeks only a\nmaximum a posteriori assignment of data points to clusters, we show that search\nalgorithms provide a practical alternative to expensive MCMC and variational\ntechniques. When a true posterior sample is desired, the solution found by\nsearch can serve as a good initializer for MCMC. Experimental results show that\nusing these techniques is it possible to apply DP mixture models to very large\ndata sets.\n",
        "published": "2009-07-10T13:23:37Z",
        "pdf_link": "http://arxiv.org/pdf/0907.1812v1"
    },
    {
        "id": "http://arxiv.org/abs/0908.0939v1",
        "title": "Clustering for Improved Learning in Maze Traversal Problem",
        "summary": "  The maze traversal problem (finding the shortest distance to the goal from\nany position in a maze) has been an interesting challenge in computational\nintelligence. Recent work has shown that the cellular simultaneous recurrent\nneural network (CSRN) can solve this problem for simple mazes. This thesis\nfocuses on exploiting relevant information about the maze to improve learning\nand decrease the training time for the CSRN to solve mazes. Appropriate\nvariables are identified to create useful clusters using relevant information.\nThe CSRN was next modified to allow for an additional external input. With this\nadditional input, several methods were tested and results show that clustering\nthe mazes improves the overall learning of the traversal problem for the CSRN.\n",
        "published": "2009-08-06T19:48:20Z",
        "pdf_link": "http://arxiv.org/pdf/0908.0939v1"
    },
    {
        "id": "http://arxiv.org/abs/0909.3609v1",
        "title": "Randomized Algorithms for Large scale SVMs",
        "summary": "  We propose a randomized algorithm for training Support vector machines(SVMs)\non large datasets. By using ideas from Random projections we show that the\ncombinatorial dimension of SVMs is $O({log} n)$ with high probability. This\nestimate of combinatorial dimension is used to derive an iterative algorithm,\ncalled RandSVM, which at each step calls an existing solver to train SVMs on a\nrandomly chosen subset of size $O({log} n)$. The algorithm has probabilistic\nguarantees and is capable of training SVMs with Kernels for both classification\nand regression problems. Experiments done on synthetic and real life data sets\ndemonstrate that the algorithm scales up existing SVM learners, without loss of\naccuracy.\n",
        "published": "2009-09-19T23:40:10Z",
        "pdf_link": "http://arxiv.org/pdf/0909.3609v1"
    },
    {
        "id": "http://arxiv.org/abs/0909.4603v1",
        "title": "Scalable Inference for Latent Dirichlet Allocation",
        "summary": "  We investigate the problem of learning a topic model - the well-known Latent\nDirichlet Allocation - in a distributed manner, using a cluster of C processors\nand dividing the corpus to be learned equally among them. We propose a simple\napproximated method that can be tuned, trading speed for accuracy according to\nthe task at hand. Our approach is asynchronous, and therefore suitable for\nclusters of heterogenous machines.\n",
        "published": "2009-09-25T05:23:33Z",
        "pdf_link": "http://arxiv.org/pdf/0909.4603v1"
    },
    {
        "id": "http://arxiv.org/abs/0910.0349v1",
        "title": "Post-Processing of Discovered Association Rules Using Ontologies",
        "summary": "  In Data Mining, the usefulness of association rules is strongly limited by\nthe huge amount of delivered rules. In this paper we propose a new approach to\nprune and filter discovered rules. Using Domain Ontologies, we strengthen the\nintegration of user knowledge in the post-processing task. Furthermore, an\ninteractive and iterative framework is designed to assist the user along the\nanalyzing task. On the one hand, we represent user domain knowledge using a\nDomain Ontology over database. On the other hand, a novel technique is\nsuggested to prune and to filter discovered rules. The proposed framework was\napplied successfully over the client database provided by Nantes Habitat.\n",
        "published": "2009-10-02T08:40:01Z",
        "pdf_link": "http://arxiv.org/pdf/0910.0349v1"
    },
    {
        "id": "http://arxiv.org/abs/0910.0668v2",
        "title": "Variable sigma Gaussian processes: An expectation propagation\n  perspective",
        "summary": "  Gaussian processes (GPs) provide a probabilistic nonparametric representation\nof functions in regression, classification, and other problems. Unfortunately,\nexact learning with GPs is intractable for large datasets. A variety of\napproximate GP methods have been proposed that essentially map the large\ndataset into a small set of basis points. The most advanced of these, the\nvariable-sigma GP (VSGP) (Walder et al., 2008), allows each basis point to have\nits own length scale. However, VSGP was only derived for regression. We\ndescribe how VSGP can be applied to classification and other problems, by\nderiving it as an expectation propagation algorithm. In this view, sparse GP\napproximations correspond to a KL-projection of the true posterior onto a\ncompact exponential family of GPs. VSGP constitutes one such family, and we\nshow how to enlarge this family to get additional accuracy. In particular, we\nshow that endowing each basis point with its own full covariance matrix\nprovides a significant increase in approximation power.\n",
        "published": "2009-10-05T03:30:13Z",
        "pdf_link": "http://arxiv.org/pdf/0910.0668v2"
    },
    {
        "id": "http://arxiv.org/abs/0910.2540v1",
        "title": "Effectiveness and Limitations of Statistical Spam Filters",
        "summary": "  In this paper we discuss the techniques involved in the design of the famous\nstatistical spam filters that include Naive Bayes, Term Frequency-Inverse\nDocument Frequency, K-Nearest Neighbor, Support Vector Machine, and Bayes\nAdditive Regression Tree. We compare these techniques with each other in terms\nof accuracy, recall, precision, etc. Further, we discuss the effectiveness and\nlimitations of statistical filters in filtering out various types of spam from\nlegitimate e-mails.\n",
        "published": "2009-10-14T07:43:03Z",
        "pdf_link": "http://arxiv.org/pdf/0910.2540v1"
    },
    {
        "id": "http://arxiv.org/abs/0910.4683v2",
        "title": "Competing with Gaussian linear experts",
        "summary": "  We study the problem of online regression. We prove a theoretical bound on\nthe square loss of Ridge Regression. We do not make any assumptions about input\nvectors or outcomes. We also show that Bayesian Ridge Regression can be thought\nof as an online algorithm competing with all the Gaussian linear experts.\n",
        "published": "2009-10-24T22:40:40Z",
        "pdf_link": "http://arxiv.org/pdf/0910.4683v2"
    },
    {
        "id": "http://arxiv.org/abs/0910.5461v1",
        "title": "Anomaly Detection with Score functions based on Nearest Neighbor Graphs",
        "summary": "  We propose a novel non-parametric adaptive anomaly detection algorithm for\nhigh dimensional data based on score functions derived from nearest neighbor\ngraphs on $n$-point nominal data. Anomalies are declared whenever the score of\na test sample falls below $\\alpha$, which is supposed to be the desired false\nalarm level. The resulting anomaly detector is shown to be asymptotically\noptimal in that it is uniformly most powerful for the specified false alarm\nlevel, $\\alpha$, for the case when the anomaly density is a mixture of the\nnominal and a known density. Our algorithm is computationally efficient, being\nlinear in dimension and quadratic in data size. It does not require choosing\ncomplicated tuning parameters or function approximation classes and it can\nadapt to local structure such as local change in dimensionality. We demonstrate\nthe algorithm on both artificial and real data sets in high dimensional feature\nspaces.\n",
        "published": "2009-10-28T18:46:41Z",
        "pdf_link": "http://arxiv.org/pdf/0910.5461v1"
    },
    {
        "id": "http://arxiv.org/abs/0911.0225v1",
        "title": "A Mirroring Theorem and its Application to a New Method of Unsupervised\n  Hierarchical Pattern Classification",
        "summary": "  In this paper, we prove a crucial theorem called Mirroring Theorem which\naffirms that given a collection of samples with enough information in it such\nthat it can be classified into classes and subclasses then (i) There exists a\nmapping which classifies and subclassifies these samples (ii) There exists a\nhierarchical classifier which can be constructed by using Mirroring Neural\nNetworks (MNNs) in combination with a clustering algorithm that can approximate\nthis mapping. Thus, the proof of the Mirroring theorem provides a theoretical\nbasis for the existence and a practical feasibility of constructing\nhierarchical classifiers, given the maps. Our proposed Mirroring Theorem can\nalso be considered as an extension to Kolmogrovs theorem in providing a\nrealistic solution for unsupervised classification. The techniques we develop,\nare general in nature and have led to the construction of learning machines\nwhich are (i) tree like in structure, (ii) modular (iii) with each module\nrunning on a common algorithm (tandem algorithm) and (iv) selfsupervised. We\nhave actually built the architecture, developed the tandem algorithm of such a\nhierarchical classifier and demonstrated it on an example problem.\n",
        "published": "2009-11-02T19:53:01Z",
        "pdf_link": "http://arxiv.org/pdf/0911.0225v1"
    },
    {
        "id": "http://arxiv.org/abs/0911.2904v4",
        "title": "Sequential anomaly detection in the presence of noise and limited\n  feedback",
        "summary": "  This paper describes a methodology for detecting anomalies from sequentially\nobserved and potentially noisy data. The proposed approach consists of two main\nelements: (1) {\\em filtering}, or assigning a belief or likelihood to each\nsuccessive measurement based upon our ability to predict it from previous noisy\nobservations, and (2) {\\em hedging}, or flagging potential anomalies by\ncomparing the current belief against a time-varying and data-adaptive\nthreshold. The threshold is adjusted based on the available feedback from an\nend user. Our algorithms, which combine universal prediction with recent work\non online convex programming, do not require computing posterior distributions\ngiven all current observations and involve simple primal-dual parameter\nupdates. At the heart of the proposed approach lie exponential-family models\nwhich can be used in a wide variety of contexts and applications, and which\nyield methods that achieve sublinear per-round regret against both static and\nslowly varying product distributions with marginals drawn from the same\nexponential family. Moreover, the regret against static distributions coincides\nwith the minimax value of the corresponding online strongly convex game. We\nalso prove bounds on the number of mistakes made during the hedging step\nrelative to the best offline choice of the threshold with access to all\nestimated beliefs and feedback signals. We validate the theory on synthetic\ndata drawn from a time-varying distribution over binary vectors of high\ndimensionality, as well as on the Enron email dataset.\n",
        "published": "2009-11-15T18:43:10Z",
        "pdf_link": "http://arxiv.org/pdf/0911.2904v4"
    },
    {
        "id": "http://arxiv.org/abs/0911.3304v1",
        "title": "Keystroke Dynamics Authentication For Collaborative Systems",
        "summary": "  We present in this paper a study on the ability and the benefits of using a\nkeystroke dynamics authentication method for collaborative systems.\nAuthentication is a challenging issue in order to guarantee the security of use\nof collaborative systems during the access control step. Many solutions exist\nin the state of the art such as the use of one time passwords or smart-cards.\nWe focus in this paper on biometric based solutions that do not necessitate any\nadditional sensor. Keystroke dynamics is an interesting solution as it uses\nonly the keyboard and is invisible for users. Many methods have been published\nin this field. We make a comparative study of many of them considering the\noperational constraints of use for collaborative systems.\n",
        "published": "2009-11-17T13:35:40Z",
        "pdf_link": "http://arxiv.org/pdf/0911.3304v1"
    },
    {
        "id": "http://arxiv.org/abs/0911.4863v2",
        "title": "Statistical exponential families: A digest with flash cards",
        "summary": "  This document describes concisely the ubiquitous class of exponential family\ndistributions met in statistics. The first part recalls definitions and\nsummarizes main properties and duality with Bregman divergences (all proofs are\nskipped). The second part lists decompositions and related formula of common\nexponential family distributions. We recall the Fisher-Rao-Riemannian\ngeometries and the dual affine connection information geometries of statistical\nmanifolds. It is intended to maintain and update this document and catalog by\nadding new distribution items.\n",
        "published": "2009-11-25T14:26:54Z",
        "pdf_link": "http://arxiv.org/pdf/0911.4863v2"
    },
    {
        "id": "http://arxiv.org/abs/1001.0405v1",
        "title": "Optimal Query Complexity for Reconstructing Hypergraphs",
        "summary": "  In this paper we consider the problem of reconstructing a hidden weighted\nhypergraph of constant rank using additive queries. We prove the following: Let\n$G$ be a weighted hidden hypergraph of constant rank with n vertices and $m$\nhyperedges. For any $m$ there exists a non-adaptive algorithm that finds the\nedges of the graph and their weights using $$ O(\\frac{m\\log n}{\\log m}) $$\nadditive queries. This solves the open problem in [S. Choi, J. H. Kim. Optimal\nQuery Complexity Bounds for Finding Graphs. {\\em STOC}, 749--758,~2008].\n  When the weights of the hypergraph are integers that are less than\n$O(poly(n^d/m))$ where $d$ is the rank of the hypergraph (and therefore for\nunweighted hypergraphs) there exists a non-adaptive algorithm that finds the\nedges of the graph and their weights using $$ O(\\frac{m\\log \\frac{n^d}{m}}{\\log\nm}). $$ additive queries.\n  Using the information theoretic bound the above query complexities are tight.\n",
        "published": "2010-01-03T19:54:40Z",
        "pdf_link": "http://arxiv.org/pdf/1001.0405v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.0879v1",
        "title": "Linear Probability Forecasting",
        "summary": "  Multi-class classification is one of the most important tasks in machine\nlearning. In this paper we consider two online multi-class classification\nproblems: classification by a linear model and by a kernelized model. The\nquality of predictions is measured by the Brier loss function. We suggest two\ncomputationally efficient algorithms to work with these problems and prove\ntheoretical guarantees on their losses. We kernelize one of the algorithms and\nprove theoretical guarantees on its loss. We perform experiments and compare\nour algorithms with logistic regression.\n",
        "published": "2010-01-06T12:40:13Z",
        "pdf_link": "http://arxiv.org/pdf/1001.0879v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.1079v1",
        "title": "Measuring Latent Causal Structure",
        "summary": "  Discovering latent representations of the observed world has become\nincreasingly more relevant in data analysis. Much of the effort concentrates on\nbuilding latent variables which can be used in prediction problems, such as\nclassification and regression. A related goal of learning latent structure from\ndata is that of identifying which hidden common causes generate the\nobservations, such as in applications that require predicting the effect of\npolicies. This will be the main problem tackled in our contribution: given a\ndataset of indicators assumed to be generated by unknown and unmeasured common\ncauses, we wish to discover which hidden common causes are those, and how they\ngenerate our data. This is possible under the assumption that observed\nvariables are linear functions of the latent causes with additive noise.\nPrevious results in the literature present solutions for the case where each\nobserved variable is a noisy function of a single latent variable. We show how\nto extend the existing results for some cases where observed variables measure\nmore than one latent variable.\n",
        "published": "2010-01-07T14:41:21Z",
        "pdf_link": "http://arxiv.org/pdf/1001.1079v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.2957v2",
        "title": "Asymptotic Learning Curve and Renormalizable Condition in Statistical\n  Learning Theory",
        "summary": "  Bayes statistics and statistical physics have the common mathematical\nstructure, where the log likelihood function corresponds to the random\nHamiltonian. Recently, it was discovered that the asymptotic learning curves in\nBayes estimation are subject to a universal law, even if the log likelihood\nfunction can not be approximated by any quadratic form. However, it is left\nunknown what mathematical property ensures such a universal law. In this paper,\nwe define a renormalizable condition of the statistical estimation problem, and\nshow that, under such a condition, the asymptotic learning curves are ensured\nto be subject to the universal law, even if the true distribution is\nunrealizable and singular for a statistical model. Also we study a\nnonrenormalizable case, in which the learning curves have the different\nasymptotic behaviors from the universal law.\n",
        "published": "2010-01-18T05:34:09Z",
        "pdf_link": "http://arxiv.org/pdf/1001.2957v2"
    },
    {
        "id": "http://arxiv.org/abs/1001.3478v1",
        "title": "Role of Interestingness Measures in CAR Rule Ordering for Associative\n  Classifier: An Empirical Approach",
        "summary": "  Associative Classifier is a novel technique which is the integration of\nAssociation Rule Mining and Classification. The difficult task in building\nAssociative Classifier model is the selection of relevant rules from a large\nnumber of class association rules (CARs). A very popular method of ordering\nrules for selection is based on confidence, support and antecedent size (CSA).\nOther methods are based on hybrid orderings in which CSA method is combined\nwith other measures. In the present work, we study the effect of using\ndifferent interestingness measures of Association rules in CAR rule ordering\nand selection for associative classifier.\n",
        "published": "2010-01-20T07:30:02Z",
        "pdf_link": "http://arxiv.org/pdf/1001.3478v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.5007v2",
        "title": "Trajectory Clustering and an Application to Airspace Monitoring",
        "summary": "  This paper presents a framework aimed at monitoring the behavior of aircraft\nin a given airspace. Nominal trajectories are determined and learned using data\ndriven methods. Standard procedures are used by air traffic controllers (ATC)\nto guide aircraft, ensure the safety of the airspace, and to maximize the\nrunway occupancy. Even though standard procedures are used by ATC, the control\nof the aircraft remains with the pilots, leading to a large variability in the\nflight patterns observed. Two methods to identify typical operations and their\nvariability from recorded radar tracks are presented. This knowledge base is\nthen used to monitor the conformance of current operations against operations\npreviously identified as standard. A tool called AirTrajectoryMiner is\npresented, aiming at monitoring the instantaneous health of the airspace, in\nreal time. The airspace is \"healthy\" when all aircraft are flying according to\nthe nominal procedures. A measure of complexity is introduced, measuring the\nconformance of current flight to nominal flight patterns. When an aircraft does\nnot conform, the complexity increases as more attention from ATC is required to\nensure a safe separation between aircraft.\n",
        "published": "2010-01-27T19:24:33Z",
        "pdf_link": "http://arxiv.org/pdf/1001.5007v2"
    },
    {
        "id": "http://arxiv.org/abs/1002.0709v1",
        "title": "Aggregating Algorithm competing with Banach lattices",
        "summary": "  The paper deals with on-line regression settings with signals belonging to a\nBanach lattice. Our algorithms work in a semi-online setting where all the\ninputs are known in advance and outcomes are unknown and given step by step. We\napply the Aggregating Algorithm to construct a prediction method whose\ncumulative loss over all the input vectors is comparable with the cumulative\nloss of any linear functional on the Banach lattice. As a by-product we get an\nalgorithm that takes signals from an arbitrary domain. Its cumulative loss is\ncomparable with the cumulative loss of any predictor function from Besov and\nTriebel-Lizorkin spaces. We describe several applications of our setting.\n",
        "published": "2010-02-03T11:31:24Z",
        "pdf_link": "http://arxiv.org/pdf/1002.0709v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.1144v1",
        "title": "A CHAID Based Performance Prediction Model in Educational Data Mining",
        "summary": "  The performance in higher secondary school education in India is a turning\npoint in the academic lives of all students. As this academic performance is\ninfluenced by many factors, it is essential to develop predictive data mining\nmodel for students' performance so as to identify the slow learners and study\nthe influence of the dominant factors on their academic performance. In the\npresent investigation, a survey cum experimental methodology was adopted to\ngenerate a database and it was constructed from a primary and a secondary\nsource. While the primary data was collected from the regular students, the\nsecondary data was gathered from the school and office of the Chief Educational\nOfficer (CEO). A total of 1000 datasets of the year 2006 from five different\nschools in three different districts of Tamilnadu were collected. The raw data\nwas preprocessed in terms of filling up missing values, transforming values in\none form into another and relevant attribute/ variable selection. As a result,\nwe had 772 student records, which were used for CHAID prediction model\nconstruction. A set of prediction rules were extracted from CHIAD prediction\nmodel and the efficiency of the generated CHIAD prediction model was found. The\naccuracy of the present model was compared with other model and it has been\nfound to be satisfactory.\n",
        "published": "2010-02-05T08:27:17Z",
        "pdf_link": "http://arxiv.org/pdf/1002.1144v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.1156v1",
        "title": "Dimensionality Reduction: An Empirical Study on the Usability of IFE-CF\n  (Independent Feature Elimination- by C-Correlation and F-Correlation)\n  Measures",
        "summary": "  The recent increase in dimensionality of data has thrown a great challenge to\nthe existing dimensionality reduction methods in terms of their effectiveness.\nDimensionality reduction has emerged as one of the significant preprocessing\nsteps in machine learning applications and has been effective in removing\ninappropriate data, increasing learning accuracy, and improving\ncomprehensibility. Feature redundancy exercises great influence on the\nperformance of classification process. Towards the better classification\nperformance, this paper addresses the usefulness of truncating the highly\ncorrelated and redundant attributes. Here, an effort has been made to verify\nthe utility of dimensionality reduction by applying LVQ (Learning Vector\nQuantization) method on two Benchmark datasets of 'Pima Indian Diabetic\npatients' and 'Lung cancer patients'.\n",
        "published": "2010-02-05T08:59:05Z",
        "pdf_link": "http://arxiv.org/pdf/1002.1156v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.1782v3",
        "title": "Online Distributed Sensor Selection",
        "summary": "  A key problem in sensor networks is to decide which sensors to query when, in\norder to obtain the most useful information (e.g., for performing accurate\nprediction), subject to constraints (e.g., on power and bandwidth). In many\napplications the utility function is not known a priori, must be learned from\ndata, and can even change over time. Furthermore for large sensor networks\nsolving a centralized optimization problem to select sensors is not feasible,\nand thus we seek a fully distributed solution. In this paper, we present\nDistributed Online Greedy (DOG), an efficient, distributed algorithm for\nrepeatedly selecting sensors online, only receiving feedback about the utility\nof the selected sensors. We prove very strong theoretical no-regret guarantees\nthat apply whenever the (unknown) utility function satisfies a natural\ndiminishing returns property called submodularity. Our algorithm has extremely\nlow communication requirements, and scales well to large sensor deployments. We\nextend DOG to allow observation-dependent sensor selection. We empirically\ndemonstrate the effectiveness of our algorithm on several real-world sensing\ntasks.\n",
        "published": "2010-02-09T07:32:59Z",
        "pdf_link": "http://arxiv.org/pdf/1002.1782v3"
    },
    {
        "id": "http://arxiv.org/abs/1002.2044v1",
        "title": "On the Stability of Empirical Risk Minimization in the Presence of\n  Multiple Risk Minimizers",
        "summary": "  Recently Kutin and Niyogi investigated several notions of algorithmic\nstability--a property of a learning map conceptually similar to\ncontinuity--showing that training-stability is sufficient for consistency of\nEmpirical Risk Minimization while distribution-free CV-stability is necessary\nand sufficient for having finite VC-dimension. This paper concerns a phase\ntransition in the training stability of ERM, conjectured by the same authors.\nKutin and Niyogi proved that ERM on finite hypothesis spaces containing a\nunique risk minimizer has training stability that scales exponentially with\nsample size, and conjectured that the existence of multiple risk minimizers\nprevents even super-quadratic convergence. We prove this result for the\nstrictly weaker notion of CV-stability, positively resolving the conjecture.\n",
        "published": "2010-02-10T09:08:56Z",
        "pdf_link": "http://arxiv.org/pdf/1002.2044v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.2780v1",
        "title": "Collaborative Filtering in a Non-Uniform World: Learning with the\n  Weighted Trace Norm",
        "summary": "  We show that matrix completion with trace-norm regularization can be\nsignificantly hurt when entries of the matrix are sampled non-uniformly. We\nintroduce a weighted version of the trace-norm regularizer that works well also\nwith non-uniform sampling. Our experimental results demonstrate that the\nweighted trace-norm regularization indeed yields significant gains on the\n(highly non-uniformly sampled) Netflix dataset.\n",
        "published": "2010-02-14T16:37:04Z",
        "pdf_link": "http://arxiv.org/pdf/1002.2780v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.3345v2",
        "title": "Interactive Submodular Set Cover",
        "summary": "  We introduce a natural generalization of submodular set cover and exact\nactive learning with a finite hypothesis class (query learning). We call this\nnew problem interactive submodular set cover. Applications include advertising\nin social networks with hidden information. We give an approximation guarantee\nfor a novel greedy algorithm and give a hardness of approximation result which\nmatches up to constant factors. We also discuss negative results for simpler\napproaches and present encouraging early experimental results.\n",
        "published": "2010-02-17T18:43:59Z",
        "pdf_link": "http://arxiv.org/pdf/1002.3345v2"
    },
    {
        "id": "http://arxiv.org/abs/1002.4007v1",
        "title": "Word level Script Identification from Bangla and Devanagri Handwritten\n  Texts mixed with Roman Script",
        "summary": "  India is a multi-lingual country where Roman script is often used alongside\ndifferent Indic scripts in a text document. To develop a script specific\nhandwritten Optical Character Recognition (OCR) system, it is therefore\nnecessary to identify the scripts of handwritten text correctly. In this paper,\nwe present a system, which automatically separates the scripts of handwritten\nwords from a document, written in Bangla or Devanagri mixed with Roman scripts.\nIn this script separation technique, we first, extract the text lines and words\nfrom document pages using a script independent Neighboring Component Analysis\ntechnique. Then we have designed a Multi Layer Perceptron (MLP) based\nclassifier for script separation, trained with 8 different wordlevel holistic\nfeatures. Two equal sized datasets, one with Bangla and Roman scripts and the\nother with Devanagri and Roman scripts, are prepared for the system evaluation.\nOn respective independent text samples, word-level script identification\naccuracies of 99.29% and 98.43% are achieved.\n",
        "published": "2010-02-21T19:48:16Z",
        "pdf_link": "http://arxiv.org/pdf/1002.4007v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.4058v3",
        "title": "Contextual Bandit Algorithms with Supervised Learning Guarantees",
        "summary": "  We address the problem of learning in an online, bandit setting where the\nlearner must repeatedly select among $K$ actions, but only receives partial\nfeedback based on its choices. We establish two new facts: First, using a new\nalgorithm called Exp4.P, we show that it is possible to compete with the best\nin a set of $N$ experts with probability $1-\\delta$ while incurring regret at\nmost $O(\\sqrt{KT\\ln(N/\\delta)})$ over $T$ time steps. The new algorithm is\ntested empirically in a large-scale, real-world dataset. Second, we give a new\nalgorithm called VE that competes with a possibly infinite set of policies of\nVC-dimension $d$ while incurring regret at most $O(\\sqrt{T(d\\ln(T) + \\ln\n(1/\\delta))})$ with probability $1-\\delta$. These guarantees improve on those\nof all previous algorithms, whether in a stochastic or adversarial environment,\nand bring us closer to providing supervised learning type guarantees for the\ncontextual bandit setting.\n",
        "published": "2010-02-22T07:11:39Z",
        "pdf_link": "http://arxiv.org/pdf/1002.4058v3"
    },
    {
        "id": "http://arxiv.org/abs/1002.4908v2",
        "title": "Adaptive Bound Optimization for Online Convex Optimization",
        "summary": "  We introduce a new online convex optimization algorithm that adaptively\nchooses its regularization function based on the loss functions observed so\nfar. This is in contrast to previous algorithms that use a fixed regularization\nfunction such as L2-squared, and modify it only via a single time-dependent\nparameter. Our algorithm's regret bounds are worst-case optimal, and for\ncertain realistic classes of loss functions they are much better than existing\nbounds. These bounds are problem-dependent, which means they can exploit the\nstructure of the actual problem instance. Critically, however, our algorithm\ndoes not need to know this structure in advance. Rather, we prove competitive\nguarantees that show the algorithm provides a bound within a constant factor of\nthe best possible bound (of a certain functional form) in hindsight.\n",
        "published": "2010-02-26T01:36:34Z",
        "pdf_link": "http://arxiv.org/pdf/1002.4908v2"
    },
    {
        "id": "http://arxiv.org/abs/1003.0024v1",
        "title": "Asymptotic Analysis of Generative Semi-Supervised Learning",
        "summary": "  Semisupervised learning has emerged as a popular framework for improving\nmodeling accuracy while controlling labeling cost. Based on an extension of\nstochastic composite likelihood we quantify the asymptotic accuracy of\ngenerative semi-supervised learning. In doing so, we complement\ndistribution-free analysis by providing an alternative framework to measure the\nvalue associated with different labeling policies and resolve the fundamental\nquestion of how much data to label and in what manner. We demonstrate our\napproach with both simulation studies and real world experiments using naive\nBayes for text classification and MRFs and CRFs for structured prediction in\nNLP.\n",
        "published": "2010-02-26T21:59:02Z",
        "pdf_link": "http://arxiv.org/pdf/1003.0024v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.0470v2",
        "title": "Unsupervised Supervised Learning II: Training Margin Based Classifiers\n  without Labels",
        "summary": "  Many popular linear classifiers, such as logistic regression, boosting, or\nSVM, are trained by optimizing a margin-based risk function. Traditionally,\nthese risk functions are computed based on a labeled dataset. We develop a\nnovel technique for estimating such risks using only unlabeled data and the\nmarginal label distribution. We prove that the proposed risk estimator is\nconsistent on high-dimensional datasets and demonstrate it on synthetic and\nreal-world data. In particular, we show how the estimate is used for evaluating\nclassifiers in transfer learning, and for training classifiers with no labeled\ndata whatsoever.\n",
        "published": "2010-03-01T22:32:18Z",
        "pdf_link": "http://arxiv.org/pdf/1003.0470v2"
    },
    {
        "id": "http://arxiv.org/abs/1003.0516v1",
        "title": "Model Selection with the Loss Rank Principle",
        "summary": "  A key issue in statistics and machine learning is to automatically select the\n\"right\" model complexity, e.g., the number of neighbors to be averaged over in\nk nearest neighbor (kNN) regression or the polynomial degree in regression with\npolynomials. We suggest a novel principle - the Loss Rank Principle (LoRP) -\nfor model selection in regression and classification. It is based on the loss\nrank, which counts how many other (fictitious) data would be fitted better.\nLoRP selects the model that has minimal loss rank. Unlike most penalized\nmaximum likelihood variants (AIC, BIC, MDL), LoRP depends only on the\nregression functions and the loss function. It works without a stochastic noise\nmodel, and is directly applicable to any non-parametric regressor, like kNN.\n",
        "published": "2010-03-02T08:21:07Z",
        "pdf_link": "http://arxiv.org/pdf/1003.0516v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.0691v1",
        "title": "Statistical and Computational Tradeoffs in Stochastic Composite\n  Likelihood",
        "summary": "  Maximum likelihood estimators are often of limited practical use due to the\nintensive computation they require. We propose a family of alternative\nestimators that maximize a stochastic variation of the composite likelihood\nfunction. Each of the estimators resolve the computation-accuracy tradeoff\ndifferently, and taken together they span a continuous spectrum of\ncomputation-accuracy tradeoff resolutions. We prove the consistency of the\nestimators, provide formulas for their asymptotic variance, statistical\nrobustness, and computational complexity. We discuss experimental results in\nthe context of Boltzmann machines and conditional random fields. The\ntheoretical and experimental studies demonstrate the effectiveness of the\nestimators when the computational resources are insufficient. They also\ndemonstrate that in some cases reduced computational complexity is associated\nwith robustness thereby increasing statistical accuracy.\n",
        "published": "2010-03-02T21:54:16Z",
        "pdf_link": "http://arxiv.org/pdf/1003.0691v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.0696v1",
        "title": "Exponential Family Hybrid Semi-Supervised Learning",
        "summary": "  We present an approach to semi-supervised learning based on an exponential\nfamily characterization. Our approach generalizes previous work on coupled\npriors for hybrid generative/discriminative models. Our model is more flexible\nand natural than previous approaches. Experimental results on several data sets\nshow that our approach also performs better in practice.\n",
        "published": "2010-03-02T22:27:31Z",
        "pdf_link": "http://arxiv.org/pdf/1003.0696v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.1450v1",
        "title": "A New Clustering Approach based on Page's Path Similarity for Navigation\n  Patterns Mining",
        "summary": "  In recent years, predicting the user's next request in web navigation has\nreceived much attention. An information source to be used for dealing with such\nproblem is the left information by the previous web users stored at the web\naccess log on the web servers. Purposed systems for this problem work based on\nthis idea that if a large number of web users request specific pages of a\nwebsite on a given session, it can be concluded that these pages are satisfying\nsimilar information needs, and therefore they are conceptually related. In this\nstudy, a new clustering approach is introduced that employs logical path\nstoring of a website pages as another parameter which is regarded as a\nsimilarity parameter and conceptual relation between web pages. The results of\nsimulation have shown that the proposed approach is more than others precise in\ndetermining the clusters.\n",
        "published": "2010-03-07T11:08:33Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1450v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.1510v1",
        "title": "Hierarchical Web Page Classification Based on a Topic Model and\n  Neighboring Pages Integration",
        "summary": "  Most Web page classification models typically apply the bag of words (BOW)\nmodel to represent the feature space. The original BOW representation, however,\nis unable to recognize semantic relationships between terms. One possible\nsolution is to apply the topic model approach based on the Latent Dirichlet\nAllocation algorithm to cluster the term features into a set of latent topics.\nTerms assigned into the same topic are semantically related. In this paper, we\npropose a novel hierarchical classification method based on a topic model and\nby integrating additional term features from neighboring pages. Our\nhierarchical classification method consists of two phases: (1) feature\nrepresentation by using a topic model and integrating neighboring pages, and\n(2) hierarchical Support Vector Machines (SVM) classification model constructed\nfrom a confusion matrix. From the experimental results, the approach of using\nthe proposed hierarchical SVM model by integrating current page with\nneighboring pages via the topic model yielded the best performance with the\naccuracy equal to 90.33% and the F1 measure of 90.14%; an improvement of 5.12%\nand 5.13% over the original SVM model, respectively.\n",
        "published": "2010-03-07T18:32:47Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1510v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.2218v1",
        "title": "Supermartingales in Prediction with Expert Advice",
        "summary": "  We apply the method of defensive forecasting, based on the use of\ngame-theoretic supermartingales, to prediction with expert advice. In the\ntraditional setting of a countable number of experts and a finite number of\noutcomes, the Defensive Forecasting Algorithm is very close to the well-known\nAggregating Algorithm. Not only the performance guarantees but also the\npredictions are the same for these two methods of fundamentally different\nnature. We discuss also a new setting where the experts can give advice\nconditional on the learner's future decision. Both the algorithms can be\nadapted to the new setting and give the same performance guarantees as in the\ntraditional setting. Finally, we outline an application of defensive\nforecasting to a setting with several loss functions.\n",
        "published": "2010-03-10T21:53:56Z",
        "pdf_link": "http://arxiv.org/pdf/1003.2218v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.0027v2",
        "title": "Learning from Multiple Outlooks",
        "summary": "  We propose a novel problem formulation of learning a single task when the\ndata are provided in different feature spaces. Each such space is called an\noutlook, and is assumed to contain both labeled and unlabeled data. The\nobjective is to take advantage of the data from all the outlooks to better\nclassify each of the outlooks. We devise an algorithm that computes optimal\naffine mappings from different outlooks to a target outlook by matching moments\nof the empirical distributions. We further derive a probabilistic\ninterpretation of the resulting algorithm and a sample complexity bound\nindicating how many samples are needed to adequately find the mapping. We\nreport the results of extensive experiments on activity recognition tasks that\nshow the value of the proposed approach in boosting performance.\n",
        "published": "2010-04-30T21:52:17Z",
        "pdf_link": "http://arxiv.org/pdf/1005.0027v2"
    },
    {
        "id": "http://arxiv.org/abs/1005.0047v1",
        "title": "A Geometric View of Conjugate Priors",
        "summary": "  In Bayesian machine learning, conjugate priors are popular, mostly due to\nmathematical convenience. In this paper, we show that there are deeper reasons\nfor choosing a conjugate prior. Specifically, we formulate the conjugate prior\nin the form of Bregman divergence and show that it is the inherent geometry of\nconjugate priors that makes them appropriate and intuitive. This geometric\ninterpretation allows one to view the hyperparameters of conjugate priors as\nthe {\\it effective} sample points, thus providing additional intuition. We use\nthis geometric understanding of conjugate priors to derive the hyperparameters\nand expression of the prior used to couple the generative and discriminative\ncomponents of a hybrid model for semi-supervised learning.\n",
        "published": "2010-05-01T06:06:36Z",
        "pdf_link": "http://arxiv.org/pdf/1005.0047v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.0075v1",
        "title": "Distributive Stochastic Learning for Delay-Optimal OFDMA Power and\n  Subband Allocation",
        "summary": "  In this paper, we consider the distributive queue-aware power and subband\nallocation design for a delay-optimal OFDMA uplink system with one base\nstation, $K$ users and $N_F$ independent subbands. Each mobile has an uplink\nqueue with heterogeneous packet arrivals and delay requirements. We model the\nproblem as an infinite horizon average reward Markov Decision Problem (MDP)\nwhere the control actions are functions of the instantaneous Channel State\nInformation (CSI) as well as the joint Queue State Information (QSI). To\naddress the distributive requirement and the issue of exponential memory\nrequirement and computational complexity, we approximate the subband allocation\nQ-factor by the sum of the per-user subband allocation Q-factor and derive a\ndistributive online stochastic learning algorithm to estimate the per-user\nQ-factor and the Lagrange multipliers (LM) simultaneously and determine the\ncontrol actions using an auction mechanism. We show that under the proposed\nauction mechanism, the distributive online learning converges almost surely\n(with probability 1). For illustration, we apply the proposed distributive\nstochastic learning framework to an application example with exponential packet\nsize distribution. We show that the delay-optimal power control has the {\\em\nmulti-level water-filling} structure where the CSI determines the instantaneous\npower allocation and the QSI determines the water-level. The proposed algorithm\nhas linear signaling overhead and computational complexity $\\mathcal O(KN)$,\nwhich is desirable from an implementation perspective.\n",
        "published": "2010-05-01T13:57:15Z",
        "pdf_link": "http://arxiv.org/pdf/1005.0075v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.0340v1",
        "title": "Statistical Learning in Automated Troubleshooting: Application to LTE\n  Interference Mitigation",
        "summary": "  This paper presents a method for automated healing as part of off-line\nautomated troubleshooting. The method combines statistical learning with\nconstraint optimization. The automated healing aims at locally optimizing radio\nresource management (RRM) or system parameters of cells with poor performance\nin an iterative manner. The statistical learning processes the data using\nLogistic Regression (LR) to extract closed form (functional) relations between\nKey Performance Indicators (KPIs) and Radio Resource Management (RRM)\nparameters. These functional relations are then processed by an optimization\nengine which proposes new parameter values. The advantage of the proposed\nformulation is the small number of iterations required by the automated healing\nmethod to converge, making it suitable for off-line implementation. The\nproposed method is applied to heal an Inter-Cell Interference Coordination\n(ICIC) process in a 3G Long Term Evolution (LTE) network which is based on\nsoft-frequency reuse scheme. Numerical simulations illustrate the benefits of\nthe proposed approach.\n",
        "published": "2010-05-03T16:35:49Z",
        "pdf_link": "http://arxiv.org/pdf/1005.0340v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.0897v1",
        "title": "The Complex Gaussian Kernel LMS algorithm",
        "summary": "  Although the real reproducing kernels are used in an increasing number of\nmachine learning problems, complex kernels have not, yet, been used, in spite\nof their potential interest in applications such as communications. In this\nwork, we focus our attention on the complex gaussian kernel and its possible\napplication in the complex Kernel LMS algorithm. In order to derive the\ngradients needed to develop the complex kernel LMS (CKLMS), we employ the\npowerful tool of Wirtinger's Calculus, which has recently attracted much\nattention in the signal processing community. Writinger's calculus simplifies\ncomputations and offers an elegant tool for treating complex signals. To this\nend, the notion of Writinger's calculus is extended to include complex RKHSs.\nExperiments verify that the CKLMS offers significant performance improvements\nover the traditional complex LMS or Widely Linear complex LMS (WL-LMS)\nalgorithms, when dealing with nonlinearities.\n",
        "published": "2010-05-06T06:42:51Z",
        "pdf_link": "http://arxiv.org/pdf/1005.0897v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.0902v2",
        "title": "Extension of Wirtinger Calculus in RKH Spaces and the Complex Kernel LMS",
        "summary": "  Over the last decade, kernel methods for nonlinear processing have\nsuccessfully been used in the machine learning community. However, so far, the\nemphasis has been on batch techniques. It is only recently, that online\nadaptive techniques have been considered in the context of signal processing\ntasks. To the best of our knowledge, no kernel-based strategy has been\ndeveloped, so far, that is able to deal with complex valued signals. In this\npaper, we take advantage of a technique called complexification of real RKHSs\nto attack this problem. In order to derive gradients and subgradients of\noperators that need to be defined on the associated complex RKHSs, we employ\nthe powerful tool ofWirtinger's Calculus, which has recently attracted much\nattention in the signal processing community. Writinger's calculus simplifies\ncomputations and offers an elegant tool for treating complex signals. To this\nend, in this paper, the notion of Writinger's calculus is extended, for the\nfirst time, to include complex RKHSs and use it to derive the Complex Kernel\nLeast-Mean-Square (CKLMS) algorithm. Experiments verify that the CKLMS can be\nused to derive nonlinear stable algorithms, which offer significant performance\nimprovements over the traditional complex LMS orWidely Linear complex LMS\n(WL-LMS) algorithms, when dealing with nonlinearities.\n",
        "published": "2010-05-06T06:59:22Z",
        "pdf_link": "http://arxiv.org/pdf/1005.0902v2"
    },
    {
        "id": "http://arxiv.org/abs/1005.1545v2",
        "title": "Improving Semi-Supervised Support Vector Machines Through Unlabeled\n  Instances Selection",
        "summary": "  Semi-supervised support vector machines (S3VMs) are a kind of popular\napproaches which try to improve learning performance by exploiting unlabeled\ndata. Though S3VMs have been found helpful in many situations, they may\ndegenerate performance and the resultant generalization ability may be even\nworse than using the labeled data only. In this paper, we try to reduce the\nchance of performance degeneration of S3VMs. Our basic idea is that, rather\nthan exploiting all unlabeled data, the unlabeled instances should be selected\nsuch that only the ones which are very likely to be helpful are exploited,\nwhile some highly risky unlabeled instances are avoided. We propose the\nS3VM-\\emph{us} method by using hierarchical clustering to select the unlabeled\ninstances. Experiments on a broad range of data sets over eighty-eight\ndifferent settings show that the chance of performance degeneration of\nS3VM-\\emph{us} is much smaller than that of existing S3VMs.\n",
        "published": "2010-05-10T13:49:01Z",
        "pdf_link": "http://arxiv.org/pdf/1005.1545v2"
    },
    {
        "id": "http://arxiv.org/abs/1005.1918v2",
        "title": "Prediction with Expert Advice under Discounted Loss",
        "summary": "  We study prediction with expert advice in the setting where the losses are\naccumulated with some discounting---the impact of old losses may gradually\nvanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm\nfor Regression to this case, propose a suitable new variant of exponential\nweights algorithm, and prove respective loss bounds.\n",
        "published": "2010-05-11T19:27:35Z",
        "pdf_link": "http://arxiv.org/pdf/1005.1918v2"
    },
    {
        "id": "http://arxiv.org/abs/1005.2179v1",
        "title": "Detecting Blackholes and Volcanoes in Directed Networks",
        "summary": "  In this paper, we formulate a novel problem for finding blackhole and volcano\npatterns in a large directed graph. Specifically, a blackhole pattern is a\ngroup which is made of a set of nodes in a way such that there are only inlinks\nto this group from the rest nodes in the graph. In contrast, a volcano pattern\nis a group which only has outlinks to the rest nodes in the graph. Both\npatterns can be observed in real world. For instance, in a trading network, a\nblackhole pattern may represent a group of traders who are manipulating the\nmarket. In the paper, we first prove that the blackhole mining problem is a\ndual problem of finding volcanoes. Therefore, we focus on finding the blackhole\npatterns. Along this line, we design two pruning schemes to guide the blackhole\nfinding process. In the first pruning scheme, we strategically prune the search\nspace based on a set of pattern-size-independent pruning rules and develop an\niBlackhole algorithm. The second pruning scheme follows a divide-and-conquer\nstrategy to further exploit the pruning results from the first pruning scheme.\nIndeed, a target directed graphs can be divided into several disconnected\nsubgraphs by the first pruning scheme, and thus the blackhole finding can be\nconducted in each disconnected subgraph rather than in a large graph. Based on\nthese two pruning schemes, we also develop an iBlackhole-DC algorithm. Finally,\nexperimental results on real-world data show that the iBlackhole-DC algorithm\ncan be several orders of magnitude faster than the iBlackhole algorithm, which\nhas a huge computational advantage over a brute-force method.\n",
        "published": "2010-05-12T19:53:29Z",
        "pdf_link": "http://arxiv.org/pdf/1005.2179v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.2243v1",
        "title": "Robustness and Generalization",
        "summary": "  We derive generalization bounds for learning algorithms based on their\nrobustness: the property that if a testing sample is \"similar\" to a training\nsample, then the testing error is close to the training error. This provides a\nnovel approach, different from the complexity or stability arguments, to study\ngeneralization of learning algorithms. We further show that a weak notion of\nrobustness is both sufficient and necessary for generalizability, which implies\nthat robustness is a fundamental property for learning algorithms to work.\n",
        "published": "2010-05-13T01:59:57Z",
        "pdf_link": "http://arxiv.org/pdf/1005.2243v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.2296v2",
        "title": "Online Learning of Noisy Data with Kernels",
        "summary": "  We study online learning when individual instances are corrupted by\nadversarially chosen random noise. We assume the noise distribution is unknown,\nand may change over time with no restriction other than having zero mean and\nbounded variance. Our technique relies on a family of unbiased estimators for\nnon-linear functions, which may be of independent interest. We show that a\nvariant of online gradient descent can learn functions in any dot-product\n(e.g., polynomial) or Gaussian kernel space with any analytic convex loss\nfunction. Our variant uses randomized estimates that need to query a random\nnumber of noisy copies of each instance, where with high probability this\nnumber is upper bounded by a constant. Allowing such multiple queries cannot be\navoided: Indeed, we show that online learning is in general impossible when\nonly one noisy copy of each instance can be accessed.\n",
        "published": "2010-05-13T10:56:01Z",
        "pdf_link": "http://arxiv.org/pdf/1005.2296v2"
    },
    {
        "id": "http://arxiv.org/abs/1005.3566v1",
        "title": "Evolution with Drifting Targets",
        "summary": "  We consider the question of the stability of evolutionary algorithms to\ngradual changes, or drift, in the target concept. We define an algorithm to be\nresistant to drift if, for some inverse polynomial drift rate in the target\nfunction, it converges to accuracy 1 -- \\epsilon , with polynomial resources,\nand then stays within that accuracy indefinitely, except with probability\n\\epsilon , at any one time. We show that every evolution algorithm, in the\nsense of Valiant (2007; 2009), can be converted using the Correlational Query\ntechnique of Feldman (2008), into such a drift resistant algorithm. For certain\nevolutionary algorithms, such as for Boolean conjunctions, we give bounds on\nthe rates of drift that they can resist. We develop some new evolution\nalgorithms that are resistant to significant drift. In particular, we give an\nalgorithm for evolving linear separators over the spherically symmetric\ndistribution that is resistant to a drift rate of O(\\epsilon /n), and another\nalgorithm over the more general product normal distributions that resists a\nsmaller drift rate.\n  The above translation result can be also interpreted as one on the robustness\nof the notion of evolvability itself under changes of definition. As a second\nresult in that direction we show that every evolution algorithm can be\nconverted to a quasi-monotonic one that can evolve from any starting point\nwithout the performance ever dipping significantly below that of the starting\npoint. This permits the somewhat unnatural feature of arbitrary performance\ndegradations to be removed from several known robustness translations.\n",
        "published": "2010-05-19T22:58:53Z",
        "pdf_link": "http://arxiv.org/pdf/1005.3566v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.3681v2",
        "title": "Learning Kernel-Based Halfspaces with the Zero-One Loss",
        "summary": "  We describe and analyze a new algorithm for agnostically learning\nkernel-based halfspaces with respect to the \\emph{zero-one} loss function.\nUnlike most previous formulations which rely on surrogate convex loss functions\n(e.g. hinge-loss in SVM and log-loss in logistic regression), we provide finite\ntime/sample guarantees with respect to the more natural zero-one loss function.\nThe proposed algorithm can learn kernel-based halfspaces in worst-case time\n$\\poly(\\exp(L\\log(L/\\epsilon)))$, for $\\emph{any}$ distribution, where $L$ is a\nLipschitz constant (which can be thought of as the reciprocal of the margin),\nand the learned classifier is worse than the optimal halfspace by at most\n$\\epsilon$. We also prove a hardness result, showing that under a certain\ncryptographic assumption, no algorithm can learn kernel-based halfspaces in\ntime polynomial in $L$.\n",
        "published": "2010-05-20T12:39:56Z",
        "pdf_link": "http://arxiv.org/pdf/1005.3681v2"
    },
    {
        "id": "http://arxiv.org/abs/1005.5462v2",
        "title": "On the clustering aspect of nonnegative matrix factorization",
        "summary": "  This paper provides a theoretical explanation on the clustering aspect of\nnonnegative matrix factorization (NMF). We prove that even without imposing\northogonality nor sparsity constraint on the basis and/or coefficient matrix,\nNMF still can give clustering results, thus providing a theoretical support for\nmany works, e.g., Xu et al. [1] and Kim et al. [2], that show the superiority\nof the standard NMF as a clustering method.\n",
        "published": "2010-05-29T15:27:16Z",
        "pdf_link": "http://arxiv.org/pdf/1005.5462v2"
    },
    {
        "id": "http://arxiv.org/abs/1005.5581v2",
        "title": "Multi-View Active Learning in the Non-Realizable Case",
        "summary": "  The sample complexity of active learning under the realizability assumption\nhas been well-studied. The realizability assumption, however, rarely holds in\npractice. In this paper, we theoretically characterize the sample complexity of\nactive learning in the non-realizable case under multi-view setting. We prove\nthat, with unbounded Tsybakov noise, the sample complexity of multi-view active\nlearning can be $\\widetilde{O}(\\log\\frac{1}{\\epsilon})$, contrasting to\nsingle-view setting where the polynomial improvement is the best possible\nachievement. We also prove that in general multi-view setting the sample\ncomplexity of active learning with unbounded Tsybakov noise is\n$\\widetilde{O}(\\frac{1}{\\epsilon})$, where the order of $1/\\epsilon$ is\nindependent of the parameter in Tsybakov noise, contrasting to previous\npolynomial bounds where the order of $1/\\epsilon$ is related to the parameter\nin Tsybakov noise.\n",
        "published": "2010-05-31T03:59:35Z",
        "pdf_link": "http://arxiv.org/pdf/1005.5581v2"
    },
    {
        "id": "http://arxiv.org/abs/1006.0475v1",
        "title": "Prediction with Advice of Unknown Number of Experts",
        "summary": "  In the framework of prediction with expert advice, we consider a recently\nintroduced kind of regret bounds: the bounds that depend on the effective\ninstead of nominal number of experts. In contrast to the NormalHedge bound,\nwhich mainly depends on the effective number of experts and also weakly depends\non the nominal one, we obtain a bound that does not contain the nominal number\nof experts at all. We use the defensive forecasting method and introduce an\napplication of defensive forecasting to multivalued supermartingales.\n",
        "published": "2010-06-02T19:41:27Z",
        "pdf_link": "http://arxiv.org/pdf/1006.0475v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.1129v2",
        "title": "Predictive PAC learnability: a paradigm for learning from exchangeable\n  input data",
        "summary": "  Exchangeable random variables form an important and well-studied\ngeneralization of i.i.d. variables, however simple examples show that no\nnontrivial concept or function classes are PAC learnable under general\nexchangeable data inputs $X_1,X_2,\\ldots$. Inspired by the work of Berti and\nRigo on a Glivenko--Cantelli theorem for exchangeable inputs, we propose a new\nparadigm, adequate for learning from exchangeable data: predictive PAC\nlearnability. A learning rule $\\mathcal L$ for a function class $\\mathscr F$ is\npredictive PAC if for every $\\e,\\delta>0$ and each function $f\\in {\\mathscr\nF}$, whenever $\\abs{\\sigma}\\geq s(\\delta,\\e)$, we have with confidence\n$1-\\delta$ that the expected difference between $f(X_{n+1})$ and the image of\n$f\\vert\\sigma$ under $\\mathcal L$ does not exceed $\\e$ conditionally on\n$X_1,X_2,\\ldots,X_n$. Thus, instead of learning the function $f$ as such, we\nare learning to a given accuracy $\\e$ the predictive behaviour of $f$ at the\nfuture points $X_i(\\omega)$, $i>n$ of the sample path. Using de Finetti's\ntheorem, we show that if a universally separable function class $\\mathscr F$ is\ndistribution-free PAC learnable under i.i.d. inputs, then it is\ndistribution-free predictive PAC learnable under exchangeable inputs, with a\nslightly worse sample complexity.\n",
        "published": "2010-06-06T18:21:06Z",
        "pdf_link": "http://arxiv.org/pdf/1006.1129v2"
    },
    {
        "id": "http://arxiv.org/abs/1006.1288v2",
        "title": "Regression on fixed-rank positive semidefinite matrices: a Riemannian\n  approach",
        "summary": "  The paper addresses the problem of learning a regression model parameterized\nby a fixed-rank positive semidefinite matrix. The focus is on the nonlinear\nnature of the search space and on scalability to high-dimensional problems. The\nmathematical developments rely on the theory of gradient descent algorithms\nadapted to the Riemannian geometry that underlies the set of fixed-rank\npositive semidefinite matrices. In contrast with previous contributions in the\nliterature, no restrictions are imposed on the range space of the learned\nmatrix. The resulting algorithms maintain a linear complexity in the problem\nsize and enjoy important invariance properties. We apply the proposed\nalgorithms to the problem of learning a distance function parameterized by a\npositive semidefinite matrix. Good performance is observed on classical\nbenchmarks.\n",
        "published": "2010-06-07T16:20:02Z",
        "pdf_link": "http://arxiv.org/pdf/1006.1288v2"
    },
    {
        "id": "http://arxiv.org/abs/1006.2156v1",
        "title": "Dyadic Prediction Using a Latent Feature Log-Linear Model",
        "summary": "  In dyadic prediction, labels must be predicted for pairs (dyads) whose\nmembers possess unique identifiers and, sometimes, additional features called\nside-information. Special cases of this problem include collaborative filtering\nand link prediction. We present the first model for dyadic prediction that\nsatisfies several important desiderata: (i) labels may be ordinal or nominal,\n(ii) side-information can be easily exploited if present, (iii) with or without\nside-information, latent features are inferred for dyad members, (iv) it is\nresistant to sample-selection bias, (v) it can learn well-calibrated\nprobabilities, and (vi) it can scale to very large datasets. To our knowledge,\nno existing method satisfies all the above criteria. In particular, many\nmethods assume that the labels are ordinal and ignore side-information when it\nis present. Experimental results show that the new method is competitive with\nstate-of-the-art methods for the special cases of collaborative filtering and\nlink prediction, and that it makes accurate predictions on nominal data.\n",
        "published": "2010-06-10T21:19:28Z",
        "pdf_link": "http://arxiv.org/pdf/1006.2156v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.2588v1",
        "title": "Agnostic Active Learning Without Constraints",
        "summary": "  We present and analyze an agnostic active learning algorithm that works\nwithout keeping a version space. This is unlike all previous approaches where a\nrestricted set of candidate hypotheses is maintained throughout learning, and\nonly hypotheses from this set are ever returned. By avoiding this version space\napproach, our algorithm sheds the computational burden and brittleness\nassociated with maintaining version spaces, yet still allows for substantial\nimprovements over supervised learning for classification.\n",
        "published": "2010-06-14T02:03:12Z",
        "pdf_link": "http://arxiv.org/pdf/1006.2588v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.3033v3",
        "title": "Extension of Wirtinger's Calculus to Reproducing Kernel Hilbert Spaces\n  and the Complex Kernel LMS",
        "summary": "  Over the last decade, kernel methods for nonlinear processing have\nsuccessfully been used in the machine learning community. The primary\nmathematical tool employed in these methods is the notion of the Reproducing\nKernel Hilbert Space. However, so far, the emphasis has been on batch\ntechniques. It is only recently, that online techniques have been considered in\nthe context of adaptive signal processing tasks. Moreover, these efforts have\nonly been focussed on real valued data sequences. To the best of our knowledge,\nno adaptive kernel-based strategy has been developed, so far, for complex\nvalued signals. Furthermore, although the real reproducing kernels are used in\nan increasing number of machine learning problems, complex kernels have not,\nyet, been used, in spite of their potential interest in applications that deal\nwith complex signals, with Communications being a typical example. In this\npaper, we present a general framework to attack the problem of adaptive\nfiltering of complex signals, using either real reproducing kernels, taking\nadvantage of a technique called \\textit{complexification} of real RKHSs, or\ncomplex reproducing kernels, highlighting the use of the complex gaussian\nkernel. In order to derive gradients of operators that need to be defined on\nthe associated complex RKHSs, we employ the powerful tool of Wirtinger's\nCalculus, which has recently attracted attention in the signal processing\ncommunity. To this end, in this paper, the notion of Wirtinger's calculus is\nextended, for the first time, to include complex RKHSs and use it to derive\nseveral realizations of the Complex Kernel Least-Mean-Square (CKLMS) algorithm.\nExperiments verify that the CKLMS offers significant performance improvements\nover several linear and nonlinear algorithms, when dealing with nonlinearities.\n",
        "published": "2010-06-15T17:09:01Z",
        "pdf_link": "http://arxiv.org/pdf/1006.3033v3"
    },
    {
        "id": "http://arxiv.org/abs/1006.4832v1",
        "title": "MINLIP for the Identification of Monotone Wiener Systems",
        "summary": "  This paper studies the MINLIP estimator for the identification of Wiener\nsystems consisting of a sequence of a linear FIR dynamical model, and a\nmonotonically increasing (or decreasing) static function. Given $T$\nobservations, this algorithm boils down to solving a convex quadratic program\nwith $O(T)$ variables and inequality constraints, implementing an inference\ntechnique which is based entirely on model complexity control. The resulting\nestimates of the linear submodel are found to be almost consistent when no\nnoise is present in the data, under a condition of smoothness of the true\nnonlinearity and local Persistency of Excitation (local PE) of the data. This\nresult is novel as it does not rely on classical tools as a 'linearization'\nusing a Taylor decomposition, nor exploits stochastic properties of the data.\nIt is indicated how to extend the method to cope with noisy data, and empirical\nevidence contrasts performance of the estimator against other recently proposed\ntechniques.\n",
        "published": "2010-06-24T16:42:38Z",
        "pdf_link": "http://arxiv.org/pdf/1006.4832v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.5090v1",
        "title": "PAC learnability of a concept class under non-atomic measures: a problem\n  by Vidyasagar",
        "summary": "  In response to a 1997 problem of M. Vidyasagar, we state a necessary and\nsufficient condition for distribution-free PAC learnability of a concept class\n$\\mathscr C$ under the family of all non-atomic (diffuse) measures on the\ndomain $\\Omega$. Clearly, finiteness of the classical Vapnik-Chervonenkis\ndimension of $\\mathscr C$ is a sufficient, but no longer necessary, condition.\nBesides, learnability of $\\mathscr C$ under non-atomic measures does not imply\nthe uniform Glivenko-Cantelli property with regard to non-atomic measures. Our\nlearnability criterion is stated in terms of a combinatorial parameter\n$\\VC({\\mathscr C}\\,{\\mathrm{mod}}\\,\\omega_1)$ which we call the VC dimension of\n$\\mathscr C$ modulo countable sets. The new parameter is obtained by\n``thickening up'' single points in the definition of VC dimension to\nuncountable ``clusters''. Equivalently, $\\VC(\\mathscr C\\modd\\omega_1)\\leq d$ if\nand only if every countable subclass of $\\mathscr C$ has VC dimension $\\leq d$\noutside a countable subset of $\\Omega$. The new parameter can be also expressed\nas the classical VC dimension of $\\mathscr C$ calculated on a suitable subset\nof a compactification of $\\Omega$. We do not make any measurability assumptions\non $\\mathscr C$, assuming instead the validity of Martin's Axiom (MA).\n",
        "published": "2010-06-26T01:44:57Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5090v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0660v1",
        "title": "The Latent Bernoulli-Gauss Model for Data Analysis",
        "summary": "  We present a new latent-variable model employing a Gaussian mixture\nintegrated with a feature selection procedure (the Bernoulli part of the model)\nwhich together form a \"Latent Bernoulli-Gauss\" distribution. The model is\napplied to MAP estimation, clustering, feature selection and collaborative\nfiltering and fares favorably with the state-of-the-art latent-variable models.\n",
        "published": "2010-07-05T11:46:35Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0660v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0824v1",
        "title": "Filtrage vaste marge pour l'étiquetage séquentiel à noyaux de\n  signaux",
        "summary": "  We address in this paper the problem of multi-channel signal sequence\nlabeling. In particular, we consider the problem where the signals are\ncontaminated by noise or may present some dephasing with respect to their\nlabels. For that, we propose to jointly learn a SVM sample classifier with a\ntemporal filtering of the channels. This will lead to a large margin filtering\nthat is adapted to the specificity of each channel (noise and time-lag). We\nderive algorithms to solve the optimization problem and we discuss different\nfilter regularizations for automated scaling or selection of channels. Our\napproach is tested on a non-linear toy example and on a BCI dataset. Results\nshow that the classification performance on these problems can be improved by\nlearning a large margin filtering.\n",
        "published": "2010-07-06T07:47:00Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0824v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.1282v1",
        "title": "A note on sample complexity of learning binary output neural networks\n  under fixed input distributions",
        "summary": "  We show that the learning sample complexity of a sigmoidal neural network\nconstructed by Sontag (1992) required to achieve a given misclassification\nerror under a fixed purely atomic distribution can grow arbitrarily fast: for\nany prescribed rate of growth there is an input distribution having this rate\nas the sample complexity, and the bound is asymptotically tight. The rate can\nbe superexponential, a non-recursive function, etc. We further observe that\nSontag's ANN is not Glivenko-Cantelli under any input distribution having a\nnon-atomic part.\n",
        "published": "2010-07-08T03:58:25Z",
        "pdf_link": "http://arxiv.org/pdf/1007.1282v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.2049v1",
        "title": "Reinforcement Learning via AIXI Approximation",
        "summary": "  This paper introduces a principled approach for the design of a scalable\ngeneral reinforcement learning agent. This approach is based on a direct\napproximation of AIXI, a Bayesian optimality notion for general reinforcement\nlearning agents. Previously, it has been unclear whether the theory of AIXI\ncould motivate the design of practical algorithms. We answer this hitherto open\nquestion in the affirmative, by providing the first computationally feasible\napproximation to the AIXI agent. To develop our approximation, we introduce a\nMonte Carlo Tree Search algorithm along with an agent-specific extension of the\nContext Tree Weighting algorithm. Empirically, we present a set of encouraging\nresults on a number of stochastic, unknown, and partially observable domains.\n",
        "published": "2010-07-13T08:48:18Z",
        "pdf_link": "http://arxiv.org/pdf/1007.2049v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.3799v1",
        "title": "Adapting to the Shifting Intent of Search Queries",
        "summary": "  Search engines today present results that are often oblivious to abrupt\nshifts in intent. For example, the query `independence day' usually refers to a\nUS holiday, but the intent of this query abruptly changed during the release of\na major film by that name. While no studies exactly quantify the magnitude of\nintent-shifting traffic, studies suggest that news events, seasonal topics, pop\nculture, etc account for 50% of all search queries. This paper shows that the\nsignals a search engine receives can be used to both determine that a shift in\nintent has happened, as well as find a result that is now more relevant. We\npresent a meta-algorithm that marries a classifier with a bandit algorithm to\nachieve regret that depends logarithmically on the number of query impressions,\nunder certain assumptions. We provide strong evidence that this regret is close\nto the best achievable. Finally, via a series of experiments, we demonstrate\nthat our algorithm outperforms prior approaches, particularly as the amount of\nintent-shifting traffic increases.\n",
        "published": "2010-07-22T04:58:24Z",
        "pdf_link": "http://arxiv.org/pdf/1007.3799v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.5133v1",
        "title": "Comparison of Support Vector Machine and Back Propagation Neural Network\n  in Evaluating the Enterprise Financial Distress",
        "summary": "  Recently, applying the novel data mining techniques for evaluating enterprise\nfinancial distress has received much research alternation. Support Vector\nMachine (SVM) and back propagation neural (BPN) network has been applied\nsuccessfully in many areas with excellent generalization results, such as rule\nextraction, classification and evaluation. In this paper, a model based on SVM\nwith Gaussian RBF kernel is proposed here for enterprise financial distress\nevaluation. BPN network is considered one of the simplest and are most general\nmethods used for supervised training of multilayered neural network. The\ncomparative results show that through the difference between the performance\nmeasures is marginal; SVM gives higher precision and lower error rates.\n",
        "published": "2010-07-29T07:36:49Z",
        "pdf_link": "http://arxiv.org/pdf/1007.5133v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.0336v1",
        "title": "Close Clustering Based Automated Color Image Annotation",
        "summary": "  Most image-search approaches today are based on the text based tags\nassociated with the images which are mostly human generated and are subject to\nvarious kinds of errors. The results of a query to the image database thus can\noften be misleading and may not satisfy the requirements of the user. In this\nwork we propose our approach to automate this tagging process of images, where\nimage results generated can be fine filtered based on a probabilistic tagging\nmechanism. We implement a tool which helps to automate the tagging process by\nmaintaining a training database, wherein the system is trained to identify\ncertain set of input images, the results generated from which are used to\ncreate a probabilistic tagging mechanism. Given a certain set of segments in an\nimage it calculates the probability of presence of particular keywords. This\nprobability table is further used to generate the candidate tags for input\nimages.\n",
        "published": "2010-08-02T16:30:02Z",
        "pdf_link": "http://arxiv.org/pdf/1008.0336v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.0528v1",
        "title": "Bounded Coordinate-Descent for Biological Sequence Classification in\n  High Dimensional Predictor Space",
        "summary": "  We present a framework for discriminative sequence classification where the\nlearner works directly in the high dimensional predictor space of all\nsubsequences in the training set. This is possible by employing a new\ncoordinate-descent algorithm coupled with bounding the magnitude of the\ngradient for selecting discriminative subsequences fast. We characterize the\nloss functions for which our generic learning algorithm can be applied and\npresent concrete implementations for logistic regression (binomial\nlog-likelihood loss) and support vector machines (squared hinge loss).\nApplication of our algorithm to protein remote homology detection and remote\nfold recognition results in performance comparable to that of state-of-the-art\nmethods (e.g., kernel support vector machines). Unlike state-of-the-art\nclassifiers, the resulting classification models are simply lists of weighted\ndiscriminative subsequences and can thus be interpreted and related to the\nbiological problem.\n",
        "published": "2010-08-03T12:10:40Z",
        "pdf_link": "http://arxiv.org/pdf/1008.0528v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.1398v1",
        "title": "Semi-Supervised Kernel PCA",
        "summary": "  We present three generalisations of Kernel Principal Components Analysis\n(KPCA) which incorporate knowledge of the class labels of a subset of the data\npoints. The first, MV-KPCA, penalises within class variances similar to Fisher\ndiscriminant analysis. The second, LSKPCA is a hybrid of least squares\nregression and kernel PCA. The final LR-KPCA is an iteratively reweighted\nversion of the previous which achieves a sigmoid loss function on the labeled\npoints. We provide a theoretical risk bound as well as illustrative experiments\non real and toy data sets.\n",
        "published": "2010-08-08T11:25:12Z",
        "pdf_link": "http://arxiv.org/pdf/1008.1398v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.4232v1",
        "title": "Online Learning in Case of Unbounded Losses Using the Follow Perturbed\n  Leader Algorithm",
        "summary": "  In this paper the sequential prediction problem with expert advice is\nconsidered for the case where losses of experts suffered at each step cannot be\nbounded in advance. We present some modification of Kalai and Vempala algorithm\nof following the perturbed leader where weights depend on past losses of the\nexperts. New notions of a volume and a scaled fluctuation of a game are\nintroduced. We present a probabilistic algorithm protected from unrestrictedly\nlarge one-step losses. This algorithm has the optimal performance in the case\nwhen the scaled fluctuations of one-step losses of experts of the pool tend to\nzero.\n",
        "published": "2010-08-25T09:09:29Z",
        "pdf_link": "http://arxiv.org/pdf/1008.4232v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.4532v1",
        "title": "Switching between Hidden Markov Models using Fixed Share",
        "summary": "  In prediction with expert advice the goal is to design online prediction\nalgorithms that achieve small regret (additional loss on the whole data)\ncompared to a reference scheme. In the simplest such scheme one compares to the\nloss of the best expert in hindsight. A more ambitious goal is to split the\ndata into segments and compare to the best expert on each segment. This is\nappropriate if the nature of the data changes between segments. The standard\nfixed-share algorithm is fast and achieves small regret compared to this\nscheme.\n  Fixed share treats the experts as black boxes: there are no assumptions about\nhow they generate their predictions. But if the experts are learning, the\nfollowing question arises: should the experts learn from all data or only from\ndata in their own segment? The original algorithm naturally addresses the first\ncase. Here we consider the second option, which is more appropriate exactly\nwhen the nature of the data changes between segments. In general extending\nfixed share to this second case will slow it down by a factor of T on T\noutcomes. We show, however, that no such slowdown is necessary if the experts\nare hidden Markov models.\n",
        "published": "2010-08-26T15:36:22Z",
        "pdf_link": "http://arxiv.org/pdf/1008.4532v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.4654v1",
        "title": "Freezing and Sleeping: Tracking Experts that Learn by Evolving Past\n  Posteriors",
        "summary": "  A problem posed by Freund is how to efficiently track a small pool of experts\nout of a much larger set. This problem was solved when Bousquet and Warmuth\nintroduced their mixing past posteriors (MPP) algorithm in 2001.\n  In Freund's problem the experts would normally be considered black boxes.\nHowever, in this paper we re-examine Freund's problem in case the experts have\ninternal structure that enables them to learn. In this case the problem has two\npossible interpretations: should the experts learn from all data or only from\nthe subsequence on which they are being tracked? The MPP algorithm solves the\nfirst case. Our contribution is to generalise MPP to address the second option.\nThe results we obtain apply to any expert structure that can be formalised\nusing (expert) hidden Markov models. Curiously enough, for our interpretation\nthere are \\emph{two} natural reference schemes: freezing and sleeping. For each\nscheme, we provide an efficient prediction strategy and prove the relevant loss\nbound.\n",
        "published": "2010-08-27T06:53:28Z",
        "pdf_link": "http://arxiv.org/pdf/1008.4654v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.0117v1",
        "title": "Exploring Language-Independent Emotional Acoustic Features via Feature\n  Selection",
        "summary": "  We propose a novel feature selection strategy to discover\nlanguage-independent acoustic features that tend to be responsible for emotions\nregardless of languages, linguistics and other factors. Experimental results\nsuggest that the language-independent feature subset discovered yields the\nperformance comparable to the full feature set on various emotional speech\ncorpora.\n",
        "published": "2010-09-01T08:29:49Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0117v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.0306v1",
        "title": "Fast Overlapping Group Lasso",
        "summary": "  The group Lasso is an extension of the Lasso for feature selection on\n(predefined) non-overlapping groups of features. The non-overlapping group\nstructure limits its applicability in practice. There have been several recent\nattempts to study a more general formulation, where groups of features are\ngiven, potentially with overlaps between the groups. The resulting optimization\nis, however, much more challenging to solve due to the group overlaps. In this\npaper, we consider the efficient optimization of the overlapping group Lasso\npenalized problem. We reveal several key properties of the proximal operator\nassociated with the overlapping group Lasso, and compute the proximal operator\nby solving the smooth and convex dual problem, which allows the use of the\ngradient descent type of algorithms for the optimization. We have performed\nempirical evaluations using the breast cancer gene expression data set, which\nconsists of 8,141 genes organized into (overlapping) gene sets. Experimental\nresults demonstrate the efficiency and effectiveness of the proposed algorithm.\n",
        "published": "2010-09-02T00:25:58Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0306v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.2566v1",
        "title": "Reinforcement Learning by Comparing Immediate Reward",
        "summary": "  This paper introduces an approach to Reinforcement Learning Algorithm by\ncomparing their immediate rewards using a variation of Q-Learning algorithm.\nUnlike the conventional Q-Learning, the proposed algorithm compares current\nreward with immediate reward of past move and work accordingly. Relative reward\nbased Q-learning is an approach towards interactive learning. Q-Learning is a\nmodel free reinforcement learning method that used to learn the agents. It is\nobserved that under normal circumstances algorithm take more episodes to reach\noptimal Q-value due to its normal reward or sometime negative reward. In this\nnew form of algorithm agents select only those actions which have a higher\nimmediate reward signal in comparison to previous one. The contribution of this\narticle is the presentation of new Q-Learning Algorithm in order to maximize\nthe performance of algorithm and reduce the number of episode required to reach\noptimal Q-value. Effectiveness of proposed algorithm is simulated in a 20 x20\nGrid world deterministic environment and the result for the two forms of\nQ-Learning Algorithms is given.\n",
        "published": "2010-09-14T03:53:11Z",
        "pdf_link": "http://arxiv.org/pdf/1009.2566v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.3240v2",
        "title": "A Unified View of Regularized Dual Averaging and Mirror Descent with\n  Implicit Updates",
        "summary": "  We study three families of online convex optimization algorithms:\nfollow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual\naveraging (RDA), and composite-objective mirror descent. We first prove\nequivalence theorems that show all of these algorithms are instantiations of a\ngeneral FTRL update. This provides theoretical insight on previous experimental\nobservations. In particular, even though the FOBOS composite mirror descent\nalgorithm handles L1 regularization explicitly, it has been observed that RDA\nis even more effective at producing sparsity. Our results demonstrate that\nFOBOS uses subgradient approximations to the L1 penalty from previous rounds,\nleading to less sparsity than RDA, which handles the cumulative penalty in\nclosed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two,\nand outperforms both on a large, real-world dataset.\n  Our second contribution is a unified analysis which produces regret bounds\nthat match (up to logarithmic terms) or improve the best previously known\nbounds. This analysis also extends these algorithms in two important ways: we\nsupport a more general type of composite objective and we analyze implicit\nupdates, which replace the subgradient approximation of the current loss\nfunction with an exact optimization.\n",
        "published": "2010-09-16T18:40:32Z",
        "pdf_link": "http://arxiv.org/pdf/1009.3240v2"
    },
    {
        "id": "http://arxiv.org/abs/1009.3346v1",
        "title": "Conditional Random Fields and Support Vector Machines: A Hybrid Approach",
        "summary": "  We propose a novel hybrid loss for multiclass and structured prediction\nproblems that is a convex combination of log loss for Conditional Random Fields\n(CRFs) and a multiclass hinge loss for Support Vector Machines (SVMs). We\nprovide a sufficient condition for when the hybrid loss is Fisher consistent\nfor classification. This condition depends on a measure of dominance between\nlabels - specifically, the gap in per observation probabilities between the\nmost likely labels. We also prove Fisher consistency is necessary for\nparametric consistency when learning models such as CRFs.\n  We demonstrate empirically that the hybrid loss typically performs as least\nas well as - and often better than - both of its constituent losses on variety\nof tasks. In doing so we also provide an empirical comparison of the efficacy\nof probabilistic and margin based approaches to multiclass and structured\nprediction and the effects of label dominance on these results.\n",
        "published": "2010-09-17T06:47:25Z",
        "pdf_link": "http://arxiv.org/pdf/1009.3346v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.3604v5",
        "title": "Geometric Decision Tree",
        "summary": "  In this paper we present a new algorithm for learning oblique decision trees.\nMost of the current decision tree algorithms rely on impurity measures to\nassess the goodness of hyperplanes at each node while learning a decision tree\nin a top-down fashion. These impurity measures do not properly capture the\ngeometric structures in the data. Motivated by this, our algorithm uses a\nstrategy to assess the hyperplanes in such a way that the geometric structure\nin the data is taken into account. At each node of the decision tree, we find\nthe clustering hyperplanes for both the classes and use their angle bisectors\nas the split rule at that node. We show through empirical studies that this\nidea leads to small decision trees and better performance. We also present some\nanalysis to show that the angle bisectors of clustering hyperplanes that we use\nas the split rules at each node, are solutions of an interesting optimization\nproblem and hence argue that this is a principled method of learning a decision\ntree.\n",
        "published": "2010-09-19T03:54:12Z",
        "pdf_link": "http://arxiv.org/pdf/1009.3604v5"
    },
    {
        "id": "http://arxiv.org/abs/1009.3613v5",
        "title": "On the Doubt about Margin Explanation of Boosting",
        "summary": "  Margin theory provides one of the most popular explanations to the success of\n\\texttt{AdaBoost}, where the central point lies in the recognition that\n\\textit{margin} is the key for characterizing the performance of\n\\texttt{AdaBoost}. This theory has been very influential, e.g., it has been\nused to argue that \\texttt{AdaBoost} usually does not overfit since it tends to\nenlarge the margin even after the training error reaches zero. Previously the\n\\textit{minimum margin bound} was established for \\texttt{AdaBoost}, however,\n\\cite{Breiman1999} pointed out that maximizing the minimum margin does not\nnecessarily lead to a better generalization. Later, \\cite{Reyzin:Schapire2006}\nemphasized that the margin distribution rather than minimum margin is crucial\nto the performance of \\texttt{AdaBoost}. In this paper, we first present the\n\\textit{$k$th margin bound} and further study on its relationship to previous\nwork such as the minimum margin bound and Emargin bound. Then, we improve the\nprevious empirical Bernstein bounds\n\\citep{Maurer:Pontil2009,Audibert:Munos:Szepesvari2009}, and based on such\nfindings, we defend the margin-based explanation against Breiman's doubts by\nproving a new generalization error bound that considers exactly the same\nfactors as \\cite{Schapire:Freund:Bartlett:Lee1998} but is sharper than\n\\cite{Breiman1999}'s minimum margin bound. By incorporating factors such as\naverage margin and variance, we present a generalization error bound that is\nheavily related to the whole margin distribution. We also provide margin\ndistribution bounds for generalization error of voting classifiers in finite\nVC-dimension space.\n",
        "published": "2010-09-19T07:26:37Z",
        "pdf_link": "http://arxiv.org/pdf/1009.3613v5"
    },
    {
        "id": "http://arxiv.org/abs/1009.3702v1",
        "title": "Totally Corrective Multiclass Boosting with Binary Weak Learners",
        "summary": "  In this work, we propose a new optimization framework for multiclass boosting\nlearning. In the literature, AdaBoost.MO and AdaBoost.ECC are the two\nsuccessful multiclass boosting algorithms, which can use binary weak learners.\nWe explicitly derive these two algorithms' Lagrange dual problems based on\ntheir regularized loss functions. We show that the Lagrange dual formulations\nenable us to design totally-corrective multiclass algorithms by using the\nprimal-dual optimization technique. Experiments on benchmark data sets suggest\nthat our multiclass boosting can achieve a comparable generalization capability\nwith state-of-the-art, but the convergence speed is much faster than stage-wise\ngradient descent boosting. In other words, the new totally corrective\nalgorithms can maximize the margin more aggressively.\n",
        "published": "2010-09-20T06:35:11Z",
        "pdf_link": "http://arxiv.org/pdf/1009.3702v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.3896v2",
        "title": "Optimistic Rates for Learning with a Smooth Loss",
        "summary": "  We establish an excess risk bound of O(H R_n^2 + R_n \\sqrt{H L*}) for\nempirical risk minimization with an H-smooth loss function and a hypothesis\nclass with Rademacher complexity R_n, where L* is the best risk achievable by\nthe hypothesis class. For typical hypothesis classes where R_n = \\sqrt{R/n},\nthis translates to a learning rate of O(RH/n) in the separable (L*=0) case and\nO(RH/n + \\sqrt{L^* RH/n}) more generally. We also provide similar guarantees\nfor online and stochastic convex optimization with a smooth non-negative\nobjective.\n",
        "published": "2010-09-20T17:35:35Z",
        "pdf_link": "http://arxiv.org/pdf/1009.3896v2"
    },
    {
        "id": "http://arxiv.org/abs/1009.4766v1",
        "title": "Efficient L1/Lq Norm Regularization",
        "summary": "  Sparse learning has recently received increasing attention in many areas\nincluding machine learning, statistics, and applied mathematics. The mixed-norm\nregularization based on the L1/Lq norm with q > 1 is attractive in many\napplications of regression and classification in that it facilitates group\nsparsity in the model. The resulting optimization problem is, however,\nchallenging to solve due to the structure of the L1/Lq -regularization.\nExisting work deals with special cases including q = 2,infinity, and they\ncannot be easily extended to the general case. In this paper, we propose an\nefficient algorithm based on the accelerated gradient method for solving the\nL1/Lq -regularized problem, which is applicable for all values of q larger than\n1, thus significantly extending existing work. One key building block of the\nproposed algorithm is the L1/Lq -regularized Euclidean projection (EP1q). Our\ntheoretical analysis reveals the key properties of EP1q and illustrates why\nEP1q for the general q is significantly more challenging to solve than the\nspecial cases. Based on our theoretical analysis, we develop an efficient\nalgorithm for EP1q by solving two zero finding problems. Experimental results\ndemonstrate the efficiency of the proposed algorithm.\n",
        "published": "2010-09-24T05:53:28Z",
        "pdf_link": "http://arxiv.org/pdf/1009.4766v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.4791v2",
        "title": "Multi-parametric Solution-path Algorithm for Instance-weighted Support\n  Vector Machines",
        "summary": "  An instance-weighted variant of the support vector machine (SVM) has\nattracted considerable attention recently since they are useful in various\nmachine learning tasks such as non-stationary data analysis, heteroscedastic\ndata modeling, transfer learning, learning to rank, and transduction. An\nimportant challenge in these scenarios is to overcome the computational\nbottleneck---instance weights often change dynamically or adaptively, and thus\nthe weighted SVM solutions must be repeatedly computed. In this paper, we\ndevelop an algorithm that can efficiently and exactly update the weighted SVM\nsolutions for arbitrary change of instance weights. Technically, this\ncontribution can be regarded as an extension of the conventional solution-path\nalgorithm for a single regularization parameter to multiple instance-weight\nparameters. However, this extension gives rise to a significant problem that\nbreakpoints (at which the solution path turns) have to be identified in\nhigh-dimensional space. To facilitate this, we introduce a parametric\nrepresentation of instance weights. We also provide a geometric interpretation\nin weight space using a notion of critical region: a polyhedron in which the\ncurrent affine solution remains to be optimal. Then we find breakpoints at\nintersections of the solution path and boundaries of polyhedrons. Through\nextensive experiments on various practical applications, we demonstrate the\nusefulness of the proposed algorithm.\n",
        "published": "2010-09-24T09:53:32Z",
        "pdf_link": "http://arxiv.org/pdf/1009.4791v2"
    },
    {
        "id": "http://arxiv.org/abs/1009.5419v2",
        "title": "Portfolio Allocation for Bayesian Optimization",
        "summary": "  Bayesian optimization with Gaussian processes has become an increasingly\npopular tool in the machine learning community. It is efficient and can be used\nwhen very little is known about the objective function, making it popular in\nexpensive black-box optimization scenarios. It uses Bayesian methods to sample\nthe objective efficiently using an acquisition function which incorporates the\nmodel's estimate of the objective and the uncertainty at any given point.\nHowever, there are several different parameterized acquisition functions in the\nliterature, and it is often unclear which one to use. Instead of using a single\nacquisition function, we adopt a portfolio of acquisition functions governed by\nan online multi-armed bandit strategy. We propose several portfolio strategies,\nthe best of which we call GP-Hedge, and show that this method outperforms the\nbest individual acquisition function. We also provide a theoretical bound on\nthe algorithm's performance.\n",
        "published": "2010-09-28T00:41:45Z",
        "pdf_link": "http://arxiv.org/pdf/1009.5419v2"
    },
    {
        "id": "http://arxiv.org/abs/1009.5773v4",
        "title": "Fast Reinforcement Learning for Energy-Efficient Wireless Communications",
        "summary": "  We consider the problem of energy-efficient point-to-point transmission of\ndelay-sensitive data (e.g. multimedia data) over a fading channel. Existing\nresearch on this topic utilizes either physical-layer centric solutions, namely\npower-control and adaptive modulation and coding (AMC), or system-level\nsolutions based on dynamic power management (DPM); however, there is currently\nno rigorous and unified framework for simultaneously utilizing both\nphysical-layer centric and system-level techniques to achieve the minimum\npossible energy consumption, under delay constraints, in the presence of\nstochastic and a priori unknown traffic and channel conditions. In this report,\nwe propose such a framework. We formulate the stochastic optimization problem\nas a Markov decision process (MDP) and solve it online using reinforcement\nlearning. The advantages of the proposed online method are that (i) it does not\nrequire a priori knowledge of the traffic arrival and channel statistics to\ndetermine the jointly optimal power-control, AMC, and DPM policies; (ii) it\nexploits partial information about the system so that less information needs to\nbe learned than when using conventional reinforcement learning algorithms; and\n(iii) it obviates the need for action exploration, which severely limits the\nadaptation speed and run-time performance of conventional reinforcement\nlearning algorithms. Our results show that the proposed learning algorithms can\nconverge up to two orders of magnitude faster than a state-of-the-art learning\nalgorithm for physical layer power-control and up to three orders of magnitude\nfaster than conventional reinforcement learning algorithms.\n",
        "published": "2010-09-29T05:23:20Z",
        "pdf_link": "http://arxiv.org/pdf/1009.5773v4"
    },
    {
        "id": "http://arxiv.org/abs/1009.5972v1",
        "title": "The Attentive Perceptron",
        "summary": "  We propose a focus of attention mechanism to speed up the Perceptron\nalgorithm. Focus of attention speeds up the Perceptron algorithm by lowering\nthe number of features evaluated throughout training and prediction. Whereas\nthe traditional Perceptron evaluates all the features of each example, the\nAttentive Perceptron evaluates less features for easy to classify examples,\nthereby achieving significant speedups and small losses in prediction accuracy.\nFocus of attention allows the Attentive Perceptron to stop the evaluation of\nfeatures at any interim point and filter the example. This creates an attentive\nfilter which concentrates computation at examples that are hard to classify,\nand quickly filters examples that are easy to classify.\n",
        "published": "2010-09-29T18:55:02Z",
        "pdf_link": "http://arxiv.org/pdf/1009.5972v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.0287v1",
        "title": "Queue-Aware Distributive Resource Control for Delay-Sensitive Two-Hop\n  MIMO Cooperative Systems",
        "summary": "  In this paper, we consider a queue-aware distributive resource control\nalgorithm for two-hop MIMO cooperative systems. We shall illustrate that relay\nbuffering is an effective way to reduce the intrinsic half-duplex penalty in\ncooperative systems. The complex interactions of the queues at the source node\nand the relays are modeled as an average-cost infinite horizon Markov Decision\nProcess (MDP). The traditional approach solving this MDP problem involves\ncentralized control with huge complexity. To obtain a distributive and low\ncomplexity solution, we introduce a linear structure which approximates the\nvalue function of the associated Bellman equation by the sum of per-node value\nfunctions. We derive a distributive two-stage two-winner auction-based control\npolicy which is a function of the local CSI and local QSI only. Furthermore, to\nestimate the best fit approximation parameter, we propose a distributive online\nstochastic learning algorithm using stochastic approximation theory. Finally,\nwe establish technical conditions for almost-sure convergence and show that\nunder heavy traffic, the proposed low complexity distributive control is global\noptimal.\n",
        "published": "2010-10-02T03:57:46Z",
        "pdf_link": "http://arxiv.org/pdf/1010.0287v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.1526v6",
        "title": "Time Series Classification by Class-Specific Mahalanobis Distance\n  Measures",
        "summary": "  To classify time series by nearest neighbors, we need to specify or learn one\nor several distance measures. We consider variations of the Mahalanobis\ndistance measures which rely on the inverse covariance matrix of the data.\nUnfortunately --- for time series data --- the covariance matrix has often low\nrank. To alleviate this problem we can either use a pseudoinverse, covariance\nshrinking or limit the matrix to its diagonal. We review these alternatives and\nbenchmark them against competitive methods such as the related Large Margin\nNearest Neighbor Classification (LMNN) and the Dynamic Time Warping (DTW)\ndistance. As we expected, we find that the DTW is superior, but the Mahalanobis\ndistance measures are one to two orders of magnitude faster. To get best\nresults with Mahalanobis distance measures, we recommend learning one distance\nmeasure per class using either covariance shrinking or the diagonal approach.\n",
        "published": "2010-10-07T19:48:23Z",
        "pdf_link": "http://arxiv.org/pdf/1010.1526v6"
    },
    {
        "id": "http://arxiv.org/abs/1010.1763v3",
        "title": "Algorithms for nonnegative matrix factorization with the beta-divergence",
        "summary": "  This paper describes algorithms for nonnegative matrix factorization (NMF)\nwith the beta-divergence (beta-NMF). The beta-divergence is a family of cost\nfunctions parametrized by a single shape parameter beta that takes the\nEuclidean distance, the Kullback-Leibler divergence and the Itakura-Saito\ndivergence as special cases (beta = 2,1,0, respectively). The proposed\nalgorithms are based on a surrogate auxiliary function (a local majorization of\nthe criterion function). We first describe a majorization-minimization (MM)\nalgorithm that leads to multiplicative updates, which differ from standard\nheuristic multiplicative updates by a beta-dependent power exponent. The\nmonotonicity of the heuristic algorithm can however be proven for beta in (0,1)\nusing the proposed auxiliary function. Then we introduce the concept of\nmajorization-equalization (ME) algorithm which produces updates that move along\nconstant level sets of the auxiliary function and lead to larger steps than MM.\nSimulations on synthetic and real data illustrate the faster convergence of the\nME approach. The paper also describes how the proposed algorithms can be\nadapted to two common variants of NMF : penalized NMF (i.e., when a penalty\nfunction of the factors is added to the criterion function) and convex-NMF\n(when the dictionary is assumed to belong to a known subspace).\n",
        "published": "2010-10-08T18:53:27Z",
        "pdf_link": "http://arxiv.org/pdf/1010.1763v3"
    },
    {
        "id": "http://arxiv.org/abs/1010.3484v1",
        "title": "Hardness Results for Agnostically Learning Low-Degree Polynomial\n  Threshold Functions",
        "summary": "  Hardness results for maximum agreement problems have close connections to\nhardness results for proper learning in computational learning theory. In this\npaper we prove two hardness results for the problem of finding a low degree\npolynomial threshold function (PTF) which has the maximum possible agreement\nwith a given set of labeled examples in $\\R^n \\times \\{-1,1\\}.$ We prove that\nfor any constants $d\\geq 1, \\eps > 0$,\n  {itemize}\n  Assuming the Unique Games Conjecture, no polynomial-time algorithm can find a\ndegree-$d$ PTF that is consistent with a $(\\half + \\eps)$ fraction of a given\nset of labeled examples in $\\R^n \\times \\{-1,1\\}$, even if there exists a\ndegree-$d$ PTF that is consistent with a $1-\\eps$ fraction of the examples.\n  It is $\\NP$-hard to find a degree-2 PTF that is consistent with a $(\\half +\n\\eps)$ fraction of a given set of labeled examples in $\\R^n \\times \\{-1,1\\}$,\neven if there exists a halfspace (degree-1 PTF) that is consistent with a $1 -\n\\eps$ fraction of the examples.\n  {itemize}\n  These results immediately imply the following hardness of learning results:\n(i) Assuming the Unique Games Conjecture, there is no better-than-trivial\nproper learning algorithm that agnostically learns degree-$d$ PTFs under\narbitrary distributions; (ii) There is no better-than-trivial learning\nalgorithm that outputs degree-2 PTFs and agnostically learns halfspaces (i.e.\ndegree-1 PTFs) under arbitrary distributions.\n",
        "published": "2010-10-18T05:46:46Z",
        "pdf_link": "http://arxiv.org/pdf/1010.3484v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.4050v1",
        "title": "Efficient Matrix Completion with Gaussian Models",
        "summary": "  A general framework based on Gaussian models and a MAP-EM algorithm is\nintroduced in this paper for solving matrix/table completion problems. The\nnumerical experiments with the standard and challenging movie ratings data show\nthat the proposed approach, based on probably one of the simplest probabilistic\nmodels, leads to the results in the same ballpark as the state-of-the-art, at a\nlower computational cost.\n",
        "published": "2010-10-19T21:01:45Z",
        "pdf_link": "http://arxiv.org/pdf/1010.4050v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.4253v1",
        "title": "Large-Scale Clustering Based on Data Compression",
        "summary": "  This paper considers the clustering problem for large data sets. We propose\nan approach based on distributed optimization. The clustering problem is\nformulated as an optimization problem of maximizing the classification gain. We\nshow that the optimization problem can be reformulated and decomposed into\nsmall-scale sub optimization problems by using the Dantzig-Wolfe decomposition\nmethod. Generally speaking, the Dantzig-Wolfe method can only be used for\nconvex optimization problems, where the duality gaps are zero. Even though, the\nconsidered optimization problem in this paper is non-convex, we prove that the\nduality gap goes to zero, as the problem size goes to infinity. Therefore, the\nDantzig-Wolfe method can be applied here. In the proposed approach, the\nclustering problem is iteratively solved by a group of computers coordinated by\none center processor, where each computer solves one independent small-scale\nsub optimization problem during each iteration, and only a small amount of data\ncommunication is needed between the computers and center processor. Numerical\nresults show that the proposed approach is effective and efficient.\n",
        "published": "2010-10-20T17:21:38Z",
        "pdf_link": "http://arxiv.org/pdf/1010.4253v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.4408v1",
        "title": "Sublinear Optimization for Machine Learning",
        "summary": "  We give sublinear-time approximation algorithms for some optimization\nproblems arising in machine learning, such as training linear classifiers and\nfinding minimum enclosing balls. Our algorithms can be extended to some\nkernelized versions of these problems, such as SVDD, hard margin SVM, and\nL2-SVM, for which sublinear-time algorithms were not known before. These new\nalgorithms use a combination of a novel sampling techniques and a new\nmultiplicative update algorithm. We give lower bounds which show the running\ntimes of many of our algorithms to be nearly best possible in the unit-cost RAM\nmodel. We also give implementations of our algorithms in the semi-streaming\nsetting, obtaining the first low pass polylogarithmic space and sublinear time\nalgorithms achieving arbitrary approximation factor.\n",
        "published": "2010-10-21T09:57:12Z",
        "pdf_link": "http://arxiv.org/pdf/1010.4408v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.0472v1",
        "title": "Regularized Risk Minimization by Nesterov's Accelerated Gradient\n  Methods: Algorithmic Extensions and Empirical Studies",
        "summary": "  Nesterov's accelerated gradient methods (AGM) have been successfully applied\nin many machine learning areas. However, their empirical performance on\ntraining max-margin models has been inferior to existing specialized solvers.\nIn this paper, we first extend AGM to strongly convex and composite objective\nfunctions with Bregman style prox-functions. Our unifying framework covers both\nthe $\\infty$-memory and 1-memory styles of AGM, tunes the Lipschiz constant\nadaptively, and bounds the duality gap. Then we demonstrate various ways to\napply this framework of methods to a wide range of machine learning problems.\nEmphasis will be given on their rate of convergence and how to efficiently\ncompute the gradient and optimize the models. The experimental results show\nthat with our extensions AGM outperforms state-of-the-art solvers on max-margin\nmodels.\n",
        "published": "2010-11-01T23:41:35Z",
        "pdf_link": "http://arxiv.org/pdf/1011.0472v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.1576v4",
        "title": "Online Importance Weight Aware Updates",
        "summary": "  An importance weight quantifies the relative importance of one example over\nanother, coming up in applications of boosting, asymmetric classification\ncosts, reductions, and active learning. The standard approach for dealing with\nimportance weights in gradient descent is via multiplication of the gradient.\nWe first demonstrate the problems of this approach when importance weights are\nlarge, and argue in favor of more sophisticated ways for dealing with them. We\nthen develop an approach which enjoys an invariance property: that updating\ntwice with importance weight $h$ is equivalent to updating once with importance\nweight $2h$. For many important losses this has a closed form update which\nsatisfies standard regret guarantees when all examples have $h=1$. We also\nbriefly discuss two other reasonable approaches for handling large importance\nweights. Empirically, these approaches yield substantially superior prediction\nwith similar computational performance while reducing the sensitivity of the\nalgorithm to the exact setting of the learning rate. We apply these to online\nactive learning yielding an extraordinarily fast active learning algorithm that\nworks even in the presence of adversarial noise.\n",
        "published": "2010-11-06T18:40:15Z",
        "pdf_link": "http://arxiv.org/pdf/1011.1576v4"
    },
    {
        "id": "http://arxiv.org/abs/1011.5668v1",
        "title": "On Theorem 2.3 in \"Prediction, Learning, and Games\" by Cesa-Bianchi and\n  Lugosi",
        "summary": "  The note presents a modified proof of a loss bound for the exponentially\nweighted average forecaster with time-varying potential. The regret term of the\nalgorithm is upper-bounded by sqrt{n ln(N)} (uniformly in n), where N is the\nnumber of experts and n is the number of steps.\n",
        "published": "2010-11-25T18:52:30Z",
        "pdf_link": "http://arxiv.org/pdf/1011.5668v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.4170v1",
        "title": "The Role of Normalization in the Belief Propagation Algorithm",
        "summary": "  An important part of problems in statistical physics and computer science can\nbe expressed as the computation of marginal probabilities over a Markov Random\nField. The belief propagation algorithm, which is an exact procedure to compute\nthese marginals when the underlying graph is a tree, has gained its popularity\nas an efficient way to approximate them in the more general case. In this\npaper, we focus on an aspect of the algorithm that did not get that much\nattention in the literature, which is the effect of the normalization of the\nmessages. We show in particular that, for a large class of normalization\nstrategies, it is possible to focus only on belief convergence. Following this,\nwe express the necessary and sufficient conditions for local stability of a\nfixed point in terms of the graph structure and the beliefs values at the fixed\npoint. We also explicit some connexion between the normalization constants and\nthe underlying Bethe Free Energy.\n",
        "published": "2011-01-21T16:11:05Z",
        "pdf_link": "http://arxiv.org/pdf/1101.4170v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.4681v6",
        "title": "Close the Gaps: A Learning-while-Doing Algorithm for a Class of\n  Single-Product Revenue Management Problems",
        "summary": "  We consider a retailer selling a single product with limited on-hand\ninventory over a finite selling season. Customer demand arrives according to a\nPoisson process, the rate of which is influenced by a single action taken by\nthe retailer (such as price adjustment, sales commission, advertisement\nintensity, etc.). The relationship between the action and the demand rate is\nnot known in advance. However, the retailer is able to learn the optimal action\n\"on the fly\" as she maximizes her total expected revenue based on the observed\ndemand reactions.\n  Using the pricing problem as an example, we propose a dynamic\n\"learning-while-doing\" algorithm that only involves function value estimation\nto achieve a near-optimal performance. Our algorithm employs a series of\nshrinking price intervals and iteratively tests prices within that interval\nusing a set of carefully chosen parameters. We prove that the convergence rate\nof our algorithm is among the fastest of all possible algorithms in terms of\nasymptotic \"regret\" (the relative loss comparing to the full information\noptimal solution). Our result closes the performance gaps between parametric\nand non-parametric learning and between a post-price mechanism and a\ncustomer-bidding mechanism. Important managerial insight from this research is\nthat the values of information on both the parametric form of the demand\nfunction as well as each customer's exact reservation price are less important\nthan prior literature suggests. Our results also suggest that firms would be\nbetter off to perform dynamic learning and action concurrently rather than\nsequentially.\n",
        "published": "2011-01-24T22:12:37Z",
        "pdf_link": "http://arxiv.org/pdf/1101.4681v6"
    },
    {
        "id": "http://arxiv.org/abs/1101.5039v1",
        "title": "A Novel Template-Based Learning Model",
        "summary": "  This article presents a model which is capable of learning and abstracting\nnew concepts based on comparing observations and finding the resemblance\nbetween the observations. In the model, the new observations are compared with\nthe templates which have been derived from the previous experiences. In the\nfirst stage, the objects are first represented through a geometric description\nwhich is used for finding the object boundaries and a descriptor which is\ninspired by the human visual system and then they are fed into the model. Next,\nthe new observations are identified through comparing them with the\npreviously-learned templates and are used for producing new templates. The\ncomparisons are made based on measures like Euclidean or correlation distance.\nThe new template is created by applying onion-pealing algorithm. The algorithm\nconsecutively uses convex hulls which are made by the points representing the\nobjects. If the new observation is remarkably similar to one of the observed\ncategories, it is no longer utilized in creating a new template. The existing\ntemplates are used to provide a description of the new observation. This\ndescription is provided in the templates space. Each template represents a\ndimension of the feature space. The degree of the resemblance each template\nbears to each object indicates the value associated with the object in that\ndimension of the templates space. In this way, the description of the new\nobservation becomes more accurate and detailed as the time passes and the\nexperiences increase. We have used this model for learning and recognizing the\nnew polygons in the polygon space. Representing the polygons was made possible\nthrough employing a geometric method and a method inspired by human visual\nsystem. Various implementations of the model have been compared. The evaluation\nresults of the model prove its efficiency in learning and deriving new\ntemplates.\n",
        "published": "2011-01-26T12:21:13Z",
        "pdf_link": "http://arxiv.org/pdf/1101.5039v1"
    },
    {
        "id": "http://arxiv.org/abs/1102.0836v2",
        "title": "EigenNet: A Bayesian hybrid of generative and conditional models for\n  sparse learning",
        "summary": "  It is a challenging task to select correlated variables in a high dimensional\nspace. To address this challenge, the elastic net has been developed and\nsuccessfully applied to many applications. Despite its great success, the\nelastic net does not explicitly use correlation information embedded in data to\nselect correlated variables. To overcome this limitation, we present a novel\nBayesian hybrid model, the EigenNet, that uses the eigenstructures of data to\nguide variable selection. Specifically, it integrates a sparse conditional\nclassification model with a generative model capturing variable correlations in\na principled Bayesian framework. We reparameterize the hybrid model in the\neigenspace to avoid overfiting and to increase the computational efficiency of\nits MCMC sampler. Furthermore, we provide an alternative view to the EigenNet\nfrom a regularization perspective: the EigenNet has an adaptive\neigenspace-based composite regularizer, which naturally generalizes the\n$l_{1/2}$ regularizer used by the elastic net. Experiments on synthetic and\nreal data show that the EigenNet significantly outperforms the lasso, the\nelastic net, and the Bayesian lasso in terms of prediction accuracy, especially\nwhen the number of training samples is smaller than the number of variables.\n",
        "published": "2011-02-04T04:40:07Z",
        "pdf_link": "http://arxiv.org/pdf/1102.0836v2"
    },
    {
        "id": "http://arxiv.org/abs/1102.2808v5",
        "title": "Transductive Ordinal Regression",
        "summary": "  Ordinal regression is commonly formulated as a multi-class problem with\nordinal constraints. The challenge of designing accurate classifiers for\nordinal regression generally increases with the number of classes involved, due\nto the large number of labeled patterns that are needed. The availability of\nordinal class labels, however, is often costly to calibrate or difficult to\nobtain. Unlabeled patterns, on the other hand, often exist in much greater\nabundance and are freely available. To take benefits from the abundance of\nunlabeled patterns, we present a novel transductive learning paradigm for\nordinal regression in this paper, namely Transductive Ordinal Regression (TOR).\nThe key challenge of the present study lies in the precise estimation of both\nthe ordinal class label of the unlabeled data and the decision functions of the\nordinal classes, simultaneously. The core elements of the proposed TOR include\nan objective function that caters to several commonly used loss functions\ncasted in transductive settings, for general ordinal regression. A label\nswapping scheme that facilitates a strictly monotonic decrease in the objective\nfunction value is also introduced. Extensive numerical studies on commonly used\nbenchmark datasets including the real world sentiment prediction problem are\nthen presented to showcase the characteristics and efficacies of the proposed\ntransductive ordinal regression. Further, comparisons to recent\nstate-of-the-art ordinal regression methods demonstrate the introduced\ntransductive learning paradigm for ordinal regression led to the robust and\nimproved performance.\n",
        "published": "2011-02-14T15:53:06Z",
        "pdf_link": "http://arxiv.org/pdf/1102.2808v5"
    },
    {
        "id": "http://arxiv.org/abs/1103.0598v1",
        "title": "Learning transformed product distributions",
        "summary": "  We consider the problem of learning an unknown product distribution $X$ over\n$\\{0,1\\}^n$ using samples $f(X)$ where $f$ is a \\emph{known} transformation\nfunction. Each choice of a transformation function $f$ specifies a learning\nproblem in this framework.\n  Information-theoretic arguments show that for every transformation function\n$f$ the corresponding learning problem can be solved to accuracy $\\eps$, using\n$\\tilde{O}(n/\\eps^2)$ examples, by a generic algorithm whose running time may\nbe exponential in $n.$ We show that this learning problem can be\ncomputationally intractable even for constant $\\eps$ and rather simple\ntransformation functions. Moreover, the above sample complexity bound is nearly\noptimal for the general problem, as we give a simple explicit linear\ntransformation function $f(x)=w \\cdot x$ with integer weights $w_i \\leq n$ and\nprove that the corresponding learning problem requires $\\Omega(n)$ samples.\n  As our main positive result we give a highly efficient algorithm for learning\na sum of independent unknown Bernoulli random variables, corresponding to the\ntransformation function $f(x)= \\sum_{i=1}^n x_i$. Our algorithm learns to\n$\\eps$-accuracy in poly$(n)$ time, using a surprising poly$(1/\\eps)$ number of\nsamples that is independent of $n.$ We also give an efficient algorithm that\nuses $\\log n \\cdot \\poly(1/\\eps)$ samples but has running time that is only\n$\\poly(\\log n, 1/\\eps).$\n",
        "published": "2011-03-03T02:46:51Z",
        "pdf_link": "http://arxiv.org/pdf/1103.0598v1"
    },
    {
        "id": "http://arxiv.org/abs/1103.1013v2",
        "title": "A Feature Selection Method for Multivariate Performance Measures",
        "summary": "  Feature selection with specific multivariate performance measures is the key\nto the success of many applications, such as image retrieval and text\nclassification. The existing feature selection methods are usually designed for\nclassification error. In this paper, we propose a generalized sparse\nregularizer. Based on the proposed regularizer, we present a unified feature\nselection framework for general loss functions. In particular, we study the\nnovel feature selection paradigm by optimizing multivariate performance\nmeasures. The resultant formulation is a challenging problem for\nhigh-dimensional data. Hence, a two-layer cutting plane algorithm is proposed\nto solve this problem, and the convergence is presented. In addition, we adapt\nthe proposed method to optimize multivariate measures for multiple instance\nlearning problems. The analyses by comparing with the state-of-the-art feature\nselection methods show that the proposed method is superior to others.\nExtensive experiments on large-scale and high-dimensional real world datasets\nshow that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a\nsmall subset of features, and achieves significantly improved performances over\nSVM$^{perf}$ in terms of $F_1$-score.\n",
        "published": "2011-03-05T07:10:41Z",
        "pdf_link": "http://arxiv.org/pdf/1103.1013v2"
    },
    {
        "id": "http://arxiv.org/abs/1103.4204v1",
        "title": "Parallel Online Learning",
        "summary": "  In this work we study parallelization of online learning, a core primitive in\nmachine learning. In a parallel environment all known approaches for parallel\nonline learning lead to delayed updates, where the model is updated using\nout-of-date information. In the worst case, or when examples are temporally\ncorrelated, delay can have a very adverse effect on the learning algorithm.\nHere, we analyze and present preliminary empirical results on a set of learning\narchitectures based on a feature sharding approach that present various\ntradeoffs between delay, degree of parallelism, representation power and\nempirical performance.\n",
        "published": "2011-03-22T04:54:35Z",
        "pdf_link": "http://arxiv.org/pdf/1103.4204v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.0235v1",
        "title": "Gaussian Robust Classification",
        "summary": "  Supervised learning is all about the ability to generalize knowledge.\nSpecifically, the goal of the learning is to train a classifier using training\ndata, in such a way that it will be capable of classifying new unseen data\ncorrectly. In order to acheive this goal, it is important to carefully design\nthe learner, so it will not overfit the training data. The later can is done\nusually by adding a regularization term. The statistical learning theory\nexplains the success of this method by claiming that it restricts the\ncomplexity of the learned model. This explanation, however, is rather abstract\nand does not have a geometric intuition. The generalization error of a\nclassifier may be thought of as correlated with its robustness to perturbations\nof the data: a classifier that copes with disturbance is expected to generalize\nwell. Indeed, Xu et al. [2009] have shown that the SVM formulation is\nequivalent to a robust optimization (RO) formulation, in which an adversary\ndisplaces the training and testing points within a ball of pre-determined\nradius. In this work we explore a different kind of robustness, namely changing\neach data point with a Gaussian cloud centered at the sample. Loss is evaluated\nas the expectation of an underlying loss function on the cloud. This setup fits\nthe fact that in many applications, the data is sampled along with noise. We\ndevelop an RO framework, in which the adversary chooses the covariance of the\nnoise. In our algorithm named GURU, the tuning parameter is a spectral bound on\nthe noise, thus it can be estimated using physical or applicative\nconsiderations. Our experiments show that this framework performs as well as\nSVM and even slightly better in some cases. Generalizations for Mercer kernels\nand for the multiclass case are presented as well. We also show that our\nframework may be further generalized, using the technique of convex perspective\nfunctions.\n",
        "published": "2011-04-01T19:33:05Z",
        "pdf_link": "http://arxiv.org/pdf/1104.0235v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.0651v3",
        "title": "Meaningful Clustered Forest: an Automatic and Robust Clustering\n  Algorithm",
        "summary": "  We propose a new clustering technique that can be regarded as a numerical\nmethod to compute the proximity gestalt. The method analyzes edge length\nstatistics in the MST of the dataset and provides an a contrario cluster\ndetection criterion. The approach is fully parametric on the chosen distance\nand can detect arbitrarily shaped clusters. The method is also automatic, in\nthe sense that only a single parameter is left to the user. This parameter has\nan intuitive interpretation as it controls the expected number of false\ndetections. We show that the iterative application of our method can (1)\nprovide robustness to noise and (2) solve a masking phenomenon in which a\nhighly populated and salient cluster dominates the scene and inhibits the\ndetection of less-populated, but still salient, clusters.\n",
        "published": "2011-04-04T19:04:25Z",
        "pdf_link": "http://arxiv.org/pdf/1104.0651v3"
    },
    {
        "id": "http://arxiv.org/abs/1104.2097v1",
        "title": "PAC learnability versus VC dimension: a footnote to a basic result of\n  statistical learning",
        "summary": "  A fundamental result of statistical learnig theory states that a concept\nclass is PAC learnable if and only if it is a uniform Glivenko-Cantelli class\nif and only if the VC dimension of the class is finite. However, the theorem is\nonly valid under special assumptions of measurability of the class, in which\ncase the PAC learnability even becomes consistent. Otherwise, there is a\nclassical example, constructed under the Continuum Hypothesis by Dudley and\nDurst and further adapted by Blumer, Ehrenfeucht, Haussler, and Warmuth, of a\nconcept class of VC dimension one which is neither uniform Glivenko-Cantelli\nnor consistently PAC learnable. We show that, rather surprisingly, under an\nadditional set-theoretic hypothesis which is much milder than the Continuum\nHypothesis (Martin's Axiom), PAC learnability is equivalent to finite VC\ndimension for every concept class.\n",
        "published": "2011-04-12T01:15:03Z",
        "pdf_link": "http://arxiv.org/pdf/1104.2097v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.4664v1",
        "title": "Temporal Second Difference Traces",
        "summary": "  Q-learning is a reliable but inefficient off-policy temporal-difference\nmethod, backing up reward only one step at a time. Replacing traces, using a\nrecency heuristic, are more efficient but less reliable. In this work, we\nintroduce model-free, off-policy temporal difference methods that make better\nuse of experience than Watkins' Q(\\lambda). We introduce both Optimistic\nQ(\\lambda) and the temporal second difference trace (TSDT). TSDT is\nparticularly powerful in deterministic domains. TSDT uses neither recency nor\nfrequency heuristics, storing (s,a,r,s',\\delta) so that off-policy updates can\nbe performed after apparently suboptimal actions have been taken. There are\nadditional advantages when using state abstraction, as in MAXQ. We demonstrate\nthat TSDT does significantly better than both Q-learning and Watkins'\nQ(\\lambda) in a deterministic cliff-walking domain. Results in a noisy\ncliff-walking domain are less advantageous for TSDT, but demonstrate the\nefficacy of Optimistic Q(\\lambda), a replacing trace with some of the\nadvantages of TSDT.\n",
        "published": "2011-04-24T22:59:24Z",
        "pdf_link": "http://arxiv.org/pdf/1104.4664v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.5059v1",
        "title": "Reducing Commitment to Tasks with Off-Policy Hierarchical Reinforcement\n  Learning",
        "summary": "  In experimenting with off-policy temporal difference (TD) methods in\nhierarchical reinforcement learning (HRL) systems, we have observed unwanted\non-policy learning under reproducible conditions. Here we present modifications\nto several TD methods that prevent unintentional on-policy learning from\noccurring. These modifications create a tension between exploration and\nlearning. Traditional TD methods require commitment to finishing subtasks\nwithout exploration in order to update Q-values for early actions with high\nprobability. One-step intra-option learning and temporal second difference\ntraces (TSDT) do not suffer from this limitation. We demonstrate that our HRL\nsystem is efficient without commitment to completion of subtasks in a\ncliff-walking domain, contrary to a widespread claim in the literature that it\nis critical for efficiency of learning. Furthermore, decreasing commitment as\nexploration progresses is shown to improve both online performance and the\nresultant policy in the taxicab domain, opening a new avenue for research into\nwhen it is more beneficial to continue with the current subtask or to replan.\n",
        "published": "2011-04-27T00:58:52Z",
        "pdf_link": "http://arxiv.org/pdf/1104.5059v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.5071v1",
        "title": "Attacking and Defending Covert Channels and Behavioral Models",
        "summary": "  In this paper we present methods for attacking and defending $k$-gram\nstatistical analysis techniques that are used, for example, in network traffic\nanalysis and covert channel detection. The main new result is our demonstration\nof how to use a behavior's or process' $k$-order statistics to build a\nstochastic process that has those same $k$-order stationary statistics but\npossesses different, deliberately designed, $(k+1)$-order statistics if\ndesired. Such a model realizes a \"complexification\" of the process or behavior\nwhich a defender can use to monitor whether an attacker is shaping the\nbehavior. By deliberately introducing designed $(k+1)$-order behaviors, the\ndefender can check to see if those behaviors are present in the data. We also\ndevelop constructs for source codes that respect the $k$-order statistics of a\nprocess while encoding covert information. One fundamental consequence of these\nresults is that certain types of behavior analyses techniques come down to an\n{\\em arms race} in the sense that the advantage goes to the party that has more\ncomputing resources applied to the problem.\n",
        "published": "2011-04-27T04:12:47Z",
        "pdf_link": "http://arxiv.org/pdf/1104.5071v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.0471v1",
        "title": "Suboptimal Solution Path Algorithm for Support Vector Machine",
        "summary": "  We consider a suboptimal solution path algorithm for the Support Vector\nMachine. The solution path algorithm is an effective tool for solving a\nsequence of a parametrized optimization problems in machine learning. The path\nof the solutions provided by this algorithm are very accurate and they satisfy\nthe optimality conditions more strictly than other SVM optimization algorithms.\nIn many machine learning application, however, this strict optimality is often\nunnecessary, and it adversely affects the computational efficiency. Our\nalgorithm can generate the path of suboptimal solutions within an arbitrary\nuser-specified tolerance level. It allows us to control the trade-off between\nthe accuracy of the solution and the computational cost. Moreover, We also show\nthat our suboptimal solutions can be interpreted as the solution of a\n\\emph{perturbed optimization problem} from the original one. We provide some\ntheoretical analyses of our algorithm based on this novel interpretation. The\nexperimental results also demonstrate the effectiveness of our algorithm.\n",
        "published": "2011-05-03T03:14:14Z",
        "pdf_link": "http://arxiv.org/pdf/1105.0471v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.0857v1",
        "title": "Domain Adaptation: Overfitting and Small Sample Statistics",
        "summary": "  We study the prevalent problem when a test distribution differs from the\ntraining distribution. We consider a setting where our training set consists of\na small number of sample domains, but where we have many samples in each\ndomain. Our goal is to generalize to a new domain. For example, we may want to\nlearn a similarity function using only certain classes of objects, but we\ndesire that this similarity function be applicable to object classes not\npresent in our training sample (e.g. we might seek to learn that \"dogs are\nsimilar to dogs\" even though images of dogs were absent from our training set).\nOur theoretical analysis shows that we can select many more features than\ndomains while avoiding overfitting by utilizing data-dependent variance\nproperties. We present a greedy feature selection algorithm based on using\nT-statistics. Our experiments validate this theory showing that our T-statistic\nbased greedy feature selection is more robust at avoiding overfitting than the\nclassical greedy procedure.\n",
        "published": "2011-05-04T15:50:44Z",
        "pdf_link": "http://arxiv.org/pdf/1105.0857v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.1033v2",
        "title": "Adaptively Learning the Crowd Kernel",
        "summary": "  We introduce an algorithm that, given n objects, learns a similarity matrix\nover all n^2 pairs, from crowdsourced data alone. The algorithm samples\nresponses to adaptively chosen triplet-based relative-similarity queries. Each\nquery has the form \"is object 'a' more similar to 'b' or to 'c'?\" and is chosen\nto be maximally informative given the preceding responses. The output is an\nembedding of the objects into Euclidean space (like MDS); we refer to this as\nthe \"crowd kernel.\" SVMs reveal that the crowd kernel captures prominent and\nsubtle features across a number of domains, such as \"is striped\" among neckties\nand \"vowel vs. consonant\" among letters.\n",
        "published": "2011-05-05T11:03:03Z",
        "pdf_link": "http://arxiv.org/pdf/1105.1033v2"
    },
    {
        "id": "http://arxiv.org/abs/1105.2550v3",
        "title": "A Maximal Large Deviation Inequality for Sub-Gaussian Variables",
        "summary": "  In this short note we prove a maximal concentration lemma for sub-Gaussian\nrandom variables stating that for independent sub-Gaussian random variables we\nhave \\[P<(\\max_{1\\le i\\le N}S_{i}>\\epsilon>)\n\\le\\exp<(-\\frac{1}{N^2}\\sum_{i=1}^{N}\\frac{\\epsilon^{2}}{2\\sigma_{i}^{2}}>), \\]\nwhere $S_i$ is the sum of $i$ zero mean independent sub-Gaussian random\nvariables and $\\sigma_i$ is the variance of the $i$th random variable.\n",
        "published": "2011-05-12T19:29:21Z",
        "pdf_link": "http://arxiv.org/pdf/1105.2550v3"
    },
    {
        "id": "http://arxiv.org/abs/1105.4272v1",
        "title": "Calibration with Changing Checking Rules and Its Application to\n  Short-Term Trading",
        "summary": "  We provide a natural learning process in which a financial trader without a\nrisk receives a gain in case when Stock Market is inefficient. In this process,\nthe trader rationally choose his gambles using a prediction made by a\nrandomized calibrated algorithm. Our strategy is based on Dawid's notion of\ncalibration with more general changing checking rules and on some modification\nof Kakade and Foster's randomized algorithm for computing calibrated forecasts.\n",
        "published": "2011-05-21T17:28:12Z",
        "pdf_link": "http://arxiv.org/pdf/1105.4272v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.4618v1",
        "title": "Bounding the Fat Shattering Dimension of a Composition Function Class\n  Built Using a Continuous Logic Connective",
        "summary": "  We begin this report by describing the Probably Approximately Correct (PAC)\nmodel for learning a concept class, consisting of subsets of a domain, and a\nfunction class, consisting of functions from the domain to the unit interval.\nTwo combinatorial parameters, the Vapnik-Chervonenkis (VC) dimension and its\ngeneralization, the Fat Shattering dimension of scale e, are explained and a\nfew examples of their calculations are given with proofs. We then explain\nSauer's Lemma, which involves the VC dimension and is used to prove the\nequivalence of a concept class being distribution-free PAC learnable and it\nhaving finite VC dimension.\n  As the main new result of our research, we explore the construction of a new\nfunction class, obtained by forming compositions with a continuous logic\nconnective, a uniformly continuous function from the unit hypercube to the unit\ninterval, from a collection of function classes. Vidyasagar had proved that\nsuch a composition function class has finite Fat Shattering dimension of all\nscales if the classes in the original collection do; however, no estimates of\nthe dimension were known. Using results by Mendelson-Vershynin and Talagrand,\nwe bound the Fat Shattering dimension of scale e of this new function class in\nterms of the Fat Shattering dimensions of the collection's classes.\n  We conclude this report by providing a few open questions and future research\ntopics involving the PAC learning model.\n",
        "published": "2011-05-23T20:04:16Z",
        "pdf_link": "http://arxiv.org/pdf/1105.4618v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.4701v3",
        "title": "Online Learning, Stability, and Stochastic Gradient Descent",
        "summary": "  In batch learning, stability together with existence and uniqueness of the\nsolution corresponds to well-posedness of Empirical Risk Minimization (ERM)\nmethods; recently, it was proved that CV_loo stability is necessary and\nsufficient for generalization and consistency of ERM. In this note, we\nintroduce CV_on stability, which plays a similar note in online learning. We\nshow that stochastic gradient descent (SDG) with the usual hypotheses is CVon\nstable and we then discuss the implications of CV_on stability for convergence\nof SGD.\n",
        "published": "2011-05-24T07:58:30Z",
        "pdf_link": "http://arxiv.org/pdf/1105.4701v3"
    },
    {
        "id": "http://arxiv.org/abs/1105.5196v1",
        "title": "Large-Scale Music Annotation and Retrieval: Learning to Rank in Joint\n  Semantic Spaces",
        "summary": "  Music prediction tasks range from predicting tags given a song or clip of\naudio, predicting the name of the artist, or predicting related songs given a\nsong, clip, artist name or tag. That is, we are interested in every semantic\nrelationship between the different musical concepts in our database. In\nrealistically sized databases, the number of songs is measured in the hundreds\nof thousands or more, and the number of artists in the tens of thousands or\nmore, providing a considerable challenge to standard machine learning\ntechniques. In this work, we propose a method that scales to such datasets\nwhich attempts to capture the semantic similarities between the database items\nby modeling audio, artist names, and tags in a single low-dimensional semantic\nspace. This choice of space is learnt by optimizing the set of prediction tasks\nof interest jointly using multi-task learning. Our method both outperforms\nbaseline methods and, in comparison to them, is faster and consumes less\nmemory. We then demonstrate how our method learns an interpretable model, where\nthe semantic space captures well the similarities of interest.\n",
        "published": "2011-05-26T03:41:47Z",
        "pdf_link": "http://arxiv.org/pdf/1105.5196v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.5592v1",
        "title": "Kernel Belief Propagation",
        "summary": "  We propose a nonparametric generalization of belief propagation, Kernel\nBelief Propagation (KBP), for pairwise Markov random fields. Messages are\nrepresented as functions in a reproducing kernel Hilbert space (RKHS), and\nmessage updates are simple linear operations in the RKHS. KBP makes none of the\nassumptions commonly required in classical BP algorithms: the variables need\nnot arise from a finite domain or a Gaussian distribution, nor must their\nrelations take any particular parametric form. Rather, the relations between\nvariables are represented implicitly, and are learned nonparametrically from\ntraining data. KBP has the advantage that it may be used on any domain where\nkernels are defined (Rd, strings, groups), even where explicit parametric\nmodels are not known, or closed form expressions for the BP updates do not\nexist. The computational cost of message updates in KBP is polynomial in the\ntraining data size. We also propose a constant time approximate message update\nprocedure by representing messages using a small number of basis functions. In\nexperiments, we apply KBP to image denoising, depth prediction from still\nimages, and protein configuration prediction: KBP is faster than competing\nclassical and nonparametric approaches (by orders of magnitude, in some cases),\nwhile providing significantly more accurate results.\n",
        "published": "2011-05-27T15:56:11Z",
        "pdf_link": "http://arxiv.org/pdf/1105.5592v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.6041v1",
        "title": "The Perceptron with Dynamic Margin",
        "summary": "  The classical perceptron rule provides a varying upper bound on the maximum\nmargin, namely the length of the current weight vector divided by the total\nnumber of updates up to that time. Requiring that the perceptron updates its\ninternal state whenever the normalized margin of a pattern is found not to\nexceed a certain fraction of this dynamic upper bound we construct a new\napproximate maximum margin classifier called the perceptron with dynamic margin\n(PDM). We demonstrate that PDM converges in a finite number of steps and derive\nan upper bound on them. We also compare experimentally PDM with other\nperceptron-like algorithms and support vector machines on hard margin tasks\ninvolving linear kernels which are equivalent to 2-norm soft margin.\n",
        "published": "2011-05-30T17:02:09Z",
        "pdf_link": "http://arxiv.org/pdf/1105.6041v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.1379v4",
        "title": "A Unified Framework for Approximating and Clustering Data",
        "summary": "  Given a set $F$ of $n$ positive functions over a ground set $X$, we consider\nthe problem of computing $x^*$ that minimizes the expression $\\sum_{f\\in\nF}f(x)$, over $x\\in X$. A typical application is \\emph{shape fitting}, where we\nwish to approximate a set $P$ of $n$ elements (say, points) by a shape $x$ from\na (possibly infinite) family $X$ of shapes. Here, each point $p\\in P$\ncorresponds to a function $f$ such that $f(x)$ is the distance from $p$ to $x$,\nand we seek a shape $x$ that minimizes the sum of distances from each point in\n$P$. In the $k$-clustering variant, each $x\\in X$ is a tuple of $k$ shapes, and\n$f(x)$ is the distance from $p$ to its closest shape in $x$.\n  Our main result is a unified framework for constructing {\\em coresets} and\n{\\em approximate clustering} for such general sets of functions. To achieve our\nresults, we forge a link between the classic and well defined notion of\n$\\varepsilon$-approximations from the theory of PAC Learning and VC dimension,\nto the relatively new (and not so consistent) paradigm of coresets, which are\nsome kind of \"compressed representation\" of the input set $F$. Using\ntraditional techniques, a coreset usually implies an LTAS (linear time\napproximation scheme) for the corresponding optimization problem, which can be\ncomputed in parallel, via one pass over the data, and using only\npolylogarithmic space (i.e, in the streaming model).\n  We show how to generalize the results of our framework for squared distances\n(as in $k$-mean), distances to the $q$th power, and deterministic\nconstructions.\n",
        "published": "2011-06-07T15:52:39Z",
        "pdf_link": "http://arxiv.org/pdf/1106.1379v4"
    },
    {
        "id": "http://arxiv.org/abs/1106.1684v1",
        "title": "Max-Margin Stacking and Sparse Regularization for Linear Classifier\n  Combination and Selection",
        "summary": "  The main principle of stacked generalization (or Stacking) is using a\nsecond-level generalizer to combine the outputs of base classifiers in an\nensemble. In this paper, we investigate different combination types under the\nstacking framework; namely weighted sum (WS), class-dependent weighted sum\n(CWS) and linear stacked generalization (LSG). For learning the weights, we\npropose using regularized empirical risk minimization with the hinge loss. In\naddition, we propose using group sparsity for regularization to facilitate\nclassifier selection. We performed experiments using two different ensemble\nsetups with differing diversities on 8 real-world datasets. Results show the\npower of regularized learning with the hinge loss function. Using sparse\nregularization, we are able to reduce the number of selected classifiers of the\ndiverse ensemble without sacrificing accuracy. With the non-diverse ensembles,\nwe even gain accuracy on average by using sparse regularization.\n",
        "published": "2011-06-08T23:03:47Z",
        "pdf_link": "http://arxiv.org/pdf/1106.1684v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.1770v3",
        "title": "Reinforcement learning based sensing policy optimization for energy\n  efficient cognitive radio networks",
        "summary": "  This paper introduces a machine learning based collaborative multi-band\nspectrum sensing policy for cognitive radios. The proposed sensing policy\nguides secondary users to focus the search of unused radio spectrum to those\nfrequencies that persistently provide them high data rate. The proposed policy\nis based on machine learning, which makes it adaptive with the temporally and\nspatially varying radio spectrum. Furthermore, there is no need for dynamic\nmodeling of the primary activity since it is implicitly learned over time.\nEnergy efficiency is achieved by minimizing the number of assigned sensors per\neach subband under a constraint on miss detection probability. It is important\nto control the missed detections because they cause collisions with primary\ntransmissions and lead to retransmissions at both the primary and secondary\nuser. Simulations show that the proposed machine learning based sensing policy\nimproves the overall throughput of the secondary network and improves the\nenergy efficiency while controlling the miss detection probability.\n",
        "published": "2011-06-09T10:40:08Z",
        "pdf_link": "http://arxiv.org/pdf/1106.1770v3"
    },
    {
        "id": "http://arxiv.org/abs/1106.1887v4",
        "title": "Learning the Dependence Graph of Time Series with Latent Factors",
        "summary": "  This paper considers the problem of learning, from samples, the dependency\nstructure of a system of linear stochastic differential equations, when some of\nthe variables are latent. In particular, we observe the time evolution of some\nvariables, and never observe other variables; from this, we would like to find\nthe dependency structure between the observed variables - separating out the\nspurious interactions caused by the (marginalizing out of the) latent\nvariables' time series. We develop a new method, based on convex optimization,\nto do so in the case when the number of latent variables is smaller than the\nnumber of observed ones. For the case when the dependency structure between the\nobserved variables is sparse, we theoretically establish a high-dimensional\nscaling result for structure recovery. We verify our theoretical result with\nboth synthetic and real data (from the stock market).\n",
        "published": "2011-06-09T19:34:29Z",
        "pdf_link": "http://arxiv.org/pdf/1106.1887v4"
    },
    {
        "id": "http://arxiv.org/abs/1106.3355v2",
        "title": "On epsilon-optimality of the pursuit learning algorithm",
        "summary": "  Estimator algorithms in learning automata are useful tools for adaptive,\nreal-time optimization in computer science and engineering applications. This\npaper investigates theoretical convergence properties for a special case of\nestimator algorithms: the pursuit learning algorithm. In this note, we identify\nand fill a gap in existing proofs of probabilistic convergence for pursuit\nlearning. It is tradition to take the pursuit learning tuning parameter to be\nfixed in practical applications, but our proof sheds light on the importance of\na vanishing sequence of tuning parameters in a theoretical convergence\nanalysis.\n",
        "published": "2011-06-16T21:32:26Z",
        "pdf_link": "http://arxiv.org/pdf/1106.3355v2"
    },
    {
        "id": "http://arxiv.org/abs/1106.3395v1",
        "title": "Decoding finger movements from ECoG signals using switching linear\n  models",
        "summary": "  One of the major challenges of ECoG-based Brain-Machine Interfaces is the\nmovement prediction of a human subject. Several methods exist to predict an arm\n2-D trajectory. The fourth BCI Competition gives a dataset in which the aim is\nto predict individual finger movements (5-D trajectory). The difficulty lies in\nthe fact that there is no simple relation between ECoG signals and finger\nmovement. We propose in this paper to decode finger flexions using switching\nmodels. This method permits to simplify the system as it is now described as an\nensemble of linear models depending on an internal state. We show that an\ninteresting accuracy prediction can be obtained by such a model.\n",
        "published": "2011-06-17T06:53:47Z",
        "pdf_link": "http://arxiv.org/pdf/1106.3395v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.3396v1",
        "title": "Large margin filtering for signal sequence labeling",
        "summary": "  Signal Sequence Labeling consists in predicting a sequence of labels given an\nobserved sequence of samples. A naive way is to filter the signal in order to\nreduce the noise and to apply a classification algorithm on the filtered\nsamples. We propose in this paper to jointly learn the filter with the\nclassifier leading to a large margin filtering for classification. This method\nallows to learn the optimal cutoff frequency and phase of the filter that may\nbe different from zero. Two methods are proposed and tested on a toy dataset\nand on a real life BCI dataset from BCI Competition III.\n",
        "published": "2011-06-17T06:54:35Z",
        "pdf_link": "http://arxiv.org/pdf/1106.3396v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.3397v1",
        "title": "Handling uncertainties in SVM classification",
        "summary": "  This paper addresses the pattern classification problem arising when\navailable target data include some uncertainty information. Target data\nconsidered here is either qualitative (a class label) or quantitative (an\nestimation of the posterior probability). Our main contribution is a SVM\ninspired formulation of this problem allowing to take into account class label\nthrough a hinge loss as well as probability estimates using epsilon-insensitive\ncost function together with a minimum norm (maximum margin) objective. This\nformulation shows a dual form leading to a quadratic problem and allows the use\nof a representer theorem and associated kernel. The solution provided can be\nused for both decision and posterior probability estimation. Based on empirical\nevidence our method outperforms regular SVM in terms of probability predictions\nand classification performances.\n",
        "published": "2011-06-17T06:55:24Z",
        "pdf_link": "http://arxiv.org/pdf/1106.3397v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.4064v2",
        "title": "Algorithmic Programming Language Identification",
        "summary": "  Motivated by the amount of code that goes unidentified on the web, we\nintroduce a practical method for algorithmically identifying the programming\nlanguage of source code. Our work is based on supervised learning and\nintelligent statistical features. We also explored, but abandoned, a\ngrammatical approach. In testing, our implementation greatly outperforms that\nof an existing tool that relies on a Bayesian classifier. Code is written in\nPython and available under an MIT license.\n",
        "published": "2011-06-21T00:37:23Z",
        "pdf_link": "http://arxiv.org/pdf/1106.4064v2"
    },
    {
        "id": "http://arxiv.org/abs/1106.4574v1",
        "title": "Better Mini-Batch Algorithms via Accelerated Gradient Methods",
        "summary": "  Mini-batch algorithms have been proposed as a way to speed-up stochastic\nconvex optimization problems. We study how such algorithms can be improved\nusing accelerated gradient methods. We provide a novel analysis, which shows\nhow standard gradient methods may sometimes be insufficient to obtain a\nsignificant speed-up and propose a novel accelerated gradient algorithm, which\ndeals with this deficiency, enjoys a uniformly superior guarantee and works\nwell in practice.\n",
        "published": "2011-06-22T20:59:20Z",
        "pdf_link": "http://arxiv.org/pdf/1106.4574v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.5267v1",
        "title": "Potential-Based Shaping and Q-Value Initialization are Equivalent",
        "summary": "  Shaping has proven to be a powerful but precarious means of improving\nreinforcement learning performance. Ng, Harada, and Russell (1999) proposed the\npotential-based shaping algorithm for adding shaping rewards in a way that\nguarantees the learner will learn optimal behavior. In this note, we prove\ncertain similarities between this shaping algorithm and the initialization step\nrequired for several reinforcement learning algorithms. More specifically, we\nprove that a reinforcement learner with initial Q-values based on the shaping\nalgorithm's potential function make the same updates throughout learning as a\nlearner receiving potential-based shaping rewards. We further prove that under\na broad category of policies, the behavior of these two learners are\nindistinguishable. The comparison provides intuition on the theoretical\nproperties of the shaping algorithm as well as a suggestion for a simpler\nmethod for capturing the algorithm's benefit. In addition, the equivalence\nraises previously unaddressed issues concerning the efficiency of learning with\npotential-based shaping.\n",
        "published": "2011-06-26T21:07:01Z",
        "pdf_link": "http://arxiv.org/pdf/1106.5267v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.6186v1",
        "title": "IBSEAD: - A Self-Evolving Self-Obsessed Learning Algorithm for Machine\n  Learning",
        "summary": "  We present IBSEAD or distributed autonomous entity systems based Interaction\n- a learning algorithm for the computer to self-evolve in a self-obsessed\nmanner. This learning algorithm will present the computer to look at the\ninternal and external environment in series of independent entities, which will\ninteract with each other, with and/or without knowledge of the computer's\nbrain. When a learning algorithm interacts, it does so by detecting and\nunderstanding the entities in the human algorithm. However, the problem with\nthis approach is that the algorithm does not consider the interaction of the\nthird party or unknown entities, which may be interacting with each other.\nThese unknown entities in their interaction with the non-computer entities make\nan effect in the environment that influences the information and the behaviour\nof the computer brain. Such details and the ability to process the dynamic and\nunsettling nature of these interactions are absent in the current learning\nalgorithm such as the decision tree learning algorithm. IBSEAD is able to\nevaluate and consider such algorithms and thus give us a better accuracy in\nsimulation of the highly evolved nature of the human brain. Processes such as\ndreams, imagination and novelty, that exist in humans are not fully simulated\nby the existing learning algorithms. Also, Hidden Markov models (HMM) are\nuseful in finding \"hidden\" entities, which may be known or unknown. However,\nthis model fails to consider the case of unknown entities which maybe unclear\nor unknown. IBSEAD is better because it considers three types of entities-\nknown, unknown and invisible. We present our case with a comparison of existing\nalgorithms in known environments and cases and present the results of the\nexperiments using dry run of the simulated runs of the existing machine\nlearning algorithms versus IBSEAD.\n",
        "published": "2011-06-30T11:08:35Z",
        "pdf_link": "http://arxiv.org/pdf/1106.6186v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.6258v2",
        "title": "A Note on Improved Loss Bounds for Multiple Kernel Learning",
        "summary": "  In this paper, we correct an upper bound, presented in~\\cite{hs-11}, on the\ngeneralisation error of classifiers learned through multiple kernel learning.\nThe bound in~\\cite{hs-11} uses Rademacher complexity and has an\\emph{additive}\ndependence on the logarithm of the number of kernels and the margin achieved by\nthe classifier. However, there are some errors in parts of the proof which are\ncorrected in this paper. Unfortunately, the final result turns out to be a risk\nbound which has a \\emph{multiplicative} dependence on the logarithm of the\nnumber of kernels and the margin achieved by the classifier.\n",
        "published": "2011-06-30T15:03:58Z",
        "pdf_link": "http://arxiv.org/pdf/1106.6258v2"
    },
    {
        "id": "http://arxiv.org/abs/1107.0922v1",
        "title": "GraphLab: A Distributed Framework for Machine Learning in the Cloud",
        "summary": "  Machine Learning (ML) techniques are indispensable in a wide range of fields.\nUnfortunately, the exponential increase of dataset sizes are rapidly extending\nthe runtime of sequential algorithms and threatening to slow future progress in\nML. With the promise of affordable large-scale parallel computing, Cloud\nsystems offer a viable platform to resolve the computational challenges in ML.\nHowever, designing and implementing efficient, provably correct distributed ML\nalgorithms is often prohibitively challenging. To enable ML researchers to\neasily and efficiently use parallel systems, we introduced the GraphLab\nabstraction which is designed to represent the computational patterns in ML\nalgorithms while permitting efficient parallel and distributed implementations.\nIn this paper we provide a formal description of the GraphLab parallel\nabstraction and present an efficient distributed implementation. We conduct a\ncomprehensive evaluation of GraphLab on three state-of-the-art ML algorithms\nusing real large-scale data and a 64 node EC2 cluster of 512 processors. We\nfind that GraphLab achieves orders of magnitude performance gains over Hadoop\nwhile performing comparably or superior to hand-tuned MPI implementations.\n",
        "published": "2011-07-05T16:56:53Z",
        "pdf_link": "http://arxiv.org/pdf/1107.0922v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.2490v2",
        "title": "Towards Optimal One Pass Large Scale Learning with Averaged Stochastic\n  Gradient Descent",
        "summary": "  For large scale learning problems, it is desirable if we can obtain the\noptimal model parameters by going through the data in only one pass. Polyak and\nJuditsky (1992) showed that asymptotically the test performance of the simple\naverage of the parameters obtained by stochastic gradient descent (SGD) is as\ngood as that of the parameters which minimize the empirical cost. However, to\nour knowledge, despite its optimal asymptotic convergence rate, averaged SGD\n(ASGD) received little attention in recent research on large scale learning.\nOne possible reason is that it may take a prohibitively large number of\ntraining samples for ASGD to reach its asymptotic region for most real\nproblems. In this paper, we present a finite sample analysis for the method of\nPolyak and Juditsky (1992). Our analysis shows that it indeed usually takes a\nhuge number of samples for ASGD to reach its asymptotic region for improperly\nchosen learning rate. More importantly, based on our analysis, we propose a\nsimple way to properly set learning rate so that it takes a reasonable amount\nof data for ASGD to reach its asymptotic region. We compare ASGD using our\nproposed learning rate with other well known algorithms for training large\nscale linear classifiers. The experiments clearly show the superiority of ASGD.\n",
        "published": "2011-07-13T08:57:29Z",
        "pdf_link": "http://arxiv.org/pdf/1107.2490v2"
    },
    {
        "id": "http://arxiv.org/abs/1107.3407v1",
        "title": "Discovering Knowledge using a Constraint-based Language",
        "summary": "  Discovering pattern sets or global patterns is an attractive issue from the\npattern mining community in order to provide useful information. By combining\nlocal patterns satisfying a joint meaning, this approach produces patterns of\nhigher level and thus more useful for the data analyst than the usual local\npatterns, while reducing the number of patterns. In parallel, recent works\ninvestigating relationships between data mining and constraint programming (CP)\nshow that the CP paradigm is a nice framework to model and mine such patterns\nin a declarative and generic way. We present a constraint-based language which\nenables us to define queries addressing patterns sets and global patterns. The\nusefulness of such a declarative approach is highlighted by several examples\ncoming from the clustering based on associations. This language has been\nimplemented in the CP framework.\n",
        "published": "2011-07-18T12:01:28Z",
        "pdf_link": "http://arxiv.org/pdf/1107.3407v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.4080v1",
        "title": "On the Universality of Online Mirror Descent",
        "summary": "  We show that for a general class of convex online learning problems, Mirror\nDescent can always achieve a (nearly) optimal regret guarantee.\n",
        "published": "2011-07-20T19:34:00Z",
        "pdf_link": "http://arxiv.org/pdf/1107.4080v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.4606v2",
        "title": "The Divergence of Reinforcement Learning Algorithms with Value-Iteration\n  and Function Approximation",
        "summary": "  This paper gives specific divergence examples of value-iteration for several\nmajor Reinforcement Learning and Adaptive Dynamic Programming algorithms, when\nusing a function approximator for the value function. These divergence examples\ndiffer from previous divergence examples in the literature, in that they are\napplicable for a greedy policy, i.e. in a \"value iteration\" scenario. Perhaps\nsurprisingly, with a greedy policy, it is also possible to get divergence for\nthe algorithms TD(1) and Sarsa(1). In addition to these divergences, we also\nachieve divergence for the Adaptive Dynamic Programming algorithms HDP, DHP and\nGDHP.\n",
        "published": "2011-07-22T13:05:48Z",
        "pdf_link": "http://arxiv.org/pdf/1107.4606v2"
    },
    {
        "id": "http://arxiv.org/abs/1107.5520v1",
        "title": "Axioms for Rational Reinforcement Learning",
        "summary": "  We provide a formal, simple and intuitive theory of rational decision making\nincluding sequential decisions that affect the environment. The theory has a\ngeometric flavor, which makes the arguments easy to visualize and understand.\nOur theory is for complete decision makers, which means that they have a\ncomplete set of preferences. Our main result shows that a complete rational\ndecision maker implicitly has a probabilistic model of the environment. We have\na countable version of this result that brings light on the issue of countable\nvs finite additivity by showing how it depends on the geometry of the space\nwhich we have preferences over. This is achieved through fruitfully connecting\nrationality with the Hahn-Banach Theorem. The theory presented here can be\nviewed as a formalization and extension of the betting odds approach to\nprobability of Ramsey and De Finetti.\n",
        "published": "2011-07-27T16:29:06Z",
        "pdf_link": "http://arxiv.org/pdf/1107.5520v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.5671v1",
        "title": "Automatic Network Reconstruction using ASP",
        "summary": "  Building biological models by inferring functional dependencies from\nexperimental data is an im- portant issue in Molecular Biology. To relieve the\nbiologist from this traditionally manual process, various approaches have been\nproposed to increase the degree of automation. However, available ap- proaches\noften yield a single model only, rely on specific assumptions, and/or use\ndedicated, heuris- tic algorithms that are intolerant to changing circumstances\nor requirements in the view of the rapid progress made in Biotechnology. Our\naim is to provide a declarative solution to the problem by ap- peal to Answer\nSet Programming (ASP) overcoming these difficulties. We build upon an existing\napproach to Automatic Network Reconstruction proposed by part of the authors.\nThis approach has firm mathematical foundations and is well suited for ASP due\nto its combinatorial flavor providing a characterization of all models\nexplaining a set of experiments. The usage of ASP has several ben- efits over\nthe existing heuristic algorithms. First, it is declarative and thus\ntransparent for biological experts. Second, it is elaboration tolerant and thus\nallows for an easy exploration and incorporation of biological constraints.\nThird, it allows for exploring the entire space of possible models. Finally,\nour approach offers an excellent performance, matching existing,\nspecial-purpose systems.\n",
        "published": "2011-07-28T10:36:30Z",
        "pdf_link": "http://arxiv.org/pdf/1107.5671v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.2486v1",
        "title": "Feature Extraction for Change-Point Detection using Stationary Subspace\n  Analysis",
        "summary": "  Detecting changes in high-dimensional time series is difficult because it\ninvolves the comparison of probability densities that need to be estimated from\nfinite samples. In this paper, we present the first feature extraction method\ntailored to change point detection, which is based on an extended version of\nStationary Subspace Analysis. We reduce the dimensionality of the data to the\nmost non-stationary directions, which are most informative for detecting state\nchanges in the time series. In extensive simulations on synthetic data we show\nthat the accuracy of three change point detection algorithms is significantly\nincreased by a prior feature extraction step. These findings are confirmed in\nan application to industrial fault monitoring.\n",
        "published": "2011-08-11T18:54:02Z",
        "pdf_link": "http://arxiv.org/pdf/1108.2486v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.4559v2",
        "title": "Optimal Algorithms for Ridge and Lasso Regression with Partially\n  Observed Attributes",
        "summary": "  We consider the most common variants of linear regression, including Ridge,\nLasso and Support-vector regression, in a setting where the learner is allowed\nto observe only a fixed number of attributes of each example at training time.\nWe present simple and efficient algorithms for these problems: for Lasso and\nRidge regression they need the same total number of attributes (up to\nconstants) as do full-information algorithms, for reaching a certain accuracy.\nFor Support-vector regression, we require exponentially less attributes\ncompared to the state of the art. By that, we resolve an open problem recently\nposed by Cesa-Bianchi et al. (2010). Experiments show the theoretical bounds to\nbe justified by superior performance compared to the state of the art.\n",
        "published": "2011-08-23T11:52:35Z",
        "pdf_link": "http://arxiv.org/pdf/1108.4559v2"
    },
    {
        "id": "http://arxiv.org/abs/1108.4961v1",
        "title": "Non-trivial two-armed partial-monitoring games are bandits",
        "summary": "  We consider online learning in partial-monitoring games against an oblivious\nadversary. We show that when the number of actions available to the learner is\ntwo and the game is nontrivial then it is reducible to a bandit-like game and\nthus the minimax regret is $\\Theta(\\sqrt{T})$.\n",
        "published": "2011-08-24T22:38:40Z",
        "pdf_link": "http://arxiv.org/pdf/1108.4961v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.0093v4",
        "title": "Local Component Analysis",
        "summary": "  Kernel density estimation, a.k.a. Parzen windows, is a popular density\nestimation method, which can be used for outlier detection or clustering. With\nmultivariate data, its performance is heavily reliant on the metric used within\nthe kernel. Most earlier work has focused on learning only the bandwidth of the\nkernel (i.e., a scalar multiplicative factor). In this paper, we propose to\nlearn a full Euclidean metric through an expectation-minimization (EM)\nprocedure, which can be seen as an unsupervised counterpart to neighbourhood\ncomponent analysis (NCA). In order to avoid overfitting with a fully\nnonparametric density estimator in high dimensions, we also consider a\nsemi-parametric Gaussian-Parzen density model, where some of the variables are\nmodelled through a jointly Gaussian density, while others are modelled through\nParzen windows. For these two models, EM leads to simple closed-form updates\nbased on matrix inversions and eigenvalue decompositions. We show empirically\nthat our method leads to density estimators with higher test-likelihoods than\nnatural competing methods, and that the metrics may be used within most\nunsupervised learning techniques that rely on such metrics, such as spectral\nclustering or manifold learning methods. Finally, we present a stochastic\napproximation scheme which allows for the use of this method in a large-scale\nsetting.\n",
        "published": "2011-09-01T05:28:55Z",
        "pdf_link": "http://arxiv.org/pdf/1109.0093v4"
    },
    {
        "id": "http://arxiv.org/abs/1109.1844v2",
        "title": "Weighted Clustering",
        "summary": "  One of the most prominent challenges in clustering is \"the user's dilemma,\"\nwhich is the problem of selecting an appropriate clustering algorithm for a\nspecific task. A formal approach for addressing this problem relies on the\nidentification of succinct, user-friendly properties that formally capture when\ncertain clustering methods are preferred over others.\n  Until now these properties focused on advantages of classical Linkage-Based\nalgorithms, failing to identify when other clustering paradigms, such as\npopular center-based methods, are preferable. We present surprisingly simple\nnew properties that delineate the differences between common clustering\nparadigms, which clearly and formally demonstrates advantages of center-based\napproaches for some applications. These properties address how sensitive\nalgorithms are to changes in element frequencies, which we capture in a\ngeneralized setting where every element is associated with a real-valued\nweight.\n",
        "published": "2011-09-08T20:53:54Z",
        "pdf_link": "http://arxiv.org/pdf/1109.1844v2"
    },
    {
        "id": "http://arxiv.org/abs/1109.2047v1",
        "title": "Learning From Labeled And Unlabeled Data: An Empirical Study Across\n  Techniques And Domains",
        "summary": "  There has been increased interest in devising learning techniques that\ncombine unlabeled data with labeled data ? i.e. semi-supervised learning.\nHowever, to the best of our knowledge, no study has been performed across\nvarious techniques and different types and amounts of labeled and unlabeled\ndata. Moreover, most of the published work on semi-supervised learning\ntechniques assumes that the labeled and unlabeled data come from the same\ndistribution. It is possible for the labeling process to be associated with a\nselection bias such that the distributions of data points in the labeled and\nunlabeled sets are different. Not correcting for such bias can result in biased\nfunction approximation with potentially poor performance. In this paper, we\npresent an empirical study of various semi-supervised learning techniques on a\nvariety of datasets. We attempt to answer various questions such as the effect\nof independence or relevance amongst features, the effect of the size of the\nlabeled and unlabeled sets and the effect of noise. We also investigate the\nimpact of sample-selection bias on the semi-supervised learning techniques\nunder study and implement a bivariate probit technique particularly designed to\ncorrect for such bias.\n",
        "published": "2011-09-09T15:56:58Z",
        "pdf_link": "http://arxiv.org/pdf/1109.2047v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.2141v1",
        "title": "Efficiency versus Convergence of Boolean Kernels for On-Line Learning\n  Algorithms",
        "summary": "  The paper studies machine learning problems where each example is described\nusing a set of Boolean features and where hypotheses are represented by linear\nthreshold elements. One method of increasing the expressiveness of learned\nhypotheses in this context is to expand the feature set to include conjunctions\nof basic features. This can be done explicitly or where possible by using a\nkernel function. Focusing on the well known Perceptron and Winnow algorithms,\nthe paper demonstrates a tradeoff between the computational efficiency with\nwhich the algorithm can be run over the expanded feature space and the\ngeneralization ability of the corresponding learning algorithm. We first\ndescribe several kernel functions which capture either limited forms of\nconjunctions or all conjunctions. We show that these kernels can be used to\nefficiently run the Perceptron algorithm over a feature space of exponentially\nmany conjunctions; however we also show that using such kernels, the Perceptron\nalgorithm can provably make an exponential number of mistakes even when\nlearning simple functions. We then consider the question of whether kernel\nfunctions can analogously be used to run the multiplicative-update Winnow\nalgorithm over an expanded feature space of exponentially many conjunctions.\nKnown upper bounds imply that the Winnow algorithm can learn Disjunctive Normal\nForm (DNF) formulae with a polynomial mistake bound in this setting. However,\nwe prove that it is computationally hard to simulate Winnows behavior for\nlearning DNF over such a feature set. This implies that the kernel functions\nwhich correspond to running Winnow for this problem are not efficiently\ncomputable, and that there is no general construction that can run Winnow with\nkernels.\n",
        "published": "2011-09-09T20:31:05Z",
        "pdf_link": "http://arxiv.org/pdf/1109.2141v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.2147v1",
        "title": "Risk-Sensitive Reinforcement Learning Applied to Control under\n  Constraints",
        "summary": "  In this paper, we consider Markov Decision Processes (MDPs) with error\nstates. Error states are those states entering which is undesirable or\ndangerous. We define the risk with respect to a policy as the probability of\nentering such a state when the policy is pursued. We consider the problem of\nfinding good policies whose risk is smaller than some user-specified threshold,\nand formalize it as a constrained MDP with two criteria. The first criterion\ncorresponds to the value function originally given. We will show that the risk\ncan be formulated as a second criterion function based on a cumulative return,\nwhose definition is independent of the original value function. We present a\nmodel free, heuristic reinforcement learning algorithm that aims at finding\ngood deterministic policies. It is based on weighting the original value\nfunction and the risk. The weight parameter is adapted in order to find a\nfeasible solution for the constrained problem that has a good performance with\nrespect to the value function. The algorithm was successfully applied to the\ncontrol of a feed tank with stochastic inflows that lies upstream of a\ndistillation column. This control task was originally formulated as an optimal\ncontrol problem with chance constraints, and it was solved under certain\nassumptions on the model to obtain an optimal solution. The power of our\nlearning algorithm is that it can be used even when some of these restrictive\nassumptions are relaxed.\n",
        "published": "2011-09-09T20:32:41Z",
        "pdf_link": "http://arxiv.org/pdf/1109.2147v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.2296v1",
        "title": "Bandits with an Edge",
        "summary": "  We consider a bandit problem over a graph where the rewards are not directly\nobserved. Instead, the decision maker can compare two nodes and receive\n(stochastic) information pertaining to the difference in their value. The graph\nstructure describes the set of possible comparisons. Consequently, comparing\nbetween two nodes that are relatively far requires estimating the difference\nbetween every pair of nodes on the path between them. We analyze this problem\nfrom the perspective of sample complexity: How many queries are needed to find\nan approximately optimal node with probability more than $1-\\delta$ in the PAC\nsetup? We show that the topology of the graph plays a crucial in defining the\nsample complexity: graphs with a low diameter have a much better sample\ncomplexity.\n",
        "published": "2011-09-11T09:00:53Z",
        "pdf_link": "http://arxiv.org/pdf/1109.2296v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.3318v2",
        "title": "Distributed User Profiling via Spectral Methods",
        "summary": "  User profiling is a useful primitive for constructing personalised services,\nsuch as content recommendation. In the present paper we investigate the\nfeasibility of user profiling in a distributed setting, with no central\nauthority and only local information exchanges between users. We compute a\nprofile vector for each user (i.e., a low-dimensional vector that characterises\nher taste) via spectral transformation of observed user-produced ratings for\nitems. Our two main contributions follow: i) We consider a low-rank\nprobabilistic model of user taste. More specifically, we consider that users\nand items are partitioned in a constant number of classes, such that users and\nitems within the same class are statistically identical. We prove that without\nprior knowledge of the compositions of the classes, based solely on few random\nobserved ratings (namely $O(N\\log N)$ such ratings for $N$ users), we can\npredict user preference with high probability for unrated items by running a\nlocal vote among users with similar profile vectors. In addition, we provide\nempirical evaluations characterising the way in which spectral profiling\nperformance depends on the dimension of the profile space. Such evaluations are\nperformed on a data set of real user ratings provided by Netflix. ii) We\ndevelop distributed algorithms which provably achieve an embedding of users\ninto a low-dimensional space, based on spectral transformation. These involve\nsimple message passing among users, and provably converge to the desired\nembedding. Our method essentially relies on a novel combination of gossiping\nand the algorithm proposed by Oja and Karhunen.\n",
        "published": "2011-09-15T11:31:31Z",
        "pdf_link": "http://arxiv.org/pdf/1109.3318v2"
    },
    {
        "id": "http://arxiv.org/abs/1109.3437v4",
        "title": "Learning Topic Models by Belief Propagation",
        "summary": "  Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model\nfor probabilistic topic modeling, which attracts worldwide interests and\ntouches on many important applications in text mining, computer vision and\ncomputational biology. This paper represents LDA as a factor graph within the\nMarkov random field (MRF) framework, which enables the classic loopy belief\npropagation (BP) algorithm for approximate inference and parameter estimation.\nAlthough two commonly-used approximate inference methods, such as variational\nBayes (VB) and collapsed Gibbs sampling (GS), have gained great successes in\nlearning LDA, the proposed BP is competitive in both speed and accuracy as\nvalidated by encouraging experimental results on four large-scale document data\nsets. Furthermore, the BP algorithm has the potential to become a generic\nlearning scheme for variants of LDA-based topic models. To this end, we show\nhow to learn two typical variants of LDA-based topic models, such as\nauthor-topic models (ATM) and relational topic models (RTM), using BP based on\nthe factor graph representation.\n",
        "published": "2011-09-15T19:20:48Z",
        "pdf_link": "http://arxiv.org/pdf/1109.3437v4"
    },
    {
        "id": "http://arxiv.org/abs/1109.5078v1",
        "title": "Application of distances between terms for flat and hierarchical data",
        "summary": "  In machine learning, distance-based algorithms, and other approaches, use\ninformation that is represented by propositional data. However, this kind of\nrepresentation can be quite restrictive and, in many cases, it requires more\ncomplex structures in order to represent data in a more natural way. Terms are\nthe basis for functional and logic programming representation. Distances\nbetween terms are a useful tool not only to compare terms, but also to\ndetermine the search space in many of these applications. This dissertation\napplies distances between terms, exploiting the features of each distance and\nthe possibility to compare from propositional data types to hierarchical\nrepresentations. The distances between terms are applied through the k-NN\n(k-nearest neighbor) classification algorithm using XML as a common language\nrepresentation. To be able to represent these data in an XML structure and to\ntake advantage of the benefits of distance between terms, it is necessary to\napply some transformations. These transformations allow the conversion of flat\ndata into hierarchical data represented in XML, using some techniques based on\nintuitive associations between the names and values of variables and\nassociations based on attribute similarity.\n  Several experiments with the distances between terms of Nienhuys-Cheng and\nEstruch et al. were performed. In the case of originally propositional data,\nthese distances are compared to the Euclidean distance. In all cases, the\nexperiments were performed with the distance-weighted k-nearest neighbor\nalgorithm, using several exponents for the attraction function (weighted\ndistance). It can be seen that in some cases, the term distances can\nsignificantly improve the results on approaches applied to flat\nrepresentations.\n",
        "published": "2011-09-23T13:51:31Z",
        "pdf_link": "http://arxiv.org/pdf/1109.5078v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.5231v4",
        "title": "Noise Tolerance under Risk Minimization",
        "summary": "  In this paper we explore noise tolerant learning of classifiers. We formulate\nthe problem as follows. We assume that there is an ${\\bf unobservable}$\ntraining set which is noise-free. The actual training set given to the learning\nalgorithm is obtained from this ideal data set by corrupting the class label of\neach example. The probability that the class label of an example is corrupted\nis a function of the feature vector of the example. This would account for most\nkinds of noisy data one encounters in practice. We say that a learning method\nis noise tolerant if the classifiers learnt with the ideal noise-free data and\nwith noisy data, both have the same classification accuracy on the noise-free\ndata. In this paper we analyze the noise tolerance properties of risk\nminimization (under different loss functions), which is a generic method for\nlearning classifiers. We show that risk minimization under 0-1 loss function\nhas impressive noise tolerance properties and that under squared error loss is\ntolerant only to uniform noise; risk minimization under other loss functions is\nnot noise tolerant. We conclude the paper with some discussion on implications\nof these theoretical results.\n",
        "published": "2011-09-24T04:50:55Z",
        "pdf_link": "http://arxiv.org/pdf/1109.5231v4"
    },
    {
        "id": "http://arxiv.org/abs/1110.1073v1",
        "title": "Active Learning with Multiple Views",
        "summary": "  Active learners alleviate the burden of labeling large amounts of data by\ndetecting and asking the user to label only the most informative examples in\nthe domain. We focus here on active learning for multi-view domains, in which\nthere are several disjoint subsets of features (views), each of which is\nsufficient to learn the target concept. In this paper we make several\ncontributions. First, we introduce Co-Testing, which is the first approach to\nmulti-view active learning. Second, we extend the multi-view learning framework\nby also exploiting weak views, which are adequate only for learning a concept\nthat is more general/specific than the target concept. Finally, we empirically\nshow that Co-Testing outperforms existing active learners on a variety of real\nworld domains such as wrapper induction, Web page classification, advertisement\nremoval, and discourse tree parsing.\n",
        "published": "2011-10-05T18:59:49Z",
        "pdf_link": "http://arxiv.org/pdf/1110.1073v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.1075v1",
        "title": "The Augmented Complex Kernel LMS",
        "summary": "  Recently, a unified framework for adaptive kernel based signal processing of\ncomplex data was presented by the authors, which, besides offering techniques\nto map the input data to complex Reproducing Kernel Hilbert Spaces, developed a\nsuitable Wirtinger-like Calculus for general Hilbert Spaces. In this short\npaper, the extended Wirtinger's calculus is adopted to derive complex\nkernel-based widely-linear estimation filters. Furthermore, we illuminate\nseveral important characteristics of the widely linear filters. We show that,\nalthough in many cases the gains from adopting widely linear estimation\nfilters, as alternatives to ordinary linear ones, are rudimentary, for the case\nof kernel based widely linear filters significant performance improvements can\nbe obtained.\n",
        "published": "2011-10-05T19:03:35Z",
        "pdf_link": "http://arxiv.org/pdf/1110.1075v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.2098v3",
        "title": "Dynamic Matrix Factorization: A State Space Approach",
        "summary": "  Matrix factorization from a small number of observed entries has recently\ngarnered much attention as the key ingredient of successful recommendation\nsystems. One unresolved problem in this area is how to adapt current methods to\nhandle changing user preferences over time. Recent proposals to address this\nissue are heuristic in nature and do not fully exploit the time-dependent\nstructure of the problem. As a principled and general temporal formulation, we\npropose a dynamical state space model of matrix factorization. Our proposal\nbuilds upon probabilistic matrix factorization, a Bayesian model with Gaussian\npriors. We utilize results in state tracking, such as the Kalman filter, to\nprovide accurate recommendations in the presence of both process and\nmeasurement noise. We show how system parameters can be learned via\nexpectation-maximization and provide comparisons to current published\ntechniques.\n",
        "published": "2011-10-10T16:35:51Z",
        "pdf_link": "http://arxiv.org/pdf/1110.2098v3"
    },
    {
        "id": "http://arxiv.org/abs/1110.2136v3",
        "title": "Active Learning Using Smooth Relative Regret Approximations with\n  Applications",
        "summary": "  The disagreement coefficient of Hanneke has become a central data independent\ninvariant in proving active learning rates. It has been shown in various ways\nthat a concept class with low complexity together with a bound on the\ndisagreement coefficient at an optimal solution allows active learning rates\nthat are superior to passive learning ones.\n  We present a different tool for pool based active learning which follows from\nthe existence of a certain uniform version of low disagreement coefficient, but\nis not equivalent to it. In fact, we present two fundamental active learning\nproblems of significant interest for which our approach allows nontrivial\nactive learning bounds. However, any general purpose method relying on the\ndisagreement coefficient bounds only fails to guarantee any useful bounds for\nthese problems.\n  The tool we use is based on the learner's ability to compute an estimator of\nthe difference between the loss of any hypotheses and some fixed \"pivotal\"\nhypothesis to within an absolute error of at most $\\eps$ times the\n",
        "published": "2011-10-10T18:32:32Z",
        "pdf_link": "http://arxiv.org/pdf/1110.2136v3"
    },
    {
        "id": "http://arxiv.org/abs/1110.2416v1",
        "title": "Supervised learning of short and high-dimensional temporal sequences for\n  life science measurements",
        "summary": "  The analysis of physiological processes over time are often given by\nspectrometric or gene expression profiles over time with only few time points\nbut a large number of measured variables. The analysis of such temporal\nsequences is challenging and only few methods have been proposed. The\ninformation can be encoded time independent, by means of classical expression\ndifferences for a single time point or in expression profiles over time.\nAvailable methods are limited to unsupervised and semi-supervised settings. The\npredictive variables can be identified only by means of wrapper or\npost-processing techniques. This is complicated due to the small number of\nsamples for such studies. Here, we present a supervised learning approach,\ntermed Supervised Topographic Mapping Through Time (SGTM-TT). It learns a\nsupervised mapping of the temporal sequences onto a low dimensional grid. We\nutilize a hidden markov model (HMM) to account for the time domain and\nrelevance learning to identify the relevant feature dimensions most predictive\nover time. The learned mapping can be used to visualize the temporal sequences\nand to predict the class of a new sequence. The relevance learning permits the\nidentification of discriminating masses or gen expressions and prunes\ndimensions which are unnecessary for the classification task or encode mainly\nnoise. In this way we obtain a very efficient learning system for temporal\nsequences. The results indicate that using simultaneous supervised learning and\nmetric adaptation significantly improves the prediction accuracy for\nsynthetically and real life data in comparison to the standard techniques. The\ndiscriminating features, identified by relevance learning, compare favorably\nwith the results of alternative methods. Our method permits the visualization\nof the data on a low dimensional grid, highlighting the observed temporal\nstructure.\n",
        "published": "2011-10-11T16:19:06Z",
        "pdf_link": "http://arxiv.org/pdf/1110.2416v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.3347v1",
        "title": "Dynamic Batch Bayesian Optimization",
        "summary": "  Bayesian optimization (BO) algorithms try to optimize an unknown function\nthat is expensive to evaluate using minimum number of evaluations/experiments.\nMost of the proposed algorithms in BO are sequential, where only one experiment\nis selected at each iteration. This method can be time inefficient when each\nexperiment takes a long time and more than one experiment can be ran\nconcurrently. On the other hand, requesting a fix-sized batch of experiments at\neach iteration causes performance inefficiency in BO compared to the sequential\npolicies. In this paper, we present an algorithm that asks a batch of\nexperiments at each time step t where the batch size p_t is dynamically\ndetermined in each step. Our algorithm is based on the observation that the\nsequence of experiments selected by the sequential policy can sometimes be\nalmost independent from each other. Our algorithm identifies such scenarios and\nrequest those experiments at the same time without degrading the performance.\nWe evaluate our proposed method using the Expected Improvement policy and the\nresults show substantial speedup with little impact on the performance in eight\nreal and synthetic benchmarks.\n",
        "published": "2011-10-14T21:47:12Z",
        "pdf_link": "http://arxiv.org/pdf/1110.3347v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.4181v1",
        "title": "Injecting External Solutions Into CMA-ES",
        "summary": "  This report considers how to inject external candidate solutions into the\nCMA-ES algorithm. The injected solutions might stem from a gradient or a Newton\nstep, a surrogate model optimizer or any other oracle or search mechanism. They\ncan also be the result of a repair mechanism, for example to render infeasible\nsolutions feasible. Only small modifications to the CMA-ES are necessary to\nturn injection into a reliable and effective method: too long steps need to be\ntightly renormalized. The main objective of this report is to reveal this\nsimple mechanism. Depending on the source of the injected solutions,\ninteresting variants of CMA-ES arise. When the best-ever solution is always\n(re-)injected, an elitist variant of CMA-ES with weighted multi-recombination\narises. When \\emph{all} solutions are injected from an \\emph{external} source,\nthe resulting algorithm might be viewed as \\emph{adaptive encoding} with\nstep-size control. In first experiments, injected solutions of very good\nquality lead to a convergence speed twice as fast as on the (simple) sphere\nfunction without injection. This means that we observe an impressive speed-up\non otherwise difficult to solve functions. Single bad injected solutions on the\nother hand do no significant harm.\n",
        "published": "2011-10-19T04:42:33Z",
        "pdf_link": "http://arxiv.org/pdf/1110.4181v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.4416v1",
        "title": "Data-dependent kernels in nearly-linear time",
        "summary": "  We propose a method to efficiently construct data-dependent kernels which can\nmake use of large quantities of (unlabeled) data. Our construction makes an\napproximation in the standard construction of semi-supervised kernels in\nSindhwani et al. 2005. In typical cases these kernels can be computed in\nnearly-linear time (in the amount of data), improving on the cubic time of the\nstandard construction, enabling large scale semi-supervised learning in a\nvariety of contexts. The methods are validated on semi-supervised and\nunsupervised problems on data sets containing upto 64,000 sample points.\n",
        "published": "2011-10-20T00:56:53Z",
        "pdf_link": "http://arxiv.org/pdf/1110.4416v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.4481v1",
        "title": "Learning Hierarchical and Topographic Dictionaries with Structured\n  Sparsity",
        "summary": "  Recent work in signal processing and statistics have focused on defining new\nregularization functions, which not only induce sparsity of the solution, but\nalso take into account the structure of the problem. We present in this paper a\nclass of convex penalties introduced in the machine learning community, which\ntake the form of a sum of l_2 and l_infinity-norms over groups of variables.\nThey extend the classical group-sparsity regularization in the sense that the\ngroups possibly overlap, allowing more flexibility in the group design. We\nreview efficient optimization methods to deal with the corresponding inverse\nproblems, and their application to the problem of learning dictionaries of\nnatural image patches: On the one hand, dictionary learning has indeed proven\neffective for various signal processing tasks. On the other hand, structured\nsparsity provides a natural framework for modeling dependencies between\ndictionary elements. We thus consider a structured sparse regularization to\nlearn dictionaries embedded in a particular structure, for instance a tree or a\ntwo-dimensional grid. In the latter case, the results we obtain are similar to\nthe dictionaries produced by topographic independent component analysis.\n",
        "published": "2011-10-20T09:50:58Z",
        "pdf_link": "http://arxiv.org/pdf/1110.4481v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.5051v1",
        "title": "Wikipedia Edit Number Prediction based on Temporal Dynamics Only",
        "summary": "  In this paper, we describe our approach to the Wikipedia Participation\nChallenge which aims to predict the number of edits a Wikipedia editor will\nmake in the next 5 months. The best submission from our team, \"zeditor\",\nachieved 41.7% improvement over WMF's baseline predictive model and the final\nrank of 3rd place among 96 teams. An interesting characteristic of our approach\nis that only temporal dynamics features (i.e., how the number of edits changes\nin recent periods, etc.) are used in a self-supervised learning framework,\nwhich makes it easy to be generalised to other application domains.\n",
        "published": "2011-10-23T14:41:21Z",
        "pdf_link": "http://arxiv.org/pdf/1110.5051v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.6287v1",
        "title": "Deciding of HMM parameters based on number of critical points for\n  gesture recognition from motion capture data",
        "summary": "  This paper presents a method of choosing number of states of a HMM based on\nnumber of critical points of the motion capture data. The choice of Hidden\nMarkov Models(HMM) parameters is crucial for recognizer's performance as it is\nthe first step of the training and cannot be corrected automatically within\nHMM. In this article we define predictor of number of states based on number of\ncritical points of the sequence and test its effectiveness against sample data.\n",
        "published": "2011-10-28T10:20:25Z",
        "pdf_link": "http://arxiv.org/pdf/1110.6287v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.6755v2",
        "title": "PAC-Bayes-Bernstein Inequality for Martingales and its Application to\n  Multiarmed Bandits",
        "summary": "  We develop a new tool for data-dependent analysis of the\nexploration-exploitation trade-off in learning under limited feedback. Our tool\nis based on two main ingredients. The first ingredient is a new concentration\ninequality that makes it possible to control the concentration of weighted\naverages of multiple (possibly uncountably many) simultaneously evolving and\ninterdependent martingales. The second ingredient is an application of this\ninequality to the exploration-exploitation trade-off via importance weighted\nsampling. We apply the new tool to the stochastic multiarmed bandit problem,\nhowever, the main importance of this paper is the development and understanding\nof the new tool rather than improvement of existing algorithms for stochastic\nmultiarmed bandits. In the follow-up work we demonstrate that the new tool can\nimprove over state-of-the-art in structurally richer problems, such as\nstochastic multiarmed bandits with side information (Seldin et al., 2011a).\n",
        "published": "2011-10-31T11:36:49Z",
        "pdf_link": "http://arxiv.org/pdf/1110.6755v2"
    },
    {
        "id": "http://arxiv.org/abs/1111.1386v1",
        "title": "Confidence Estimation in Structured Prediction",
        "summary": "  Structured classification tasks such as sequence labeling and dependency\nparsing have seen much interest by the Natural Language Processing and the\nmachine learning communities. Several online learning algorithms were adapted\nfor structured tasks such as Perceptron, Passive- Aggressive and the recently\nintroduced Confidence-Weighted learning . These online algorithms are easy to\nimplement, fast to train and yield state-of-the-art performance. However,\nunlike probabilistic models like Hidden Markov Model and Conditional random\nfields, these methods generate models that output merely a prediction with no\nadditional information regarding confidence in the correctness of the output.\nIn this work we fill the gap proposing few alternatives to compute the\nconfidence in the output of non-probabilistic algorithms.We show how to compute\nconfidence estimates in the prediction such that the confidence reflects the\nprobability that the word is labeled correctly. We then show how to use our\nmethods to detect mislabeled words, trade recall for precision and active\nlearning. We evaluate our methods on four noun-phrase chunking and named entity\nrecognition sequence labeling tasks, and on dependency parsing for 14\nlanguages.\n",
        "published": "2011-11-06T08:43:21Z",
        "pdf_link": "http://arxiv.org/pdf/1111.1386v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.1422v1",
        "title": "Robust Interactive Learning",
        "summary": "  In this paper we propose and study a generalization of the standard\nactive-learning model where a more general type of query, class conditional\nquery, is allowed. Such queries have been quite useful in applications, but\nhave been lacking theoretical understanding. In this work, we characterize the\npower of such queries under two well-known noise models. We give nearly tight\nupper and lower bounds on the number of queries needed to learn both for the\ngeneral agnostic setting and for the bounded noise model. We further show that\nour methods can be made adaptive to the (unknown) noise rate, with only\nnegligible loss in query complexity.\n",
        "published": "2011-11-06T14:01:14Z",
        "pdf_link": "http://arxiv.org/pdf/1111.1422v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.4460v1",
        "title": "Parametrized Stochastic Multi-armed Bandits with Binary Rewards",
        "summary": "  In this paper, we consider the problem of multi-armed bandits with a large,\npossibly infinite number of correlated arms. We assume that the arms have\nBernoulli distributed rewards, independent across time, where the probabilities\nof success are parametrized by known attribute vectors for each arm, as well as\nan unknown preference vector, each of dimension $n$. For this model, we seek an\nalgorithm with a total regret that is sub-linear in time and independent of the\nnumber of arms. We present such an algorithm, which we call the Two-Phase\nAlgorithm, and analyze its performance. We show upper bounds on the total\nregret which applies uniformly in time, for both the finite and infinite arm\ncases. The asymptotics of the finite arm bound show that for any $f \\in\n\\omega(\\log(T))$, the total regret can be made to be $O(n \\cdot f(T))$. In the\ninfinite arm case, the total regret is $O(\\sqrt{n^3 T})$.\n",
        "published": "2011-11-18T19:23:47Z",
        "pdf_link": "http://arxiv.org/pdf/1111.4460v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.4470v3",
        "title": "Efficient Regression in Metric Spaces via Approximate Lipschitz\n  Extension",
        "summary": "  We present a framework for performing efficient regression in general metric\nspaces. Roughly speaking, our regressor predicts the value at a new point by\ncomputing a Lipschitz extension --- the smoothest function consistent with the\nobserved data --- after performing structural risk minimization to avoid\noverfitting. We obtain finite-sample risk bounds with minimal structural and\nnoise assumptions, and a natural speed-precision tradeoff. The offline\n(learning) and online (prediction) stages can be solved by convex programming,\nbut this naive approach has runtime complexity $O(n^3)$, which is prohibitive\nfor large datasets. We design instead a regression algorithm whose speed and\ngeneralization performance depend on the intrinsic dimension of the data, to\nwhich the algorithm adapts. While our main innovation is algorithmic, the\nstatistical results may also be of independent interest.\n",
        "published": "2011-11-18T20:32:33Z",
        "pdf_link": "http://arxiv.org/pdf/1111.4470v3"
    },
    {
        "id": "http://arxiv.org/abs/1111.4541v2",
        "title": "Large Scale Spectral Clustering Using Approximate Commute Time Embedding",
        "summary": "  Spectral clustering is a novel clustering method which can detect complex\nshapes of data clusters. However, it requires the eigen decomposition of the\ngraph Laplacian matrix, which is proportion to $O(n^3)$ and thus is not\nsuitable for large scale systems. Recently, many methods have been proposed to\naccelerate the computational time of spectral clustering. These approximate\nmethods usually involve sampling techniques by which a lot information of the\noriginal data may be lost. In this work, we propose a fast and accurate\nspectral clustering approach using an approximate commute time embedding, which\nis similar to the spectral embedding. The method does not require using any\nsampling technique and computing any eigenvector at all. Instead it uses random\nprojection and a linear time solver to find the approximate embedding. The\nexperiments in several synthetic and real datasets show that the proposed\napproach has better clustering quality and is faster than the state-of-the-art\napproximate spectral clustering methods.\n",
        "published": "2011-11-19T08:39:34Z",
        "pdf_link": "http://arxiv.org/pdf/1111.4541v2"
    },
    {
        "id": "http://arxiv.org/abs/1111.6082v3",
        "title": "Trading Regret for Efficiency: Online Convex Optimization with Long Term\n  Constraints",
        "summary": "  In this paper we propose a framework for solving constrained online convex\noptimization problem. Our motivation stems from the observation that most\nalgorithms proposed for online convex optimization require a projection onto\nthe convex set $\\mathcal{K}$ from which the decisions are made. While for\nsimple shapes (e.g. Euclidean ball) the projection is straightforward, for\narbitrary complex sets this is the main computational challenge and may be\ninefficient in practice. In this paper, we consider an alternative online\nconvex optimization problem. Instead of requiring decisions belong to\n$\\mathcal{K}$ for all rounds, we only require that the constraints which define\nthe set $\\mathcal{K}$ be satisfied in the long run. We show that our framework\ncan be utilized to solve a relaxed version of online learning with side\nconstraints addressed in \\cite{DBLP:conf/colt/MannorT06} and\n\\cite{DBLP:conf/aaai/KvetonYTM08}. By turning the problem into an online\nconvex-concave optimization problem, we propose an efficient algorithm which\nachieves $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret bound and\n$\\tilde{\\mathcal{O}}(T^{3/4})$ bound for the violation of constraints. Then we\nmodify the algorithm in order to guarantee that the constraints are satisfied\nin the long run. This gain is achieved at the price of getting\n$\\tilde{\\mathcal{O}}(T^{3/4})$ regret bound. Our second algorithm is based on\nthe Mirror Prox method \\citep{nemirovski-2005-prox} to solve variational\ninequalities which achieves $\\tilde{\\mathcal{\\mathcal{O}}}(T^{2/3})$ bound for\nboth regret and the violation of constraints when the domain $\\K$ can be\ndescribed by a finite number of linear constraints. Finally, we extend the\nresult to the setting where we only have partial access to the convex set\n$\\mathcal{K}$ and propose a multipoint bandit feedback algorithm with the same\nbounds in expectation as our first algorithm.\n",
        "published": "2011-11-25T18:51:29Z",
        "pdf_link": "http://arxiv.org/pdf/1111.6082v3"
    },
    {
        "id": "http://arxiv.org/abs/1111.6337v4",
        "title": "Regret Bound by Variation for Online Convex Optimization",
        "summary": "  In citep{Hazan-2008-extract}, the authors showed that the regret of online\nlinear optimization can be bounded by the total variation of the cost vectors.\nIn this paper, we extend this result to general online convex optimization. We\nfirst analyze the limitations of the algorithm in \\citep{Hazan-2008-extract}\nwhen applied it to online convex optimization. We then present two algorithms\nfor online convex optimization whose regrets are bounded by the variation of\ncost functions. We finally consider the bandit setting, and present a\nrandomized algorithm for online bandit convex optimization with a\nvariation-based regret bound. We show that the regret bound for online bandit\nconvex optimization is optimal when the variation of cost functions is\nindependent of the number of trials.\n",
        "published": "2011-11-28T03:50:18Z",
        "pdf_link": "http://arxiv.org/pdf/1111.6337v4"
    },
    {
        "id": "http://arxiv.org/abs/1112.1125v2",
        "title": "Learning in embodied action-perception loops through exploration",
        "summary": "  Although exploratory behaviors are ubiquitous in the animal kingdom, their\ncomputational underpinnings are still largely unknown. Behavioral Psychology\nhas identified learning as a primary drive underlying many exploratory\nbehaviors. Exploration is seen as a means for an animal to gather sensory data\nuseful for reducing its ignorance about the environment. While related problems\nhave been addressed in Data Mining and Reinforcement Learning, the\ncomputational modeling of learning-driven exploration by embodied agents is\nlargely unrepresented.\n  Here, we propose a computational theory for learning-driven exploration based\non the concept of missing information that allows an agent to identify\ninformative actions using Bayesian inference. We demonstrate that when\nembodiment constraints are high, agents must actively coordinate their actions\nto learn efficiently. Compared to earlier approaches, our exploration policy\nyields more efficient learning across a range of worlds with diverse\nstructures. The improved learning in turn affords greater success in general\ntasks including navigation and reward gathering. We conclude by discussing how\nthe proposed theory relates to previous information-theoretic objectives of\nbehavior, such as predictive information and the free energy principle, and how\nit might contribute to a general theory of exploratory behavior.\n",
        "published": "2011-12-06T00:13:44Z",
        "pdf_link": "http://arxiv.org/pdf/1112.1125v2"
    },
    {
        "id": "http://arxiv.org/abs/1112.1390v1",
        "title": "An Identity for Kernel Ridge Regression",
        "summary": "  This paper derives an identity connecting the square loss of ridge regression\nin on-line mode with the loss of the retrospectively best regressor. Some\ncorollaries about the properties of the cumulative loss of on-line ridge\nregression are also obtained.\n",
        "published": "2011-12-06T20:15:37Z",
        "pdf_link": "http://arxiv.org/pdf/1112.1390v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.1966v1",
        "title": "Bipartite ranking algorithm for classification and survival analysis",
        "summary": "  Unsupervised aggregation of independently built univariate predictors is\nexplored as an alternative regularization approach for noisy, sparse datasets.\nBipartite ranking algorithm Smooth Rank implementing this approach is\nintroduced. The advantages of this algorithm are demonstrated on two types of\nproblems. First, Smooth Rank is applied to two-class problems from bio-medical\nfield, where ranking is often preferable to classification. In comparison\nagainst SVMs with radial and linear kernels, Smooth Rank had the best\nperformance on 8 out of 12 benchmark benchmarks. The second area of application\nis survival analysis, which is reduced here to bipartite ranking in a way which\nallows one to use commonly accepted measures of methods performance. In\ncomparison of Smooth Rank with Cox PH regression and CoxPath methods, Smooth\nRank proved to be the best on 9 out of 10 benchmark datasets.\n",
        "published": "2011-12-08T21:33:38Z",
        "pdf_link": "http://arxiv.org/pdf/1112.1966v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.3712v1",
        "title": "Analysis and Extension of Arc-Cosine Kernels for Large Margin\n  Classification",
        "summary": "  We investigate a recently proposed family of positive-definite kernels that\nmimic the computation in large neural networks. We examine the properties of\nthese kernels using tools from differential geometry; specifically, we analyze\nthe geometry of surfaces in Hilbert space that are induced by these kernels.\nWhen this geometry is described by a Riemannian manifold, we derive results for\nthe metric, curvature, and volume element. Interestingly, though, we find that\nthe simplest kernel in this family does not admit such an interpretation. We\nexplore two variations of these kernels that mimic computation in neural\nnetworks with different activation functions. We experiment with these new\nkernels on several data sets and highlight their general trends in performance\nfor classification.\n",
        "published": "2011-12-16T05:21:10Z",
        "pdf_link": "http://arxiv.org/pdf/1112.3712v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.3714v1",
        "title": "Nonnegative Matrix Factorization for Semi-supervised Dimensionality\n  Reduction",
        "summary": "  We show how to incorporate information from labeled examples into nonnegative\nmatrix factorization (NMF), a popular unsupervised learning algorithm for\ndimensionality reduction. In addition to mapping the data into a space of lower\ndimensionality, our approach aims to preserve the nonnegative components of the\ndata that are important for classification. We identify these components from\nthe support vectors of large-margin classifiers and derive iterative updates to\npreserve them in a semi-supervised version of NMF. These updates have a simple\nmultiplicative form like their unsupervised counterparts; they are also\nguaranteed at each iteration to decrease their loss function---a weighted sum\nof I-divergences that captures the trade-off between unsupervised and\nsupervised learning. We evaluate these updates for dimensionality reduction\nwhen they are used as a precursor to linear classification. In this role, we\nfind that they yield much better performance than their unsupervised\ncounterparts. We also find one unexpected benefit of the low dimensional\nrepresentations discovered by our approach: often they yield more accurate\nclassifiers than both ordinary and transductive SVMs trained in the original\ninput space.\n",
        "published": "2011-12-16T05:33:59Z",
        "pdf_link": "http://arxiv.org/pdf/1112.3714v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.4020v1",
        "title": "Clustering and Latent Semantic Indexing Aspects of the Nonnegative\n  Matrix Factorization",
        "summary": "  This paper provides a theoretical support for clustering aspect of the\nnonnegative matrix factorization (NMF). By utilizing the Karush-Kuhn-Tucker\noptimality conditions, we show that NMF objective is equivalent to graph\nclustering objective, so clustering aspect of the NMF has a solid\njustification. Different from previous approaches which usually discard the\nnonnegativity constraints, our approach guarantees the stationary point being\nused in deriving the equivalence is located on the feasible region in the\nnonnegative orthant. Additionally, since clustering capability of a matrix\ndecomposition technique can sometimes imply its latent semantic indexing (LSI)\naspect, we will also evaluate LSI aspect of the NMF by showing its capability\nin solving the synonymy and polysemy problems in synthetic datasets. And more\nextensive evaluation will be conducted by comparing LSI performances of the NMF\nand the singular value decomposition (SVD), the standard LSI method, using some\nstandard datasets.\n",
        "published": "2011-12-17T03:57:06Z",
        "pdf_link": "http://arxiv.org/pdf/1112.4020v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.4133v1",
        "title": "Evaluation of Performance Measures for Classifiers Comparison",
        "summary": "  The selection of the best classification algorithm for a given dataset is a\nvery widespread problem, occuring each time one has to choose a classifier to\nsolve a real-world problem. It is also a complex task with many important\nmethodological decisions to make. Among those, one of the most crucial is the\nchoice of an appropriate measure in order to properly assess the classification\nperformance and rank the algorithms. In this article, we focus on this specific\ntask. We present the most popular measures and compare their behavior through\ndiscrimination plots. We then discuss their properties from a more theoretical\nperspective. It turns out several of them are equivalent for classifiers\ncomparison purposes. Futhermore. they can also lead to interpretation problems.\nAmong the numerous measures proposed over the years, it appears that the\nclassical overall success rate and marginal rates are the more suitable for\nclassifier comparison task.\n",
        "published": "2011-12-18T08:02:49Z",
        "pdf_link": "http://arxiv.org/pdf/1112.4133v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.4722v2",
        "title": "Modeling transition dynamics in MDPs with RKHS embeddings of conditional\n  distributions",
        "summary": "  We propose a new, nonparametric approach to estimating the value function in\nreinforcement learning. This approach makes use of a recently developed\nrepresentation of conditional distributions as functions in a reproducing\nkernel Hilbert space. Such representations bypass the need for estimating\ntransition probabilities, and apply to any domain on which kernels can be\ndefined. Our approach avoids the need to approximate intractable integrals\nsince expectations are represented as RKHS inner products whose computation has\nlinear complexity in the sample size. Thus, we can efficiently perform value\nfunction estimation in a wide variety of settings, including finite state\nspaces, continuous states spaces, and partially observable tasks where only\nsensor measurements are available. A second advantage of the approach is that\nwe learn the conditional distribution representation from a training sample,\nand do not require an exhaustive exploration of the state space. We prove\nconvergence of our approach either to the optimal policy, or to the closest\nprojection of the optimal policy in our model class, under reasonable\nassumptions. In experiments, we demonstrate the performance of our algorithm on\na learning task in a continuous state space (the under-actuated pendulum), and\non a navigation problem where only images from a sensor are observed. We\ncompare with least-squares policy iteration where a Gaussian process is used\nfor value function estimation. Our algorithm achieves better performance in\nboth tasks.\n",
        "published": "2011-12-20T15:21:26Z",
        "pdf_link": "http://arxiv.org/pdf/1112.4722v2"
    },
    {
        "id": "http://arxiv.org/abs/1112.5246v3",
        "title": "Combining One-Class Classifiers via Meta-Learning",
        "summary": "  Selecting the best classifier among the available ones is a difficult task,\nespecially when only instances of one class exist. In this work we examine the\nnotion of combining one-class classifiers as an alternative for selecting the\nbest classifier. In particular, we propose two new one-class classification\nperformance measures to weigh classifiers and show that a simple ensemble that\nimplements these measures can outperform the most popular one-class ensembles.\nFurthermore, we propose a new one-class ensemble scheme, TUPSO, which uses\nmeta-learning to combine one-class classifiers. Our experiments demonstrate the\nsuperiority of TUPSO over all other tested ensembles and show that the TUPSO\nperformance is statistically indistinguishable from that of the hypothetical\nbest classifier.\n",
        "published": "2011-12-22T08:07:56Z",
        "pdf_link": "http://arxiv.org/pdf/1112.5246v3"
    },
    {
        "id": "http://arxiv.org/abs/1112.6209v5",
        "title": "Building high-level features using large scale unsupervised learning",
        "summary": "  We consider the problem of building high-level, class-specific feature\ndetectors from only unlabeled data. For example, is it possible to learn a face\ndetector using only unlabeled images? To answer this, we train a 9-layered\nlocally connected sparse autoencoder with pooling and local contrast\nnormalization on a large dataset of images (the model has 1 billion\nconnections, the dataset has 10 million 200x200 pixel images downloaded from\nthe Internet). We train this network using model parallelism and asynchronous\nSGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to\nwhat appears to be a widely-held intuition, our experimental results reveal\nthat it is possible to train a face detector without having to label images as\ncontaining a face or not. Control experiments show that this feature detector\nis robust not only to translation but also to scaling and out-of-plane\nrotation. We also find that the same network is sensitive to other high-level\nconcepts such as cat faces and human bodies. Starting with these learned\nfeatures, we trained our network to obtain 15.8% accuracy in recognizing 20,000\nobject categories from ImageNet, a leap of 70% relative improvement over the\nprevious state-of-the-art.\n",
        "published": "2011-12-29T00:26:54Z",
        "pdf_link": "http://arxiv.org/pdf/1112.6209v5"
    },
    {
        "id": "http://arxiv.org/abs/1112.6399v1",
        "title": "Two-Manifold Problems",
        "summary": "  Recently, there has been much interest in spectral approaches to learning\nmanifolds---so-called kernel eigenmap methods. These methods have had some\nsuccesses, but their applicability is limited because they are not robust to\nnoise. To address this limitation, we look at two-manifold problems, in which\nwe simultaneously reconstruct two related manifolds, each representing a\ndifferent view of the same data. By solving these interconnected learning\nproblems together and allowing information to flow between them, two-manifold\nalgorithms are able to succeed where a non-integrated approach would fail: each\nview allows us to suppress noise in the other, reducing bias in the same way\nthat an instrumental variable allows us to remove bias in a {linear}\ndimensionality reduction problem. We propose a class of algorithms for\ntwo-manifold problems, based on spectral decomposition of cross-covariance\noperators in Hilbert space. Finally, we discuss situations where two-manifold\nproblems are useful, and demonstrate that solving a two-manifold problem can\naid in learning a nonlinear dynamical system from limited data.\n",
        "published": "2011-12-29T19:52:14Z",
        "pdf_link": "http://arxiv.org/pdf/1112.6399v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.0292v1",
        "title": "T-Learning",
        "summary": "  Traditional Reinforcement Learning (RL) has focused on problems involving\nmany states and few actions, such as simple grid worlds. Most real world\nproblems, however, are of the opposite type, Involving Few relevant states and\nmany actions. For example, to return home from a conference, humans identify\nonly few subgoal states such as lobby, taxi, airport etc. Each valid behavior\nconnecting two such states can be viewed as an action, and there are trillions\nof them. Assuming the subgoal identification problem is already solved, the\nquality of any RL method---in real-world settings---depends less on how well it\nscales with the number of states than on how well it scales with the number of\nactions. This is where our new method T-Learning excels, by evaluating the\nrelatively few possible transits from one state to another in a\npolicy-independent way, rather than a huge number of state-action pairs, or\nstates in traditional policy-dependent ways. Illustrative experiments\ndemonstrate that performance improvements of T-Learning over Q-learning can be\narbitrarily large.\n",
        "published": "2011-12-31T17:29:08Z",
        "pdf_link": "http://arxiv.org/pdf/1201.0292v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.0838v2",
        "title": "A Topic Modeling Toolbox Using Belief Propagation",
        "summary": "  Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model\nfor probabilistic topic modeling, which attracts worldwide interests and\ntouches on many important applications in text mining, computer vision and\ncomputational biology. This paper introduces a topic modeling toolbox (TMBP)\nbased on the belief propagation (BP) algorithms. TMBP toolbox is implemented by\nMEX C++/Matlab/Octave for either Windows 7 or Linux. Compared with existing\ntopic modeling packages, the novelty of this toolbox lies in the BP algorithms\nfor learning LDA-based topic models. The current version includes BP algorithms\nfor latent Dirichlet allocation (LDA), author-topic models (ATM), relational\ntopic models (RTM), and labeled LDA (LaLDA). This toolbox is an ongoing project\nand more BP-based algorithms for various topic models will be added in the near\nfuture. Interested users may also extend BP algorithms for learning more\ncomplicated topic models. The source codes are freely available under the GNU\nGeneral Public Licence, Version 1.0 at https://mloss.org/software/view/399/.\n",
        "published": "2012-01-04T07:07:06Z",
        "pdf_link": "http://arxiv.org/pdf/1201.0838v2"
    },
    {
        "id": "http://arxiv.org/abs/1201.1670v1",
        "title": "Customers Behavior Modeling by Semi-Supervised Learning in Customer\n  Relationship Management",
        "summary": "  Leveraging the power of increasing amounts of data to analyze customer base\nfor attracting and retaining the most valuable customers is a major problem\nfacing companies in this information age. Data mining technologies extract\nhidden information and knowledge from large data stored in databases or data\nwarehouses, thereby supporting the corporate decision making process. CRM uses\ndata mining (one of the elements of CRM) techniques to interact with customers.\nThis study investigates the use of a technique, semi-supervised learning, for\nthe management and analysis of customer-related data warehouse and information.\nThe idea of semi-supervised learning is to learn not only from the labeled\ntraining data, but to exploit also the structural information in additionally\navailable unlabeled data. The proposed semi-supervised method is a model by\nmeans of a feed-forward neural network trained by a back propagation algorithm\n(multi-layer perceptron) in order to predict the category of an unknown\ncustomer (potential customers). In addition, this technique can be used with\nRapid Miner tools for both labeled and unlabeled data.\n",
        "published": "2012-01-08T23:59:27Z",
        "pdf_link": "http://arxiv.org/pdf/1201.1670v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.2173v1",
        "title": "Automatic Detection of Diabetes Diagnosis using Feature Weighted Support\n  Vector Machines based on Mutual Information and Modified Cuckoo Search",
        "summary": "  Diabetes is a major health problem in both developing and developed countries\nand its incidence is rising dramatically. In this study, we investigate a novel\nautomatic approach to diagnose Diabetes disease based on Feature Weighted\nSupport Vector Machines (FW-SVMs) and Modified Cuckoo Search (MCS). The\nproposed model consists of three stages: Firstly, PCA is applied to select an\noptimal subset of features out of set of all the features. Secondly, Mutual\nInformation is employed to construct the FWSVM by weighting different features\nbased on their degree of importance. Finally, since parameter selection plays a\nvital role in classification accuracy of SVMs, MCS is applied to select the\nbest parameter values. The proposed MI-MCS-FWSVM method obtains 93.58% accuracy\non UCI dataset. The experimental results demonstrate that our method\noutperforms the previous methods by not only giving more accurate results but\nalso significantly speeding up the classification procedure.\n",
        "published": "2012-01-10T11:03:42Z",
        "pdf_link": "http://arxiv.org/pdf/1201.2173v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.2416v1",
        "title": "Stochastic Low-Rank Kernel Learning for Regression",
        "summary": "  We present a novel approach to learn a kernel-based regression function. It\nis based on the useof conical combinations of data-based parameterized kernels\nand on a new stochastic convex optimization procedure of which we establish\nconvergence guarantees. The overall learning procedure has the nice properties\nthat a) the learned conical combination is automatically designed to perform\nthe regression task at hand and b) the updates implicated by the optimization\nprocedure are quite inexpensive. In order to shed light on the appositeness of\nour learning strategy, we present empirical results from experiments conducted\non various benchmark datasets.\n",
        "published": "2012-01-11T21:03:55Z",
        "pdf_link": "http://arxiv.org/pdf/1201.2416v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.2902v1",
        "title": "Acoustical Quality Assessment of the Classroom Environment",
        "summary": "  Teaching is one of the most important factors affecting any education system.\nMany research efforts have been conducted to facilitate the presentation modes\nused by instructors in classrooms as well as provide means for students to\nreview lectures through web browsers. Other studies have been made to provide\nacoustical design recommendations for classrooms like room size and\nreverberation times. However, using acoustical features of classrooms as a way\nto provide education systems with feedback about the learning process was not\nthoroughly investigated in any of these studies. We propose a system that\nextracts different sound features of students and instructors, and then uses\nmachine learning techniques to evaluate the acoustical quality of any learning\nenvironment. We infer conclusions about the students' satisfaction with the\nquality of lectures. Using classifiers instead of surveys and other subjective\nways of measures can facilitate and speed such experiments which enables us to\nperform them continuously. We believe our system enables education systems to\ncontinuously review and improve their teaching strategies and acoustical\nquality of classrooms.\n",
        "published": "2012-01-13T17:46:17Z",
        "pdf_link": "http://arxiv.org/pdf/1201.2902v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.5283v5",
        "title": "An Efficient Primal-Dual Prox Method for Non-Smooth Optimization",
        "summary": "  We study the non-smooth optimization problems in machine learning, where both\nthe loss function and the regularizer are non-smooth functions. Previous\nstudies on efficient empirical loss minimization assume either a smooth loss\nfunction or a strongly convex regularizer, making them unsuitable for\nnon-smooth optimization. We develop a simple yet efficient method for a family\nof non-smooth optimization problems where the dual form of the loss function is\nbilinear in primal and dual variables. We cast a non-smooth optimization\nproblem into a minimax optimization problem, and develop a primal dual prox\nmethod that solves the minimax optimization problem at a rate of $O(1/T)$\n{assuming that the proximal step can be efficiently solved}, significantly\nfaster than a standard subgradient descent method that has an $O(1/\\sqrt{T})$\nconvergence rate. Our empirical study verifies the efficiency of the proposed\nmethod for various non-smooth optimization problems that arise ubiquitously in\nmachine learning by comparing it to the state-of-the-art first order methods.\n",
        "published": "2012-01-24T04:09:54Z",
        "pdf_link": "http://arxiv.org/pdf/1201.5283v5"
    },
    {
        "id": "http://arxiv.org/abs/1201.6053v1",
        "title": "A Comparison Between Data Mining Prediction Algorithms for Fault\n  Detection(Case study: Ahanpishegan co.)",
        "summary": "  In the current competitive world, industrial companies seek to manufacture\nproducts of higher quality which can be achieved by increasing reliability,\nmaintainability and thus the availability of products. On the other hand,\nimprovement in products lifecycle is necessary for achieving high reliability.\nTypically, maintenance activities are aimed to reduce failures of industrial\nmachinery and minimize the consequences of such failures. So the industrial\ncompanies try to improve their efficiency by using different fault detection\ntechniques. One strategy is to process and analyze previous generated data to\npredict future failures. The purpose of this paper is to detect wasted parts\nusing different data mining algorithms and compare the accuracy of these\nalgorithms. A combination of thermal and physical characteristics has been used\nand the algorithms were implemented on Ahanpishegan's current data to estimate\nthe availability of its produced parts.\n  Keywords: Data Mining, Fault Detection, Availability, Prediction Algorithms.\n",
        "published": "2012-01-29T16:23:54Z",
        "pdf_link": "http://arxiv.org/pdf/1201.6053v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.6462v1",
        "title": "Active Learning of Custering with Side Information Using $\\eps$-Smooth\n  Relative Regret Approximations",
        "summary": "  Clustering is considered a non-supervised learning setting, in which the goal\nis to partition a collection of data points into disjoint clusters. Often a\nbound $k$ on the number of clusters is given or assumed by the practitioner.\nMany versions of this problem have been defined, most notably $k$-means and\n$k$-median.\n  An underlying problem with the unsupervised nature of clustering it that of\ndetermining a similarity function. One approach for alleviating this difficulty\nis known as clustering with side information, alternatively, semi-supervised\nclustering. Here, the practitioner incorporates side information in the form of\n\"must be clustered\" or \"must be separated\" labels for data point pairs. Each\nsuch piece of information comes at a \"query cost\" (often involving human\nresponse solicitation). The collection of labels is then incorporated in the\nusual clustering algorithm as either strict or as soft constraints, possibly\nadding a pairwise constraint penalty function to the chosen clustering\nobjective.\n  Our work is mostly related to clustering with side information. We ask how to\nchoose the pairs of data points. Our analysis gives rise to a method provably\nbetter than simply choosing them uniformly at random. Roughly speaking, we show\nthat the distribution must be biased so as more weight is placed on pairs\nincident to elements in smaller clusters in some optimal solution. Of course we\ndo not know the optimal solution, hence we don't know the bias. Using the\nrecently introduced method of $\\eps$-smooth relative regret approximations of\nAilon, Begleiter and Ezra, we can show an iterative process that improves both\nthe clustering and the bias in tandem. The process provably converges to the\noptimal solution faster (in terms of query cost) than an algorithm selecting\npairs uniformly.\n",
        "published": "2012-01-31T07:46:08Z",
        "pdf_link": "http://arxiv.org/pdf/1201.6462v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.1334v2",
        "title": "Contextual Bandit Learning with Predictable Rewards",
        "summary": "  Contextual bandit learning is a reinforcement learning problem where the\nlearner repeatedly receives a set of features (context), takes an action and\nreceives a reward based on the action and context. We consider this problem\nunder a realizability assumption: there exists a function in a (known) function\nclass, always capable of predicting the expected reward, given the action and\ncontext. Under this assumption, we show three things. We present a new\nalgorithm---Regressor Elimination--- with a regret similar to the agnostic\nsetting (i.e. in the absence of realizability assumption). We prove a new lower\nbound showing no algorithm can achieve superior performance in the worst case\neven with the realizability assumption. However, we do show that for any set of\npolicies (mapping contexts to actions), there is a distribution over rewards\n(given context) such that our new algorithm has constant regret unlike the\nprevious approaches.\n",
        "published": "2012-02-07T02:27:55Z",
        "pdf_link": "http://arxiv.org/pdf/1202.1334v2"
    },
    {
        "id": "http://arxiv.org/abs/1202.1558v1",
        "title": "On the Performance of Maximum Likelihood Inverse Reinforcement Learning",
        "summary": "  Inverse reinforcement learning (IRL) addresses the problem of recovering a\ntask description given a demonstration of the optimal policy used to solve such\na task. The optimal policy is usually provided by an expert or teacher, making\nIRL specially suitable for the problem of apprenticeship learning. The task\ndescription is encoded in the form of a reward function of a Markov decision\nprocess (MDP). Several algorithms have been proposed to find the reward\nfunction corresponding to a set of demonstrations. One of the algorithms that\nhas provided best results in different applications is a gradient method to\noptimize a policy squared error criterion. On a parallel line of research,\nother authors have presented recently a gradient approximation of the maximum\nlikelihood estimate of the reward signal. In general, both approaches\napproximate the gradient estimate and the criteria at different stages to make\nthe algorithm tractable and efficient. In this work, we provide a detailed\ndescription of the different methods to highlight differences in terms of\nreward estimation, policy similarity and computational costs. We also provide\nexperimental results to evaluate the differences in performance of the methods.\n",
        "published": "2012-02-07T23:14:36Z",
        "pdf_link": "http://arxiv.org/pdf/1202.1558v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.3890v1",
        "title": "PAC Bounds for Discounted MDPs",
        "summary": "  We study upper and lower bounds on the sample-complexity of learning\nnear-optimal behaviour in finite-state discounted Markov Decision Processes\n(MDPs). For the upper bound we make the assumption that each action leads to at\nmost two possible next-states and prove a new bound for a UCRL-style algorithm\non the number of time-steps when it is not Probably Approximately Correct\n(PAC). The new lower bound strengthens previous work by being both more general\n(it applies to all policies) and tighter. The upper and lower bounds match up\nto logarithmic factors.\n",
        "published": "2012-02-17T11:59:55Z",
        "pdf_link": "http://arxiv.org/pdf/1202.3890v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.6221v2",
        "title": "Confusion Matrix Stability Bounds for Multiclass Classification",
        "summary": "  In this paper, we provide new theoretical results on the generalization\nproperties of learning algorithms for multiclass classification problems. The\noriginality of our work is that we propose to use the confusion matrix of a\nclassifier as a measure of its quality; our contribution is in the line of work\nwhich attempts to set up and study the statistical properties of new evaluation\nmeasures such as, e.g. ROC curves. In the confusion-based learning framework we\npropose, we claim that a targetted objective is to minimize the size of the\nconfusion matrix C, measured through its operator norm ||C||. We derive\ngeneralization bounds on the (size of the) confusion matrix in an extended\nframework of uniform stability, adapted to the case of matrix valued loss.\nPivotal to our study is a very recent matrix concentration inequality that\ngeneralizes McDiarmid's inequality. As an illustration of the relevance of our\ntheoretical results, we show how two SVM learning procedures can be proved to\nbe confusion-friendly. To the best of our knowledge, the present paper is the\nfirst that focuses on the confusion matrix from a theoretical point of view.\n",
        "published": "2012-02-28T14:03:11Z",
        "pdf_link": "http://arxiv.org/pdf/1202.6221v2"
    },
    {
        "id": "http://arxiv.org/abs/1203.0298v2",
        "title": "Application of Gist SVM in Cancer Detection",
        "summary": "  In this paper, we study the application of GIST SVM in disease prediction\n(detection of cancer). Pattern classification problems can be effectively\nsolved by Support vector machines. Here we propose a classifier which can\ndifferentiate patients having benign and malignant cancer cells. To improve the\naccuracy of classification, we propose to determine the optimal size of the\ntraining set and perform feature selection. To find the optimal size of the\ntraining set, different sizes of training sets are experimented and the one\nwith highest classification rate is selected. The optimal features are selected\nthrough their F-Scores.\n",
        "published": "2012-03-01T14:40:02Z",
        "pdf_link": "http://arxiv.org/pdf/1203.0298v2"
    },
    {
        "id": "http://arxiv.org/abs/1203.2557v3",
        "title": "On the Necessity of Irrelevant Variables",
        "summary": "  This work explores the effects of relevant and irrelevant boolean variables\non the accuracy of classifiers. The analysis uses the assumption that the\nvariables are conditionally independent given the class, and focuses on a\nnatural family of learning algorithms for such sources when the relevant\nvariables have a small advantage over random guessing. The main result is that\nalgorithms relying predominately on irrelevant variables have error\nprobabilities that quickly go to 0 in situations where algorithms that limit\nthe use of irrelevant variables have errors bounded below by a positive\nconstant. We also show that accurate learning is possible even when there are\nso few examples that one cannot determine with high confidence whether or not\nany individual variable is relevant.\n",
        "published": "2012-03-12T17:17:34Z",
        "pdf_link": "http://arxiv.org/pdf/1203.2557v3"
    },
    {
        "id": "http://arxiv.org/abs/1203.3832v1",
        "title": "Data Mining: A Prediction for Performance Improvement of Engineering\n  Students using Classification",
        "summary": "  Now-a-days the amount of data stored in educational database increasing\nrapidly. These databases contain hidden information for improvement of\nstudents' performance. Educational data mining is used to study the data\navailable in the educational field and bring out the hidden knowledge from it.\nClassification methods like decision trees, Bayesian network etc can be applied\non the educational data for predicting the student's performance in\nexamination. This prediction will help to identify the weak students and help\nthem to score better marks. The C4.5, ID3 and CART decision tree algorithms are\napplied on engineering student's data to predict their performance in the final\nexam. The outcome of the decision tree predicted the number of students who are\nlikely to pass, fail or promoted to next year. The results provide steps to\nimprove the performance of the students who were predicted to fail or promoted.\nAfter the declaration of the results in the final examination the marks\nobtained by the students are fed into the system and the results were analyzed\nfor the next session. The comparative analysis of the results states that the\nprediction has helped the weaker students to improve and brought out betterment\nin the result.\n",
        "published": "2012-03-17T02:06:41Z",
        "pdf_link": "http://arxiv.org/pdf/1203.3832v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.4598v1",
        "title": "Adaptive Mixture Methods Based on Bregman Divergences",
        "summary": "  We investigate adaptive mixture methods that linearly combine outputs of $m$\nconstituent filters running in parallel to model a desired signal. We use\n\"Bregman divergences\" and obtain certain multiplicative updates to train the\nlinear combination weights under an affine constraint or without any\nconstraints. We use unnormalized relative entropy and relative entropy to\ndefine two different Bregman divergences that produce an unnormalized\nexponentiated gradient update and a normalized exponentiated gradient update on\nthe mixture weights, respectively. We then carry out the mean and the\nmean-square transient analysis of these adaptive algorithms when they are used\nto combine outputs of $m$ constituent filters. We illustrate the accuracy of\nour results and demonstrate the effectiveness of these updates for sparse\nmixture systems.\n",
        "published": "2012-03-20T21:32:33Z",
        "pdf_link": "http://arxiv.org/pdf/1203.4598v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.4788v1",
        "title": "Very Short Literature Survey From Supervised Learning To Surrogate\n  Modeling",
        "summary": "  The past century was era of linear systems. Either systems (especially\nindustrial ones) were simple (quasi)linear or linear approximations were\naccurate enough. In addition, just at the ending decades of the century\nprofusion of computing devices were available, before then due to lack of\ncomputational resources it was not easy to evaluate available nonlinear system\nstudies. At the moment both these two conditions changed, systems are highly\ncomplex and also pervasive amount of computation strength is cheap and easy to\nachieve. For recent era, a new branch of supervised learning well known as\nsurrogate modeling (meta-modeling, surface modeling) has been devised which\naimed at answering new needs of modeling realm. This short literature survey is\non to introduce surrogate modeling to whom is familiar with the concepts of\nsupervised learning. Necessity, challenges and visions of the topic are\nconsidered.\n",
        "published": "2012-03-21T17:29:17Z",
        "pdf_link": "http://arxiv.org/pdf/1203.4788v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.5716v2",
        "title": "Credal Classification based on AODE and compression coefficients",
        "summary": "  Bayesian model averaging (BMA) is an approach to average over alternative\nmodels; yet, it usually gets excessively concentrated around the single most\nprobable model, therefore achieving only sub-optimal classification\nperformance. The compression-based approach (Boulle, 2007) overcomes this\nproblem, averaging over the different models by applying a logarithmic\nsmoothing over the models' posterior probabilities. This approach has shown\nexcellent performances when applied to ensembles of naive Bayes classifiers.\nAODE is another ensemble of models with high performance (Webb, 2005), based on\na collection of non-naive classifiers (called SPODE) whose probabilistic\npredictions are aggregated by simple arithmetic mean. Aggregating the SPODEs\nvia BMA rather than by arithmetic mean deteriorates the performance; instead,\nwe aggregate the SPODEs via the compression coefficients and we show that the\nresulting classifier obtains a slight but consistent improvement over AODE.\nHowever, an important issue in any Bayesian ensemble of models is the\narbitrariness in the choice of the prior over the models. We address this\nproblem by the paradigm of credal classification, namely by substituting the\nunique prior with a set of priors. Credal classifier automatically recognize\nthe prior-dependent instances, namely the instances whose most probable class\nvaries, when different priors are considered; in these cases, credal\nclassifiers remain reliable by returning a set of classes rather than a single\nclass. We thus develop the credal version of both the BMA-based and the\ncompression-based ensemble of SPODEs, substituting the single prior over the\nmodels by a set of priors. Experiments show that both credal classifiers\nprovide higher classification reliability than their determinate counterparts;\nmoreover the compression-based credal classifier compares favorably to previous\ncredal classifiers.\n",
        "published": "2012-03-26T16:25:35Z",
        "pdf_link": "http://arxiv.org/pdf/1203.5716v2"
    },
    {
        "id": "http://arxiv.org/abs/1204.0566v2",
        "title": "The Kernelized Stochastic Batch Perceptron",
        "summary": "  We present a novel approach for training kernel Support Vector Machines,\nestablish learning runtime guarantees for our method that are better then those\nof any other known kernelized SVM optimization approach, and show that our\nmethod works well in practice compared to existing alternatives.\n",
        "published": "2012-04-03T00:33:53Z",
        "pdf_link": "http://arxiv.org/pdf/1204.0566v2"
    },
    {
        "id": "http://arxiv.org/abs/1204.2609v2",
        "title": "Stochastic Feature Mapping for PAC-Bayes Classification",
        "summary": "  Probabilistic generative modeling of data distributions can potentially\nexploit hidden information which is useful for discriminative classification.\nThis observation has motivated the development of approaches that couple\ngenerative and discriminative models for classification. In this paper, we\npropose a new approach to couple generative and discriminative models in an\nunified framework based on PAC-Bayes risk theory. We first derive the\nmodel-parameter-independent stochastic feature mapping from a practical MAP\nclassifier operating on generative models. Then we construct a linear\nstochastic classifier equipped with the feature mapping, and derive the\nexplicit PAC-Bayes risk bounds for such classifier for both supervised and\nsemi-supervised learning. Minimizing the risk bound, using an EM-like iterative\nprocedure, results in a new posterior over hidden variables (E-step) and the\nupdate rules of model parameters (M-step). The derivation of the posterior is\nalways feasible due to the way of equipping feature mapping and the explicit\nform of bounding risk. The derived posterior allows the tuning of generative\nmodels and subsequently the feature mappings for better classification. The\nderived update rules of the model parameters are same to those of the uncoupled\nmodels as the feature mapping is model-parameter-independent. Our experiments\nshow that the coupling between data modeling generative model and the\ndiscriminative classifier via a stochastic feature mapping in this framework\nleads to a general classification tool with state-of-the-art performance.\n",
        "published": "2012-04-12T03:49:15Z",
        "pdf_link": "http://arxiv.org/pdf/1204.2609v2"
    },
    {
        "id": "http://arxiv.org/abs/1204.4329v1",
        "title": "Supervised feature evaluation by consistency analysis: application to\n  measure sets used to characterise geographic objects",
        "summary": "  Nowadays, supervised learning is commonly used in many domains. Indeed, many\nworks propose to learn new knowledge from examples that translate the expected\nbehaviour of the considered system. A key issue of supervised learning concerns\nthe description language used to represent the examples. In this paper, we\npropose a method to evaluate the feature set used to describe them. Our method\nis based on the computation of the consistency of the example base. We carried\nout a case study in the domain of geomatic in order to evaluate the sets of\nmeasures used to characterise geographic objects. The case study shows that our\nmethod allows to give relevant evaluations of measure sets.\n",
        "published": "2012-04-19T12:03:20Z",
        "pdf_link": "http://arxiv.org/pdf/1204.4329v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.0406v1",
        "title": "Minimax Classifier for Uncertain Costs",
        "summary": "  Many studies on the cost-sensitive learning assumed that a unique cost matrix\nis known for a problem. However, this assumption may not hold for many\nreal-world problems. For example, a classifier might need to be applied in\nseveral circumstances, each of which associates with a different cost matrix.\nOr, different human experts have different opinions about the costs for a given\nproblem. Motivated by these facts, this study aims to seek the minimax\nclassifier over multiple cost matrices. In summary, we theoretically proved\nthat, no matter how many cost matrices are involved, the minimax problem can be\ntackled by solving a number of standard cost-sensitive problems and\nsub-problems that involve only two cost matrices. As a result, a general\nframework for achieving minimax classifier over multiple cost matrices is\nsuggested and justified by preliminary empirical studies.\n",
        "published": "2012-05-02T12:38:11Z",
        "pdf_link": "http://arxiv.org/pdf/1205.0406v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.0610v1",
        "title": "Greedy Multiple Instance Learning via Codebook Learning and Nearest\n  Neighbor Voting",
        "summary": "  Multiple instance learning (MIL) has attracted great attention recently in\nmachine learning community. However, most MIL algorithms are very slow and\ncannot be applied to large datasets. In this paper, we propose a greedy\nstrategy to speed up the multiple instance learning process. Our contribution\nis two fold. First, we propose a density ratio model, and show that maximizing\na density ratio function is the low bound of the DD model under certain\nconditions. Secondly, we make use of a histogram ratio between positive bags\nand negative bags to represent the density ratio function and find codebooks\nseparately for positive bags and negative bags by a greedy strategy. For\ntesting, we make use of a nearest neighbor strategy to classify new bags. We\ntest our method on both small benchmark datasets and the large TRECVID MED11\ndataset. The experimental results show that our method yields comparable\naccuracy to the current state of the art, while being up to at least one order\nof magnitude faster.\n",
        "published": "2012-05-03T04:09:19Z",
        "pdf_link": "http://arxiv.org/pdf/1205.0610v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2151v1",
        "title": "A Converged Algorithm for Tikhonov Regularized Nonnegative Matrix\n  Factorization with Automatic Regularization Parameters Determination",
        "summary": "  We present a converged algorithm for Tikhonov regularized nonnegative matrix\nfactorization (NMF). We specially choose this regularization because it is\nknown that Tikhonov regularized least square (LS) is the more preferable form\nin solving linear inverse problems than the conventional LS. Because an NMF\nproblem can be decomposed into LS subproblems, it can be expected that Tikhonov\nregularized NMF will be the more appropriate approach in solving NMF problems.\nThe algorithm is derived using additive update rules which have been shown to\nhave convergence guarantee. We equip the algorithm with a mechanism to\nautomatically determine the regularization parameters based on the L-curve, a\nwell-known concept in the inverse problems community, but is rather unknown in\nthe NMF research. The introduction of this algorithm thus solves two inherent\nproblems in Tikhonov regularized NMF algorithm research, i.e., convergence\nguarantee and regularization parameters determination.\n",
        "published": "2012-05-10T03:31:39Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2151v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2265v2",
        "title": "Efficient Constrained Regret Minimization",
        "summary": "  Online learning constitutes a mathematical and compelling framework to\nanalyze sequential decision making problems in adversarial environments. The\nlearner repeatedly chooses an action, the environment responds with an outcome,\nand then the learner receives a reward for the played action. The goal of the\nlearner is to maximize his total reward. However, there are situations in\nwhich, in addition to maximizing the cumulative reward, there are some\nadditional constraints on the sequence of decisions that must be satisfied on\naverage by the learner. In this paper we study an extension to the online\nlearning where the learner aims to maximize the total reward given that some\nadditional constraints need to be satisfied. By leveraging on the theory of\nLagrangian method in constrained optimization, we propose Lagrangian\nexponentially weighted average (LEWA) algorithm, which is a primal-dual variant\nof the well known exponentially weighted average algorithm, to efficiently\nsolve constrained online decision making problems. Using novel theoretical\nanalysis, we establish the regret and the violation of the constraint bounds in\nfull information and bandit feedback models.\n",
        "published": "2012-05-08T23:06:06Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2265v2"
    },
    {
        "id": "http://arxiv.org/abs/1205.2600v1",
        "title": "A Uniqueness Theorem for Clustering",
        "summary": "  Despite the widespread use of Clustering, there is distressingly little\ngeneral theory of clustering available. Questions like \"What distinguishes a\nclustering of data from other data partitioning?\", \"Are there any principles\ngoverning all clustering paradigms?\", \"How should a user choose an appropriate\nclustering algorithm for a particular task?\", etc. are almost completely\nunanswered by the existing body of clustering literature. We consider an\naxiomatic approach to the theory of Clustering. We adopt the framework of\nKleinberg, [Kle03]. By relaxing one of Kleinberg's clustering axioms, we\nsidestep his impossibility result and arrive at a consistent set of axioms. We\nsuggest to extend these axioms, aiming to provide an axiomatic taxonomy of\nclustering paradigms. Such a taxonomy should provide users some guidance\nconcerning the choice of the appropriate clustering paradigm for a given task.\nThe main result of this paper is a set of abstract properties that characterize\nthe Single-Linkage clustering function. This characterization result provides\nnew insight into the properties of desired data groupings that make\nSingle-Linkage the appropriate choice. We conclude by considering a taxonomy of\nclustering functions based on abstract properties that each satisfies.\n",
        "published": "2012-05-09T18:48:23Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2600v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2602v1",
        "title": "The Entire Quantile Path of a Risk-Agnostic SVM Classifier",
        "summary": "  A quantile binary classifier uses the rule: Classify x as +1 if P(Y = 1|X =\nx) >= t, and as -1 otherwise, for a fixed quantile parameter t {[0, 1]. It has\nbeen shown that Support Vector Machines (SVMs) in the limit are quantile\nclassifiers with t = 1/2 . In this paper, we show that by using asymmetric cost\nof misclassification SVMs can be appropriately extended to recover, in the\nlimit, the quantile binary classifier for any t. We then present a principled\nalgorithm to solve the extended SVM classifier for all values of t\nsimultaneously. This has two implications: First, one can recover the entire\nconditional distribution P(Y = 1|X = x) = t for t {[0, 1]. Second, we can build\na risk-agnostic SVM classifier where the cost of misclassification need not be\nknown apriori. Preliminary numerical experiments show the effectiveness of the\nproposed algorithm.\n",
        "published": "2012-05-09T18:46:51Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2602v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2610v1",
        "title": "Probabilistic Structured Predictors",
        "summary": "  We consider MAP estimators for structured prediction with exponential family\nmodels. In particular, we concentrate on the case that efficient algorithms for\nuniform sampling from the output space exist. We show that under this\nassumption (i) exact computation of the partition function remains a hard\nproblem, and (ii) the partition function and the gradient of the log partition\nfunction can be approximated efficiently. Our main result is an approximation\nscheme for the partition function based on Markov Chain Monte Carlo theory. We\nalso show that the efficient uniform sampling assumption holds in several\napplication settings that are of importance in machine learning.\n",
        "published": "2012-05-09T18:36:39Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2610v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2661v1",
        "title": "REGAL: A Regularization based Algorithm for Reinforcement Learning in\n  Weakly Communicating MDPs",
        "summary": "  We provide an algorithm that achieves the optimal regret rate in an unknown\nweakly communicating Markov Decision Process (MDP). The algorithm proceeds in\nepisodes where, in each episode, it picks a policy using regularization based\non the span of the optimal bias vector. For an MDP with S states and A actions\nwhose optimal bias vector has span bounded by H, we show a regret bound of\n~O(HSpAT). We also relate the span to various diameter-like quantities\nassociated with the MDP, demonstrating how our results improve on previous\nregret bounds.\n",
        "published": "2012-05-09T14:47:06Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2661v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2664v1",
        "title": "A Bayesian Sampling Approach to Exploration in Reinforcement Learning",
        "summary": "  We present a modular approach to reinforcement learning that uses a Bayesian\nrepresentation of the uncertainty over models. The approach, BOSS (Best of\nSampled Set), drives exploration by sampling multiple models from the posterior\nand selecting actions optimistically. It extends previous work by providing a\nrule for deciding when to resample and how to combine the models. We show that\nour algorithm achieves nearoptimal reward with high probability with a sample\ncomplexity that is low relative to the speed at which the posterior\ndistribution converges during learning. We demonstrate that BOSS performs quite\nfavorably compared to state-of-the-art reinforcement-learning approaches and\nillustrate its flexibility by pairing it with a non-parametric model that\ngeneralizes across states.\n",
        "published": "2012-05-09T14:42:20Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2664v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2874v3",
        "title": "Decoupling Exploration and Exploitation in Multi-Armed Bandits",
        "summary": "  We consider a multi-armed bandit problem where the decision maker can explore\nand exploit different arms at every round. The exploited arm adds to the\ndecision maker's cumulative reward (without necessarily observing the reward)\nwhile the explored arm reveals its value. We devise algorithms for this setup\nand show that the dependence on the number of arms, k, can be much better than\nthe standard square root of k dependence, depending on the behavior of the\narms' reward sequences. For the important case of piecewise stationary\nstochastic bandits, we show a significant improvement over existing algorithms.\nOur algorithms are based on a non-uniform sampling policy, which we show is\nessential to the success of any algorithm in the adversarial setup. Finally, we\nshow some simulation results on an ultra-wide band channel selection inspired\nsetting indicating the applicability of our algorithms.\n",
        "published": "2012-05-13T15:11:00Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2874v3"
    },
    {
        "id": "http://arxiv.org/abs/1205.3549v2",
        "title": "Normalized Maximum Likelihood Coding for Exponential Family with Its\n  Applications to Optimal Clustering",
        "summary": "  We are concerned with the issue of how to calculate the normalized maximum\nlikelihood (NML) code-length. There is a problem that the normalization term of\nthe NML code-length may diverge when it is continuous and unbounded and a\nstraightforward computation of it is highly expensive when the data domain is\nfinite . In previous works it has been investigated how to calculate the NML\ncode-length for specific types of distributions. We first propose a general\nmethod for computing the NML code-length for the exponential family. Then we\nspecifically focus on Gaussian mixture model (GMM), and propose a new efficient\nmethod for computing the NML to them. We develop it by generalizing Rissanen's\nre-normalizing technique. Then we apply this method to the clustering issue, in\nwhich a clustering structure is modeled using a GMM, and the main task is to\nestimate the optimal number of clusters on the basis of the NML code-length. We\ndemonstrate using artificial data sets the superiority of the NML-based\nclustering over other criteria such as AIC, BIC in terms of the data size\nrequired for high accuracy rate to be achieved.\n",
        "published": "2012-05-16T03:54:30Z",
        "pdf_link": "http://arxiv.org/pdf/1205.3549v2"
    },
    {
        "id": "http://arxiv.org/abs/1205.4234v2",
        "title": "Visualization of features of a series of measurements with\n  one-dimensional cellular structure",
        "summary": "  This paper describes the method of visualization of periodic constituents and\ninstability areas in series of measurements, being based on the algorithm of\nsmoothing out and concept of one-dimensional cellular automata. A method can be\nused at the analysis of temporal series, related to the volumes of thematic\npublications in web-space.\n",
        "published": "2012-05-19T08:16:21Z",
        "pdf_link": "http://arxiv.org/pdf/1205.4234v2"
    },
    {
        "id": "http://arxiv.org/abs/1205.4698v2",
        "title": "The Role of Weight Shrinking in Large Margin Perceptron Learning",
        "summary": "  We introduce into the classical perceptron algorithm with margin a mechanism\nthat shrinks the current weight vector as a first step of the update. If the\nshrinking factor is constant the resulting algorithm may be regarded as a\nmargin-error-driven version of NORMA with constant learning rate. In this case\nwe show that the allowed strength of shrinking depends on the value of the\nmaximum margin. We also consider variable shrinking factors for which there is\nno such dependence. In both cases we obtain new generalizations of the\nperceptron with margin able to provably attain in a finite number of steps any\ndesirable approximation of the maximal margin hyperplane. The new approximate\nmaximum margin classifiers appear experimentally to be very competitive in\n2-norm soft margin tasks involving linear kernels.\n",
        "published": "2012-05-21T19:19:49Z",
        "pdf_link": "http://arxiv.org/pdf/1205.4698v2"
    },
    {
        "id": "http://arxiv.org/abs/1205.4810v3",
        "title": "Safe Exploration in Markov Decision Processes",
        "summary": "  In environments with uncertain dynamics exploration is necessary to learn how\nto perform well. Existing reinforcement learning algorithms provide strong\nexploration guarantees, but they tend to rely on an ergodicity assumption. The\nessence of ergodicity is that any state is eventually reachable from any other\nstate by following a suitable policy. This assumption allows for exploration\nalgorithms that operate by simply favoring states that have rarely been visited\nbefore. For most physical systems this assumption is impractical as the systems\nwould break before any reasonable exploration has taken place, i.e., most\nphysical systems don't satisfy the ergodicity assumption. In this paper we\naddress the need for safe exploration methods in Markov decision processes. We\nfirst propose a general formulation of safety through ergodicity. We show that\nimposing safety by restricting attention to the resulting set of guaranteed\nsafe policies is NP-hard. We then present an efficient algorithm for guaranteed\nsafe, but potentially suboptimal, exploration. At the core is an optimization\nformulation in which the constraints restrict attention to a subset of the\nguaranteed safe policies and the objective favors exploration policies. Our\nframework is compatible with the majority of previously proposed exploration\nmethods, which rely on an exploration bonus. Our experiments, which include a\nMartian terrain exploration problem, show that our method is able to explore\nbetter than classical exploration methods.\n",
        "published": "2012-05-22T06:02:09Z",
        "pdf_link": "http://arxiv.org/pdf/1205.4810v3"
    },
    {
        "id": "http://arxiv.org/abs/1205.4839v5",
        "title": "Off-Policy Actor-Critic",
        "summary": "  This paper presents the first actor-critic algorithm for off-policy\nreinforcement learning. Our algorithm is online and incremental, and its\nper-time-step complexity scales linearly with the number of learned weights.\nPrevious work on actor-critic algorithms is limited to the on-policy setting\nand does not take advantage of the recent advances in off-policy gradient\ntemporal-difference learning. Off-policy techniques, such as Greedy-GQ, enable\na target policy to be learned while following and obtaining data from another\n(behavior) policy. For many problems, however, actor-critic methods are more\npractical than action value methods (like Greedy-GQ) because they explicitly\nrepresent the policy; consequently, the policy can be stochastic and utilize a\nlarge action space. In this paper, we illustrate how to practically combine the\ngenerality and learning potential of off-policy learning with the flexibility\nin action selection given by actor-critic methods. We derive an incremental,\nlinear time and space complexity algorithm that includes eligibility traces,\nprove convergence under assumptions similar to previous off-policy algorithms,\nand empirically show better or comparable performance to existing algorithms on\nstandard reinforcement-learning benchmark problems.\n",
        "published": "2012-05-22T08:36:41Z",
        "pdf_link": "http://arxiv.org/pdf/1205.4839v5"
    },
    {
        "id": "http://arxiv.org/abs/1205.6432v2",
        "title": "Multiclass Learning Approaches: A Theoretical Comparison with\n  Implications",
        "summary": "  We theoretically analyze and compare the following five popular multiclass\nclassification methods: One vs. All, All Pairs, Tree-based classifiers, Error\nCorrecting Output Codes (ECOC) with randomly generated code matrices, and\nMulticlass SVM. In the first four methods, the classification is based on a\nreduction to binary classification. We consider the case where the binary\nclassifier comes from a class of VC dimension $d$, and in particular from the\nclass of halfspaces over $\\reals^d$. We analyze both the estimation error and\nthe approximation error of these methods. Our analysis reveals interesting\nconclusions of practical relevance, regarding the success of the different\napproaches under various conditions. Our proof technique employs tools from VC\ntheory to analyze the \\emph{approximation error} of hypothesis classes. This is\nin sharp contrast to most, if not all, previous uses of VC theory, which only\ndeal with estimation error.\n",
        "published": "2012-05-29T17:40:04Z",
        "pdf_link": "http://arxiv.org/pdf/1205.6432v2"
    },
    {
        "id": "http://arxiv.org/abs/1207.0166v3",
        "title": "On Multilabel Classification and Ranking with Partial Feedback",
        "summary": "  We present a novel multilabel/ranking algorithm working in partial\ninformation settings. The algorithm is based on 2nd-order descent methods, and\nrelies on upper-confidence bounds to trade-off exploration and exploitation. We\nanalyze this algorithm in a partial adversarial setting, where covariates can\nbe adversarial, but multilabel probabilities are ruled by (generalized) linear\nmodels. We show O(T^{1/2} log T) regret bounds, which improve in several ways\non the existing results. We test the effectiveness of our upper-confidence\nscheme by contrasting against full-information baselines on real-world\nmultilabel datasets, often obtaining comparable performance.\n",
        "published": "2012-06-30T23:07:03Z",
        "pdf_link": "http://arxiv.org/pdf/1207.0166v3"
    },
    {
        "id": "http://arxiv.org/abs/1207.0783v1",
        "title": "Hybrid Template Update System for Unimodal Biometric Systems",
        "summary": "  Semi-supervised template update systems allow to automatically take into\naccount the intra-class variability of the biometric data over time. Such\nsystems can be inefficient by including too many impostor's samples or skipping\ntoo many genuine's samples. In the first case, the biometric reference drifts\nfrom the real biometric data and attracts more often impostors. In the second\ncase, the biometric reference does not evolve quickly enough and also\nprogressively drifts from the real biometric data. We propose a hybrid system\nusing several biometric sub-references in order to increase per- formance of\nself-update systems by reducing the previously cited errors. The proposition is\nvalidated for a keystroke- dynamics authentication system (this modality\nsuffers of high variability over time) on two consequent datasets from the\nstate of the art.\n",
        "published": "2012-07-03T19:12:13Z",
        "pdf_link": "http://arxiv.org/pdf/1207.0783v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.0784v1",
        "title": "Web-Based Benchmark for Keystroke Dynamics Biometric Systems: A\n  Statistical Analysis",
        "summary": "  Most keystroke dynamics studies have been evaluated using a specific kind of\ndataset in which users type an imposed login and password. Moreover, these\nstudies are optimistics since most of them use different acquisition protocols,\nprivate datasets, controlled environment, etc. In order to enhance the accuracy\nof keystroke dynamics' performance, the main contribution of this paper is\ntwofold. First, we provide a new kind of dataset in which users have typed both\nan imposed and a chosen pairs of logins and passwords. In addition, the\nkeystroke dynamics samples are collected in a web-based uncontrolled\nenvironment (OS, keyboards, browser, etc.). Such kind of dataset is important\nsince it provides us more realistic results of keystroke dynamics' performance\nin comparison to the literature (controlled environment, etc.). Second, we\npresent a statistical analysis of well known assertions such as the\nrelationship between performance and password size, impact of fusion schemes on\nsystem overall performance, and others such as the relationship between\nperformance and entropy. We put into obviousness in this paper some new results\non keystroke dynamics in realistic conditions.\n",
        "published": "2012-07-03T19:12:56Z",
        "pdf_link": "http://arxiv.org/pdf/1207.0784v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.3790v1",
        "title": "Accuracy Measures for the Comparison of Classifiers",
        "summary": "  The selection of the best classification algorithm for a given dataset is a\nvery widespread problem. It is also a complex one, in the sense it requires to\nmake several important methodological choices. Among them, in this work we\nfocus on the measure used to assess the classification performance and rank the\nalgorithms. We present the most popular measures and discuss their properties.\nDespite the numerous measures proposed over the years, many of them turn out to\nbe equivalent in this specific case, to have interpretation problems, or to be\nunsuitable for our purpose. Consequently, classic overall success rate or\nmarginal rates should be preferred for this specific task.\n",
        "published": "2012-07-16T08:49:34Z",
        "pdf_link": "http://arxiv.org/pdf/1207.3790v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.4404v1",
        "title": "Better Mixing via Deep Representations",
        "summary": "  It has previously been hypothesized, and supported with some experimental\nevidence, that deeper representations, when well trained, tend to do a better\njob at disentangling the underlying factors of variation. We study the\nfollowing related conjecture: better representations, in the sense of better\ndisentangling, can be exploited to produce faster-mixing Markov chains.\nConsequently, mixing would be more efficient at higher levels of\nrepresentation. To better understand why and how this is happening, we propose\na secondary conjecture: the higher-level samples fill more uniformly the space\nthey occupy and the high-density manifolds tend to unfold when represented at\nhigher levels. The paper discusses these hypotheses and tests them\nexperimentally through visualization and measurements of mixing and\ninterpolating between samples.\n",
        "published": "2012-07-18T16:07:36Z",
        "pdf_link": "http://arxiv.org/pdf/1207.4404v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.7035v1",
        "title": "Supervised Laplacian Eigenmaps with Applications in Clinical Diagnostics\n  for Pediatric Cardiology",
        "summary": "  Electronic health records contain rich textual data which possess critical\npredictive information for machine-learning based diagnostic aids. However many\ntraditional machine learning methods fail to simultaneously integrate both\nvector space data and text. We present a supervised method using Laplacian\neigenmaps to augment existing machine-learning methods with low-dimensional\nrepresentations of textual predictors which preserve the local similarities.\nThe proposed implementation performs alternating optimization using gradient\ndescent. For the evaluation we applied our method to over 2,000 patient records\nfrom a large single-center pediatric cardiology practice to predict if patients\nwere diagnosed with cardiac disease. Our method was compared with latent\nsemantic indexing, latent Dirichlet allocation, and local Fisher discriminant\nanalysis. The results were assessed using AUC, MCC, specificity, and\nsensitivity. Results indicate supervised Laplacian eigenmaps was the highest\nperforming method in our study, achieving 0.782 and 0.374 for AUC and MCC\nrespectively. SLE showed an increase in 8.16% in AUC and 20.6% in MCC over the\nbaseline which excluded textual data and a 2.69% and 5.35% increase in AUC and\nMCC respectively over unsupervised Laplacian eigenmaps. This method allows many\nexisting machine learning predictors to effectively and efficiently utilize the\npotential of textual predictors.\n",
        "published": "2012-07-27T08:47:50Z",
        "pdf_link": "http://arxiv.org/pdf/1207.7035v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.0984v1",
        "title": "APRIL: Active Preference-learning based Reinforcement Learning",
        "summary": "  This paper focuses on reinforcement learning (RL) with limited prior\nknowledge. In the domain of swarm robotics for instance, the expert can hardly\ndesign a reward function or demonstrate the target behavior, forbidding the use\nof both standard RL and inverse reinforcement learning. Although with a limited\nexpertise, the human expert is still often able to emit preferences and rank\nthe agent demonstrations. Earlier work has presented an iterative\npreference-based RL framework: expert preferences are exploited to learn an\napproximate policy return, thus enabling the agent to achieve direct policy\nsearch. Iteratively, the agent selects a new candidate policy and demonstrates\nit; the expert ranks the new demonstration comparatively to the previous best\none; the expert's ranking feedback enables the agent to refine the approximate\npolicy return, and the process is iterated. In this paper, preference-based\nreinforcement learning is combined with active ranking in order to decrease the\nnumber of ranking queries to the expert needed to yield a satisfactory policy.\nExperiments on the mountain car and the cancer treatment testbeds witness that\na couple of dozen rankings enable to learn a competent policy.\n",
        "published": "2012-08-05T06:34:44Z",
        "pdf_link": "http://arxiv.org/pdf/1208.0984v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.1315v1",
        "title": "Data Selection for Semi-Supervised Learning",
        "summary": "  The real challenge in pattern recognition task and machine learning process\nis to train a discriminator using labeled data and use it to distinguish\nbetween future data as accurate as possible. However, most of the problems in\nthe real world have numerous data, which labeling them is a cumbersome or even\nan impossible matter. Semi-supervised learning is one approach to overcome\nthese types of problems. It uses only a small set of labeled with the company\nof huge remain and unlabeled data to train the discriminator. In\nsemi-supervised learning, it is very essential that which data is labeled and\ndepend on position of data it effectiveness changes. In this paper, we proposed\nan evolutionary approach called Artificial Immune System (AIS) to determine\nwhich data is better to be labeled to get the high quality data. The\nexperimental results represent the effectiveness of this algorithm in finding\nthese data points.\n",
        "published": "2012-08-07T01:31:32Z",
        "pdf_link": "http://arxiv.org/pdf/1208.1315v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.1544v1",
        "title": "Guess Who Rated This Movie: Identifying Users Through Subspace\n  Clustering",
        "summary": "  It is often the case that, within an online recommender system, multiple\nusers share a common account. Can such shared accounts be identified solely on\nthe basis of the user- provided ratings? Once a shared account is identified,\ncan the different users sharing it be identified as well? Whenever such user\nidentification is feasible, it opens the way to possible improvements in\npersonalized recommendations, but also raises privacy concerns. We develop a\nmodel for composite accounts based on unions of linear subspaces, and use\nsubspace clustering for carrying out the identification task. We show that a\nsignificant fraction of such accounts is identifiable in a reliable manner, and\nillustrate potential uses for personalized recommendation.\n",
        "published": "2012-08-07T23:21:31Z",
        "pdf_link": "http://arxiv.org/pdf/1208.1544v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.1829v1",
        "title": "Metric Learning across Heterogeneous Domains by Respectively Aligning\n  Both Priors and Posteriors",
        "summary": "  In this paper, we attempts to learn a single metric across two heterogeneous\ndomains where source domain is fully labeled and has many samples while target\ndomain has only a few labeled samples but abundant unlabeled samples. To the\nbest of our knowledge, this task is seldom touched. The proposed learning model\nhas a simple underlying motivation: all the samples in both the source and the\ntarget domains are mapped into a common space, where both their priors\nP(sample)s and their posteriors P(label|sample)s are forced to be respectively\naligned as much as possible. We show that the two mappings, from both the\nsource domain and the target domain to the common space, can be reparameterized\ninto a single positive semi-definite(PSD) matrix. Then we develop an efficient\nBregman Projection algorithm to optimize the PDS matrix over which a LogDet\nfunction is used to regularize. Furthermore, we also show that this model can\nbe easily kernelized and verify its effectiveness in crosslanguage retrieval\ntask and cross-domain object recognition task.\n",
        "published": "2012-08-09T07:14:37Z",
        "pdf_link": "http://arxiv.org/pdf/1208.1829v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.1846v1",
        "title": "Margin Distribution Controlled Boosting",
        "summary": "  Schapire's margin theory provides a theoretical explanation to the success of\nboosting-type methods and manifests that a good margin distribution (MD) of\ntraining samples is essential for generalization. However the statement that a\nMD is good is vague, consequently, many recently developed algorithms try to\ngenerate a MD in their goodness senses for boosting generalization. Unlike\ntheir indirect control over MD, in this paper, we propose an alternative\nboosting algorithm termed Margin distribution Controlled Boosting (MCBoost)\nwhich directly controls the MD by introducing and optimizing a key adjustable\nmargin parameter. MCBoost's optimization implementation adopts the column\ngeneration technique to ensure fast convergence and small number of weak\nclassifiers involved in the final MCBooster. We empirically demonstrate: 1)\nAdaBoost is actually also a MD controlled algorithm and its iteration number\nacts as a parameter controlling the distribution and 2) the generalization\nperformance of MCBoost evaluated on UCI benchmark datasets is validated better\nthan those of AdaBoost, L2Boost, LPBoost, AdaBoost-CG and MDBoost.\n",
        "published": "2012-08-09T08:53:11Z",
        "pdf_link": "http://arxiv.org/pdf/1208.1846v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.2112v2",
        "title": "Inverse Reinforcement Learning with Gaussian Process",
        "summary": "  We present new algorithms for inverse reinforcement learning (IRL, or inverse\noptimal control) in convex optimization settings. We argue that finite-space\nIRL can be posed as a convex quadratic program under a Bayesian inference\nframework with the objective of maximum a posterior estimation. To deal with\nproblems in large or even infinite state space, we propose a Gaussian process\nmodel and use preference graphs to represent observations of decision\ntrajectories. Our method is distinguished from other approaches to IRL in that\nit makes no assumptions about the form of the reward function and yet it\nretains the promise of computationally manageable implementations for potential\nreal-world applications. In comparison with an establish algorithm on\nsmall-scale numerical problems, our method demonstrated better accuracy in\napprenticeship learning and a more robust dependence on the number of\nobservations.\n",
        "published": "2012-08-10T08:36:49Z",
        "pdf_link": "http://arxiv.org/pdf/1208.2112v2"
    },
    {
        "id": "http://arxiv.org/abs/1208.3561v3",
        "title": "Efficient Active Learning of Halfspaces: an Aggressive Approach",
        "summary": "  We study pool-based active learning of half-spaces. We revisit the aggressive\napproach for active learning in the realizable case, and show that it can be\nmade efficient and practical, while also having theoretical guarantees under\nreasonable assumptions. We further show, both theoretically and experimentally,\nthat it can be preferable to mellow approaches. Our efficient aggressive active\nlearner of half-spaces has formal approximation guarantees that hold when the\npool is separable with a margin. While our analysis is focused on the\nrealizable setting, we show that a simple heuristic allows using the same\nalgorithm successfully for pools with low error as well. We further compare the\naggressive approach to the mellow approach, and prove that there are cases in\nwhich the aggressive approach results in significantly better label complexity\ncompared to the mellow approach. We demonstrate experimentally that substantial\nimprovements in label complexity can be achieved using the aggressive approach,\nfor both realizable and low-error settings.\n",
        "published": "2012-08-17T09:49:31Z",
        "pdf_link": "http://arxiv.org/pdf/1208.3561v3"
    },
    {
        "id": "http://arxiv.org/abs/1208.3719v2",
        "title": "Auto-WEKA: Combined Selection and Hyperparameter Optimization of\n  Classification Algorithms",
        "summary": "  Many different machine learning algorithms exist; taking into account each\nalgorithm's hyperparameters, there is a staggeringly large number of possible\nalternatives overall. We consider the problem of simultaneously selecting a\nlearning algorithm and setting its hyperparameters, going beyond previous work\nthat addresses these issues in isolation. We show that this problem can be\naddressed by a fully automated approach, leveraging recent innovations in\nBayesian optimization. Specifically, we consider a wide range of feature\nselection techniques (combining 3 search and 8 evaluator methods) and all\nclassification approaches implemented in WEKA, spanning 2 ensemble methods, 10\nmeta-methods, 27 base classifiers, and hyperparameter settings for each\nclassifier. On each of 21 popular datasets from the UCI repository, the KDD Cup\n09, variants of the MNIST dataset and CIFAR-10, we show classification\nperformance often much better than using standard selection/hyperparameter\noptimization methods. We hope that our approach will help non-expert users to\nmore effectively identify machine learning algorithms and hyperparameter\nsettings appropriate to their applications, and hence to achieve improved\nperformance.\n",
        "published": "2012-08-18T02:14:47Z",
        "pdf_link": "http://arxiv.org/pdf/1208.3719v2"
    },
    {
        "id": "http://arxiv.org/abs/1208.5801v2",
        "title": "Vector Field k-Means: Clustering Trajectories by Fitting Multiple Vector\n  Fields",
        "summary": "  Scientists study trajectory data to understand trends in movement patterns,\nsuch as human mobility for traffic analysis and urban planning. There is a\npressing need for scalable and efficient techniques for analyzing this data and\ndiscovering the underlying patterns. In this paper, we introduce a novel\ntechnique which we call vector-field $k$-means.\n  The central idea of our approach is to use vector fields to induce a\nsimilarity notion between trajectories. Other clustering algorithms seek a\nrepresentative trajectory that best describes each cluster, much like $k$-means\nidentifies a representative \"center\" for each cluster. Vector-field $k$-means,\non the other hand, recognizes that in all but the simplest examples, no single\ntrajectory adequately describes a cluster. Our approach is based on the premise\nthat movement trends in trajectory data can be modeled as flows within multiple\nvector fields, and the vector field itself is what defines each of the\nclusters. We also show how vector-field $k$-means connects techniques for\nscalar field design on meshes and $k$-means clustering.\n  We present an algorithm that finds a locally optimal clustering of\ntrajectories into vector fields, and demonstrate how vector-field $k$-means can\nbe used to mine patterns from trajectory data. We present experimental evidence\nof its effectiveness and efficiency using several datasets, including\nhistorical hurricane data, GPS tracks of people and vehicles, and anonymous\ncall records from a large phone company. We compare our results to previous\ntrajectory clustering techniques, and find that our algorithm performs faster\nin practice than the current state-of-the-art in trajectory clustering, in some\nexamples by a large margin.\n",
        "published": "2012-08-28T21:51:36Z",
        "pdf_link": "http://arxiv.org/pdf/1208.5801v2"
    },
    {
        "id": "http://arxiv.org/abs/1208.6231v1",
        "title": "Link Prediction via Generalized Coupled Tensor Factorisation",
        "summary": "  This study deals with the missing link prediction problem: the problem of\npredicting the existence of missing connections between entities of interest.\nWe address link prediction using coupled analysis of relational datasets\nrepresented as heterogeneous data, i.e., datasets in the form of matrices and\nhigher-order tensors. We propose to use an approach based on probabilistic\ninterpretation of tensor factorisation models, i.e., Generalised Coupled Tensor\nFactorisation, which can simultaneously fit a large class of tensor models to\nhigher-order tensors/matrices with com- mon latent factors using different loss\nfunctions. Numerical experiments demonstrate that joint analysis of data from\nmultiple sources via coupled factorisation improves the link prediction\nperformance and the selection of right loss function and tensor model is\ncrucial for accurately predicting missing links.\n",
        "published": "2012-08-30T16:48:05Z",
        "pdf_link": "http://arxiv.org/pdf/1208.6231v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.0853v1",
        "title": "Improving the K-means algorithm using improved downhill simplex search",
        "summary": "  The k-means algorithm is one of the well-known and most popular clustering\nalgorithms. K-means seeks an optimal partition of the data by minimizing the\nsum of squared error with an iterative optimization procedure, which belongs to\nthe category of hill climbing algorithms. As we know hill climbing searches are\nfamous for converging to local optimums. Since k-means can converge to a local\noptimum, different initial points generally lead to different convergence\ncancroids, which makes it important to start with a reasonable initial\npartition in order to achieve high quality clustering solutions. However, in\ntheory, there exist no efficient and universal methods for determining such\ninitial partitions. In this paper we tried to find an optimum initial\npartitioning for k-means algorithm. To achieve this goal we proposed a new\nimproved version of downhill simplex search, and then we used it in order to\nfind an optimal result for clustering approach and then compare this algorithm\nwith Genetic Algorithm base (GA), Genetic K-Means (GKM), Improved Genetic\nK-Means (IGKM) and k-means algorithms.\n",
        "published": "2012-09-05T03:02:26Z",
        "pdf_link": "http://arxiv.org/pdf/1209.0853v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.0913v1",
        "title": "Structuring Relevant Feature Sets with Multiple Model Learning",
        "summary": "  Feature selection is one of the most prominent learning tasks, especially in\nhigh-dimensional datasets in which the goal is to understand the mechanisms\nthat underly the learning dataset. However most of them typically deliver just\na flat set of relevant features and provide no further information on what kind\nof structures, e.g. feature groupings, might underly the set of relevant\nfeatures. In this paper we propose a new learning paradigm in which our goal is\nto uncover the structures that underly the set of relevant features for a given\nlearning problem. We uncover two types of features sets, non-replaceable\nfeatures that contain important information about the target variable and\ncannot be replaced by other features, and functionally similar features sets\nthat can be used interchangeably in learned models, given the presence of the\nnon-replaceable features, with no change in the predictive performance. To do\nso we propose a new learning algorithm that learns a number of disjoint models\nusing a model disjointness regularization constraint together with a constraint\non the predictive agreement of the disjoint models. We explore the behavior of\nour approach on a number of high-dimensional datasets, and show that, as\nexpected by their construction, these satisfy a number of properties. Namely,\nmodel disjointness, a high predictive agreement, and a similar predictive\nperformance to models learned on the full set of relevant features. The ability\nto structure the set of relevant features in such a manner can become a\nvaluable tool in different applications of scientific knowledge discovery.\n",
        "published": "2012-09-05T10:08:02Z",
        "pdf_link": "http://arxiv.org/pdf/1209.0913v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.1800v1",
        "title": "An Empirical Study of MAUC in Multi-class Problems with Uncertain Cost\n  Matrices",
        "summary": "  Cost-sensitive learning relies on the availability of a known and fixed cost\nmatrix. However, in some scenarios, the cost matrix is uncertain during\ntraining, and re-train a classifier after the cost matrix is specified would\nnot be an option. For binary classification, this issue can be successfully\naddressed by methods maximizing the Area Under the ROC Curve (AUC) metric.\nSince the AUC can measure performance of base classifiers independent of cost\nduring training, and a larger AUC is more likely to lead to a smaller total\ncost in testing using the threshold moving method. As an extension of AUC to\nmulti-class problems, MAUC has attracted lots of attentions and been widely\nused. Although MAUC also measures performance of base classifiers independent\nof cost, it is unclear whether a larger MAUC of classifiers is more likely to\nlead to a smaller total cost. In fact, it is also unclear what kinds of\npost-processing methods should be used in multi-class problems to convert base\nclassifiers into discrete classifiers such that the total cost is as small as\npossible. In the paper, we empirically explore the relationship between MAUC\nand the total cost of classifiers by applying two categories of post-processing\nmethods. Our results suggest that a larger MAUC is also beneficial.\nInterestingly, simple calibration methods that convert the output matrix into\nposterior probabilities perform better than existing sophisticated post\nre-optimization methods.\n",
        "published": "2012-09-09T14:11:04Z",
        "pdf_link": "http://arxiv.org/pdf/1209.1800v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.2501v1",
        "title": "Performance Evaluation of Predictive Classifiers For Knowledge Discovery\n  From Engineering Materials Data Sets",
        "summary": "  In this paper, naive Bayesian and C4.5 Decision Tree Classifiers(DTC) are\nsuccessively applied on materials informatics to classify the engineering\nmaterials into different classes for the selection of materials that suit the\ninput design specifications. Here, the classifiers are analyzed individually\nand their performance evaluation is analyzed with confusion matrix predictive\nparameters and standard measures, the classification results are analyzed on\ndifferent class of materials. Comparison of classifiers has found that naive\nBayesian classifier is more accurate and better than the C4.5 DTC. The\nknowledge discovered by the naive bayesian classifier can be employed for\ndecision making in materials selection in manufacturing industries.\n",
        "published": "2012-09-12T05:28:32Z",
        "pdf_link": "http://arxiv.org/pdf/1209.2501v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.2673v2",
        "title": "Conditional validity of inductive conformal predictors",
        "summary": "  Conformal predictors are set predictors that are automatically valid in the\nsense of having coverage probability equal to or exceeding a given confidence\nlevel. Inductive conformal predictors are a computationally efficient version\nof conformal predictors satisfying the same property of validity. However,\ninductive conformal predictors have been only known to control unconditional\ncoverage probability. This paper explores various versions of conditional\nvalidity and various ways to achieve them using inductive conformal predictors\nand their modifications.\n",
        "published": "2012-09-12T17:39:37Z",
        "pdf_link": "http://arxiv.org/pdf/1209.2673v2"
    },
    {
        "id": "http://arxiv.org/abs/1209.2790v1",
        "title": "Improving Energy Efficiency in Femtocell Networks: A Hierarchical\n  Reinforcement Learning Framework",
        "summary": "  This paper investigates energy efficiency for two-tier femtocell networks\nthrough combining game theory and stochastic learning. With the Stackelberg\ngame formulation, a hierarchical reinforcement learning framework is applied to\nstudy the joint average utility maximization of macrocells and femtocells\nsubject to the minimum signal-to-interference-plus-noise-ratio requirements.\nThe macrocells behave as the leaders and the femtocells are followers during\nthe learning procedure. At each time step, the leaders commit to dynamic\nstrategies based on the best responses of the followers, while the followers\ncompete against each other with no further information but the leaders'\nstrategy information. In this paper, we propose two learning algorithms to\nschedule each cell's stochastic power levels, leading by the macrocells.\nNumerical experiments are presented to validate the proposed studies and show\nthat the two learning algorithms substantially improve the energy efficiency of\nthe femtocell networks.\n",
        "published": "2012-09-13T06:47:26Z",
        "pdf_link": "http://arxiv.org/pdf/1209.2790v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.3056v1",
        "title": "Parametric Local Metric Learning for Nearest Neighbor Classification",
        "summary": "  We study the problem of learning local metrics for nearest neighbor\nclassification. Most previous works on local metric learning learn a number of\nlocal unrelated metrics. While this \"independence\" approach delivers an\nincreased flexibility its downside is the considerable risk of overfitting. We\npresent a new parametric local metric learning method in which we learn a\nsmooth metric matrix function over the data manifold. Using an approximation\nerror bound of the metric matrix function we learn local metrics as linear\ncombinations of basis metrics defined on anchor points over different regions\nof the instance space. We constrain the metric matrix function by imposing on\nthe linear combinations manifold regularization which makes the learned metric\nmatrix function vary smoothly along the geodesics of the data manifold. Our\nmetric learning method has excellent performance both in terms of predictive\npower and scalability. We experimented with several large-scale classification\nproblems, tens of thousands of instances, and compared it with several state of\nthe art metric learning methods, both global and local, as well as to SVM with\nautomatic kernel selection, all of which it outperforms in a significant\nmanner.\n",
        "published": "2012-09-13T22:47:07Z",
        "pdf_link": "http://arxiv.org/pdf/1209.3056v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.5038v1",
        "title": "Fast Randomized Model Generation for Shapelet-Based Time Series\n  Classification",
        "summary": "  Time series classification is a field which has drawn much attention over the\npast decade. A new approach for classification of time series uses\nclassification trees based on shapelets. A shapelet is a subsequence extracted\nfrom one of the time series in the dataset. A disadvantage of this approach is\nthe time required for building the shapelet-based classification tree. The\nsearch for the best shapelet requires examining all subsequences of all lengths\nfrom all time series in the training set.\n  A key goal of this work was to find an evaluation order of the shapelets\nspace which enables fast convergence to an accurate model. The comparative\nanalysis we conducted clearly indicates that a random evaluation order yields\nthe best results. Our empirical analysis of the distribution of high-quality\nshapelets within the shapelets space provides insights into why randomized\nshapelets sampling is superior to alternative evaluation orders.\n  We present an algorithm for randomized model generation for shapelet-based\nclassification that converges extremely quickly to a model with surprisingly\nhigh accuracy after evaluating only an exceedingly small fraction of the\nshapelets space.\n",
        "published": "2012-09-23T07:50:42Z",
        "pdf_link": "http://arxiv.org/pdf/1209.5038v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.5260v2",
        "title": "Towards Ultrahigh Dimensional Feature Selection for Big Data",
        "summary": "  In this paper, we present a new adaptive feature scaling scheme for\nultrahigh-dimensional feature selection on Big Data. To solve this problem\neffectively, we first reformulate it as a convex semi-infinite programming\n(SIP) problem and then propose an efficient \\emph{feature generating paradigm}.\nIn contrast with traditional gradient-based approaches that conduct\noptimization on all input features, the proposed method iteratively activates a\ngroup of features and solves a sequence of multiple kernel learning (MKL)\nsubproblems of much reduced scale. To further speed up the training, we propose\nto solve the MKL subproblems in their primal forms through a modified\naccelerated proximal gradient approach. Due to such an optimization scheme,\nsome efficient cache techniques are also developed. The feature generating\nparadigm can guarantee that the solution converges globally under mild\nconditions and achieve lower feature selection bias. Moreover, the proposed\nmethod can tackle two challenging tasks in feature selection: 1) group-based\nfeature selection with complex structures and 2) nonlinear feature selection\nwith explicit feature mappings. Comprehensive experiments on a wide range of\nsynthetic and real-world datasets containing tens of million data points with\n$O(10^{14})$ features demonstrate the competitive performance of the proposed\nmethod over state-of-the-art feature selection methods in terms of\ngeneralization performance and training efficiency.\n",
        "published": "2012-09-24T13:23:39Z",
        "pdf_link": "http://arxiv.org/pdf/1209.5260v2"
    },
    {
        "id": "http://arxiv.org/abs/1209.5335v1",
        "title": "BPRS: Belief Propagation Based Iterative Recommender System",
        "summary": "  In this paper we introduce the first application of the Belief Propagation\n(BP) algorithm in the design of recommender systems. We formulate the\nrecommendation problem as an inference problem and aim to compute the marginal\nprobability distributions of the variables which represent the ratings to be\npredicted. However, computing these marginal probability functions is\ncomputationally prohibitive for large-scale systems. Therefore, we utilize the\nBP algorithm to efficiently compute these functions. Recommendations for each\nactive user are then iteratively computed by probabilistic message passing. As\nopposed to the previous recommender algorithms, BPRS does not require solving\nthe recommendation problem for all the users if it wishes to update the\nrecommendations for only a single active. Further, BPRS computes the\nrecommendations for each user with linear complexity and without requiring a\ntraining period. Via computer simulations (using the 100K MovieLens dataset),\nwe verify that BPRS iteratively reduces the error in the predicted ratings of\nthe users until it converges. Finally, we confirm that BPRS is comparable to\nthe state of art methods such as Correlation-based neighborhood model (CorNgbr)\nand Singular Value Decomposition (SVD) in terms of rating and precision\naccuracy. Therefore, we believe that the BP-based recommendation algorithm is a\nnew promising approach which offers a significant advantage on scalability\nwhile providing competitive accuracy for the recommender systems.\n",
        "published": "2012-09-24T16:59:12Z",
        "pdf_link": "http://arxiv.org/pdf/1209.5335v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.6329v1",
        "title": "More Is Better: Large Scale Partially-supervised Sentiment\n  Classification - Appendix",
        "summary": "  We describe a bootstrapping algorithm to learn from partially labeled data,\nand the results of an empirical study for using it to improve performance of\nsentiment classification using up to 15 million unlabeled Amazon product\nreviews. Our experiments cover semi-supervised learning, domain adaptation and\nweakly supervised learning. In some cases our methods were able to reduce test\nerror by more than half using such large amount of data.\n  NOTICE: This is only the supplementary material.\n",
        "published": "2012-09-27T18:57:26Z",
        "pdf_link": "http://arxiv.org/pdf/1209.6329v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.6409v1",
        "title": "A Deterministic Analysis of an Online Convex Mixture of Expert\n  Algorithms",
        "summary": "  We analyze an online learning algorithm that adaptively combines outputs of\ntwo constituent algorithms (or the experts) running in parallel to model an\nunknown desired signal. This online learning algorithm is shown to achieve (and\nin some cases outperform) the mean-square error (MSE) performance of the best\nconstituent algorithm in the mixture in the steady-state. However, the MSE\nanalysis of this algorithm in the literature uses approximations and relies on\nstatistical models on the underlying signals and systems. Hence, such an\nanalysis may not be useful or valid for signals generated by various real life\nsystems that show high degrees of nonstationarity, limit cycles and, in many\ncases, that are even chaotic. In this paper, we produce results in an\nindividual sequence manner. In particular, we relate the time-accumulated\nsquared estimation error of this online algorithm at any time over any interval\nto the time accumulated squared estimation error of the optimal convex mixture\nof the constituent algorithms directly tuned to the underlying signal in a\ndeterministic sense without any statistical assumptions. In this sense, our\nanalysis provides the transient, steady-state and tracking behavior of this\nalgorithm in a strong sense without any approximations in the derivations or\nstatistical assumptions on the underlying signals such that our results are\nguaranteed to hold. We illustrate the introduced results through examples.\n",
        "published": "2012-09-28T01:46:47Z",
        "pdf_link": "http://arxiv.org/pdf/1209.6409v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.0473v1",
        "title": "Memory Constraint Online Multitask Classification",
        "summary": "  We investigate online kernel algorithms which simultaneously process multiple\nclassification tasks while a fixed constraint is imposed on the size of their\nactive sets. We focus in particular on the design of algorithms that can\nefficiently deal with problems where the number of tasks is extremely high and\nthe task data are large scale. Two new projection-based algorithms are\nintroduced to efficiently tackle those issues while presenting different trade\noffs on how the available memory is managed with respect to the prior\ninformation about the learning tasks. Theoretically sound budget algorithms are\ndevised by coupling the Randomized Budget Perceptron and the Forgetron\nalgorithms with the multitask kernel. We show how the two seemingly contrasting\nproperties of learning from multiple tasks and keeping a constant memory\nfootprint can be balanced, and how the sharing of the available space among\ndifferent tasks is automatically taken care of. We propose and discuss new\ninsights on the multitask kernel. Experiments show that online kernel multitask\nalgorithms running on a budget can efficiently tackle real world learning\nproblems involving multiple tasks.\n",
        "published": "2012-10-01T17:08:25Z",
        "pdf_link": "http://arxiv.org/pdf/1210.0473v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.0699v1",
        "title": "TV-SVM: Total Variation Support Vector Machine for Semi-Supervised Data\n  Classification",
        "summary": "  We introduce semi-supervised data classification algorithms based on total\nvariation (TV), Reproducing Kernel Hilbert Space (RKHS), support vector machine\n(SVM), Cheeger cut, labeled and unlabeled data points. We design binary and\nmulti-class semi-supervised classification algorithms. We compare the TV-based\nclassification algorithms with the related Laplacian-based algorithms, and show\nthat TV classification perform significantly better when the number of labeled\ndata is small.\n",
        "published": "2012-10-02T08:40:46Z",
        "pdf_link": "http://arxiv.org/pdf/1210.0699v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.2179v3",
        "title": "Fast Online EM for Big Topic Modeling",
        "summary": "  The expectation-maximization (EM) algorithm can compute the\nmaximum-likelihood (ML) or maximum a posterior (MAP) point estimate of the\nmixture models or latent variable models such as latent Dirichlet allocation\n(LDA), which has been one of the most popular probabilistic topic modeling\nmethods in the past decade. However, batch EM has high time and space\ncomplexities to learn big LDA models from big data streams. In this paper, we\npresent a fast online EM (FOEM) algorithm that infers the topic distribution\nfrom the previously unseen documents incrementally with constant memory\nrequirements. Within the stochastic approximation framework, we show that FOEM\ncan converge to the local stationary point of the LDA's likelihood function. By\ndynamic scheduling for the fast speed and parameter streaming for the low\nmemory usage, FOEM is more efficient for some lifelong topic modeling tasks\nthan the state-of-the-art online LDA algorithms to handle both big data and big\nmodels (aka, big topic modeling) on just a PC.\n",
        "published": "2012-10-08T08:17:18Z",
        "pdf_link": "http://arxiv.org/pdf/1210.2179v3"
    },
    {
        "id": "http://arxiv.org/abs/1210.2346v2",
        "title": "Blending Learning and Inference in Structured Prediction",
        "summary": "  In this paper we derive an efficient algorithm to learn the parameters of\nstructured predictors in general graphical models. This algorithm blends the\nlearning and inference tasks, which results in a significant speedup over\ntraditional approaches, such as conditional random fields and structured\nsupport vector machines. For this purpose we utilize the structures of the\npredictors to describe a low dimensional structured prediction task which\nencourages local consistencies within the different structures while learning\nthe parameters of the model. Convexity of the learning task provides the means\nto enforce the consistencies between the different parts. The\ninference-learning blending algorithm that we propose is guaranteed to converge\nto the optimum of the low dimensional primal and dual programs. Unlike many of\nthe existing approaches, the inference-learning blending allows us to learn\nefficiently high-order graphical models, over regions of any size, and very\nlarge number of parameters. We demonstrate the effectiveness of our approach,\nwhile presenting state-of-the-art results in stereo estimation, semantic\nsegmentation, shape reconstruction, and indoor scene understanding.\n",
        "published": "2012-10-08T17:19:43Z",
        "pdf_link": "http://arxiv.org/pdf/1210.2346v2"
    },
    {
        "id": "http://arxiv.org/abs/1210.4601v1",
        "title": "A Direct Approach to Multi-class Boosting and Extensions",
        "summary": "  Boosting methods combine a set of moderately accurate weaklearners to form a\nhighly accurate predictor. Despite the practical importance of multi-class\nboosting, it has received far less attention than its binary counterpart. In\nthis work, we propose a fully-corrective multi-class boosting formulation which\ndirectly solves the multi-class problem without dividing it into multiple\nbinary classification problems. In contrast, most previous multi-class boosting\nalgorithms decompose a multi-boost problem into multiple binary boosting\nproblems. By explicitly deriving the Lagrange dual of the primal optimization\nproblem, we are able to construct a column generation-based fully-corrective\napproach to boosting which directly optimizes multi-class classification\nperformance. The new approach not only updates all weak learners' coefficients\nat every iteration, but does so in a manner flexible enough to accommodate\nvarious loss functions and regularizations. For example, it enables us to\nintroduce structural sparsity through mixed-norm regularization to promote\ngroup sparsity and feature sharing. Boosting with shared features is\nparticularly beneficial in complex prediction problems where features can be\nexpensive to compute. Our experiments on various data sets demonstrate that our\ndirect multi-class boosting generalizes as well as, or better than, a range of\ncompeting multi-class boosting methods. The end result is a highly effective\nand compact ensemble classifier which can be trained in a distributed fashion.\n",
        "published": "2012-10-17T00:22:31Z",
        "pdf_link": "http://arxiv.org/pdf/1210.4601v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.5394v1",
        "title": "Bayesian Estimation for Continuous-Time Sparse Stochastic Processes",
        "summary": "  We consider continuous-time sparse stochastic processes from which we have\nonly a finite number of noisy/noiseless samples. Our goal is to estimate the\nnoiseless samples (denoising) and the signal in-between (interpolation\nproblem).\n  By relying on tools from the theory of splines, we derive the joint a priori\ndistribution of the samples and show how this probability density function can\nbe factorized. The factorization enables us to tractably implement the maximum\na posteriori and minimum mean-square error (MMSE) criteria as two statistical\napproaches for estimating the unknowns. We compare the derived statistical\nmethods with well-known techniques for the recovery of sparse signals, such as\nthe $\\ell_1$ norm and Log ($\\ell_1$-$\\ell_0$ relaxation) regularization\nmethods. The simulation results show that, under certain conditions, the\nperformance of the regularization techniques can be very close to that of the\nMMSE estimator.\n",
        "published": "2012-10-19T12:15:28Z",
        "pdf_link": "http://arxiv.org/pdf/1210.5394v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.5544v1",
        "title": "Online Learning in Decentralized Multiuser Resource Sharing Problems",
        "summary": "  In this paper, we consider the general scenario of resource sharing in a\ndecentralized system when the resource rewards/qualities are time-varying and\nunknown to the users, and using the same resource by multiple users leads to\nreduced quality due to resource sharing. Firstly, we consider a\nuser-independent reward model with no communication between the users, where a\nuser gets feedback about the congestion level in the resource it uses.\nSecondly, we consider user-specific rewards and allow costly communication\nbetween the users. The users have a cooperative goal of achieving the highest\nsystem utility. There are multiple obstacles in achieving this goal such as the\ndecentralized nature of the system, unknown resource qualities, communication,\ncomputation and switching costs. We propose distributed learning algorithms\nwith logarithmic regret with respect to the optimal allocation. Our logarithmic\nregret result holds under both i.i.d. and Markovian reward models, as well as\nunder communication, computation and switching costs.\n",
        "published": "2012-10-19T21:31:50Z",
        "pdf_link": "http://arxiv.org/pdf/1210.5544v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.6292v2",
        "title": "A density-sensitive hierarchical clustering method",
        "summary": "  We define a hierarchical clustering method: $\\alpha$-unchaining single\nlinkage or $SL(\\alpha)$. The input of this algorithm is a finite metric space\nand a certain parameter $\\alpha$. This method is sensitive to the density of\nthe distribution and offers some solution to the so called chaining effect. We\nalso define a modified version, $SL^*(\\alpha)$, to treat the chaining through\npoints or small blocks. We study the theoretical properties of these methods\nand offer some theoretical background for the treatment of chaining effects.\n",
        "published": "2012-10-23T17:12:01Z",
        "pdf_link": "http://arxiv.org/pdf/1210.6292v2"
    },
    {
        "id": "http://arxiv.org/abs/1210.7657v1",
        "title": "Text Classification with Compression Algorithms",
        "summary": "  This work concerns a comparison of SVM kernel methods in text categorization\ntasks. In particular I define a kernel function that estimates the similarity\nbetween two objects computing by their compressed lengths. In fact, compression\nalgorithms can detect arbitrarily long dependencies within the text strings.\nData text vectorization looses information in feature extractions and is highly\nsensitive by textual language. Furthermore, these methods are language\nindependent and require no text preprocessing. Moreover, the accuracy computed\non the datasets (Web-KB, 20ng and Reuters-21578), in some case, is greater than\nGaussian, linear and polynomial kernels. The method limits are represented by\ncomputational time complexity of the Gram matrix and by very poor performance\non non-textual datasets.\n",
        "published": "2012-10-29T13:30:27Z",
        "pdf_link": "http://arxiv.org/pdf/1210.7657v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.0210v1",
        "title": "Extension of TSVM to Multi-Class and Hierarchical Text Classification\n  Problems With General Losses",
        "summary": "  Transductive SVM (TSVM) is a well known semi-supervised large margin learning\nmethod for binary text classification. In this paper we extend this method to\nmulti-class and hierarchical classification problems. We point out that the\ndetermination of labels of unlabeled examples with fixed classifier weights is\na linear programming problem. We devise an efficient technique for solving it.\nThe method is applicable to general loss functions. We demonstrate the value of\nthe new method using large margin loss on a number of multi-class and\nhierarchical classification datasets. For maxent loss we show empirically that\nour method is better than expectation regularization/constraint and posterior\nregularization methods, and competitive with the version of entropy\nregularization method which uses label constraints.\n",
        "published": "2012-11-01T15:52:11Z",
        "pdf_link": "http://arxiv.org/pdf/1211.0210v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.1513v2",
        "title": "K-Plane Regression",
        "summary": "  In this paper, we present a novel algorithm for piecewise linear regression\nwhich can learn continuous as well as discontinuous piecewise linear functions.\nThe main idea is to repeatedly partition the data and learn a liner model in in\neach partition. While a simple algorithm incorporating this idea does not work\nwell, an interesting modification results in a good algorithm. The proposed\nalgorithm is similar in spirit to $k$-means clustering algorithm. We show that\nour algorithm can also be viewed as an EM algorithm for maximum likelihood\nestimation of parameters under a reasonable probability model. We empirically\ndemonstrate the effectiveness of our approach by comparing its performance with\nthe state of art regression learning algorithms on some real world datasets.\n",
        "published": "2012-11-07T10:57:38Z",
        "pdf_link": "http://arxiv.org/pdf/1211.1513v2"
    },
    {
        "id": "http://arxiv.org/abs/1211.1799v1",
        "title": "Algorithm for Missing Values Imputation in Categorical Data with Use of\n  Association Rules",
        "summary": "  This paper presents algorithm for missing values imputation in categorical\ndata. The algorithm is based on using association rules and is presented in\nthree variants. Experimental shows better accuracy of missing values imputation\nusing the algorithm then using most common attribute value.\n",
        "published": "2012-11-08T09:22:11Z",
        "pdf_link": "http://arxiv.org/pdf/1211.1799v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.2260v1",
        "title": "No-Regret Algorithms for Unconstrained Online Convex Optimization",
        "summary": "  Some of the most compelling applications of online convex optimization,\nincluding online prediction and classification, are unconstrained: the natural\nfeasible set is R^n. Existing algorithms fail to achieve sub-linear regret in\nthis setting unless constraints on the comparator point x^* are known in\nadvance. We present algorithms that, without such prior knowledge, offer\nnear-optimal regret bounds with respect to any choice of x^*. In particular,\nregret with respect to x^* = 0 is constant. We then prove lower bounds showing\nthat our guarantees are near-optimal in this setting.\n",
        "published": "2012-11-09T22:13:10Z",
        "pdf_link": "http://arxiv.org/pdf/1211.2260v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.3046v4",
        "title": "Recovering the Optimal Solution by Dual Random Projection",
        "summary": "  Random projection has been widely used in data classification. It maps\nhigh-dimensional data into a low-dimensional subspace in order to reduce the\ncomputational cost in solving the related optimization problem. While previous\nstudies are focused on analyzing the classification performance of using random\nprojection, in this work, we consider the recovery problem, i.e., how to\naccurately recover the optimal solution to the original optimization problem in\nthe high-dimensional space based on the solution learned from the subspace\nspanned by random projections. We present a simple algorithm, termed Dual\nRandom Projection, that uses the dual solution of the low-dimensional\noptimization problem to recover the optimal solution to the original problem.\nOur theoretical analysis shows that with a high probability, the proposed\nalgorithm is able to accurately recover the optimal solution to the original\nproblem, provided that the data matrix is of low rank or can be well\napproximated by a low rank matrix.\n",
        "published": "2012-11-13T16:39:45Z",
        "pdf_link": "http://arxiv.org/pdf/1211.3046v4"
    },
    {
        "id": "http://arxiv.org/abs/1211.5063v2",
        "title": "On the difficulty of training Recurrent Neural Networks",
        "summary": "  There are two widely known issues with properly training Recurrent Neural\nNetworks, the vanishing and the exploding gradient problems detailed in Bengio\net al. (1994). In this paper we attempt to improve the understanding of the\nunderlying issues by exploring these problems from an analytical, a geometric\nand a dynamical systems perspective. Our analysis is used to justify a simple\nyet effective solution. We propose a gradient norm clipping strategy to deal\nwith exploding gradients and a soft constraint for the vanishing gradients\nproblem. We validate empirically our hypothesis and proposed solutions in the\nexperimental section.\n",
        "published": "2012-11-21T15:40:11Z",
        "pdf_link": "http://arxiv.org/pdf/1211.5063v2"
    },
    {
        "id": "http://arxiv.org/abs/1211.6340v1",
        "title": "An Approach of Improving Students Academic Performance by using k means\n  clustering algorithm and Decision tree",
        "summary": "  Improving students academic performance is not an easy task for the academic\ncommunity of higher learning. The academic performance of engineering and\nscience students during their first year at university is a turning point in\ntheir educational path and usually encroaches on their General Point\nAverage,GPA in a decisive manner. The students evaluation factors like class\nquizzes mid and final exam assignment lab work are studied. It is recommended\nthat all these correlated information should be conveyed to the class teacher\nbefore the conduction of final exam. This study will help the teachers to\nreduce the drop out ratio to a significant level and improve the performance of\nstudents. In this paper, we present a hybrid procedure based on Decision Tree\nof Data mining method and Data Clustering that enables academicians to predict\nstudents GPA and based on that instructor can take necessary step to improve\nstudent academic performance.\n",
        "published": "2012-11-09T09:54:29Z",
        "pdf_link": "http://arxiv.org/pdf/1211.6340v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.6581v5",
        "title": "Multi-Target Regression via Input Space Expansion: Treating Targets as\n  Inputs",
        "summary": "  In many practical applications of supervised learning the task involves the\nprediction of multiple target variables from a common set of input variables.\nWhen the prediction targets are binary the task is called multi-label\nclassification, while when the targets are continuous the task is called\nmulti-target regression. In both tasks, target variables often exhibit\nstatistical dependencies and exploiting them in order to improve predictive\naccuracy is a core challenge. A family of multi-label classification methods\naddress this challenge by building a separate model for each target on an\nexpanded input space where other targets are treated as additional input\nvariables. Despite the success of these methods in the multi-label\nclassification domain, their applicability and effectiveness in multi-target\nregression has not been studied until now. In this paper, we introduce two new\nmethods for multi-target regression, called Stacked Single-Target and Ensemble\nof Regressor Chains, by adapting two popular multi-label classification methods\nof this family. Furthermore, we highlight an inherent problem of these methods\n- a discrepancy of the values of the additional input variables between\ntraining and prediction - and develop extensions that use out-of-sample\nestimates of the target variables during training in order to tackle this\nproblem. The results of an extensive experimental evaluation carried out on a\nlarge and diverse collection of datasets show that, when the discrepancy is\nappropriately mitigated, the proposed methods attain consistent improvements\nover the independent regressions baseline. Moreover, two versions of Ensemble\nof Regression Chains perform significantly better than four state-of-the-art\nmethods including regularization-based multi-task learning methods and a\nmulti-objective random forest approach.\n",
        "published": "2012-11-28T11:42:36Z",
        "pdf_link": "http://arxiv.org/pdf/1211.6581v5"
    },
    {
        "id": "http://arxiv.org/abs/1212.0901v2",
        "title": "Advances in Optimizing Recurrent Networks",
        "summary": "  After a more than decade-long period of relatively little research activity\nin the area of recurrent neural networks, several new developments will be\nreviewed here that have allowed substantial progress both in understanding and\nin technical solutions towards more efficient training of recurrent networks.\nThese advances have been motivated by and related to the optimization issues\nsurrounding deep learning. Although recurrent networks are extremely powerful\nin what they can in principle represent in terms of modelling sequences,their\ntraining is plagued by two aspects of the same issue regarding the learning of\nlong-term dependencies. Experiments reported here evaluate the use of clipping\ngradients, spanning longer time ranges with leaky integration, advanced\nmomentum techniques, using more powerful output probability models, and\nencouraging sparser gradients to help symmetry breaking and credit assignment.\nThe experiments are performed on text and music data and show off the combined\neffects of these techniques in generally improving both training and test\nerror.\n",
        "published": "2012-12-04T23:25:34Z",
        "pdf_link": "http://arxiv.org/pdf/1212.0901v2"
    },
    {
        "id": "http://arxiv.org/abs/1212.1936v1",
        "title": "High-dimensional sequence transduction",
        "summary": "  We investigate the problem of transforming an input sequence into a\nhigh-dimensional output sequence in order to transcribe polyphonic audio music\ninto symbolic notation. We introduce a probabilistic model based on a recurrent\nneural network that is able to learn realistic output distributions given the\ninput and we devise an efficient algorithm to search for the global mode of\nthat distribution. The resulting method produces musically plausible\ntranscriptions even under high levels of noise and drastically outperforms\nprevious state-of-the-art approaches on five datasets of synthesized sounds and\nreal recordings, approximately halving the test error rate.\n",
        "published": "2012-12-09T23:28:02Z",
        "pdf_link": "http://arxiv.org/pdf/1212.1936v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.3185v3",
        "title": "Cost-Sensitive Feature Selection of Data with Errors",
        "summary": "  In data mining applications, feature selection is an essential process since\nit reduces a model's complexity. The cost of obtaining the feature values must\nbe taken into consideration in many domains. In this paper, we study the\ncost-sensitive feature selection problem on numerical data with measurement\nerrors, test costs and misclassification costs. The major contributions of this\npaper are four-fold. First, a new data model is built to address test costs and\nmisclassification costs as well as error boundaries. Second, a covering-based\nrough set with measurement errors is constructed. Given a confidence interval,\nthe neighborhood is an ellipse in a two-dimension space, or an ellipsoidal in a\nthree-dimension space, etc. Third, a new cost-sensitive feature selection\nproblem is defined on this covering-based rough set. Fourth, both backtracking\nand heuristic algorithms are proposed to deal with this new problem. The\nalgorithms are tested on six UCI (University of California - Irvine) data sets.\nExperimental results show that (1) the pruning techniques of the backtracking\nalgorithm help reducing the number of operations significantly, and (2) the\nheuristic algorithm usually obtains optimal results. This study is a step\ntoward realistic applications of cost-sensitive learning.\n",
        "published": "2012-12-13T14:31:58Z",
        "pdf_link": "http://arxiv.org/pdf/1212.3185v3"
    },
    {
        "id": "http://arxiv.org/abs/1212.3631v1",
        "title": "Learning efficient sparse and low rank models",
        "summary": "  Parsimony, including sparsity and low rank, has been shown to successfully\nmodel data in numerous machine learning and signal processing tasks.\nTraditionally, such modeling approaches rely on an iterative algorithm that\nminimizes an objective function with parsimony-promoting terms. The inherently\nsequential structure and data-dependent complexity and latency of iterative\noptimization constitute a major limitation in many applications requiring\nreal-time performance or involving large-scale data. Another limitation\nencountered by these modeling techniques is the difficulty of their inclusion\nin discriminative learning scenarios. In this work, we propose to move the\nemphasis from the model to the pursuit algorithm, and develop a process-centric\nview of parsimonious modeling, in which a learned deterministic\nfixed-complexity pursuit process is used in lieu of iterative optimization. We\nshow a principled way to construct learnable pursuit process architectures for\nstructured sparse and robust low rank models, derived from the iteration of\nproximal descent algorithms. These architectures learn to approximate the exact\nparsimonious representation at a fraction of the complexity of the standard\noptimization methods. We also show that appropriate training regimes allow to\nnaturally extend parsimonious models to discriminative settings.\nState-of-the-art results are demonstrated on several challenging problems in\nimage and audio processing with several orders of magnitude speedup compared to\nthe exact optimization algorithms.\n",
        "published": "2012-12-14T22:50:44Z",
        "pdf_link": "http://arxiv.org/pdf/1212.3631v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.4675v1",
        "title": "Analysis of Large-scale Traffic Dynamics using Non-negative Tensor\n  Factorization",
        "summary": "  In this paper, we present our work on clustering and prediction of temporal\ndynamics of global congestion configurations in large-scale road networks.\nInstead of looking into temporal traffic state variation of individual links,\nor of small areas, we focus on spatial congestion configurations of the whole\nnetwork. In our work, we aim at describing the typical temporal dynamic\npatterns of this network-level traffic state and achieving long-term prediction\nof the large-scale traffic dynamics, in a unified data-mining framework. To\nthis end, we formulate this joint task using Non-negative Tensor Factorization\n(NTF), which has been shown to be a useful decomposition tools for multivariate\ndata sequences. Clustering and prediction are performed based on the compact\ntensor factorization results. Experiments on large-scale simulated data\nillustrate the interest of our method with promising results for long-term\nforecast of traffic evolution.\n",
        "published": "2012-12-18T20:17:56Z",
        "pdf_link": "http://arxiv.org/pdf/1212.4675v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.5101v1",
        "title": "Hybrid Fuzzy-ART based K-Means Clustering Methodology to Cellular\n  Manufacturing Using Operational Time",
        "summary": "  This paper presents a new hybrid Fuzzy-ART based K-Means Clustering technique\nto solve the part machine grouping problem in cellular manufacturing systems\nconsidering operational time. The performance of the proposed technique is\ntested with problems from open literature and the results are compared to the\nexisting clustering models such as simple K-means algorithm and modified ART1\nalgorithm using an efficient modified performance measure known as modified\ngrouping efficiency (MGE) as found in the literature. The results support the\nbetter performance of the proposed algorithm. The Novelty of this study lies in\nthe simple and efficient methodology to produce quick solutions for shop floor\nmanagers with least computational efforts and time.\n",
        "published": "2012-12-20T15:53:43Z",
        "pdf_link": "http://arxiv.org/pdf/1212.5101v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.5701v1",
        "title": "ADADELTA: An Adaptive Learning Rate Method",
        "summary": "  We present a novel per-dimension learning rate method for gradient descent\ncalled ADADELTA. The method dynamically adapts over time using only first order\ninformation and has minimal computational overhead beyond vanilla stochastic\ngradient descent. The method requires no manual tuning of a learning rate and\nappears robust to noisy gradient information, different model architecture\nchoices, various data modalities and selection of hyperparameters. We show\npromising results compared to other methods on the MNIST digit classification\ntask using a single machine and on a large scale voice dataset in a distributed\ncluster environment.\n",
        "published": "2012-12-22T15:46:49Z",
        "pdf_link": "http://arxiv.org/pdf/1212.5701v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.6031v1",
        "title": "Tangent Bundle Manifold Learning via Grassmann&Stiefel Eigenmaps",
        "summary": "  One of the ultimate goals of Manifold Learning (ML) is to reconstruct an\nunknown nonlinear low-dimensional manifold embedded in a high-dimensional\nobservation space by a given set of data points from the manifold. We derive a\nlocal lower bound for the maximum reconstruction error in a small neighborhood\nof an arbitrary point. The lower bound is defined in terms of the distance\nbetween tangent spaces to the original manifold and the estimated manifold at\nthe considered point and reconstructed point, respectively. We propose an\namplification of the ML, called Tangent Bundle ML, in which the proximity not\nonly between the original manifold and its estimator but also between their\ntangent spaces is required. We present a new algorithm that solves this problem\nand gives a new solution for the ML also.\n",
        "published": "2012-12-25T12:12:57Z",
        "pdf_link": "http://arxiv.org/pdf/1212.6031v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.0179v1",
        "title": "A Novel Design Specification Distance(DSD) Based K-Mean Clustering\n  Performace Evluation on Engineering Materials Database",
        "summary": "  Organizing data into semantically more meaningful is one of the fundamental\nmodes of understanding and learning. Cluster analysis is a formal study of\nmethods for understanding and algorithm for learning. K-mean clustering\nalgorithm is one of the most fundamental and simple clustering algorithms. When\nthere is no prior knowledge about the distribution of data sets, K-mean is the\nfirst choice for clustering with an initial number of clusters. In this paper a\nnovel distance metric called Design Specification (DS) distance measure\nfunction is integrated with K-mean clustering algorithm to improve cluster\naccuracy. The K-means algorithm with proposed distance measure maximizes the\ncluster accuracy to 99.98% at P = 1.525, which is determined through the\niterative procedure. The performance of Design Specification (DS) distance\nmeasure function with K - mean algorithm is compared with the performances of\nother standard distance functions such as Euclidian, squared Euclidean, City\nBlock, and Chebshew similarity measures deployed with K-mean algorithm.The\nproposed method is evaluated on the engineering materials database. The\nexperiments on cluster analysis and the outlier profiling show that these is an\nexcellent improvement in the performance of the proposed method.\n",
        "published": "2013-01-02T07:13:19Z",
        "pdf_link": "http://arxiv.org/pdf/1301.0179v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.1936v1",
        "title": "Risk-Aversion in Multi-armed Bandits",
        "summary": "  Stochastic multi-armed bandits solve the Exploration-Exploitation dilemma and\nultimately maximize the expected reward. Nonetheless, in many practical\nproblems, maximizing the expected reward is not the most desirable objective.\nIn this paper, we introduce a novel setting based on the principle of\nrisk-aversion where the objective is to compete against the arm with the best\nrisk-return trade-off. This setting proves to be intrinsically more difficult\nthan the standard multi-arm bandit setting due in part to an exploration risk\nwhich introduces a regret associated to the variability of an algorithm. Using\nvariance as a measure of risk, we introduce two new algorithms, investigate\ntheir theoretical guarantees, and report preliminary empirical results.\n",
        "published": "2013-01-09T18:02:54Z",
        "pdf_link": "http://arxiv.org/pdf/1301.1936v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.2012v1",
        "title": "Error Correction in Learning using SVMs",
        "summary": "  This paper is concerned with learning binary classifiers under adversarial\nlabel-noise. We introduce the problem of error-correction in learning where the\ngoal is to recover the original clean data from a label-manipulated version of\nit, given (i) no constraints on the adversary other than an upper-bound on the\nnumber of errors, and (ii) some regularity properties for the original data. We\npresent a simple and practical error-correction algorithm called SubSVMs that\nlearns individual SVMs on several small-size (log-size), class-balanced, random\nsubsets of the data and then reclassifies the training points using a majority\nvote. Our analysis reveals the need for the two main ingredients of SubSVMs,\nnamely class-balanced sampling and subsampled bagging. Experimental results on\nsynthetic as well as benchmark UCI data demonstrate the effectiveness of our\napproach. In addition to noise-tolerance, log-size subsampled bagging also\nyields significant run-time benefits over standard SVMs.\n",
        "published": "2013-01-10T00:47:21Z",
        "pdf_link": "http://arxiv.org/pdf/1301.2012v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.2609v5",
        "title": "Learning to Optimize Via Posterior Sampling",
        "summary": "  This paper considers the use of a simple posterior sampling algorithm to\nbalance between exploration and exploitation when learning to optimize actions\nsuch as in multi-armed bandit problems. The algorithm, also known as Thompson\nSampling, offers significant advantages over the popular upper confidence bound\n(UCB) approach, and can be applied to problems with finite or infinite action\nspaces and complicated relationships among action rewards. We make two\ntheoretical contributions. The first establishes a connection between posterior\nsampling and UCB algorithms. This result lets us convert regret bounds\ndeveloped for UCB algorithms into Bayesian regret bounds for posterior\nsampling. Our second theoretical contribution is a Bayesian regret bound for\nposterior sampling that applies broadly and can be specialized to many model\nclasses. This bound depends on a new notion we refer to as the eluder\ndimension, which measures the degree of dependence among action rewards.\nCompared to UCB algorithm Bayesian regret bounds for specific model classes,\nour general bound matches the best available for linear models and is stronger\nthan the best available for generalized linear models. Further, our analysis\nprovides insight into performance advantages of posterior sampling, which are\nhighlighted through simulation results that demonstrate performance surpassing\nrecently proposed UCB algorithms.\n",
        "published": "2013-01-11T21:24:11Z",
        "pdf_link": "http://arxiv.org/pdf/1301.2609v5"
    },
    {
        "id": "http://arxiv.org/abs/1301.3224v5",
        "title": "Efficient Learning of Domain-invariant Image Representations",
        "summary": "  We present an algorithm that learns representations which explicitly\ncompensate for domain mismatch and which can be efficiently realized as linear\nclassifiers. Specifically, we form a linear transformation that maps features\nfrom the target (test) domain to the source (training) domain as part of\ntraining the classifier. We optimize both the transformation and classifier\nparameters jointly, and introduce an efficient cost function based on\nmisclassification loss. Our method combines several features previously\nunavailable in a single algorithm: multi-class adaptation through\nrepresentation learning, ability to map across heterogeneous feature spaces,\nand scalability to large datasets. We present experiments on several image\ndatasets that demonstrate improved accuracy and computational advantages\ncompared to previous approaches.\n",
        "published": "2013-01-15T04:39:32Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3224v5"
    },
    {
        "id": "http://arxiv.org/abs/1301.3391v3",
        "title": "Feature grouping from spatially constrained multiplicative interaction",
        "summary": "  We present a feature learning model that learns to encode relationships\nbetween images. The model is defined as a Gated Boltzmann Machine, which is\nconstrained such that hidden units that are nearby in space can gate each\nother's connections. We show how frequency/orientation \"columns\" as well as\ntopographic filter maps follow naturally from training the model on image\npairs. The model also helps explain why square-pooling models yield feature\ngroups with similar grouping properties. Experimental results on synthetic\nimage transformations show that spatially constrained gating is an effective\nway to reduce the number of parameters and thereby to regularize a\ntransformation-learning model.\n",
        "published": "2013-01-15T16:06:11Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3391v3"
    },
    {
        "id": "http://arxiv.org/abs/1301.3485v2",
        "title": "A Semantic Matching Energy Function for Learning with Multi-relational\n  Data",
        "summary": "  Large-scale relational learning becomes crucial for handling the huge amounts\nof structured data generated daily in many application domains ranging from\ncomputational biology or information retrieval, to natural language processing.\nIn this paper, we present a new neural network architecture designed to embed\nmulti-relational graphs into a flexible continuous vector space in which the\noriginal data is kept and enhanced. The network is trained to encode the\nsemantics of these graphs in order to assign high probabilities to plausible\ncomponents. We empirically show that it reaches competitive performance in link\nprediction on standard datasets from the literature.\n",
        "published": "2013-01-15T20:52:50Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3485v2"
    },
    {
        "id": "http://arxiv.org/abs/1301.3524v1",
        "title": "How good is the Electricity benchmark for evaluating concept drift\n  adaptation",
        "summary": "  In this correspondence, we will point out a problem with testing adaptive\nclassifiers on autocorrelated data. In such a case random change alarms may\nboost the accuracy figures. Hence, we cannot be sure if the adaptation is\nworking well.\n",
        "published": "2013-01-15T22:51:40Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3524v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.3539v1",
        "title": "Learning Features with Structure-Adapting Multi-view Exponential Family\n  Harmoniums",
        "summary": "  We proposea graphical model for multi-view feature extraction that\nautomatically adapts its structure to achieve better representation of data\ndistribution. The proposed model, structure-adapting multi-view harmonium\n(SA-MVH) has switch parameters that control the connection between hidden nodes\nand input views, and learn the switch parameter while training. Numerical\nexperiments on synthetic and a real-world dataset demonstrate the useful\nbehavior of the SA-MVH, compared to existing multi-view feature extraction\nmethods.\n",
        "published": "2013-01-16T01:07:38Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3539v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.3577v3",
        "title": "Saturating Auto-Encoders",
        "summary": "  We introduce a simple new regularizer for auto-encoders whose hidden-unit\nactivation functions contain at least one zero-gradient (saturated) region.\nThis regularizer explicitly encourages activations in the saturated region(s)\nof the corresponding activation function. We call these Saturating\nAuto-Encoders (SATAE). We show that the saturation regularizer explicitly\nlimits the SATAE's ability to reconstruct inputs which are not near the data\nmanifold. Furthermore, we show that a wide variety of features can be learned\nwhen different activation functions are used. Finally, connections are\nestablished with the Contractive and Sparse Auto-Encoders.\n",
        "published": "2013-01-16T04:07:46Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3577v3"
    },
    {
        "id": "http://arxiv.org/abs/1301.3630v4",
        "title": "Behavior Pattern Recognition using A New Representation Model",
        "summary": "  We study the use of inverse reinforcement learning (IRL) as a tool for the\nrecognition of agents' behavior on the basis of observation of their sequential\ndecision behavior interacting with the environment. We model the problem faced\nby the agents as a Markov decision process (MDP) and model the observed\nbehavior of the agents in terms of forward planning for the MDP. We use IRL to\nlearn reward functions and then use these reward functions as the basis for\nclustering or classification models. Experimental studies with GridWorld, a\nnavigation problem, and the secretary problem, an optimal stopping problem,\nsuggest reward vectors found from IRL can be a good basis for behavior pattern\nrecognition problems. Empirical comparisons of our method with several existing\nIRL algorithms and with direct methods that use feature statistics observed in\nstate-action space suggest it may be superior for recognition problems.\n",
        "published": "2013-01-16T09:01:47Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3630v4"
    },
    {
        "id": "http://arxiv.org/abs/1301.3753v2",
        "title": "Switched linear encoding with rectified linear autoencoders",
        "summary": "  Several recent results in machine learning have established formal\nconnections between autoencoders---artificial neural network models that\nattempt to reproduce their inputs---and other coding models like sparse coding\nand K-means. This paper explores in depth an autoencoder model that is\nconstructed using rectified linear activations on its hidden units. Our\nanalysis builds on recent results to further unify the world of sparse linear\ncoding models. We provide an intuitive interpretation of the behavior of these\ncoding models and demonstrate this intuition using small, artificial datasets\nwith known distributions.\n",
        "published": "2013-01-16T17:04:10Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3753v2"
    },
    {
        "id": "http://arxiv.org/abs/1301.3816v1",
        "title": "Learning Output Kernels for Multi-Task Problems",
        "summary": "  Simultaneously solving multiple related learning tasks is beneficial under a\nvariety of circumstances, but the prior knowledge necessary to correctly model\ntask relationships is rarely available in practice. In this paper, we develop a\nnovel kernel-based multi-task learning technique that automatically reveals\nstructural inter-task relationships. Building over the framework of output\nkernel learning (OKL), we introduce a method that jointly learns multiple\nfunctions and a low-rank multi-task kernel by solving a non-convex\nregularization problem. Optimization is carried out via a block coordinate\ndescent strategy, where each subproblem is solved using suitable conjugate\ngradient (CG) type iterative methods for linear operator equations. The\neffectiveness of the proposed approach is demonstrated on pharmacological and\ncollaborative filtering data.\n",
        "published": "2013-01-16T20:16:02Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3816v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.5160v2",
        "title": "See the Tree Through the Lines: The Shazoo Algorithm -- Full Version --",
        "summary": "  Predicting the nodes of a given graph is a fascinating theoretical problem\nwith applications in several domains. Since graph sparsification via spanning\ntrees retains enough information while making the task much easier, trees are\nan important special case of this problem. Although it is known how to predict\nthe nodes of an unweighted tree in a nearly optimal way, in the weighted case a\nfully satisfactory algorithm is not available yet. We fill this hole and\nintroduce an efficient node predictor, Shazoo, which is nearly optimal on any\nweighted tree. Moreover, we show that Shazoo can be viewed as a common\nnontrivial generalization of both previous approaches for unweighted trees and\nweighted lines. Experiments on real-world datasets confirm that Shazoo performs\nwell in that it fully exploits the structure of the input tree, and gets very\nclose to (and sometimes better than) less scalable energy minimization methods.\n",
        "published": "2013-01-22T11:59:04Z",
        "pdf_link": "http://arxiv.org/pdf/1301.5160v2"
    },
    {
        "id": "http://arxiv.org/abs/1301.6058v1",
        "title": "Weighted Last-Step Min-Max Algorithm with Improved Sub-Logarithmic\n  Regret",
        "summary": "  In online learning the performance of an algorithm is typically compared to\nthe performance of a fixed function from some class, with a quantity called\nregret. Forster proposed a last-step min-max algorithm which was somewhat\nsimpler than the algorithm of Vovk, yet with the same regret. In fact the\nalgorithm he analyzed assumed that the choices of the adversary are bounded,\nyielding artificially only the two extreme cases. We fix this problem by\nweighing the examples in such a way that the min-max problem will be well\ndefined, and provide analysis with logarithmic regret that may have better\nmultiplicative factor than both bounds of Forster and Vovk. We also derive a\nnew bound that may be sub-logarithmic, as a recent bound of Orabona et.al, but\nmay have better multiplicative factor. Finally, we analyze the algorithm in a\nweak-type of non-stationary setting, and show a bound that is sub-linear if the\nnon-stationarity is sub-linear as well.\n",
        "published": "2013-01-25T15:09:39Z",
        "pdf_link": "http://arxiv.org/pdf/1301.6058v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.6316v3",
        "title": "Hierarchical Data Representation Model - Multi-layer NMF",
        "summary": "  In this paper, we propose a data representation model that demonstrates\nhierarchical feature learning using nsNMF. We extend unit algorithm into\nseveral layers. Experiments with document and image data successfully\ndiscovered feature hierarchies. We also prove that proposed method results in\nmuch better classification and reconstruction performance, especially for small\nnumber of features. feature hierarchies.\n",
        "published": "2013-01-27T04:51:21Z",
        "pdf_link": "http://arxiv.org/pdf/1301.6316v3"
    },
    {
        "id": "http://arxiv.org/abs/1301.6659v4",
        "title": "Clustering-Based Matrix Factorization",
        "summary": "  Recommender systems are emerging technologies that nowadays can be found in\nmany applications such as Amazon, Netflix, and so on. These systems help users\nto find relevant information, recommendations, and their preferred items.\nSlightly improvement of the accuracy of these recommenders can highly affect\nthe quality of recommendations. Matrix Factorization is a popular method in\nRecommendation Systems showing promising results in accuracy and complexity. In\nthis paper we propose an extension of matrix factorization which adds general\nneighborhood information on the recommendation model. Users and items are\nclustered into different categories to see how these categories share\npreferences. We then employ these shared interests of categories in a fusion by\nBiased Matrix Factorization to achieve more accurate recommendations. This is a\ncomplement for the current neighborhood aware matrix factorization models which\nrely on using direct neighborhood information of users and items. The proposed\nmodel is tested on two well-known recommendation system datasets: Movielens100k\nand Netflix. Our experiment shows applying the general latent features of\ncategories into factorized recommender models improves the accuracy of\nrecommendations. The current neighborhood-aware models need a great number of\nneighbors to acheive good accuracies. To the best of our knowledge, the\nproposed model is better than or comparable with the current neighborhood-aware\nmodels when they consider fewer number of neighbors.\n",
        "published": "2013-01-28T20:01:57Z",
        "pdf_link": "http://arxiv.org/pdf/1301.6659v4"
    },
    {
        "id": "http://arxiv.org/abs/1302.0540v1",
        "title": "A game-theoretic framework for classifier ensembles using weighted\n  majority voting with local accuracy estimates",
        "summary": "  In this paper, a novel approach for the optimal combination of binary\nclassifiers is proposed. The classifier combination problem is approached from\na Game Theory perspective. The proposed framework of adapted weighted majority\nrules (WMR) is tested against common rank-based, Bayesian and simple majority\nmodels, as well as two soft-output averaging rules. Experiments with ensembles\nof Support Vector Machines (SVM), Ordinary Binary Tree Classifiers (OBTC) and\nweighted k-nearest-neighbor (w/k-NN) models on benchmark datasets indicate that\nthis new adaptive WMR model, employing local accuracy estimators and the\nanalytically computed optimal weights outperform all the other simple\ncombination rules.\n",
        "published": "2013-02-03T22:12:52Z",
        "pdf_link": "http://arxiv.org/pdf/1302.0540v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.0963v1",
        "title": "RandomBoost: Simplified Multi-class Boosting through Randomization",
        "summary": "  We propose a novel boosting approach to multi-class classification problems,\nin which multiple classes are distinguished by a set of random projection\nmatrices in essence. The approach uses random projections to alleviate the\nproliferation of binary classifiers typically required to perform multi-class\nclassification. The result is a multi-class classifier with a single\nvector-valued parameter, irrespective of the number of classes involved. Two\nvariants of this approach are proposed. The first method randomly projects the\noriginal data into new spaces, while the second method randomly projects the\noutputs of learned weak classifiers. These methods are not only conceptually\nsimple but also effective and easy to implement. A series of experiments on\nsynthetic, machine learning and visual recognition data sets demonstrate that\nour proposed methods compare favorably to existing multi-class boosting\nalgorithms in terms of both the convergence rate and classification accuracy.\n",
        "published": "2013-02-05T09:04:25Z",
        "pdf_link": "http://arxiv.org/pdf/1302.0963v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.0974v1",
        "title": "A Comparison of Relaxations of Multiset Cannonical Correlation Analysis\n  and Applications",
        "summary": "  Canonical correlation analysis is a statistical technique that is used to\nfind relations between two sets of variables. An important extension in pattern\nanalysis is to consider more than two sets of variables. This problem can be\nexpressed as a quadratically constrained quadratic program (QCQP), commonly\nreferred to Multi-set Canonical Correlation Analysis (MCCA). This is a\nnon-convex problem and so greedy algorithms converge to local optima without\nany guarantees on global optimality. In this paper, we show that despite being\nhighly structured, finding the optimal solution is NP-Hard. This motivates our\nrelaxation of the QCQP to a semidefinite program (SDP). The SDP is convex, can\nbe solved reasonably efficiently and comes with both absolute and\noutput-sensitive approximation quality. In addition to theoretical guarantees,\nwe do an extensive comparison of the QCQP method and the SDP relaxation on a\nvariety of synthetic and real world data. Finally, we present two useful\nextensions: we incorporate kernel methods and computing multiple sets of\ncanonical vectors.\n",
        "published": "2013-02-05T09:45:21Z",
        "pdf_link": "http://arxiv.org/pdf/1302.0974v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.1043v2",
        "title": "The price of bandit information in multiclass online classification",
        "summary": "  We consider two scenarios of multiclass online learning of a hypothesis class\n$H\\subseteq Y^X$. In the {\\em full information} scenario, the learner is\nexposed to instances together with their labels. In the {\\em bandit} scenario,\nthe true label is not exposed, but rather an indication whether the learner's\nprediction is correct or not. We show that the ratio between the error rates in\nthe two scenarios is at most $8\\cdot|Y|\\cdot \\log(|Y|)$ in the realizable case,\nand $\\tilde{O}(\\sqrt{|Y|})$ in the agnostic case. The results are tight up to a\nlogarithmic factor and essentially answer an open question from (Daniely et.\nal. - Multiclass learnability and the erm principle).\n  We apply these results to the class of $\\gamma$-margin multiclass linear\nclassifiers in $\\reals^d$. We show that the bandit error rate of this class is\n$\\tilde{\\Theta}(\\frac{|Y|}{\\gamma^2})$ in the realizable case and\n$\\tilde{\\Theta}(\\frac{1}{\\gamma}\\sqrt{|Y|T})$ in the agnostic case. This\nresolves an open question from (Kakade et. al. - Efficient bandit algorithms\nfor online multiclass prediction).\n",
        "published": "2013-02-05T14:31:51Z",
        "pdf_link": "http://arxiv.org/pdf/1302.1043v2"
    },
    {
        "id": "http://arxiv.org/abs/1302.2157v2",
        "title": "Passive Learning with Target Risk",
        "summary": "  In this paper we consider learning in passive setting but with a slight\nmodification. We assume that the target expected loss, also referred to as\ntarget risk, is provided in advance for learner as prior knowledge. Unlike most\nstudies in the learning theory that only incorporate the prior knowledge into\nthe generalization bounds, we are able to explicitly utilize the target risk in\nthe learning process. Our analysis reveals a surprising result on the sample\ncomplexity of learning: by exploiting the target risk in the learning\nalgorithm, we show that when the loss function is both strongly convex and\nsmooth, the sample complexity reduces to $\\O(\\log (\\frac{1}{\\epsilon}))$, an\nexponential improvement compared to the sample complexity\n$\\O(\\frac{1}{\\epsilon})$ for learning with strongly convex loss functions.\nFurthermore, our proof is constructive and is based on a computationally\nefficient stochastic optimization algorithm for such settings which demonstrate\nthat the proposed algorithm is practically useful.\n",
        "published": "2013-02-08T21:18:24Z",
        "pdf_link": "http://arxiv.org/pdf/1302.2157v2"
    },
    {
        "id": "http://arxiv.org/abs/1302.2176v1",
        "title": "Minimax Optimal Algorithms for Unconstrained Linear Optimization",
        "summary": "  We design and analyze minimax-optimal algorithms for online linear\noptimization games where the player's choice is unconstrained. The player\nstrives to minimize regret, the difference between his loss and the loss of a\npost-hoc benchmark strategy. The standard benchmark is the loss of the best\nstrategy chosen from a bounded comparator set. When the the comparison set and\nthe adversary's gradients satisfy L_infinity bounds, we give the value of the\ngame in closed form and prove it approaches sqrt(2T/pi) as T -> infinity.\n  Interesting algorithms result when we consider soft constraints on the\ncomparator, rather than restricting it to a bounded set. As a warmup, we\nanalyze the game with a quadratic penalty. The value of this game is exactly\nT/2, and this value is achieved by perhaps the simplest online algorithm of\nall: unprojected gradient descent with a constant learning rate.\n  We then derive a minimax-optimal algorithm for a much softer penalty\nfunction. This algorithm achieves good bounds under the standard notion of\nregret for any comparator point, without needing to specify the comparator set\nin advance. The value of this game converges to sqrt{e} as T ->infinity; we\ngive a closed-form for the exact value as a function of T. The resulting\nalgorithm is natural in unconstrained investment or betting scenarios, since it\nguarantees at worst constant loss, while allowing for exponential reward\nagainst an \"easy\" adversary.\n",
        "published": "2013-02-08T23:16:04Z",
        "pdf_link": "http://arxiv.org/pdf/1302.2176v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.2277v2",
        "title": "A Time Series Forest for Classification and Feature Extraction",
        "summary": "  We propose a tree ensemble method, referred to as time series forest (TSF),\nfor time series classification. TSF employs a combination of the entropy gain\nand a distance measure, referred to as the Entrance (entropy and distance)\ngain, for evaluating the splits. Experimental studies show that the Entrance\ngain criterion improves the accuracy of TSF. TSF randomly samples features at\neach tree node and has a computational complexity linear in the length of a\ntime series and can be built using parallel computing techniques such as\nmulti-core computing used here. The temporal importance curve is also proposed\nto capture the important temporal characteristics useful for classification.\nExperimental studies show that TSF using simple features such as mean,\ndeviation and slope outperforms strong competitors such as one-nearest-neighbor\nclassifiers with dynamic time warping, is computationally efficient, and can\nprovide insights into the temporal characteristics.\n",
        "published": "2013-02-09T22:56:45Z",
        "pdf_link": "http://arxiv.org/pdf/1302.2277v2"
    },
    {
        "id": "http://arxiv.org/abs/1302.2436v1",
        "title": "Extracting useful rules through improved decision tree induction using\n  information entropy",
        "summary": "  Classification is widely used technique in the data mining domain, where\nscalability and efficiency are the immediate problems in classification\nalgorithms for large databases. We suggest improvements to the existing C4.5\ndecision tree algorithm. In this paper attribute oriented induction (AOI) and\nrelevance analysis are incorporated with concept hierarchys knowledge and\nHeightBalancePriority algorithm for construction of decision tree along with\nMulti level mining. The assignment of priorities to attributes is done by\nevaluating information entropy, at different levels of abstraction for building\ndecision tree using HeightBalancePriority algorithm. Modified DMQL queries are\nused to understand and explore the shortcomings of the decision trees generated\nby C4.5 classifier for education dataset and the results are compared with the\nproposed approach.\n",
        "published": "2013-02-11T10:29:17Z",
        "pdf_link": "http://arxiv.org/pdf/1302.2436v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.2550v1",
        "title": "Online Regret Bounds for Undiscounted Continuous Reinforcement Learning",
        "summary": "  We derive sublinear regret bounds for undiscounted reinforcement learning in\ncontinuous state space. The proposed algorithm combines state aggregation with\nthe use of upper confidence bounds for implementing optimism in the face of\nuncertainty. Beside the existence of an optimal policy which satisfies the\nPoisson equation, the only assumptions made are Holder continuity of rewards\nand transition probabilities.\n",
        "published": "2013-02-11T17:44:10Z",
        "pdf_link": "http://arxiv.org/pdf/1302.2550v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.2552v1",
        "title": "Selecting the State-Representation in Reinforcement Learning",
        "summary": "  The problem of selecting the right state-representation in a reinforcement\nlearning problem is considered. Several models (functions mapping past\nobservations to a finite set) of the observations are given, and it is known\nthat for at least one of these models the resulting state dynamics are indeed\nMarkovian. Without knowing neither which of the models is the correct one, nor\nwhat are the probabilistic characteristics of the resulting MDP, it is required\nto obtain as much reward as the optimal policy for the correct model (or for\nthe best of the correct models, if there are several). We propose an algorithm\nthat achieves that, with a regret of order T^{2/3} where T is the horizon time.\n",
        "published": "2013-02-11T17:49:38Z",
        "pdf_link": "http://arxiv.org/pdf/1302.2552v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.2553v2",
        "title": "Optimal Regret Bounds for Selecting the State Representation in\n  Reinforcement Learning",
        "summary": "  We consider an agent interacting with an environment in a single stream of\nactions, observations, and rewards, with no reset. This process is not assumed\nto be a Markov Decision Process (MDP). Rather, the agent has several\nrepresentations (mapping histories of past interactions to a discrete state\nspace) of the environment with unknown dynamics, only some of which result in\nan MDP. The goal is to minimize the average regret criterion against an agent\nwho knows an MDP representation giving the highest optimal reward, and acts\noptimally in it. Recent regret bounds for this setting are of order\n$O(T^{2/3})$ with an additive term constant yet exponential in some\ncharacteristics of the optimal MDP. We propose an algorithm whose regret after\n$T$ time steps is $O(\\sqrt{T})$, with all constants reasonably small. This is\noptimal in $T$ since $O(\\sqrt{T})$ is the optimal regret in the setting of\nlearning in a (single discrete) MDP.\n",
        "published": "2013-02-11T17:55:49Z",
        "pdf_link": "http://arxiv.org/pdf/1302.2553v2"
    },
    {
        "id": "http://arxiv.org/abs/1302.3219v1",
        "title": "An Efficient Dual Approach to Distance Metric Learning",
        "summary": "  Distance metric learning is of fundamental interest in machine learning\nbecause the distance metric employed can significantly affect the performance\nof many learning methods. Quadratic Mahalanobis metric learning is a popular\napproach to the problem, but typically requires solving a semidefinite\nprogramming (SDP) problem, which is computationally expensive. Standard\ninterior-point SDP solvers typically have a complexity of $O(D^{6.5})$ (with\n$D$ the dimension of input data), and can thus only practically solve problems\nexhibiting less than a few thousand variables. Since the number of variables is\n$D (D+1) / 2 $, this implies a limit upon the size of problem that can\npractically be solved of around a few hundred dimensions. The complexity of the\npopular quadratic Mahalanobis metric learning approach thus limits the size of\nproblem to which metric learning can be applied. Here we propose a\nsignificantly more efficient approach to the metric learning problem based on\nthe Lagrange dual formulation of the problem. The proposed formulation is much\nsimpler to implement, and therefore allows much larger Mahalanobis metric\nlearning problems to be solved. The time complexity of the proposed method is\n$O (D ^ 3) $, which is significantly lower than that of the SDP approach.\nExperiments on a variety of datasets demonstrate that the proposed method\nachieves an accuracy comparable to the state-of-the-art, but is applicable to\nsignificantly larger problems. We also show that the proposed method can be\napplied to solve more general Frobenius-norm regularized SDP problems\napproximately.\n",
        "published": "2013-02-13T08:48:53Z",
        "pdf_link": "http://arxiv.org/pdf/1302.3219v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.3268v2",
        "title": "Adaptive Crowdsourcing Algorithms for the Bandit Survey Problem",
        "summary": "  Very recently crowdsourcing has become the de facto platform for distributing\nand collecting human computation for a wide range of tasks and applications\nsuch as information retrieval, natural language processing and machine\nlearning. Current crowdsourcing platforms have some limitations in the area of\nquality control. Most of the effort to ensure good quality has to be done by\nthe experimenter who has to manage the number of workers needed to reach good\nresults.\n  We propose a simple model for adaptive quality control in crowdsourced\nmultiple-choice tasks which we call the \\emph{bandit survey problem}. This\nmodel is related to, but technically different from the well-known multi-armed\nbandit problem. We present several algorithms for this problem, and support\nthem with analysis and simulations. Our approach is based in our experience\nconducting relevance evaluation for a large commercial search engine.\n",
        "published": "2013-02-13T22:42:44Z",
        "pdf_link": "http://arxiv.org/pdf/1302.3268v2"
    },
    {
        "id": "http://arxiv.org/abs/1302.3283v4",
        "title": "StructBoost: Boosting Methods for Predicting Structured Output Variables",
        "summary": "  Boosting is a method for learning a single accurate predictor by linearly\ncombining a set of less accurate weak learners. Recently, structured learning\nhas found many applications in computer vision. Inspired by structured support\nvector machines (SSVM), here we propose a new boosting algorithm for structured\noutput prediction, which we refer to as StructBoost. StructBoost supports\nnonlinear structured learning by combining a set of weak structured learners.\nAs SSVM generalizes SVM, our StructBoost generalizes standard boosting\napproaches such as AdaBoost, or LPBoost to structured learning. The resulting\noptimization problem of StructBoost is more challenging than SSVM in the sense\nthat it may involve exponentially many variables and constraints. In contrast,\nfor SSVM one usually has an exponential number of constraints and a\ncutting-plane method is used. In order to efficiently solve StructBoost, we\nformulate an equivalent $ 1 $-slack formulation and solve it using a\ncombination of cutting planes and column generation. We show the versatility\nand usefulness of StructBoost on a range of problems such as optimizing the\ntree loss for hierarchical multi-class classification, optimizing the Pascal\noverlap criterion for robust visual tracking and learning conditional random\nfield parameters for image segmentation.\n",
        "published": "2013-02-14T01:01:24Z",
        "pdf_link": "http://arxiv.org/pdf/1302.3283v4"
    },
    {
        "id": "http://arxiv.org/abs/1302.3721v1",
        "title": "Thompson Sampling in Switching Environments with Bayesian Online Change\n  Point Detection",
        "summary": "  Thompson Sampling has recently been shown to be optimal in the Bernoulli\nMulti-Armed Bandit setting[Kaufmann et al., 2012]. This bandit problem assumes\nstationary distributions for the rewards. It is often unrealistic to model the\nreal world as a stationary distribution. In this paper we derive and evaluate\nalgorithms using Thompson Sampling for a Switching Multi-Armed Bandit Problem.\nWe propose a Thompson Sampling strategy equipped with a Bayesian change point\nmechanism to tackle this problem. We develop algorithms for a variety of cases\nwith constant switching rate: when switching occurs all arms change (Global\nSwitching), switching occurs independently for each arm (Per-Arm Switching),\nwhen the switching rate is known and when it must be inferred from data. This\nleads to a family of algorithms we collectively term Change-Point Thompson\nSampling (CTS). We show empirical results of the algorithm in 4 artificial\nenvironments, and 2 derived from real world data; news click-through[Yahoo!,\n2011] and foreign exchange data[Dukascopy, 2012], comparing them to some other\nbandit algorithms. In real world data CTS is the most effective.\n",
        "published": "2013-02-15T10:48:57Z",
        "pdf_link": "http://arxiv.org/pdf/1302.3721v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.5348v3",
        "title": "Graph-based Generalization Bounds for Learning Binary Relations",
        "summary": "  We investigate the generalizability of learned binary relations: functions\nthat map pairs of instances to a logical indicator. This problem has\napplication in numerous areas of machine learning, such as ranking, entity\nresolution and link prediction. Our learning framework incorporates an example\nlabeler that, given a sequence $X$ of $n$ instances and a desired training size\n$m$, subsamples $m$ pairs from $X \\times X$ without replacement. The challenge\nin analyzing this learning scenario is that pairwise combinations of random\nvariables are inherently dependent, which prevents us from using traditional\nlearning-theoretic arguments. We present a unified, graph-based analysis, which\nallows us to analyze this dependence using well-known graph identities. We are\nthen able to bound the generalization error of learned binary relations using\nRademacher complexity and algorithmic stability. The rate of uniform\nconvergence is partially determined by the labeler's subsampling process. We\nthus examine how various assumptions about subsampling affect generalization;\nunder a natural random subsampling process, our bounds guarantee\n$\\tilde{O}(1/\\sqrt{n})$ uniform convergence.\n",
        "published": "2013-02-21T17:30:42Z",
        "pdf_link": "http://arxiv.org/pdf/1302.5348v3"
    },
    {
        "id": "http://arxiv.org/abs/1302.5565v1",
        "title": "The Importance of Clipping in Neurocontrol by Direct Gradient Descent on\n  the Cost-to-Go Function and in Adaptive Dynamic Programming",
        "summary": "  In adaptive dynamic programming, neurocontrol and reinforcement learning, the\nobjective is for an agent to learn to choose actions so as to minimise a total\ncost function. In this paper we show that when discretized time is used to\nmodel the motion of the agent, it can be very important to do \"clipping\" on the\nmotion of the agent in the final time step of the trajectory. By clipping we\nmean that the final time step of the trajectory is to be truncated such that\nthe agent stops exactly at the first terminal state reached, and no distance\nfurther. We demonstrate that when clipping is omitted, learning performance can\nfail to reach the optimum; and when clipping is done properly, learning\nperformance can improve significantly.\n  The clipping problem we describe affects algorithms which use explicit\nderivatives of the model functions of the environment to calculate a learning\ngradient. These include Backpropagation Through Time for Control, and methods\nbased on Dual Heuristic Dynamic Programming. However the clipping problem does\nnot significantly affect methods based on Heuristic Dynamic Programming,\nTemporal Differences or Policy Gradient Learning algorithms. Similarly, the\nclipping problem does not affect fixed-length finite-horizon problems.\n",
        "published": "2013-02-22T12:11:42Z",
        "pdf_link": "http://arxiv.org/pdf/1302.5565v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.5797v1",
        "title": "Prediction by Random-Walk Perturbation",
        "summary": "  We propose a version of the follow-the-perturbed-leader online prediction\nalgorithm in which the cumulative losses are perturbed by independent symmetric\nrandom walks. The forecaster is shown to achieve an expected regret of the\noptimal order O(sqrt(n log N)) where n is the time horizon and N is the number\nof experts. More importantly, it is shown that the forecaster changes its\nprediction at most O(sqrt(n log N)) times, in expectation. We also extend the\nanalysis to online combinatorial optimization and show that even in this more\ngeneral setting, the forecaster rarely switches between experts while having a\nregret of near-optimal order.\n",
        "published": "2013-02-23T13:33:09Z",
        "pdf_link": "http://arxiv.org/pdf/1302.5797v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.6523v1",
        "title": "Sparse Frequency Analysis with Sparse-Derivative Instantaneous Amplitude\n  and Phase Functions",
        "summary": "  This paper addresses the problem of expressing a signal as a sum of frequency\ncomponents (sinusoids) wherein each sinusoid may exhibit abrupt changes in its\namplitude and/or phase. The Fourier transform of a narrow-band signal, with a\ndiscontinuous amplitude and/or phase function, exhibits spectral and temporal\nspreading. The proposed method aims to avoid such spreading by explicitly\nmodeling the signal of interest as a sum of sinusoids with time-varying\namplitudes. So as to accommodate abrupt changes, it is further assumed that the\namplitude/phase functions are approximately piecewise constant (i.e., their\ntime-derivatives are sparse). The proposed method is based on a convex\nvariational (optimization) approach wherein the total variation (TV) of the\namplitude functions are regularized subject to a perfect (or approximate)\nreconstruction constraint. A computationally efficient algorithm is derived\nbased on convex optimization techniques. The proposed technique can be used to\nperform band-pass filtering that is relatively insensitive to narrow-band\namplitude/phase jumps present in data, which normally pose a challenge (due to\ntransients, leakage, etc.). The method is illustrated using both synthetic\nsignals and human EEG data for the purpose of band-pass filtering and the\nestimation of phase synchrony indexes.\n",
        "published": "2013-02-26T18:18:35Z",
        "pdf_link": "http://arxiv.org/pdf/1302.6523v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.6927v1",
        "title": "Online Learning for Time Series Prediction",
        "summary": "  In this paper we address the problem of predicting a time series using the\nARMA (autoregressive moving average) model, under minimal assumptions on the\nnoise terms. Using regret minimization techniques, we develop effective online\nlearning algorithms for the prediction problem, without assuming that the noise\nterms are Gaussian, identically distributed or even independent. Furthermore,\nwe show that our algorithm's performances asymptotically approaches the\nperformance of the best ARMA model in hindsight.\n",
        "published": "2013-02-27T17:14:14Z",
        "pdf_link": "http://arxiv.org/pdf/1302.6927v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.6937v2",
        "title": "Online Convex Optimization Against Adversaries with Memory and\n  Application to Statistical Arbitrage",
        "summary": "  The framework of online learning with memory naturally captures learning\nproblems with temporal constraints, and was previously studied for the experts\nsetting. In this work we extend the notion of learning with memory to the\ngeneral Online Convex Optimization (OCO) framework, and present two algorithms\nthat attain low regret. The first algorithm applies to Lipschitz continuous\nloss functions, obtaining optimal regret bounds for both convex and strongly\nconvex losses. The second algorithm attains the optimal regret bounds and\napplies more broadly to convex losses without requiring Lipschitz continuity,\nyet is more complicated to implement. We complement our theoretic results with\nan application to statistical arbitrage in finance: we devise algorithms for\nconstructing mean-reverting portfolios.\n",
        "published": "2013-02-27T17:46:43Z",
        "pdf_link": "http://arxiv.org/pdf/1302.6937v2"
    },
    {
        "id": "http://arxiv.org/abs/1302.7263v3",
        "title": "Online Similarity Prediction of Networked Data from Known and Unknown\n  Graphs",
        "summary": "  We consider online similarity prediction problems over networked data. We\nbegin by relating this task to the more standard class prediction problem,\nshowing that, given an arbitrary algorithm for class prediction, we can\nconstruct an algorithm for similarity prediction with \"nearly\" the same mistake\nbound, and vice versa. After noticing that this general construction is\ncomputationally infeasible, we target our study to {\\em feasible} similarity\nprediction algorithms on networked data. We initially assume that the network\nstructure is {\\em known} to the learner. Here we observe that Matrix Winnow\n\\cite{w07} has a near-optimal mistake guarantee, at the price of cubic\nprediction time per round. This motivates our effort for an efficient\nimplementation of a Perceptron algorithm with a weaker mistake guarantee but\nwith only poly-logarithmic prediction time. Our focus then turns to the\nchallenging case of networks whose structure is initially {\\em unknown} to the\nlearner. In this novel setting, where the network structure is only\nincrementally revealed, we obtain a mistake-bounded algorithm with a quadratic\nprediction time per round.\n",
        "published": "2013-02-28T17:15:55Z",
        "pdf_link": "http://arxiv.org/pdf/1302.7263v3"
    },
    {
        "id": "http://arxiv.org/abs/1303.0339v1",
        "title": "Learning Hash Functions Using Column Generation",
        "summary": "  Fast nearest neighbor searching is becoming an increasingly important tool in\nsolving many large-scale problems. Recently a number of approaches to learning\ndata-dependent hash functions have been developed. In this work, we propose a\ncolumn generation based method for learning data-dependent hash functions on\nthe basis of proximity comparison information. Given a set of triplets that\nencode the pairwise proximity comparison information, our method learns hash\nfunctions that preserve the relative comparison relationships in the data as\nwell as possible within the large-margin learning framework. The learning\nprocedure is implemented using column generation and hence is named CGHash. At\neach iteration of the column generation procedure, the best hash function is\nselected. Unlike most other hashing methods, our method generalizes to new data\npoints naturally; and has a training objective which is convex, thus ensuring\nthat the global optimum can be identified. Experiments demonstrate that the\nproposed method learns compact binary codes and that its retrieval performance\ncompares favorably with state-of-the-art methods when tested on a few benchmark\ndatasets.\n",
        "published": "2013-03-02T03:01:46Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0339v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.0362v1",
        "title": "Inductive Sparse Subspace Clustering",
        "summary": "  Sparse Subspace Clustering (SSC) has achieved state-of-the-art clustering\nquality by performing spectral clustering over a $\\ell^{1}$-norm based\nsimilarity graph. However, SSC is a transductive method which does not handle\nwith the data not used to construct the graph (out-of-sample data). For each\nnew datum, SSC requires solving $n$ optimization problems in O(n) variables for\nperforming the algorithm over the whole data set, where $n$ is the number of\ndata points. Therefore, it is inefficient to apply SSC in fast online\nclustering and scalable graphing. In this letter, we propose an inductive\nspectral clustering algorithm, called inductive Sparse Subspace Clustering\n(iSSC), which makes SSC feasible to cluster out-of-sample data. iSSC adopts the\nassumption that high-dimensional data actually lie on the low-dimensional\nmanifold such that out-of-sample data could be grouped in the embedding space\nlearned from in-sample data. Experimental results show that iSSC is promising\nin clustering out-of-sample data.\n",
        "published": "2013-03-02T07:47:21Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0362v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.1271v5",
        "title": "Convex and Scalable Weakly Labeled SVMs",
        "summary": "  In this paper, we study the problem of learning from weakly labeled data,\nwhere labels of the training examples are incomplete. This includes, for\nexample, (i) semi-supervised learning where labels are partially known; (ii)\nmulti-instance learning where labels are implicitly known; and (iii) clustering\nwhere labels are completely unknown. Unlike supervised learning, learning with\nweak labels involves a difficult Mixed-Integer Programming (MIP) problem.\nTherefore, it can suffer from poor scalability and may also get stuck in local\nminimum. In this paper, we focus on SVMs and propose the WellSVM via a novel\nlabel generation strategy. This leads to a convex relaxation of the original\nMIP, which is at least as tight as existing convex Semi-Definite Programming\n(SDP) relaxations. Moreover, the WellSVM can be solved via a sequence of SVM\nsubproblems that are much more scalable than previous convex SDP relaxations.\nExperiments on three weakly labeled learning tasks, namely, (i) semi-supervised\nlearning; (ii) multi-instance learning for locating regions of interest in\ncontent-based information retrieval; and (iii) clustering, clearly demonstrate\nimproved performance, and WellSVM is also readily applicable on large data\nsets.\n",
        "published": "2013-03-06T08:20:33Z",
        "pdf_link": "http://arxiv.org/pdf/1303.1271v5"
    },
    {
        "id": "http://arxiv.org/abs/1303.1733v2",
        "title": "Multi-relational Learning Using Weighted Tensor Decomposition with\n  Modular Loss",
        "summary": "  We propose a modular framework for multi-relational learning via tensor\ndecomposition. In our learning setting, the training data contains multiple\ntypes of relationships among a set of objects, which we represent by a sparse\nthree-mode tensor. The goal is to predict the values of the missing entries. To\ndo so, we model each relationship as a function of a linear combination of\nlatent factors. We learn this latent representation by computing a low-rank\ntensor decomposition, using quasi-Newton optimization of a weighted objective\nfunction. Sparsity in the observed data is captured by the weighted objective,\nleading to improved accuracy when training data is limited. Exploiting sparsity\nalso improves efficiency, potentially up to an order of magnitude over\nunweighted approaches. In addition, our framework accommodates arbitrary\ncombinations of smooth, task-specific loss functions, making it better suited\nfor learning different types of relations. For the typical cases of real-valued\nfunctions and binary relations, we propose several loss functions and derive\nthe associated parameter gradients. We evaluate our method on synthetic and\nreal data, showing significant improvements in both accuracy and scalability\nover related factorization techniques.\n",
        "published": "2013-03-07T16:10:44Z",
        "pdf_link": "http://arxiv.org/pdf/1303.1733v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.2104v1",
        "title": "Transfer Learning for Voice Activity Detection: A Denoising Deep Neural\n  Network Perspective",
        "summary": "  Mismatching problem between the source and target noisy corpora severely\nhinder the practical use of the machine-learning-based voice activity detection\n(VAD). In this paper, we try to address this problem in the transfer learning\nprospective. Transfer learning tries to find a common learning machine or a\ncommon feature subspace that is shared by both the source corpus and the target\ncorpus. The denoising deep neural network is used as the learning machine.\nThree transfer techniques, which aim to learn common feature representations,\nare used for analysis. Experimental results demonstrate the effectiveness of\nthe transfer learning schemes on the mismatch problem.\n",
        "published": "2013-03-08T20:46:27Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2104v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.2130v2",
        "title": "Convex Discriminative Multitask Clustering",
        "summary": "  Multitask clustering tries to improve the clustering performance of multiple\ntasks simultaneously by taking their relationship into account. Most existing\nmultitask clustering algorithms fall into the type of generative clustering,\nand none are formulated as convex optimization problems. In this paper, we\npropose two convex Discriminative Multitask Clustering (DMTC) algorithms to\naddress the problems. Specifically, we first propose a Bayesian DMTC framework.\nThen, we propose two convex DMTC objectives within the framework. The first\none, which can be seen as a technical combination of the convex multitask\nfeature learning and the convex Multiclass Maximum Margin Clustering (M3C),\naims to learn a shared feature representation. The second one, which can be\nseen as a combination of the convex multitask relationship learning and M3C,\naims to learn the task relationship. The two objectives are solved in a uniform\nprocedure by the efficient cutting-plane algorithm. Experimental results on a\ntoy problem and two benchmark datasets demonstrate the effectiveness of the\nproposed algorithms.\n",
        "published": "2013-03-08T21:32:52Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2130v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.2132v2",
        "title": "Heuristic Ternary Error-Correcting Output Codes Via Weight Optimization\n  and Layered Clustering-Based Approach",
        "summary": "  One important classifier ensemble for multiclass classification problems is\nError-Correcting Output Codes (ECOCs). It bridges multiclass problems and\nbinary-class classifiers by decomposing multiclass problems to a serial\nbinary-class problems. In this paper, we present a heuristic ternary code,\nnamed Weight Optimization and Layered Clustering-based ECOC (WOLC-ECOC). It\nstarts with an arbitrary valid ECOC and iterates the following two steps until\nthe training risk converges. The first step, named Layered Clustering based\nECOC (LC-ECOC), constructs multiple strong classifiers on the most confusing\nbinary-class problem. The second step adds the new classifiers to ECOC by a\nnovel Optimized Weighted (OW) decoding algorithm, where the optimization\nproblem of the decoding is solved by the cutting plane algorithm. Technically,\nLC-ECOC makes the heuristic training process not blocked by some difficult\nbinary-class problem. OW decoding guarantees the non-increase of the training\nrisk for ensuring a small code length. Results on 14 UCI datasets and a music\ngenre classification problem demonstrate the effectiveness of WOLC-ECOC.\n",
        "published": "2013-03-08T21:40:42Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2132v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.3754v1",
        "title": "A Last-Step Regression Algorithm for Non-Stationary Online Learning",
        "summary": "  The goal of a learner in standard online learning is to maintain an average\nloss close to the loss of the best-performing single function in some class. In\nmany real-world problems, such as rating or ranking items, there is no single\nbest target function during the runtime of the algorithm, instead the best\n(local) target function is drifting over time. We develop a novel last-step\nminmax optimal algorithm in context of a drift. We analyze the algorithm in the\nworst-case regret framework and show that it maintains an average loss close to\nthat of the best slowly changing sequence of linear functions, as long as the\ntotal of drift is sublinear. In some situations, our bound improves over\nexisting bounds, and additionally the algorithm suffers logarithmic regret when\nthere is no drift. We also build on the H_infinity filter and its bound, and\ndevelop and analyze a second algorithm for drifting setting. Synthetic\nsimulations demonstrate the advantages of our algorithms in a worst-case\nconstant drift setting.\n",
        "published": "2013-03-15T12:20:53Z",
        "pdf_link": "http://arxiv.org/pdf/1303.3754v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.3934v2",
        "title": "A Quorum Sensing Inspired Algorithm for Dynamic Clustering",
        "summary": "  Quorum sensing is a decentralized biological process, through which a\ncommunity of cells with no global awareness coordinate their functional\nbehaviors based solely on cell-medium interactions and local decisions. This\npaper draws inspirations from quorum sensing and colony competition to derive a\nnew algorithm for data clustering. The algorithm treats each data as a single\ncell, and uses knowledge of local connectivity to cluster cells into multiple\ncolonies simultaneously. It simulates auto-inducers secretion in quorum sensing\nto tune the influence radius for each cell. At the same time, sparsely\ndistributed core cells spread their influences to form colonies, and\ninteractions between colonies eventually determine each cell's identity. The\nalgorithm has the flexibility to analyze not only static but also time-varying\ndata, which surpasses the capacity of many existing algorithms. Its stability\nand convergence properties are established. The algorithm is tested on several\napplications, including both synthetic and real benchmarks data sets, alleles\nclustering, community detection, image segmentation. In particular, the\nalgorithm's distinctive capability to deal with time-varying data allows us to\nexperiment it on novel applications such as robotic swarms grouping and\nswitching model identification. We believe that the algorithm's promising\nperformance would stimulate many more exciting applications.\n",
        "published": "2013-03-16T00:49:56Z",
        "pdf_link": "http://arxiv.org/pdf/1303.3934v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.4015v2",
        "title": "On multi-class learning through the minimization of the confusion matrix\n  norm",
        "summary": "  In imbalanced multi-class classification problems, the misclassification rate\nas an error measure may not be a relevant choice. Several methods have been\ndeveloped where the performance measure retained richer information than the\nmere misclassification rate: misclassification costs, ROC-based information,\netc. Following this idea of dealing with alternate measures of performance, we\npropose to address imbalanced classification problems by using a new measure to\nbe optimized: the norm of the confusion matrix. Indeed, recent results show\nthat using the norm of the confusion matrix as an error measure can be quite\ninteresting due to the fine-grain informations contained in the matrix,\nespecially in the case of imbalanced classes. Our first contribution then\nconsists in showing that optimizing criterion based on the confusion matrix\ngives rise to a common background for cost-sensitive methods aimed at dealing\nwith imbalanced classes learning problems. As our second contribution, we\npropose an extension of a recent multi-class boosting method --- namely\nAdaBoost.MM --- to the imbalanced class problem, by greedily minimizing the\nempirical norm of the confusion matrix. A theoretical analysis of the\nproperties of the proposed method is presented, while experimental results\nillustrate the behavior of the algorithm and show the relevancy of the approach\ncompared to other methods.\n",
        "published": "2013-03-16T20:09:16Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4015v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.4169v1",
        "title": "Markov Chain Monte Carlo for Arrangement of Hyperplanes in\n  Locality-Sensitive Hashing",
        "summary": "  Since Hamming distances can be calculated by bitwise computations, they can\nbe calculated with less computational load than L2 distances. Similarity\nsearches can therefore be performed faster in Hamming distance space. The\nelements of Hamming distance space are bit strings. On the other hand, the\narrangement of hyperplanes induce the transformation from the feature vectors\ninto feature bit strings. This transformation method is a type of\nlocality-sensitive hashing that has been attracting attention as a way of\nperforming approximate similarity searches at high speed. Supervised learning\nof hyperplane arrangements allows us to obtain a method that transforms them\ninto feature bit strings reflecting the information of labels applied to\nhigher-dimensional feature vectors. In this p aper, we propose a supervised\nlearning method for hyperplane arrangements in feature space that uses a Markov\nchain Monte Carlo (MCMC) method. We consider the probability density functions\nused during learning, and evaluate their performance. We also consider the\nsampling method for learning data pairs needed in learning, and we evaluate its\nperformance. We confirm that the accuracy of this learning method when using a\nsuitable probability density function and sampling method is greater than the\naccuracy of existing learning methods.\n",
        "published": "2013-03-18T07:14:15Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4169v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.4664v1",
        "title": "Large-Scale Learning with Less RAM via Randomization",
        "summary": "  We reduce the memory footprint of popular large-scale online learning methods\nby projecting our weight vector onto a coarse discrete set using randomized\nrounding. Compared to standard 32-bit float encodings, this reduces RAM usage\nby more than 50% during training and by up to 95% when making predictions from\na fixed model, with almost no loss in accuracy. We also show that randomized\ncounting can be used to implement per-coordinate learning rates, improving\nmodel quality with little additional RAM. We prove these memory-saving methods\nachieve regret guarantees similar to their exact variants. Empirical evaluation\nconfirms excellent performance, dominating standard approaches across memory\nversus accuracy tradeoffs.\n",
        "published": "2013-03-19T17:00:22Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4664v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.6390v2",
        "title": "A Note on k-support Norm Regularized Risk Minimization",
        "summary": "  The k-support norm has been recently introduced to perform correlated\nsparsity regularization. Although Argyriou et al. only reported experiments\nusing squared loss, here we apply it to several other commonly used settings\nresulting in novel machine learning algorithms with interesting and familiar\nlimit cases. Source code for the algorithms described here is available.\n",
        "published": "2013-03-26T06:01:34Z",
        "pdf_link": "http://arxiv.org/pdf/1303.6390v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.7043v1",
        "title": "Inductive Hashing on Manifolds",
        "summary": "  Learning based hashing methods have attracted considerable attention due to\ntheir ability to greatly increase the scale at which existing algorithms may\noperate. Most of these methods are designed to generate binary codes that\npreserve the Euclidean distance in the original space. Manifold learning\ntechniques, in contrast, are better able to model the intrinsic structure\nembedded in the original high-dimensional data. The complexity of these models,\nand the problems with out-of-sample data, have previously rendered them\nunsuitable for application to large-scale embedding, however. In this work, we\nconsider how to learn compact binary embeddings on their intrinsic manifolds.\nIn order to address the above-mentioned difficulties, we describe an efficient,\ninductive solution to the out-of-sample data problem, and a process by which\nnon-parametric manifold learning may be used as the basis of a hashing method.\nOur proposed approach thus allows the development of a range of new hashing\ntechniques exploiting the flexibility of the wide variety of manifold learning\napproaches available. We particularly show that hashing on the basis of t-SNE .\n",
        "published": "2013-03-28T05:45:21Z",
        "pdf_link": "http://arxiv.org/pdf/1303.7043v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.0740v1",
        "title": "O(logT) Projections for Stochastic Optimization of Smooth and Strongly\n  Convex Functions",
        "summary": "  Traditional algorithms for stochastic optimization require projecting the\nsolution at each iteration into a given domain to ensure its feasibility. When\nfacing complex domains, such as positive semi-definite cones, the projection\noperation can be expensive, leading to a high computational cost per iteration.\nIn this paper, we present a novel algorithm that aims to reduce the number of\nprojections for stochastic optimization. The proposed algorithm combines the\nstrength of several recent developments in stochastic optimization, including\nmini-batch, extra-gradient, and epoch gradient descent, in order to effectively\nexplore the smoothness and strong convexity. We show, both in expectation and\nwith a high probability, that when the objective function is both smooth and\nstrongly convex, the proposed algorithm achieves the optimal $O(1/T)$ rate of\nconvergence with only $O(\\log T)$ projections. Our empirical study verifies the\ntheoretical result.\n",
        "published": "2013-04-02T19:11:23Z",
        "pdf_link": "http://arxiv.org/pdf/1304.0740v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.1192v1",
        "title": "Efficient Distance Metric Learning by Adaptive Sampling and Mini-Batch\n  Stochastic Gradient Descent (SGD)",
        "summary": "  Distance metric learning (DML) is an important task that has found\napplications in many domains. The high computational cost of DML arises from\nthe large number of variables to be determined and the constraint that a\ndistance metric has to be a positive semi-definite (PSD) matrix. Although\nstochastic gradient descent (SGD) has been successfully applied to improve the\nefficiency of DML, it can still be computationally expensive because in order\nto ensure that the solution is a PSD matrix, it has to, at every iteration,\nproject the updated distance metric onto the PSD cone, an expensive operation.\nWe address this challenge by developing two strategies within SGD, i.e.\nmini-batch and adaptive sampling, to effectively reduce the number of updates\n(i.e., projections onto the PSD cone) in SGD. We also develop hybrid approaches\nthat combine the strength of adaptive sampling with that of mini-batch online\nlearning techniques to further improve the computational efficiency of SGD for\nDML. We prove the theoretical guarantees for both adaptive sampling and\nmini-batch based approaches for DML. We also conduct an extensive empirical\nstudy to verify the effectiveness of the proposed algorithms for DML.\n",
        "published": "2013-04-03T21:14:50Z",
        "pdf_link": "http://arxiv.org/pdf/1304.1192v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.1391v1",
        "title": "Fast SVM training using approximate extreme points",
        "summary": "  Applications of non-linear kernel Support Vector Machines (SVMs) to large\ndatasets is seriously hampered by its excessive training time. We propose a\nmodification, called the approximate extreme points support vector machine\n(AESVM), that is aimed at overcoming this burden. Our approach relies on\nconducting the SVM optimization over a carefully selected subset, called the\nrepresentative set, of the training dataset. We present analytical results that\nindicate the similarity of AESVM and SVM solutions. A linear time algorithm\nbased on convex hulls and extreme points is used to compute the representative\nset in kernel space. Extensive computational experiments on nine datasets\ncompared AESVM to LIBSVM \\citep{LIBSVM}, CVM \\citep{Tsang05}, BVM\n\\citep{Tsang07}, LASVM \\citep{Bordes05}, $\\text{SVM}^{\\text{perf}}$\n\\citep{Joachims09}, and the random features method \\citep{rahimi07}. Our AESVM\nimplementation was found to train much faster than the other methods, while its\nclassification accuracy was similar to that of LIBSVM in all cases. In\nparticular, for a seizure detection dataset, AESVM training was almost $10^3$\ntimes faster than LIBSVM and LASVM and more than forty times faster than CVM\nand BVM. Additionally, AESVM also gave competitively fast classification times.\n",
        "published": "2013-04-04T15:08:31Z",
        "pdf_link": "http://arxiv.org/pdf/1304.1391v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.2994v3",
        "title": "A Generalized Online Mirror Descent with Applications to Classification\n  and Regression",
        "summary": "  Online learning algorithms are fast, memory-efficient, easy to implement, and\napplicable to many prediction problems, including classification, regression,\nand ranking. Several online algorithms were proposed in the past few decades,\nsome based on additive updates, like the Perceptron, and some on multiplicative\nupdates, like Winnow. A unifying perspective on the design and the analysis of\nonline algorithms is provided by online mirror descent, a general prediction\nstrategy from which most first-order algorithms can be obtained as special\ncases. We generalize online mirror descent to time-varying regularizers with\ngeneric updates. Unlike standard mirror descent, our more general formulation\nalso captures second order algorithms, algorithms for composite losses and\nalgorithms for adaptive filtering. Moreover, we recover, and sometimes improve,\nknown regret bounds as special cases of our analysis using specific\nregularizers. Finally, we show the power of our approach by deriving a new\nsecond order algorithm with a regret bound invariant with respect to arbitrary\nrescalings of individual features.\n",
        "published": "2013-04-10T15:26:13Z",
        "pdf_link": "http://arxiv.org/pdf/1304.2994v3"
    },
    {
        "id": "http://arxiv.org/abs/1304.3840v1",
        "title": "A New Homogeneity Inter-Clusters Measure in SemiSupervised Clustering",
        "summary": "  Many studies in data mining have proposed a new learning called\nsemi-Supervised. Such type of learning combines unlabeled and labeled data\nwhich are hard to obtain. However, in unsupervised methods, the only unlabeled\ndata are used. The problem of significance and the effectiveness of\nsemi-supervised clustering results is becoming of main importance. This paper\npursues the thesis that muchgreater accuracy can be achieved in such clustering\nby improving the similarity computing. Hence, we introduce a new approach of\nsemisupervised clustering using an innovative new homogeneity measure of\ngenerated clusters. Our experimental results demonstrate significantly improved\naccuracy as a result.\n",
        "published": "2013-04-13T20:19:25Z",
        "pdf_link": "http://arxiv.org/pdf/1304.3840v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.5634v1",
        "title": "A Survey on Multi-view Learning",
        "summary": "  In recent years, a great many methods of learning from multi-view data by\nconsidering the diversity of different views have been proposed. These views\nmay be obtained from multiple sources or different feature subsets. In trying\nto organize and highlight similarities and differences between the variety of\nmulti-view learning approaches, we review a number of representative multi-view\nlearning algorithms in different areas and classify them into three groups: 1)\nco-training, 2) multiple kernel learning, and 3) subspace learning. Notably,\nco-training style algorithms train alternately to maximize the mutual agreement\non two distinct views of the data; multiple kernel learning algorithms exploit\nkernels that naturally correspond to different views and combine kernels either\nlinearly or non-linearly to improve learning performance; and subspace learning\nalgorithms aim to obtain a latent subspace shared by multiple views by assuming\nthat the input views are generated from this latent subspace. Though there is\nsignificant variance in the approaches to integrating multiple views to improve\nlearning performance, they mainly exploit either the consensus principle or the\ncomplementary principle to ensure the success of multi-view learning. Since\naccessing multiple views is the fundament of multi-view learning, with the\nexception of study on learning a model from multiple views, it is also valuable\nto study how to construct multiple views and how to evaluate these views.\nOverall, by exploring the consistency and complementary properties of different\nviews, multi-view learning is rendered more effective, more promising, and has\nbetter generalization ability than single-view learning.\n",
        "published": "2013-04-20T14:43:35Z",
        "pdf_link": "http://arxiv.org/pdf/1304.5634v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.5793v4",
        "title": "Continuum armed bandit problem of few variables in high dimensions",
        "summary": "  We consider the stochastic and adversarial settings of continuum armed\nbandits where the arms are indexed by [0,1]^d. The reward functions r:[0,1]^d\n-> R are assumed to intrinsically depend on at most k coordinate variables\nimplying r(x_1,..,x_d) = g(x_{i_1},..,x_{i_k}) for distinct and unknown\ni_1,..,i_k from {1,..,d} and some locally Holder continuous g:[0,1]^k -> R with\nexponent 0 < alpha <= 1. Firstly, assuming (i_1,..,i_k) to be fixed across\ntime, we propose a simple modification of the CAB1 algorithm where we construct\nthe discrete set of sampling points to obtain a bound of\nO(n^((alpha+k)/(2*alpha+k)) (log n)^((alpha)/(2*alpha+k)) C(k,d)) on the\nregret, with C(k,d) depending at most polynomially in k and sub-logarithmically\nin d. The construction is based on creating partitions of {1,..,d} into k\ndisjoint subsets and is probabilistic, hence our result holds with high\nprobability. Secondly we extend our results to also handle the more general\ncase where (i_1,...,i_k) can change over time and derive regret bounds for the\nsame.\n",
        "published": "2013-04-21T20:03:23Z",
        "pdf_link": "http://arxiv.org/pdf/1304.5793v4"
    },
    {
        "id": "http://arxiv.org/abs/1304.7158v1",
        "title": "Irreflexive and Hierarchical Relations as Translations",
        "summary": "  We consider the problem of embedding entities and relations of knowledge\nbases in low-dimensional vector spaces. Unlike most existing approaches, which\nare primarily efficient for modeling equivalence relations, our approach is\ndesigned to explicitly model irreflexive relations, such as hierarchies, by\ninterpreting them as translations operating on the low-dimensional embeddings\nof the entities. Preliminary experiments show that, despite its simplicity and\na smaller number of parameters than previous approaches, our approach achieves\nstate-of-the-art performance according to standard evaluation protocols on data\nfrom WordNet and Freebase.\n",
        "published": "2013-04-26T13:28:47Z",
        "pdf_link": "http://arxiv.org/pdf/1304.7158v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.7576v1",
        "title": "Fractal structures in Adversarial Prediction",
        "summary": "  Fractals are self-similar recursive structures that have been used in\nmodeling several real world processes. In this work we study how \"fractal-like\"\nprocesses arise in a prediction game where an adversary is generating a\nsequence of bits and an algorithm is trying to predict them. We will see that\nunder a certain formalization of the predictive payoff for the algorithm it is\nmost optimal for the adversary to produce a fractal-like sequence to minimize\nthe algorithm's ability to predict. Indeed it has been suggested before that\nfinancial markets exhibit a fractal-like behavior. We prove that a fractal-like\ndistribution arises naturally out of an optimization from the adversary's\nperspective.\n  In addition, we give optimal trade-offs between predictability and expected\ndeviation (i.e. sum of bits) for our formalization of predictive payoff. This\nresult is motivated by the observation that several time series data exhibit\nhigher deviations than expected for a completely random walk.\n",
        "published": "2013-04-29T07:16:54Z",
        "pdf_link": "http://arxiv.org/pdf/1304.7576v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.0103v1",
        "title": "Clustering Unclustered Data: Unsupervised Binary Labeling of Two\n  Datasets Having Different Class Balances",
        "summary": "  We consider the unsupervised learning problem of assigning labels to\nunlabeled data. A naive approach is to use clustering methods, but this works\nwell only when data is properly clustered and each cluster corresponds to an\nunderlying class. In this paper, we first show that this unsupervised labeling\nproblem in balanced binary cases can be solved if two unlabeled datasets having\ndifferent class balances are available. More specifically, estimation of the\nsign of the difference between probability densities of two unlabeled datasets\ngives the solution. We then introduce a new method to directly estimate the\nsign of the density difference without density estimation. Finally, we\ndemonstrate the usefulness of the proposed method against several clustering\nmethods on various toy problems and real-world datasets.\n",
        "published": "2013-05-01T06:32:12Z",
        "pdf_link": "http://arxiv.org/pdf/1305.0103v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.0208v2",
        "title": "Perceptron Mistake Bounds",
        "summary": "  We present a brief survey of existing mistake bounds and introduce novel\nbounds for the Perceptron or the kernel Perceptron algorithm. Our novel bounds\ngeneralize beyond standard margin-loss type bounds, allow for any convex and\nLipschitz loss function, and admit a very simple proof.\n",
        "published": "2013-05-01T15:45:34Z",
        "pdf_link": "http://arxiv.org/pdf/1305.0208v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.0445v2",
        "title": "Deep Learning of Representations: Looking Forward",
        "summary": "  Deep learning research aims at discovering learning algorithms that discover\nmultiple levels of distributed representations, with higher levels representing\nmore abstract concepts. Although the study of deep learning has already led to\nimpressive theoretical results, learning algorithms and breakthrough\nexperiments, several challenges lie ahead. This paper proposes to examine some\nof these challenges, centering on the questions of scaling deep learning\nalgorithms to much larger models and datasets, reducing optimization\ndifficulties due to ill-conditioning or local minima, designing more efficient\nand powerful inference and sampling procedures, and learning to disentangle the\nfactors of variation underlying the observed data. It also proposes a few\nforward-looking research directions aimed at overcoming these challenges.\n",
        "published": "2013-05-02T14:33:28Z",
        "pdf_link": "http://arxiv.org/pdf/1305.0445v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.0665v2",
        "title": "Spectral Classification Using Restricted Boltzmann Machine",
        "summary": "  In this study, a novel machine learning algorithm, restricted Boltzmann\nmachine (RBM), is introduced. The algorithm is applied for the spectral\nclassification in astronomy. RBM is a bipartite generative graphical model with\ntwo separate layers (one visible layer and one hidden layer), which can extract\nhigher level features to represent the original data. Despite generative, RBM\ncan be used for classification when modified with a free energy and a soft-max\nfunction. Before spectral classification, the original data is binarized\naccording to some rule. Then we resort to the binary RBM to classify\ncataclysmic variables (CVs) and non-CVs (one half of all the given data for\ntraining and the other half for testing). The experiment result shows\nstate-of-the-art accuracy of 100%, which indicates the efficiency of the binary\nRBM algorithm.\n",
        "published": "2013-05-03T10:20:02Z",
        "pdf_link": "http://arxiv.org/pdf/1305.0665v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.0698v1",
        "title": "Learning from Imprecise and Fuzzy Observations: Data Disambiguation\n  through Generalized Loss Minimization",
        "summary": "  Methods for analyzing or learning from \"fuzzy data\" have attracted increasing\nattention in recent years. In many cases, however, existing methods (for\nprecise, non-fuzzy data) are extended to the fuzzy case in an ad-hoc manner,\nand without carefully considering the interpretation of a fuzzy set when being\nused for modeling data. Distinguishing between an ontic and an epistemic\ninterpretation of fuzzy set-valued data, and focusing on the latter, we argue\nthat a \"fuzzification\" of learning algorithms based on an application of the\ngeneric extension principle is not appropriate. In fact, the extension\nprinciple fails to properly exploit the inductive bias underlying statistical\nand machine learning methods, although this bias, at least in principle, offers\na means for \"disambiguating\" the fuzzy data. Alternatively, we therefore\npropose a method which is based on the generalization of loss functions in\nempirical risk minimization, and which performs model identification and data\ndisambiguation simultaneously. Elaborating on the fuzzification of specific\ntypes of losses, we establish connections to well-known loss functions in\nregression and classification. We compare our approach with related methods and\nillustrate its use in logistic regression for binary classification.\n",
        "published": "2013-05-03T13:26:24Z",
        "pdf_link": "http://arxiv.org/pdf/1305.0698v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.1019v2",
        "title": "Simple Deep Random Model Ensemble",
        "summary": "  Representation learning and unsupervised learning are two central topics of\nmachine learning and signal processing. Deep learning is one of the most\neffective unsupervised representation learning approach. The main contributions\nof this paper to the topics are as follows. (i) We propose to view the\nrepresentative deep learning approaches as special cases of the knowledge reuse\nframework of clustering ensemble. (ii) We propose to view sparse coding when\nused as a feature encoder as the consensus function of clustering ensemble, and\nview dictionary learning as the training process of the base clusterings of\nclustering ensemble. (ii) Based on the above two views, we propose a very\nsimple deep learning algorithm, named deep random model ensemble (DRME). It is\na stack of random model ensembles. Each random model ensemble is a special\nk-means ensemble that discards the expectation-maximization optimization of\neach base k-means but only preserves the default initialization method of the\nbase k-means. (iv) We propose to select the most powerful representation among\nthe layers by applying DRME to clustering where the single-linkage is used as\nthe clustering algorithm. Moreover, the DRME based clustering can also detect\nthe number of the natural clusters accurately. Extensive experimental\ncomparisons with 5 representation learning methods on 19 benchmark data sets\ndemonstrate the effectiveness of DRME.\n",
        "published": "2013-05-05T14:58:15Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1019v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.1359v1",
        "title": "A Differential Equations Approach to Optimizing Regret Trade-offs",
        "summary": "  We consider the classical question of predicting binary sequences and study\nthe {\\em optimal} algorithms for obtaining the best possible regret and payoff\nfunctions for this problem. The question turns out to be also equivalent to the\nproblem of optimal trade-offs between the regrets of two experts in an \"experts\nproblem\", studied before by \\cite{kearns-regret}. While, say, a regret of\n$\\Theta(\\sqrt{T})$ is known, we argue that it important to ask what is the\nprovably optimal algorithm for this problem --- both because it leads to\nnatural algorithms, as well as because regret is in fact often comparable in\nmagnitude to the final payoffs and hence is a non-negligible term.\n  In the basic setting, the result essentially follows from a classical result\nof Cover from '65. Here instead, we focus on another standard setting, of\ntime-discounted payoffs, where the final \"stopping time\" is not specified. We\nexhibit an explicit characterization of the optimal regret for this setting.\n  To obtain our main result, we show that the optimal payoff functions have to\nsatisfy the Hermite differential equation, and hence are given by the solutions\nto this equation. It turns out that characterization of the payoff function is\nqualitatively different from the classical (non-discounted) setting, and,\nnamely, there's essentially a unique optimal solution.\n",
        "published": "2013-05-07T00:02:51Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1359v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.1363v2",
        "title": "One-Pass AUC Optimization",
        "summary": "  AUC is an important performance measure and many algorithms have been devoted\nto AUC optimization, mostly by minimizing a surrogate convex loss on a training\ndata set. In this work, we focus on one-pass AUC optimization that requires\nonly going through the training data once without storing the entire training\ndataset, where conventional online learning algorithms cannot be applied\ndirectly because AUC is measured by a sum of losses defined over pairs of\ninstances from different classes. We develop a regression-based algorithm which\nonly needs to maintain the first and second order statistics of training data\nin memory, resulting a storage requirement independent from the size of\ntraining data. To efficiently handle high dimensional data, we develop a\nrandomized algorithm that approximates the covariance matrices by low rank\nmatrices. We verify, both theoretically and empirically, the effectiveness of\nthe proposed algorithm.\n",
        "published": "2013-05-07T00:30:32Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1363v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.1707v1",
        "title": "Class Imbalance Problem in Data Mining Review",
        "summary": "  In last few years there are major changes and evolution has been done on\nclassification of data. As the application area of technology is increases the\nsize of data also increases. Classification of data becomes difficult because\nof unbounded size and imbalance nature of data. Class imbalance problem become\ngreatest issue in data mining. Imbalance problem occur where one of the two\nclasses having more sample than other classes. The most of algorithm are more\nfocusing on classification of major sample while ignoring or misclassifying\nminority sample. The minority samples are those that rarely occur but very\nimportant. There are different methods available for classification of\nimbalance data set which is divided into three main categories, the algorithmic\napproach, data-preprocessing approach and feature selection approach. Each of\nthis technique has their own advantages and disadvantages. In this paper\nsystematic study of each approach is define which gives the right direction for\nresearch in class imbalance problem.\n",
        "published": "2013-05-08T03:39:17Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1707v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.2452v1",
        "title": "Stochastic Collapsed Variational Bayesian Inference for Latent Dirichlet\n  Allocation",
        "summary": "  In the internet era there has been an explosion in the amount of digital text\ninformation available, leading to difficulties of scale for traditional\ninference algorithms for topic models. Recent advances in stochastic\nvariational inference algorithms for latent Dirichlet allocation (LDA) have\nmade it feasible to learn topic models on large-scale corpora, but these\nmethods do not currently take full advantage of the collapsed representation of\nthe model. We propose a stochastic algorithm for collapsed variational Bayesian\ninference for LDA, which is simpler and more efficient than the state of the\nart method. We show connections between collapsed variational Bayesian\ninference and MAP estimation for LDA, and leverage these connections to prove\nconvergence properties of the proposed algorithm. In experiments on large-scale\ntext corpora, the algorithm was found to converge faster and often to a better\nsolution than the previous method. Human-subject experiments also demonstrated\nthat the method can learn coherent topics in seconds on small corpora,\nfacilitating the use of topic models in interactive document analysis software.\n",
        "published": "2013-05-10T23:06:47Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2452v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.2732v1",
        "title": "An efficient algorithm for learning with semi-bandit feedback",
        "summary": "  We consider the problem of online combinatorial optimization under\nsemi-bandit feedback. The goal of the learner is to sequentially select its\nactions from a combinatorial decision set so as to minimize its cumulative\nloss. We propose a learning algorithm for this problem based on combining the\nFollow-the-Perturbed-Leader (FPL) prediction method with a novel loss\nestimation procedure called Geometric Resampling (GR). Contrary to previous\nsolutions, the resulting algorithm can be efficiently implemented for any\ndecision set where efficient offline combinatorial optimization is possible at\nall. Assuming that the elements of the decision set can be described with\nd-dimensional binary vectors with at most m non-zero entries, we show that the\nexpected regret of our algorithm after T rounds is O(m sqrt(dT log d)). As a\nside result, we also improve the best known regret bounds for FPL in the full\ninformation setting to O(m^(3/2) sqrt(T log d)), gaining a factor of sqrt(d/m)\nover previous bounds for this algorithm.\n",
        "published": "2013-05-13T10:39:47Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2732v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.2982v1",
        "title": "Estimating or Propagating Gradients Through Stochastic Neurons",
        "summary": "  Stochastic neurons can be useful for a number of reasons in deep learning\nmodels, but in many cases they pose a challenging problem: how to estimate the\ngradient of a loss function with respect to the input of such stochastic\nneurons, i.e., can we \"back-propagate\" through these stochastic neurons? We\nexamine this question, existing approaches, and present two novel families of\nsolutions, applicable in different settings. In particular, it is demonstrated\nthat a simple biologically plausible formula gives rise to an an unbiased (but\nnoisy) estimator of the gradient with respect to a binary stochastic neuron\nfiring probability. Unlike other estimators which view the noise as a small\nperturbation in order to estimate gradients by finite differences, this\nestimator is unbiased even without assuming that the stochastic perturbation is\nsmall. This estimator is also interesting because it can be applied in very\ngeneral settings which do not allow gradient back-propagation, including the\nestimation of the gradient with respect to future rewards, as required in\nreinforcement learning setups. We also propose an approach to approximating\nthis unbiased but high-variance estimator by learning to predict it using a\nbiased estimator. The second approach we propose assumes that an estimator of\nthe gradient can be back-propagated and it provides an unbiased estimator of\nthe gradient, but can only work with non-linearities unlike the hard threshold,\nbut like the rectifier, that are not flat for all of their range. This is\nsimilar to traditional sigmoidal units but has the advantage that for many\ninputs, a hard decision (e.g., a 0 output) can be produced, which would be\nconvenient for conditional computation and achieving sparse representations and\nsparse gradients.\n",
        "published": "2013-05-14T00:29:42Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2982v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.4076v5",
        "title": "Contractive De-noising Auto-encoder",
        "summary": "  Auto-encoder is a special kind of neural network based on reconstruction.\nDe-noising auto-encoder (DAE) is an improved auto-encoder which is robust to\nthe input by corrupting the original data first and then reconstructing the\noriginal input by minimizing the reconstruction error function. And contractive\nauto-encoder (CAE) is another kind of improved auto-encoder to learn robust\nfeature by introducing the Frobenius norm of the Jacobean matrix of the learned\nfeature with respect to the original input. In this paper, we combine\nde-noising auto-encoder and contractive auto- encoder, and propose another\nimproved auto-encoder, contractive de-noising auto- encoder (CDAE), which is\nrobust to both the original input and the learned feature. We stack CDAE to\nextract more abstract features and apply SVM for classification. The experiment\nresult on benchmark dataset MNIST shows that our proposed CDAE performed better\nthan both DAE and CAE, proving the effective of our method.\n",
        "published": "2013-05-17T13:42:49Z",
        "pdf_link": "http://arxiv.org/pdf/1305.4076v5"
    },
    {
        "id": "http://arxiv.org/abs/1305.4345v1",
        "title": "Ensembles of Classifiers based on Dimensionality Reduction",
        "summary": "  We present a novel approach for the construction of ensemble classifiers\nbased on dimensionality reduction. Dimensionality reduction methods represent\ndatasets using a small number of attributes while preserving the information\nconveyed by the original dataset. The ensemble members are trained based on\ndimension-reduced versions of the training set. These versions are obtained by\napplying dimensionality reduction to the original training set using different\nvalues of the input parameters. This construction meets both the diversity and\naccuracy criteria which are required to construct an ensemble classifier where\nthe former criterion is obtained by the various input parameter values and the\nlatter is achieved due to the decorrelation and noise reduction properties of\ndimensionality reduction. In order to classify a test sample, it is first\nembedded into the dimension reduced space of each individual classifier by\nusing an out-of-sample extension algorithm. Each classifier is then applied to\nthe embedded sample and the classification is obtained via a voting scheme. We\npresent three variations of the proposed approach based on the Random\nProjections, the Diffusion Maps and the Random Subspaces dimensionality\nreduction algorithms. We also present a multi-strategy ensemble which combines\nAdaBoost and Diffusion Maps. A comparison is made with the Bagging, AdaBoost,\nRotation Forest ensemble classifiers and also with the base classifier which\ndoes not incorporate dimensionality reduction. Our experiments used seventeen\nbenchmark datasets from the UCI repository. The results obtained by the\nproposed algorithms were superior in many cases to other algorithms.\n",
        "published": "2013-05-19T10:24:06Z",
        "pdf_link": "http://arxiv.org/pdf/1305.4345v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.6663v4",
        "title": "Generalized Denoising Auto-Encoders as Generative Models",
        "summary": "  Recent work has shown how denoising and contractive autoencoders implicitly\ncapture the structure of the data-generating density, in the case where the\ncorruption noise is Gaussian, the reconstruction error is the squared error,\nand the data is continuous-valued. This has led to various proposals for\nsampling from this implicitly learned density function, using Langevin and\nMetropolis-Hastings MCMC. However, it remained unclear how to connect the\ntraining procedure of regularized auto-encoders to the implicit estimation of\nthe underlying data-generating distribution when the data are discrete, or\nusing other forms of corruption process and reconstruction errors. Another\nissue is the mathematical justification which is only valid in the limit of\nsmall corruption noise. We propose here a different attack on the problem,\nwhich deals with all these issues: arbitrary (but noisy enough) corruption,\narbitrary reconstruction loss (seen as a log-likelihood), handling both\ndiscrete and continuous-valued variables, and removing the bias due to\nnon-infinitesimal corruption noise (or non-infinitesimal contractive penalty).\n",
        "published": "2013-05-29T00:25:54Z",
        "pdf_link": "http://arxiv.org/pdf/1305.6663v4"
    },
    {
        "id": "http://arxiv.org/abs/1305.7111v1",
        "title": "Test cost and misclassification cost trade-off using reframing",
        "summary": "  Many solutions to cost-sensitive classification (and regression) rely on some\nor all of the following assumptions: we have complete knowledge about the cost\ncontext at training time, we can easily re-train whenever the cost context\nchanges, and we have technique-specific methods (such as cost-sensitive\ndecision trees) that can take advantage of that information. In this paper we\naddress the problem of selecting models and minimising joint cost (integrating\nboth misclassification cost and test costs) without any of the above\nassumptions. We introduce methods and plots (such as the so-called JROC plots)\nthat can work with any off-the-shelf predictive technique, including ensembles,\nsuch that we reframe the model to use the appropriate subset of attributes (the\nfeature configuration) during deployment time. In other words, models are\ntrained with the available attributes (once and for all) and then deployed by\nsetting missing values on the attributes that are deemed ineffective for\nreducing the joint cost. As the number of feature configuration combinations\ngrows exponentially with the number of features we introduce quadratic methods\nthat are able to approximate the optimal configuration and model choices, as\nshown by the experimental results.\n",
        "published": "2013-05-30T13:52:32Z",
        "pdf_link": "http://arxiv.org/pdf/1305.7111v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.0125v1",
        "title": "Understanding ACT-R - an Outsider's Perspective",
        "summary": "  The ACT-R theory of cognition developed by John Anderson and colleagues\nendeavors to explain how humans recall chunks of information and how they solve\nproblems. ACT-R also serves as a theoretical basis for \"cognitive tutors\",\ni.e., automatic tutoring systems that help students learn mathematics, computer\nprogramming, and other subjects. The official ACT-R definition is distributed\nacross a large body of literature spanning many articles and monographs, and\nhence it is difficult for an \"outsider\" to learn the most important aspects of\nthe theory. This paper aims to provide a tutorial to the core components of the\nACT-R theory.\n",
        "published": "2013-06-01T15:48:58Z",
        "pdf_link": "http://arxiv.org/pdf/1306.0125v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.0237v3",
        "title": "Guided Random Forest in the RRF Package",
        "summary": "  Random Forest (RF) is a powerful supervised learner and has been popularly\nused in many applications such as bioinformatics.\n  In this work we propose the guided random forest (GRF) for feature selection.\nSimilar to a feature selection method called guided regularized random forest\n(GRRF), GRF is built using the importance scores from an ordinary RF. However,\nthe trees in GRRF are built sequentially, are highly correlated and do not\nallow for parallel computing, while the trees in GRF are built independently\nand can be implemented in parallel. Experiments on 10 high-dimensional gene\ndata sets show that, with a fixed parameter value (without tuning the\nparameter), RF applied to features selected by GRF outperforms RF applied to\nall features on 9 data sets and 7 of them have significant differences at the\n0.05 level. Therefore, both accuracy and interpretability are significantly\nimproved. GRF selects more features than GRRF, however, leads to better\nclassification accuracy. Note in this work the guided random forest is guided\nby the importance scores from an ordinary random forest, however, it can also\nbe guided by other methods such as human insights (by specifying $\\lambda_i$).\nGRF can be used in \"RRF\" v1.4 (and later versions), a package that also\nincludes the regularized random forest methods.\n",
        "published": "2013-06-02T18:30:45Z",
        "pdf_link": "http://arxiv.org/pdf/1306.0237v3"
    },
    {
        "id": "http://arxiv.org/abs/1306.1091v5",
        "title": "Deep Generative Stochastic Networks Trainable by Backprop",
        "summary": "  We introduce a novel training principle for probabilistic models that is an\nalternative to maximum likelihood. The proposed Generative Stochastic Networks\n(GSN) framework is based on learning the transition operator of a Markov chain\nwhose stationary distribution estimates the data distribution. The transition\ndistribution of the Markov chain is conditional on the previous state,\ngenerally involving a small move, so this conditional distribution has fewer\ndominant modes, being unimodal in the limit of small moves. Thus, it is easier\nto learn because it is easier to approximate its partition function, more like\nlearning to perform supervised function approximation, with gradients that can\nbe obtained by backprop. We provide theorems that generalize recent work on the\nprobabilistic interpretation of denoising autoencoders and obtain along the way\nan interesting justification for dependency networks and generalized\npseudolikelihood, along with a definition of an appropriate joint distribution\nand sampling mechanism even when the conditionals are not consistent. GSNs can\nbe used with missing inputs and can be used to sample subsets of variables\ngiven the rest. We validate these theoretical results with experiments on two\nimage datasets using an architecture that mimics the Deep Boltzmann Machine\nGibbs sampler but allows training to proceed with simple backprop, without the\nneed for layerwise pretraining.\n",
        "published": "2013-06-05T13:01:14Z",
        "pdf_link": "http://arxiv.org/pdf/1306.1091v5"
    },
    {
        "id": "http://arxiv.org/abs/1306.1326v1",
        "title": "Performance analysis of unsupervised feature selection methods",
        "summary": "  Feature selection (FS) is a process which attempts to select more informative\nfeatures. In some cases, too many redundant or irrelevant features may\noverpower main features for classification. Feature selection can remedy this\nproblem and therefore improve the prediction accuracy and reduce the\ncomputational overhead of classification algorithms. The main aim of feature\nselection is to determine a minimal feature subset from a problem domain while\nretaining a suitably high accuracy in representing the original features. In\nthis paper, Principal Component Analysis (PCA), Rough PCA, Unsupervised Quick\nReduct (USQR) algorithm and Empirical Distribution Ranking (EDR) approaches are\napplied to discover discriminative features that will be the most adequate ones\nfor classification. Efficiency of the approaches is evaluated using standard\nclassification metrics.\n",
        "published": "2013-06-06T07:42:33Z",
        "pdf_link": "http://arxiv.org/pdf/1306.1326v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.2347v4",
        "title": "Auditing: Active Learning with Outcome-Dependent Query Costs",
        "summary": "  We propose a learning setting in which unlabeled data is free, and the cost\nof a label depends on its value, which is not known in advance. We study binary\nclassification in an extreme case, where the algorithm only pays for negative\nlabels. Our motivation are applications such as fraud detection, in which\ninvestigating an honest transaction should be avoided if possible. We term the\nsetting auditing, and consider the auditing complexity of an algorithm: the\nnumber of negative labels the algorithm requires in order to learn a hypothesis\nwith low relative error. We design auditing algorithms for simple hypothesis\nclasses (thresholds and rectangles), and show that with these algorithms, the\nauditing complexity can be significantly lower than the active label\ncomplexity. We also discuss a general competitive approach for auditing and\npossible modifications to the framework.\n",
        "published": "2013-06-10T20:18:48Z",
        "pdf_link": "http://arxiv.org/pdf/1306.2347v4"
    },
    {
        "id": "http://arxiv.org/abs/1306.3108v2",
        "title": "Guaranteed Classification via Regularized Similarity Learning",
        "summary": "  Learning an appropriate (dis)similarity function from the available data is a\ncentral problem in machine learning, since the success of many machine learning\nalgorithms critically depends on the choice of a similarity function to compare\nexamples. Despite many approaches for similarity metric learning have been\nproposed, there is little theoretical study on the links between similarity\nmet- ric learning and the classification performance of the result classifier.\nIn this paper, we propose a regularized similarity learning formulation\nassociated with general matrix-norms, and establish their generalization\nbounds. We show that the generalization error of the resulting linear separator\ncan be bounded by the derived generalization bound of similarity learning. This\nshows that a good gen- eralization of the learnt similarity function guarantees\na good classification of the resulting linear classifier. Our results extend\nand improve those obtained by Bellet at al. [3]. Due to the techniques\ndependent on the notion of uniform stability [6], the bound obtained there\nholds true only for the Frobenius matrix- norm regularization. Our techniques\nusing the Rademacher complexity [5] and its related Khinchin-type inequality\nenable us to establish bounds for regularized similarity learning formulations\nassociated with general matrix-norms including sparse L 1 -norm and mixed\n(2,1)-norm.\n",
        "published": "2013-06-13T13:47:51Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3108v2"
    },
    {
        "id": "http://arxiv.org/abs/1306.3895v2",
        "title": "On-line PCA with Optimal Regrets",
        "summary": "  We carefully investigate the on-line version of PCA, where in each trial a\nlearning algorithm plays a k-dimensional subspace, and suffers the compression\nloss on the next instance when projected into the chosen subspace. In this\nsetting, we analyze two popular on-line algorithms, Gradient Descent (GD) and\nExponentiated Gradient (EG). We show that both algorithms are essentially\noptimal in the worst-case. This comes as a surprise, since EG is known to\nperform sub-optimally when the instances are sparse. This different behavior of\nEG for PCA is mainly related to the non-negativity of the loss in this case,\nwhich makes the PCA setting qualitatively different from other settings studied\nin the literature. Furthermore, we show that when considering regret bounds as\nfunction of a loss budget, EG remains optimal and strictly outperforms GD.\nNext, we study the extension of the PCA setting, in which the Nature is allowed\nto play with dense instances, which are positive matrices with bounded largest\neigenvalue. Again we can show that EG is optimal and strictly better than GD in\nthis setting.\n",
        "published": "2013-06-17T15:29:00Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3895v2"
    },
    {
        "id": "http://arxiv.org/abs/1306.4653v4",
        "title": "Multiarmed Bandits With Limited Expert Advice",
        "summary": "  We solve the COLT 2013 open problem of \\citet{SCB} on minimizing regret in\nthe setting of advice-efficient multiarmed bandits with expert advice. We give\nan algorithm for the setting of K arms and N experts out of which we are\nallowed to query and use only M experts' advices in each round, which has a\nregret bound of \\tilde{O}\\bigP{\\sqrt{\\frac{\\min\\{K, M\\} N}{M} T}} after T\nrounds. We also prove that any algorithm for this problem must have expected\nregret at least \\tilde{\\Omega}\\bigP{\\sqrt{\\frac{\\min\\{K, M\\} N}{M}T}}, thus\nshowing that our upper bound is nearly tight.\n",
        "published": "2013-06-19T19:25:51Z",
        "pdf_link": "http://arxiv.org/pdf/1306.4653v4"
    },
    {
        "id": "http://arxiv.org/abs/1306.4947v2",
        "title": "Machine Teaching for Bayesian Learners in the Exponential Family",
        "summary": "  What if there is a teacher who knows the learning goal and wants to design\ngood training data for a machine learner? We propose an optimal teaching\nframework aimed at learners who employ Bayesian models. Our framework is\nexpressed as an optimization problem over teaching examples that balance the\nfuture loss of the learner and the effort of the teacher. This optimization\nproblem is in general hard. In the case where the learner employs conjugate\nexponential family models, we present an approximate algorithm for finding the\noptimal teaching set. Our algorithm optimizes the aggregate sufficient\nstatistics, then unpacks them into actual teaching examples. We give several\nexamples to illustrate our framework.\n",
        "published": "2013-06-20T18:04:24Z",
        "pdf_link": "http://arxiv.org/pdf/1306.4947v2"
    },
    {
        "id": "http://arxiv.org/abs/1306.5349v1",
        "title": "Song-based Classification techniques for Endangered Bird Conservation",
        "summary": "  The work presented in this paper is part of a global framework which long\nterm goal is to design a wireless sensor network able to support the\nobservation of a population of endangered birds. We present the first stage for\nwhich we have conducted a knowledge discovery approach on a sample of\nacoustical data. We use MFCC features extracted from bird songs and we exploit\ntwo knowledge discovery techniques. One that relies on clustering-based\napproaches, that highlights the homogeneity in the songs of the species. The\nother, based on predictive modeling, that demonstrates the good performances of\nvarious machine learning techniques for the identification process. The\nknowledge elicited provides promising results to consider a widespread study\nand to elicit guidelines for designing a first version of the automatic\napproach for data collection based on acoustic sensors.\n",
        "published": "2013-06-22T19:32:05Z",
        "pdf_link": "http://arxiv.org/pdf/1306.5349v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.5487v1",
        "title": "Model Reframing by Feature Context Change",
        "summary": "  The feature space (including both input and output variables) characterises a\ndata mining problem. In predictive (supervised) problems, the quality and\navailability of features determines the predictability of the dependent\nvariable, and the performance of data mining models in terms of\nmisclassification or regression error. Good features, however, are usually\ndifficult to obtain. It is usual that many instances come with missing values,\neither because the actual value for a given attribute was not available or\nbecause it was too expensive. This is usually interpreted as a utility or\ncost-sensitive learning dilemma, in this case between misclassification (or\nregression error) costs and attribute tests costs. Both misclassification cost\n(MC) and test cost (TC) can be integrated into a single measure, known as joint\ncost (JC). We introduce methods and plots (such as the so-called JROC plots)\nthat can work with any of-the-shelf predictive technique, including ensembles,\nsuch that we re-frame the model to use the appropriate subset of attributes\n(the feature configuration) during deployment time. In other words, models are\ntrained with the available attributes (once and for all) and then deployed by\nsetting missing values on the attributes that are deemed ineffective for\nreducing the joint cost. As the number of feature configuration combinations\ngrows exponentially with the number of features we introduce quadratic methods\nthat are able to approximate the optimal configuration and model choices, as\nshown by the experimental results.\n",
        "published": "2013-06-23T23:36:40Z",
        "pdf_link": "http://arxiv.org/pdf/1306.5487v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.2893v2",
        "title": "Multiclass learnability and the ERM principle",
        "summary": "  We study the sample complexity of multiclass prediction in several learning\nsettings. For the PAC setting our analysis reveals a surprising phenomenon: In\nsharp contrast to binary classification, we show that there exist multiclass\nhypothesis classes for which some Empirical Risk Minimizers (ERM learners) have\nlower sample complexity than others. Furthermore, there are classes that are\nlearnable by some ERM learners, while other ERM learners will fail to learn\nthem. We propose a principle for designing good ERM learners, and use this\nprinciple to prove tight bounds on the sample complexity of learning {\\em\nsymmetric} multiclass hypothesis classes---classes that are invariant under\npermutations of label names. We further provide a characterization of mistake\nand regret bounds for multiclass learning in the online setting and the bandit\nsetting, using new generalizations of Littlestone's dimension.\n",
        "published": "2013-08-13T15:15:37Z",
        "pdf_link": "http://arxiv.org/pdf/1308.2893v2"
    },
    {
        "id": "http://arxiv.org/abs/1308.3432v1",
        "title": "Estimating or Propagating Gradients Through Stochastic Neurons for\n  Conditional Computation",
        "summary": "  Stochastic neurons and hard non-linearities can be useful for a number of\nreasons in deep learning models, but in many cases they pose a challenging\nproblem: how to estimate the gradient of a loss function with respect to the\ninput of such stochastic or non-smooth neurons? I.e., can we \"back-propagate\"\nthrough these stochastic neurons? We examine this question, existing\napproaches, and compare four families of solutions, applicable in different\nsettings. One of them is the minimum variance unbiased gradient estimator for\nstochatic binary neurons (a special case of the REINFORCE algorithm). A second\napproach, introduced here, decomposes the operation of a binary stochastic\nneuron into a stochastic binary part and a smooth differentiable part, which\napproximates the expected effect of the pure stochatic binary neuron to first\norder. A third approach involves the injection of additive or multiplicative\nnoise in a computational graph that is otherwise differentiable. A fourth\napproach heuristically copies the gradient with respect to the stochastic\noutput directly as an estimator of the gradient with respect to the sigmoid\nargument (we call this the straight-through estimator). To explore a context\nwhere these estimators are useful, we consider a small-scale version of {\\em\nconditional computation}, where sparse stochastic units form a distributed\nrepresentation of gaters that can turn off in combinatorially many ways large\nchunks of the computation performed in the rest of the neural network. In this\ncase, it is important that the gating units produce an actual 0 most of the\ntime. The resulting sparsity can be potentially be exploited to greatly reduce\nthe computational cost of large deep networks for which conditional computation\nwould be useful.\n",
        "published": "2013-08-15T15:19:34Z",
        "pdf_link": "http://arxiv.org/pdf/1308.3432v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.3509v1",
        "title": "Stochastic Optimization for Machine Learning",
        "summary": "  It has been found that stochastic algorithms often find good solutions much\nmore rapidly than inherently-batch approaches. Indeed, a very useful rule of\nthumb is that often, when solving a machine learning problem, an iterative\ntechnique which relies on performing a very large number of\nrelatively-inexpensive updates will often outperform one which performs a\nsmaller number of much \"smarter\" but computationally-expensive updates.\n  In this thesis, we will consider the application of stochastic algorithms to\ntwo of the most important machine learning problems. Part i is concerned with\nthe supervised problem of binary classification using kernelized linear\nclassifiers, for which the data have labels belonging to exactly two classes\n(e.g. \"has cancer\" or \"doesn't have cancer\"), and the learning problem is to\nfind a linear classifier which is best at predicting the label. In Part ii, we\nwill consider the unsupervised problem of Principal Component Analysis, for\nwhich the learning task is to find the directions which contain most of the\nvariance of the data distribution.\n  Our goal is to present stochastic algorithms for both problems which are,\nabove all, practical--they work well on real-world data, in some cases better\nthan all known competing algorithms. A secondary, but still very important,\ngoal is to derive theoretical bounds on the performance of these algorithms\nwhich are at least competitive with, and often better than, those known for\nother approaches.\n",
        "published": "2013-08-15T20:59:32Z",
        "pdf_link": "http://arxiv.org/pdf/1308.3509v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.3541v2",
        "title": "Knapsack Constrained Contextual Submodular List Prediction with\n  Application to Multi-document Summarization",
        "summary": "  We study the problem of predicting a set or list of options under knapsack\nconstraint. The quality of such lists are evaluated by a submodular reward\nfunction that measures both quality and diversity. Similar to DAgger (Ross et\nal., 2010), by a reduction to online learning, we show how to adapt two\nsequence prediction models to imitate greedy maximization under knapsack\nconstraint problems: CONSEQOPT (Dey et al., 2012) and SCP (Ross et al., 2013).\nExperiments on extractive multi-document summarization show that our approach\noutperforms existing state-of-the-art methods.\n",
        "published": "2013-08-16T03:46:25Z",
        "pdf_link": "http://arxiv.org/pdf/1308.3541v2"
    },
    {
        "id": "http://arxiv.org/abs/1308.3750v1",
        "title": "Comment on \"robustness and regularization of support vector machines\" by\n  H. Xu, et al., (Journal of Machine Learning Research, vol. 10, pp. 1485-1510,\n  2009, arXiv:0803.3490)",
        "summary": "  This paper comments on the published work dealing with robustness and\nregularization of support vector machines (Journal of Machine Learning\nResearch, vol. 10, pp. 1485-1510, 2009) [arXiv:0803.3490] by H. Xu, etc. They\nproposed a theorem to show that it is possible to relate robustness in the\nfeature space and robustness in the sample space directly. In this paper, we\npropose a counter example that rejects their theorem.\n",
        "published": "2013-08-17T03:56:03Z",
        "pdf_link": "http://arxiv.org/pdf/1308.3750v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.4828v1",
        "title": "The Sample-Complexity of General Reinforcement Learning",
        "summary": "  We present a new algorithm for general reinforcement learning where the true\nenvironment is known to belong to a finite class of N arbitrary models. The\nalgorithm is shown to be near-optimal for all but O(N log^2 N) time-steps with\nhigh probability. Infinite classes are also considered where we show that\ncompactness is a key criterion for determining the existence of uniform\nsample-complexity bounds. A matching lower bound is given for the finite case.\n",
        "published": "2013-08-22T11:39:06Z",
        "pdf_link": "http://arxiv.org/pdf/1308.4828v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.5281v1",
        "title": "Ensemble of Distributed Learners for Online Classification of Dynamic\n  Data Streams",
        "summary": "  We present an efficient distributed online learning scheme to classify data\ncaptured from distributed, heterogeneous, and dynamic data sources. Our scheme\nconsists of multiple distributed local learners, that analyze different streams\nof data that are correlated to a common event that needs to be classified. Each\nlearner uses a local classifier to make a local prediction. The local\npredictions are then collected by each learner and combined using a weighted\nmajority rule to output the final prediction. We propose a novel online\nensemble learning algorithm to update the aggregation rule in order to adapt to\nthe underlying data dynamics. We rigorously determine a bound for the worst\ncase misclassification probability of our algorithm which depends on the\nmisclassification probabilities of the best static aggregation rule, and of the\nbest local classifier. Importantly, the worst case misclassification\nprobability of our algorithm tends asymptotically to 0 if the misclassification\nprobability of the best static aggregation rule or the misclassification\nprobability of the best local classifier tend to 0. Then we extend our\nalgorithm to address challenges specific to the distributed implementation and\nwe prove new bounds that apply to these settings. Finally, we test our scheme\nby performing an evaluation study on several data sets. When applied to data\nsets widely used by the literature dealing with dynamic data streams and\nconcept drift, our scheme exhibits performance gains ranging from 34% to 71%\nwith respect to state of the art solutions.\n",
        "published": "2013-08-24T02:33:11Z",
        "pdf_link": "http://arxiv.org/pdf/1308.5281v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.6324v2",
        "title": "Prediction of breast cancer recurrence using Classification Restricted\n  Boltzmann Machine with Dropping",
        "summary": "  In this paper, we apply Classification Restricted Boltzmann Machine\n(ClassRBM) to the problem of predicting breast cancer recurrence. According to\nthe Polish National Cancer Registry, in 2010 only, the breast cancer caused\nalmost 25% of all diagnosed cases of cancer in Poland. We propose how to use\nClassRBM for predicting breast cancer return and discovering relevant inputs\n(symptoms) in illness reappearance. Next, we outline a general probabilistic\nframework for learning Boltzmann machines with masks, which we refer to as\nDropping. The fashion of generating masks leads to different learning methods,\ni.e., DropOut, DropConnect. We propose a new method called DropPart which is a\ngeneralization of DropConnect. In DropPart the Beta distribution instead of\nBernoulli distribution in DropConnect is used. At the end, we carry out an\nexperiment using real-life dataset consisting of 949 cases, provided by the\nInstitute of Oncology Ljubljana.\n",
        "published": "2013-08-28T22:08:29Z",
        "pdf_link": "http://arxiv.org/pdf/1308.6324v2"
    },
    {
        "id": "http://arxiv.org/abs/1309.0489v3",
        "title": "Relative Comparison Kernel Learning with Auxiliary Kernels",
        "summary": "  In this work we consider the problem of learning a positive semidefinite\nkernel matrix from relative comparisons of the form: \"object A is more similar\nto object B than it is to C\", where comparisons are given by humans. Existing\nsolutions to this problem assume many comparisons are provided to learn a high\nquality kernel. However, this can be considered unrealistic for many real-world\ntasks since relative assessments require human input, which is often costly or\ndifficult to obtain. Because of this, only a limited number of these\ncomparisons may be provided. In this work, we explore methods for aiding the\nprocess of learning a kernel with the help of auxiliary kernels built from more\neasily extractable information regarding the relationships among objects. We\npropose a new kernel learning approach in which the target kernel is defined as\na conic combination of auxiliary kernels and a kernel whose elements are\nlearned directly. We formulate a convex optimization to solve for this target\nkernel that adds only minor overhead to methods that use no auxiliary\ninformation. Empirical results show that in the presence of few training\nrelative comparisons, our method can learn kernels that generalize to more\nout-of-sample comparisons than methods that do not utilize auxiliary\ninformation, as well as similar methods that learn metrics over objects.\n",
        "published": "2013-09-02T19:29:34Z",
        "pdf_link": "http://arxiv.org/pdf/1309.0489v3"
    },
    {
        "id": "http://arxiv.org/abs/1309.3697v1",
        "title": "Group Learning and Opinion Diffusion in a Broadcast Network",
        "summary": "  We analyze the following group learning problem in the context of opinion\ndiffusion: Consider a network with $M$ users, each facing $N$ options. In a\ndiscrete time setting, at each time step, each user chooses $K$ out of the $N$\noptions, and receive randomly generated rewards, whose statistics depend on the\noptions chosen as well as the user itself, and are unknown to the users. Each\nuser aims to maximize their expected total rewards over a certain time horizon\nthrough an online learning process, i.e., a sequence of exploration (sampling\nthe return of each option) and exploitation (selecting empirically good\noptions) steps.\n  Within this context we consider two group learning scenarios, (1) users with\nuniform preferences and (2) users with diverse preferences, and examine how a\nuser should construct its learning process to best extract information from\nother's decisions and experiences so as to maximize its own reward. Performance\nis measured in {\\em weak regret}, the difference between the user's total\nreward and the reward from a user-specific best single-action policy (i.e.,\nalways selecting the set of options generating the highest mean rewards for\nthis user). Within each scenario we also consider two cases: (i) when users\nexchange full information, meaning they share the actual rewards they obtained\nfrom their choices, and (ii) when users exchange limited information, e.g.,\nonly their choices but not rewards obtained from these choices.\n",
        "published": "2013-09-14T19:56:58Z",
        "pdf_link": "http://arxiv.org/pdf/1309.3697v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.3877v1",
        "title": "A Metric-learning based framework for Support Vector Machines and\n  Multiple Kernel Learning",
        "summary": "  Most metric learning algorithms, as well as Fisher's Discriminant Analysis\n(FDA), optimize some cost function of different measures of within-and\nbetween-class distances. On the other hand, Support Vector Machines(SVMs) and\nseveral Multiple Kernel Learning (MKL) algorithms are based on the SVM large\nmargin theory. Recently, SVMs have been analyzed from SVM and metric learning,\nand to develop new algorithms that build on the strengths of each. Inspired by\nthe metric learning interpretation of SVM, we develop here a new\nmetric-learning based SVM framework in which we incorporate metric learning\nconcepts within SVM. We extend the optimization problem of SVM to include some\nmeasure of the within-class distance and along the way we develop a new\nwithin-class distance measure which is appropriate for SVM. In addition, we\nadopt the same approach for MKL and show that it can be also formulated as a\nMahalanobis metric learning problem. Our end result is a number of SVM/MKL\nalgorithms that incorporate metric learning concepts. We experiment with them\non a set of benchmark datasets and observe important predictive performance\nimprovements.\n",
        "published": "2013-09-16T09:39:25Z",
        "pdf_link": "http://arxiv.org/pdf/1309.3877v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.5605v1",
        "title": "Stochastic Bound Majorization",
        "summary": "  Recently a majorization method for optimizing partition functions of\nlog-linear models was proposed alongside a novel quadratic variational\nupper-bound. In the batch setting, it outperformed state-of-the-art first- and\nsecond-order optimization methods on various learning tasks. We propose a\nstochastic version of this bound majorization method as well as a low-rank\nmodification for high-dimensional data-sets. The resulting stochastic\nsecond-order method outperforms stochastic gradient descent (across variations\nand various tunings) both in terms of the number of iterations and computation\ntime till convergence while finding a better quality parameter setting. The\nproposed method bridges first- and second-order stochastic optimization methods\nby maintaining a computational complexity that is linear in the data dimension\nand while exploiting second order information about the pseudo-global curvature\nof the objective function (as opposed to the local curvature in the Hessian).\n",
        "published": "2013-09-22T14:46:15Z",
        "pdf_link": "http://arxiv.org/pdf/1309.5605v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.5823v1",
        "title": "A Kernel Classification Framework for Metric Learning",
        "summary": "  Learning a distance metric from the given training samples plays a crucial\nrole in many machine learning tasks, and various models and optimization\nalgorithms have been proposed in the past decade. In this paper, we generalize\nseveral state-of-the-art metric learning methods, such as large margin nearest\nneighbor (LMNN) and information theoretic metric learning (ITML), into a kernel\nclassification framework. First, doublets and triplets are constructed from the\ntraining samples, and a family of degree-2 polynomial kernel functions are\nproposed for pairs of doublets or triplets. Then, a kernel classification\nframework is established, which can not only generalize many popular metric\nlearning methods such as LMNN and ITML, but also suggest new metric learning\nmethods, which can be efficiently implemented, interestingly, by using the\nstandard support vector machine (SVM) solvers. Two novel metric learning\nmethods, namely doublet-SVM and triplet-SVM, are then developed under the\nproposed framework. Experimental results show that doublet-SVM and triplet-SVM\nachieve competitive classification accuracies with state-of-the-art metric\nlearning methods such as ITML and LMNN but with significantly less training\ntime.\n",
        "published": "2013-09-23T14:39:48Z",
        "pdf_link": "http://arxiv.org/pdf/1309.5823v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.5904v1",
        "title": "Fenchel Duals for Drifting Adversaries",
        "summary": "  We describe a primal-dual framework for the design and analysis of online\nconvex optimization algorithms for {\\em drifting regret}. Existing literature\nshows (nearly) optimal drifting regret bounds only for the $\\ell_2$ and the\n$\\ell_1$-norms. Our work provides a connection between these algorithms and the\nOnline Mirror Descent ($\\omd$) updates; one key insight that results from our\nwork is that in order for these algorithms to succeed, it suffices to have the\ngradient of the regularizer to be bounded (in an appropriate norm). For\nsituations (like for the $\\ell_1$ norm) where the vanilla regularizer does not\nhave this property, we have to {\\em shift} the regularizer to ensure this.\nThus, this helps explain the various updates presented in \\cite{bansal10,\nbuchbinder12}. We also consider the online variant of the problem with\n1-lookahead, and with movement costs in the $\\ell_2$-norm. Our primal dual\napproach yields nearly optimal competitive ratios for this problem.\n",
        "published": "2013-09-23T18:14:02Z",
        "pdf_link": "http://arxiv.org/pdf/1309.5904v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.7598v1",
        "title": "On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori\n  Perturbations",
        "summary": "  In this paper we describe how MAP inference can be used to sample efficiently\nfrom Gibbs distributions. Specifically, we provide means for drawing either\napproximate or unbiased samples from Gibbs' distributions by introducing low\ndimensional perturbations and solving the corresponding MAP assignments. Our\napproach also leads to new ways to derive lower bounds on partition functions.\nWe demonstrate empirically that our method excels in the typical \"high signal -\nhigh coupling\" regime. The setting results in ragged energy landscapes that are\nchallenging for alternative approaches to sampling and/or lower bounds.\n",
        "published": "2013-09-29T13:48:52Z",
        "pdf_link": "http://arxiv.org/pdf/1309.7598v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.7750v2",
        "title": "An Extensive Experimental Study on the Cluster-based Reference Set\n  Reduction for speeding-up the k-NN Classifier",
        "summary": "  The k-Nearest Neighbor (k-NN) classification algorithm is one of the most\nwidely-used lazy classifiers because of its simplicity and ease of\nimplementation. It is considered to be an effective classifier and has many\napplications. However, its major drawback is that when sequential search is\nused to find the neighbors, it involves high computational cost. Speeding-up\nk-NN search is still an active research field. Hwang and Cho have recently\nproposed an adaptive cluster-based method for fast Nearest Neighbor searching.\nThe effectiveness of this method is based on the adjustment of three\nparameters. However, the authors evaluated their method by setting specific\nparameter values and using only one dataset. In this paper, an extensive\nexperimental study of this method is presented. The results, which are based on\nfive real life datasets, illustrate that if the parameters of the method are\ncarefully defined, one can achieve even better classification performance.\n",
        "published": "2013-09-30T08:24:14Z",
        "pdf_link": "http://arxiv.org/pdf/1309.7750v2"
    },
    {
        "id": "http://arxiv.org/abs/1309.7982v1",
        "title": "On the Feature Discovery for App Usage Prediction in Smartphones",
        "summary": "  With the increasing number of mobile Apps developed, they are now closely\nintegrated into daily life. In this paper, we develop a framework to predict\nmobile Apps that are most likely to be used regarding the current device status\nof a smartphone. Such an Apps usage prediction framework is a crucial\nprerequisite for fast App launching, intelligent user experience, and power\nmanagement of smartphones. By analyzing real App usage log data, we discover\ntwo kinds of features: The Explicit Feature (EF) from sensing readings of\nbuilt-in sensors, and the Implicit Feature (IF) from App usage relations. The\nIF feature is derived by constructing the proposed App Usage Graph (abbreviated\nas AUG) that models App usage transitions. In light of AUG, we are able to\ndiscover usage relations among Apps. Since users may have different usage\nbehaviors on their smartphones, we further propose one personalized feature\nselection algorithm. We explore minimum description length (MDL) from the\ntraining data and select those features which need less length to describe the\ntraining data. The personalized feature selection can successfully reduce the\nlog size and the prediction time. Finally, we adopt the kNN classification\nmodel to predict Apps usage. Note that through the features selected by the\nproposed personalized feature selection algorithm, we only need to keep these\nfeatures, which in turn reduces the prediction time and avoids the curse of\ndimensionality when using the kNN classifier. We conduct a comprehensive\nexperimental study based on a real mobile App usage dataset. The results\ndemonstrate the effectiveness of the proposed framework and show the predictive\ncapability for App usage prediction.\n",
        "published": "2013-09-26T14:44:10Z",
        "pdf_link": "http://arxiv.org/pdf/1309.7982v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.1177v2",
        "title": "Clustering on Multiple Incomplete Datasets via Collective Kernel\n  Learning",
        "summary": "  Multiple datasets containing different types of features may be available for\na given task. For instance, users' profiles can be used to group users for\nrecommendation systems. In addition, a model can also use users' historical\nbehaviors and credit history to group users. Each dataset contains different\ninformation and suffices for learning. A number of clustering algorithms on\nmultiple datasets were proposed during the past few years. These algorithms\nassume that at least one dataset is complete. So far as we know, all the\nprevious methods will not be applicable if there is no complete dataset\navailable. However, in reality, there are many situations where no dataset is\ncomplete. As in building a recommendation system, some new users may not have a\nprofile or historical behaviors, while some may not have a credit history.\nHence, no available dataset is complete. In order to solve this problem, we\npropose an approach called Collective Kernel Learning to infer hidden sample\nsimilarity from multiple incomplete datasets. The idea is to collectively\ncompletes the kernel matrices of incomplete datasets by optimizing the\nalignment of the shared instances of the datasets. Furthermore, a clustering\nalgorithm is proposed based on the kernel matrix. The experiments on both\nsynthetic and real datasets demonstrate the effectiveness of the proposed\napproach. The proposed clustering algorithm outperforms the comparison\nalgorithms by as much as two times in normalized mutual information.\n",
        "published": "2013-10-04T06:18:59Z",
        "pdf_link": "http://arxiv.org/pdf/1310.1177v2"
    },
    {
        "id": "http://arxiv.org/abs/1310.2049v1",
        "title": "Fast Multi-Instance Multi-Label Learning",
        "summary": "  In many real-world tasks, particularly those involving data objects with\ncomplicated semantics such as images and texts, one object can be represented\nby multiple instances and simultaneously be associated with multiple labels.\nSuch tasks can be formulated as multi-instance multi-label learning (MIML)\nproblems, and have been extensively studied during the past few years. Existing\nMIML approaches have been found useful in many applications; however, most of\nthem can only handle moderate-sized data. To efficiently handle large data\nsets, in this paper we propose the MIMLfast approach, which first constructs a\nlow-dimensional subspace shared by all labels, and then trains label specific\nlinear models to optimize approximated ranking loss via stochastic gradient\ndescent. Although the MIML problem is complicated, MIMLfast is able to achieve\nexcellent performance by exploiting label relations with shared space and\ndiscovering sub-concepts for complicated labels. Experiments show that the\nperformance of MIMLfast is highly competitive to state-of-the-art techniques,\nwhereas its time cost is much less; particularly, on a data set with 20K bags\nand 180K instances, MIMLfast is more than 100 times faster than existing MIML\napproaches. On a larger data set where none of existing approaches can return\nresults in 24 hours, MIMLfast takes only 12 minutes. Moreover, our approach is\nable to identify the most representative instance for each label, and thus\nproviding a chance to understand the relation between input patterns and output\nlabel semantics.\n",
        "published": "2013-10-08T09:03:28Z",
        "pdf_link": "http://arxiv.org/pdf/1310.2049v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.2646v1",
        "title": "Localized Iterative Methods for Interpolation in Graph Structured Data",
        "summary": "  In this paper, we present two localized graph filtering based methods for\ninterpolating graph signals defined on the vertices of arbitrary graphs from\nonly a partial set of samples. The first method is an extension of previous\nwork on reconstructing bandlimited graph signals from partially observed\nsamples. The iterative graph filtering approach very closely approximates the\nsolution proposed in the that work, while being computationally more efficient.\nAs an alternative, we propose a regularization based framework in which we\ndefine the cost of reconstruction to be a combination of smoothness of the\ngraph signal and the reconstruction error with respect to the known samples,\nand find solutions that minimize this cost. We provide both a closed form\nsolution and a computationally efficient iterative solution of the optimization\nproblem. The experimental results on the recommendation system datasets\ndemonstrate effectiveness of the proposed methods.\n",
        "published": "2013-10-09T22:24:28Z",
        "pdf_link": "http://arxiv.org/pdf/1310.2646v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.2959v2",
        "title": "Scaling Graph-based Semi Supervised Learning to Large Number of Labels\n  Using Count-Min Sketch",
        "summary": "  Graph-based Semi-supervised learning (SSL) algorithms have been successfully\nused in a large number of applications. These methods classify initially\nunlabeled nodes by propagating label information over the structure of graph\nstarting from seed nodes. Graph-based SSL algorithms usually scale linearly\nwith the number of distinct labels (m), and require O(m) space on each node.\nUnfortunately, there exist many applications of practical significance with\nvery large m over large graphs, demanding better space and time complexity. In\nthis paper, we propose MAD-SKETCH, a novel graph-based SSL algorithm which\ncompactly stores label distribution on each node using Count-min Sketch, a\nrandomized data structure. We present theoretical analysis showing that under\nmild conditions, MAD-SKETCH can reduce space complexity at each node from O(m)\nto O(log m), and achieve similar savings in time complexity as well. We support\nour analysis through experiments on multiple real world datasets. We observe\nthat MAD-SKETCH achieves similar performance as existing state-of-the-art\ngraph- based SSL algorithms, while requiring smaller memory footprint and at\nthe same time achieving up to 10x speedup. We find that MAD-SKETCH is able to\nscale to datasets with one million labels, which is beyond the scope of\nexisting graph- based SSL algorithms.\n",
        "published": "2013-10-10T20:30:06Z",
        "pdf_link": "http://arxiv.org/pdf/1310.2959v2"
    },
    {
        "id": "http://arxiv.org/abs/1310.4977v1",
        "title": "Learning Tensors in Reproducing Kernel Hilbert Spaces with Multilinear\n  Spectral Penalties",
        "summary": "  We present a general framework to learn functions in tensor product\nreproducing kernel Hilbert spaces (TP-RKHSs). The methodology is based on a\nnovel representer theorem suitable for existing as well as new spectral\npenalties for tensors. When the functions in the TP-RKHS are defined on the\nCartesian product of finite discrete sets, in particular, our main problem\nformulation admits as a special case existing tensor completion problems. Other\nspecial cases include transfer learning with multimodal side information and\nmultilinear multitask learning. For the latter case, our kernel-based view is\ninstrumental to derive nonlinear extensions of existing model classes. We give\na novel algorithm and show in experiments the usefulness of the proposed\nextensions.\n",
        "published": "2013-10-18T11:37:33Z",
        "pdf_link": "http://arxiv.org/pdf/1310.4977v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.5008v1",
        "title": "Thompson Sampling in Dynamic Systems for Contextual Bandit Problems",
        "summary": "  We consider the multiarm bandit problems in the timevarying dynamic system\nfor rich structural features. For the nonlinear dynamic model, we propose the\napproximate inference for the posterior distributions based on Laplace\nApproximation. For the context bandit problems, Thompson Sampling is adopted\nbased on the underlying posterior distributions of the parameters. More\nspecifically, we introduce the discount decays on the previous samples impact\nand analyze the different decay rates with the underlying sample dynamics.\nConsequently, the exploration and exploitation is adaptively tradeoff according\nto the dynamics in the system.\n",
        "published": "2013-10-17T04:17:20Z",
        "pdf_link": "http://arxiv.org/pdf/1310.5008v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.5249v1",
        "title": "Graph-Based Approaches to Clustering Network-Constrained Trajectory Data",
        "summary": "  Clustering trajectory data attracted considerable attention in the last few\nyears. Most of prior work assumed that moving objects can move freely in an\neuclidean space and did not consider the eventual presence of an underlying\nroad network and its influence on evaluating the similarity between\ntrajectories. In this paper, we present an approach to clustering such\nnetwork-constrained trajectory data. More precisely we aim at discovering\ngroups of road segments that are often travelled by the same trajectories. To\nachieve this end, we model the interactions between segments w.r.t. their\nsimilarity as a weighted graph to which we apply a community detection\nalgorithm to discover meaningful clusters. We showcase our proposition through\nexperimental results obtained on synthetic datasets.\n",
        "published": "2013-10-19T17:24:39Z",
        "pdf_link": "http://arxiv.org/pdf/1310.5249v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.5393v1",
        "title": "Multi-Task Regularization with Covariance Dictionary for Linear\n  Classifiers",
        "summary": "  In this paper we propose a multi-task linear classifier learning problem\ncalled D-SVM (Dictionary SVM). D-SVM uses a dictionary of parameter covariance\nshared by all tasks to do multi-task knowledge transfer among different tasks.\nWe formally define the learning problem of D-SVM and show two interpretations\nof this problem, from both the probabilistic and kernel perspectives. From the\nprobabilistic perspective, we show that our learning formulation is actually a\nMAP estimation on all optimization variables. We also show its equivalence to a\nmultiple kernel learning problem in which one is trying to find a re-weighting\nkernel for features from a dictionary of basis (despite the fact that only\nlinear classifiers are learned). Finally, we describe an alternative\noptimization scheme to minimize the objective function and present empirical\nstudies to valid our algorithm.\n",
        "published": "2013-10-21T01:06:56Z",
        "pdf_link": "http://arxiv.org/pdf/1310.5393v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.5665v3",
        "title": "Learning Theory and Algorithms for Revenue Optimization in Second-Price\n  Auctions with Reserve",
        "summary": "  Second-price auctions with reserve play a critical role for modern search\nengine and popular online sites since the revenue of these companies often\ndirectly de- pends on the outcome of such auctions. The choice of the reserve\nprice is the main mechanism through which the auction revenue can be influenced\nin these electronic markets. We cast the problem of selecting the reserve price\nto optimize revenue as a learning problem and present a full theoretical\nanalysis dealing with the complex properties of the corresponding loss\nfunction. We further give novel algorithms for solving this problem and report\nthe results of several experiments in both synthetic and real data\ndemonstrating their effectiveness.\n",
        "published": "2013-10-21T18:27:25Z",
        "pdf_link": "http://arxiv.org/pdf/1310.5665v3"
    },
    {
        "id": "http://arxiv.org/abs/1310.5796v4",
        "title": "Relative Deviation Learning Bounds and Generalization with Unbounded\n  Loss Functions",
        "summary": "  We present an extensive analysis of relative deviation bounds, including\ndetailed proofs of two-sided inequalities and their implications. We also give\ndetailed proofs of two-sided generalization bounds that hold in the general\ncase of unbounded loss functions, under the assumption that a moment of the\nloss is bounded. These bounds are useful in the analysis of importance\nweighting and other learning tasks such as unbounded regression.\n",
        "published": "2013-10-22T04:28:12Z",
        "pdf_link": "http://arxiv.org/pdf/1310.5796v4"
    },
    {
        "id": "http://arxiv.org/abs/1310.6007v3",
        "title": "Efficient Optimization for Sparse Gaussian Process Regression",
        "summary": "  We propose an efficient optimization algorithm for selecting a subset of\ntraining data to induce sparsity for Gaussian process regression. The algorithm\nestimates an inducing set and the hyperparameters using a single objective,\neither the marginal likelihood or a variational free energy. The space and time\ncomplexity are linear in training set size, and the algorithm can be applied to\nlarge regression problems on discrete or continuous domains. Empirical\nevaluation shows state-of-art performance in discrete cases and competitive\nresults in the continuous case.\n",
        "published": "2013-10-22T18:44:29Z",
        "pdf_link": "http://arxiv.org/pdf/1310.6007v3"
    },
    {
        "id": "http://arxiv.org/abs/1310.6304v2",
        "title": "Combining Structured and Unstructured Randomness in Large Scale PCA",
        "summary": "  Principal Component Analysis (PCA) is a ubiquitous tool with many\napplications in machine learning including feature construction, subspace\nembedding, and outlier detection. In this paper, we present an algorithm for\ncomputing the top principal components of a dataset with a large number of rows\n(examples) and columns (features). Our algorithm leverages both structured and\nunstructured random projections to retain good accuracy while being\ncomputationally efficient. We demonstrate the technique on the winning\nsubmission the KDD 2010 Cup.\n",
        "published": "2013-10-23T17:33:26Z",
        "pdf_link": "http://arxiv.org/pdf/1310.6304v2"
    },
    {
        "id": "http://arxiv.org/abs/1310.7795v1",
        "title": "An Unsupervised Feature Learning Approach to Improve Automatic Incident\n  Detection",
        "summary": "  Sophisticated automatic incident detection (AID) technology plays a key role\nin contemporary transportation systems. Though many papers were devoted to\nstudy incident classification algorithms, few study investigated how to enhance\nfeature representation of incidents to improve AID performance. In this paper,\nwe propose to use an unsupervised feature learning algorithm to generate higher\nlevel features to represent incidents. We used real incident data in the\nexperiments and found that effective feature mapping function can be learnt\nfrom the data crosses the test sites. With the enhanced features, detection\nrate (DR), false alarm rate (FAR) and mean time to detect (MTTD) are\nsignificantly improved in all of the three representative cases. This approach\nalso provides an alternative way to reduce the amount of labeled data, which is\nexpensive to obtain, required in training better incident classifiers since the\nfeature learning is unsupervised.\n",
        "published": "2013-10-29T13:18:41Z",
        "pdf_link": "http://arxiv.org/pdf/1310.7795v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.8418v4",
        "title": "An efficient distributed learning algorithm based on effective local\n  functional approximations",
        "summary": "  Scalable machine learning over big data is an important problem that is\nreceiving a lot of attention in recent years. On popular distributed\nenvironments such as Hadoop running on a cluster of commodity machines,\ncommunication costs are substantial and algorithms need to be designed suitably\nconsidering those costs. In this paper we give a novel approach to the\ndistributed training of linear classifiers (involving smooth losses and L2\nregularization) that is designed to reduce the total communication costs. At\neach iteration, the nodes minimize locally formed approximate objective\nfunctions; then the resulting minimizers are combined to form a descent\ndirection to move. Our approach gives a lot of freedom in the formation of the\napproximate objective function as well as in the choice of methods to solve\nthem. The method is shown to have $O(log(1/\\epsilon))$ time convergence. The\nmethod can be viewed as an iterative parameter mixing method. A special\ninstantiation yields a parallel stochastic gradient descent method with strong\nconvergence. When communication times between nodes are large, our method is\nmuch faster than the Terascale method (Agarwal et al., 2011), which is a state\nof the art distributed solver based on the statistical query model (Chuet al.,\n2006) that computes function and gradient values in a distributed fashion. We\nalso evaluate against other recent distributed methods and demonstrate superior\nperformance of our method.\n",
        "published": "2013-10-31T08:00:21Z",
        "pdf_link": "http://arxiv.org/pdf/1310.8418v4"
    },
    {
        "id": "http://arxiv.org/abs/1310.8428v2",
        "title": "Multilabel Classification through Random Graph Ensembles",
        "summary": "  We present new methods for multilabel classification, relying on ensemble\nlearning on a collection of random output graphs imposed on the multilabel and\na kernel-based structured output learner as the base classifier. For ensemble\nlearning, differences among the output graphs provide the required base\nclassifier diversity and lead to improved performance in the increasing size of\nthe ensemble. We study different methods of forming the ensemble prediction,\nincluding majority voting and two methods that perform inferences over the\ngraph structures before or after combining the base models into the ensemble.\nWe compare the methods against the state-of-the-art machine learning approaches\non a set of heterogeneous multilabel benchmark problems, including multilabel\nAdaBoost, convex multitask feature learning, as well as single target learning\napproaches represented by Bagging and SVM. In our experiments, the random graph\nensembles are very competitive and robust, ranking first or second on most of\nthe datasets. Overall, our results show that random graph ensembles are viable\nalternatives to flat multilabel and multitask learners.\n",
        "published": "2013-10-31T09:00:39Z",
        "pdf_link": "http://arxiv.org/pdf/1310.8428v2"
    },
    {
        "id": "http://arxiv.org/abs/1311.0202v1",
        "title": "A systematic comparison of supervised classifiers",
        "summary": "  Pattern recognition techniques have been employed in a myriad of industrial,\nmedical, commercial and academic applications. To tackle such a diversity of\ndata, many techniques have been devised. However, despite the long tradition of\npattern recognition research, there is no technique that yields the best\nclassification in all scenarios. Therefore, the consideration of as many as\npossible techniques presents itself as an fundamental practice in applications\naiming at high accuracy. Typical works comparing methods either emphasize the\nperformance of a given algorithm in validation tests or systematically compare\nvarious algorithms, assuming that the practical use of these methods is done by\nexperts. In many occasions, however, researchers have to deal with their\npractical classification tasks without an in-depth knowledge about the\nunderlying mechanisms behind parameters. Actually, the adequate choice of\nclassifiers and parameters alike in such practical circumstances constitutes a\nlong-standing problem and is the subject of the current paper. We carried out a\nstudy on the performance of nine well-known classifiers implemented by the Weka\nframework and compared the dependence of the accuracy with their configuration\nparameter configurations. The analysis of performance with default parameters\nrevealed that the k-nearest neighbors method exceeds by a large margin the\nother methods when high dimensional datasets are considered. When other\nconfiguration of parameters were allowed, we found that it is possible to\nimprove the quality of SVM in more than 20% even if parameters are set\nrandomly. Taken together, the investigation conducted in this paper suggests\nthat, apart from the SVM implementation, Weka's default configuration of\nparameters provides an performance close the one achieved with the optimal\nconfiguration.\n",
        "published": "2013-10-17T03:44:18Z",
        "pdf_link": "http://arxiv.org/pdf/1311.0202v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.0800v1",
        "title": "Distributed Exploration in Multi-Armed Bandits",
        "summary": "  We study exploration in Multi-Armed Bandits in a setting where $k$ players\ncollaborate in order to identify an $\\epsilon$-optimal arm. Our motivation\ncomes from recent employment of bandit algorithms in computationally intensive,\nlarge-scale applications. Our results demonstrate a non-trivial tradeoff\nbetween the number of arm pulls required by each of the players, and the amount\nof communication between them. In particular, our main result shows that by\nallowing the $k$ players to communicate only once, they are able to learn\n$\\sqrt{k}$ times faster than a single player. That is, distributing learning to\n$k$ players gives rise to a factor $\\sqrt{k}$ parallel speed-up. We complement\nthis result with a lower bound showing this is in general the best possible. On\nthe other extreme, we present an algorithm that achieves the ideal factor $k$\nspeed-up in learning performance, with communication only logarithmic in\n$1/\\epsilon$.\n",
        "published": "2013-11-04T18:19:25Z",
        "pdf_link": "http://arxiv.org/pdf/1311.0800v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.0914v1",
        "title": "A Divide-and-Conquer Solver for Kernel Support Vector Machines",
        "summary": "  The kernel support vector machine (SVM) is one of the most widely used\nclassification methods; however, the amount of computation required becomes the\nbottleneck when facing millions of samples. In this paper, we propose and\nanalyze a novel divide-and-conquer solver for kernel SVMs (DC-SVM). In the\ndivision step, we partition the kernel SVM problem into smaller subproblems by\nclustering the data, so that each subproblem can be solved independently and\nefficiently. We show theoretically that the support vectors identified by the\nsubproblem solution are likely to be support vectors of the entire kernel SVM\nproblem, provided that the problem is partitioned appropriately by kernel\nclustering. In the conquer step, the local solutions from the subproblems are\nused to initialize a global coordinate descent solver, which converges quickly\nas suggested by our analysis. By extending this idea, we develop a multilevel\nDivide-and-Conquer SVM algorithm with adaptive clustering and early prediction\nstrategy, which outperforms state-of-the-art methods in terms of training\nspeed, testing accuracy, and memory usage. As an example, on the covtype\ndataset with half-a-million samples, DC-SVM is 7 times faster than LIBSVM in\nobtaining the exact SVM solution (to within $10^{-6}$ relative error) which\nachieves 96.15% prediction accuracy. Moreover, with our proposed early\nprediction strategy, DC-SVM achieves about 96% accuracy in only 12 minutes,\nwhich is more than 100 times faster than LIBSVM.\n",
        "published": "2013-11-04T22:06:40Z",
        "pdf_link": "http://arxiv.org/pdf/1311.0914v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.0989v2",
        "title": "Large Margin Distribution Machine",
        "summary": "  Support vector machine (SVM) has been one of the most popular learning\nalgorithms, with the central idea of maximizing the minimum margin, i.e., the\nsmallest distance from the instances to the classification boundary. Recent\ntheoretical results, however, disclosed that maximizing the minimum margin does\nnot necessarily lead to better generalization performances, and instead, the\nmargin distribution has been proven to be more crucial. In this paper, we\npropose the Large margin Distribution Machine (LDM), which tries to achieve a\nbetter generalization performance by optimizing the margin distribution. We\ncharacterize the margin distribution by the first- and second-order statistics,\ni.e., the margin mean and variance. The LDM is a general learning approach\nwhich can be used in any place where SVM can be applied, and its superiority is\nverified both theoretically and empirically in this paper.\n",
        "published": "2013-11-05T08:46:26Z",
        "pdf_link": "http://arxiv.org/pdf/1311.0989v2"
    },
    {
        "id": "http://arxiv.org/abs/1311.1958v3",
        "title": "Constructing Time Series Shape Association Measures: Minkowski Distance\n  and Data Standardization",
        "summary": "  It is surprising that last two decades many works in time series data mining\nand clustering were concerned with measures of similarity of time series but\nnot with measures of association that can be used for measuring possible direct\nand inverse relationships between time series. Inverse relationships can exist\nbetween dynamics of prices and sell volumes, between growth patterns of\ncompetitive companies, between well production data in oilfields, between wind\nvelocity and air pollution concentration etc. The paper develops a theoretical\nbasis for analysis and construction of time series shape association measures.\nStarting from the axioms of time series shape association measures it studies\nthe methods of construction of measures satisfying these axioms. Several\ngeneral methods of construction of such measures suitable for measuring time\nseries shape similarity and shape association are proposed. Time series shape\nassociation measures based on Minkowski distance and data standardization\nmethods are considered. The cosine similarity and the Pearsons correlation\ncoefficient are obtained as particular cases of the proposed general methods\nthat can be used also for construction of new association measures in data\nanalysis.\n",
        "published": "2013-11-07T12:14:24Z",
        "pdf_link": "http://arxiv.org/pdf/1311.1958v3"
    },
    {
        "id": "http://arxiv.org/abs/1311.2097v3",
        "title": "Risk-sensitive Reinforcement Learning",
        "summary": "  We derive a family of risk-sensitive reinforcement learning methods for\nagents, who face sequential decision-making tasks in uncertain environments. By\napplying a utility function to the temporal difference (TD) error, nonlinear\ntransformations are effectively applied not only to the received rewards but\nalso to the true transition probabilities of the underlying Markov decision\nprocess. When appropriate utility functions are chosen, the agents' behaviors\nexpress key features of human behavior as predicted by prospect theory\n(Kahneman and Tversky, 1979), for example different risk-preferences for gains\nand losses as well as the shape of subjective probability curves. We derive a\nrisk-sensitive Q-learning algorithm, which is necessary for modeling human\nbehavior when transition probabilities are unknown, and prove its convergence.\nAs a proof of principle for the applicability of the new framework we apply it\nto quantify human behavior in a sequential investment task. We find, that the\nrisk-sensitive variant provides a significantly better fit to the behavioral\ndata and that it leads to an interpretation of the subject's responses which is\nindeed consistent with prospect theory. The analysis of simultaneously measured\nfMRI signals show a significant correlation of the risk-sensitive TD error with\nBOLD signal change in the ventral striatum. In addition we find a significant\ncorrelation of the risk-sensitive Q-values with neural activity in the\nstriatum, cingulate cortex and insula, which is not present if standard\nQ-values are used.\n",
        "published": "2013-11-08T22:25:26Z",
        "pdf_link": "http://arxiv.org/pdf/1311.2097v3"
    },
    {
        "id": "http://arxiv.org/abs/1311.2115v7",
        "title": "Fast large-scale optimization by unifying stochastic gradient and\n  quasi-Newton methods",
        "summary": "  We present an algorithm for minimizing a sum of functions that combines the\ncomputational efficiency of stochastic gradient descent (SGD) with the second\norder curvature information leveraged by quasi-Newton methods. We unify these\ndisparate approaches by maintaining an independent Hessian approximation for\neach contributing function in the sum. We maintain computational tractability\nand limit memory requirements even for high dimensional optimization problems\nby storing and manipulating these quadratic approximations in a shared, time\nevolving, low dimensional subspace. Each update step requires only a single\ncontributing function or minibatch evaluation (as in SGD), and each step is\nscaled using an approximate inverse Hessian and little to no adjustment of\nhyperparameters is required (as is typical for quasi-Newton methods). This\nalgorithm contrasts with earlier stochastic second order techniques that treat\nthe Hessian of each contributing function as a noisy approximation to the full\nHessian, rather than as a target for direct estimation. We experimentally\ndemonstrate improved convergence on seven diverse optimization problems. The\nalgorithm is released as open source Python and MATLAB packages.\n",
        "published": "2013-11-09T00:54:37Z",
        "pdf_link": "http://arxiv.org/pdf/1311.2115v7"
    },
    {
        "id": "http://arxiv.org/abs/1311.2137v1",
        "title": "A Structured Prediction Approach for Missing Value Imputation",
        "summary": "  Missing value imputation is an important practical problem. There is a large\nbody of work on it, but there does not exist any work that formulates the\nproblem in a structured output setting. Also, most applications have\nconstraints on the imputed data, for example on the distribution associated\nwith each variable. None of the existing imputation methods use these\nconstraints. In this paper we propose a structured output approach for missing\nvalue imputation that also incorporates domain constraints. We focus on large\nmargin models, but it is easy to extend the ideas to probabilistic models. We\ndeal with the intractable inference step in learning via a piecewise training\ntechnique that is simple, efficient, and effective. Comparison with existing\nstate-of-the-art and baseline imputation methods shows that our method gives\nsignificantly improved performance on the Hamming loss measure.\n",
        "published": "2013-11-09T06:15:15Z",
        "pdf_link": "http://arxiv.org/pdf/1311.2137v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.2139v1",
        "title": "Large Margin Semi-supervised Structured Output Learning",
        "summary": "  In structured output learning, obtaining labelled data for real-world\napplications is usually costly, while unlabelled examples are available in\nabundance. Semi-supervised structured classification has been developed to\nhandle large amounts of unlabelled structured data. In this work, we consider\nsemi-supervised structural SVMs with domain constraints. The optimization\nproblem, which in general is not convex, contains the loss terms associated\nwith the labelled and unlabelled examples along with the domain constraints. We\npropose a simple optimization approach, which alternates between solving a\nsupervised learning problem and a constraint matching problem. Solving the\nconstraint matching problem is difficult for structured prediction, and we\npropose an efficient and effective hill-climbing method to solve it. The\nalternating optimization is carried out within a deterministic annealing\nframework, which helps in effective constraint matching, and avoiding local\nminima which are not very useful. The algorithm is simple to implement and\nachieves comparable generalization performance on benchmark datasets.\n",
        "published": "2013-11-09T06:47:22Z",
        "pdf_link": "http://arxiv.org/pdf/1311.2139v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.2271v1",
        "title": "More data speeds up training time in learning halfspaces over sparse\n  vectors",
        "summary": "  The increased availability of data in recent years has led several authors to\nask whether it is possible to use data as a {\\em computational} resource. That\nis, if more data is available, beyond the sample complexity limit, is it\npossible to use the extra examples to speed up the computation time required to\nperform the learning task?\n  We give the first positive answer to this question for a {\\em natural\nsupervised learning problem} --- we consider agnostic PAC learning of\nhalfspaces over $3$-sparse vectors in $\\{-1,1,0\\}^n$. This class is\ninefficiently learnable using $O\\left(n/\\epsilon^2\\right)$ examples. Our main\ncontribution is a novel, non-cryptographic, methodology for establishing\ncomputational-statistical gaps, which allows us to show that, under a widely\nbelieved assumption that refuting random $\\mathrm{3CNF}$ formulas is hard, it\nis impossible to efficiently learn this class using only\n$O\\left(n/\\epsilon^2\\right)$ examples. We further show that under stronger\nhardness assumptions, even $O\\left(n^{1.499}/\\epsilon^2\\right)$ examples do not\nsuffice. On the other hand, we show a new algorithm that learns this class\nefficiently using $\\tilde{\\Omega}\\left(n^2/\\epsilon^2\\right)$ examples. This\nformally establishes the tradeoff between sample and computational complexity\nfor a natural supervised learning problem.\n",
        "published": "2013-11-10T13:28:19Z",
        "pdf_link": "http://arxiv.org/pdf/1311.2271v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.2276v1",
        "title": "A Quantitative Evaluation Framework for Missing Value Imputation\n  Algorithms",
        "summary": "  We consider the problem of quantitatively evaluating missing value imputation\nalgorithms. Given a dataset with missing values and a choice of several\nimputation algorithms to fill them in, there is currently no principled way to\nrank the algorithms using a quantitative metric. We develop a framework based\non treating imputation evaluation as a problem of comparing two distributions\nand show how it can be used to compute quantitative metrics. We present an\nefficient procedure for applying this framework to practical datasets,\ndemonstrate several metrics derived from the existing literature on comparing\ndistributions, and propose a new metric called Neighborhood-based Dissimilarity\nScore which is fast to compute and provides similar results. Results are shown\non several datasets, metrics, and imputations algorithms.\n",
        "published": "2013-11-10T14:17:47Z",
        "pdf_link": "http://arxiv.org/pdf/1311.2276v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.2334v4",
        "title": "Embed and Conquer: Scalable Embeddings for Kernel k-Means on MapReduce",
        "summary": "  The kernel $k$-means is an effective method for data clustering which extends\nthe commonly-used $k$-means algorithm to work on a similarity matrix over\ncomplex data structures. The kernel $k$-means algorithm is however\ncomputationally very complex as it requires the complete data matrix to be\ncalculated and stored. Further, the kernelized nature of the kernel $k$-means\nalgorithm hinders the parallelization of its computations on modern\ninfrastructures for distributed computing. In this paper, we are defining a\nfamily of kernel-based low-dimensional embeddings that allows for scaling\nkernel $k$-means on MapReduce via an efficient and unified parallelization\nstrategy. Afterwards, we propose two methods for low-dimensional embedding that\nadhere to our definition of the embedding family. Exploiting the proposed\nparallelization strategy, we present two scalable MapReduce algorithms for\nkernel $k$-means. We demonstrate the effectiveness and efficiency of the\nproposed algorithms through an empirical evaluation on benchmark data sets.\n",
        "published": "2013-11-11T02:37:16Z",
        "pdf_link": "http://arxiv.org/pdf/1311.2334v4"
    },
    {
        "id": "http://arxiv.org/abs/1311.2378v1",
        "title": "An Empirical Evaluation of Sequence-Tagging Trainers",
        "summary": "  The task of assigning label sequences to a set of observed sequences is\ncommon in computational linguistics. Several models for sequence labeling have\nbeen proposed over the last few years. Here, we focus on discriminative models\nfor sequence labeling. Many batch and online (updating model parameters after\nvisiting each example) learning algorithms have been proposed in the\nliterature. On large datasets, online algorithms are preferred as batch\nlearning methods are slow. These online algorithms were designed to solve\neither a primal or a dual problem. However, there has been no systematic\ncomparison of these algorithms in terms of their speed, generalization\nperformance (accuracy/likelihood) and their ability to achieve steady state\ngeneralization performance fast. With this aim, we compare different algorithms\nand make recommendations, useful for a practitioner. We conclude that the\nselection of an algorithm for sequence labeling depends on the evaluation\ncriterion used and its implementation simplicity.\n",
        "published": "2013-11-11T08:26:09Z",
        "pdf_link": "http://arxiv.org/pdf/1311.2378v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.2987v1",
        "title": "Learning Input and Recurrent Weight Matrices in Echo State Networks",
        "summary": "  Echo State Networks (ESNs) are a special type of the temporally deep network\nmodel, the Recurrent Neural Network (RNN), where the recurrent matrix is\ncarefully designed and both the recurrent and input matrices are fixed. An ESN\nuses the linearity of the activation function of the output units to simplify\nthe learning of the output matrix. In this paper, we devise a special technique\nthat take advantage of this linearity in the output units of an ESN, to learn\nthe input and recurrent matrices. This has not been done in earlier ESNs due to\ntheir well known difficulty in learning those matrices. Compared to the\ntechnique of BackPropagation Through Time (BPTT) in learning general RNNs, our\nproposed method exploits linearity of activation function in the output units\nto formulate the relationships amongst the various matrices in an RNN. These\nrelationships results in the gradient of the cost function having an analytical\nform and being more accurate. This would enable us to compute the gradients\ninstead of obtaining them by recursion as in BPTT. Experimental results on\nphone state classification show that learning one or both the input and\nrecurrent matrices in an ESN yields superior results compared to traditional\nESNs that do not learn these matrices, especially when longer time steps are\nused.\n",
        "published": "2013-11-13T00:11:09Z",
        "pdf_link": "http://arxiv.org/pdf/1311.2987v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.3157v1",
        "title": "Multiple Closed-Form Local Metric Learning for K-Nearest Neighbor\n  Classifier",
        "summary": "  Many researches have been devoted to learn a Mahalanobis distance metric,\nwhich can effectively improve the performance of kNN classification. Most\napproaches are iterative and computational expensive and linear rigidity still\ncritically limits metric learning algorithm to perform better. We proposed a\ncomputational economical framework to learn multiple metrics in closed-form.\n",
        "published": "2013-11-12T17:25:29Z",
        "pdf_link": "http://arxiv.org/pdf/1311.3157v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.4235v1",
        "title": "On the definition of a general learning system with user-defined\n  operators",
        "summary": "  In this paper, we push forward the idea of machine learning systems whose\noperators can be modified and fine-tuned for each problem. This allows us to\npropose a learning paradigm where users can write (or adapt) their operators,\naccording to the problem, data representation and the way the information\nshould be navigated. To achieve this goal, data instances, background\nknowledge, rules, programs and operators are all written in the same functional\nlanguage, Erlang. Since changing operators affect how the search space needs to\nbe explored, heuristics are learnt as a result of a decision process based on\nreinforcement learning where each action is defined as a choice of operator and\nrule. As a result, the architecture can be seen as a 'system for writing\nmachine learning systems' or to explore new operators where the policy reuse\n(as a kind of transfer learning) is allowed. States and actions are represented\nin a Q matrix which is actually a table, from which a supervised model is\nlearnt. This makes it possible to have a more flexible mapping between old and\nnew problems, since we work with an abstraction of rules and actions. We\ninclude some examples sharing reuse and the application of the system gErl to\nIQ problems. In order to evaluate gErl, we will test it against some structured\nproblems: a selection of IQ test tasks and some experiments on some structured\nprediction problems (list patterns).\n",
        "published": "2013-11-18T00:48:14Z",
        "pdf_link": "http://arxiv.org/pdf/1311.4235v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.4486v2",
        "title": "Discriminative Density-ratio Estimation",
        "summary": "  The covariate shift is a challenging problem in supervised learning that\nresults from the discrepancy between the training and test distributions. An\neffective approach which recently drew a considerable attention in the research\ncommunity is to reweight the training samples to minimize that discrepancy. In\nspecific, many methods are based on developing Density-ratio (DR) estimation\ntechniques that apply to both regression and classification problems. Although\nthese methods work well for regression problems, their performance on\nclassification problems is not satisfactory. This is due to a key observation\nthat these methods focus on matching the sample marginal distributions without\npaying attention to preserving the separation between classes in the reweighted\nspace. In this paper, we propose a novel method for Discriminative\nDensity-ratio (DDR) estimation that addresses the aforementioned problem and\naims at estimating the density-ratio of joint distributions in a class-wise\nmanner. The proposed algorithm is an iterative procedure that alternates\nbetween estimating the class information for the test data and estimating new\ndensity ratio for each class. To incorporate the estimated class information of\nthe test data, a soft matching technique is proposed. In addition, we employ an\neffective criterion which adopts mutual information as an indicator to stop the\niterative procedure while resulting in a decision boundary that lies in a\nsparse region. Experiments on synthetic and benchmark datasets demonstrate the\nsuperiority of the proposed method in terms of both accuracy and robustness.\n",
        "published": "2013-11-18T18:41:20Z",
        "pdf_link": "http://arxiv.org/pdf/1311.4486v2"
    },
    {
        "id": "http://arxiv.org/abs/1311.5068v1",
        "title": "Gromov-Hausdorff stability of linkage-based hierarchical clustering\n  methods",
        "summary": "  A hierarchical clustering method is stable if small perturbations on the data\nset produce small perturbations in the result. These perturbations are measured\nusing the Gromov-Hausdorff metric. We study the problem of stability on\nlinkage-based hierarchical clustering methods. We obtain that, under some basic\nconditions, standard linkage-based methods are semi-stable. This means that\nthey are stable if the input data is close enough to an ultrametric space. We\nprove that, apart from exotic examples, introducing any unchaining condition in\nthe algorithm always produces unstable methods.\n",
        "published": "2013-11-20T14:31:00Z",
        "pdf_link": "http://arxiv.org/pdf/1311.5068v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.5636v1",
        "title": "Learning Non-Linear Feature Maps",
        "summary": "  Feature selection plays a pivotal role in learning, particularly in areas\nwere parsimonious features can provide insight into the underlying process,\nsuch as biology. Recent approaches for non-linear feature selection employing\ngreedy optimisation of Centred Kernel Target Alignment(KTA), while exhibiting\nstrong results in terms of generalisation accuracy and sparsity, can become\ncomputationally prohibitive for high-dimensional datasets. We propose randSel,\na randomised feature selection algorithm, with attractive scaling properties.\nOur theoretical analysis of randSel provides strong probabilistic guarantees\nfor the correct identification of relevant features. Experimental results on\nreal and artificial data, show that the method successfully identifies\neffective features, performing better than a number of competitive approaches.\n",
        "published": "2013-11-22T01:49:26Z",
        "pdf_link": "http://arxiv.org/pdf/1311.5636v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.6041v3",
        "title": "No Free Lunch Theorem and Bayesian probability theory: two sides of the\n  same coin. Some implications for black-box optimization and metaheuristics",
        "summary": "  Challenging optimization problems, which elude acceptable solution via\nconventional calculus methods, arise commonly in different areas of industrial\ndesign and practice. Hard optimization problems are those who manifest the\nfollowing behavior: a) high number of independent input variables; b) very\ncomplex or irregular multi-modal fitness; c) computational expensive fitness\nevaluation. This paper will focus on some theoretical issues that have strong\nimplications for practice. I will stress how an interpretation of the No Free\nLunch theorem leads naturally to a general Bayesian optimization framework. The\nchoice of a prior over the space of functions is a critical and inevitable step\nin every black-box optimization.\n",
        "published": "2013-11-23T19:19:37Z",
        "pdf_link": "http://arxiv.org/pdf/1311.6041v3"
    },
    {
        "id": "http://arxiv.org/abs/1311.6184v4",
        "title": "Bounding the Test Log-Likelihood of Generative Models",
        "summary": "  Several interesting generative learning algorithms involve a complex\nprobability distribution over many random variables, involving intractable\nnormalization constants or latent variable normalization. Some of them may even\nnot have an analytic expression for the unnormalized probability function and\nno tractable approximation. This makes it difficult to estimate the quality of\nthese models, once they have been trained, or to monitor their quality (e.g.\nfor early stopping) while training. A previously proposed method is based on\nconstructing a non-parametric density estimator of the model's probability\nfunction from samples generated by the model. We revisit this idea, propose a\nmore efficient estimator, and prove that it provides a lower bound on the true\ntest log-likelihood, and an unbiased estimator as the number of generated\nsamples goes to infinity, although one that incorporates the effect of poor\nmixing. We further propose a biased variant of the estimator that can be used\nreliably with a finite number of samples for the purpose of model comparison.\n",
        "published": "2013-11-24T23:28:49Z",
        "pdf_link": "http://arxiv.org/pdf/1311.6184v4"
    },
    {
        "id": "http://arxiv.org/abs/1311.6211v1",
        "title": "Novelty Detection Under Multi-Instance Multi-Label Framework",
        "summary": "  Novelty detection plays an important role in machine learning and signal\nprocessing. This paper studies novelty detection in a new setting where the\ndata object is represented as a bag of instances and associated with multiple\nclass labels, referred to as multi-instance multi-label (MIML) learning.\nContrary to the common assumption in MIML that each instance in a bag belongs\nto one of the known classes, in novelty detection, we focus on the scenario\nwhere bags may contain novel-class instances. The goal is to determine, for any\ngiven instance in a new bag, whether it belongs to a known class or a novel\nclass. Detecting novelty in the MIML setting captures many real-world phenomena\nand has many potential applications. For example, in a collection of tagged\nimages, the tag may only cover a subset of objects existing in the images.\nDiscovering an object whose class has not been previously tagged can be useful\nfor the purpose of soliciting a label for the new object class. To address this\nnovel problem, we present a discriminative framework for detecting new class\ninstances. Experiments demonstrate the effectiveness of our proposed method,\nand reveal that the presence of unlabeled novel instances in training bags is\nhelpful to the detection of such instances in testing stage.\n",
        "published": "2013-11-25T05:27:41Z",
        "pdf_link": "http://arxiv.org/pdf/1311.6211v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.6396v2",
        "title": "A Unified Approach to Universal Prediction: Generalized Upper and Lower\n  Bounds",
        "summary": "  We study sequential prediction of real-valued, arbitrary and unknown\nsequences under the squared error loss as well as the best parametric predictor\nout of a large, continuous class of predictors. Inspired by recent results from\ncomputational learning theory, we refrain from any statistical assumptions and\ndefine the performance with respect to the class of general parametric\npredictors. In particular, we present generic lower and upper bounds on this\nrelative performance by transforming the prediction task into a parameter\nlearning problem. We first introduce the lower bounds on this relative\nperformance in the mixture of experts framework, where we show that for any\nsequential algorithm, there always exists a sequence for which the performance\nof the sequential algorithm is lower bounded by zero. We then introduce a\nsequential learning algorithm to predict such arbitrary and unknown sequences,\nand calculate upper bounds on its total squared prediction error for every\nbounded sequence. We further show that in some scenarios we achieve matching\nlower and upper bounds demonstrating that our algorithms are optimal in a\nstrong minimax sense such that their performances cannot be improved further.\nAs an interesting result we also prove that for the worst case scenario, the\nperformance of randomized algorithms can be achieved by sequential algorithms\nso that randomized algorithms does not improve the performance.\n",
        "published": "2013-11-25T18:36:26Z",
        "pdf_link": "http://arxiv.org/pdf/1311.6396v2"
    },
    {
        "id": "http://arxiv.org/abs/1311.6556v2",
        "title": "Double Ramp Loss Based Reject Option Classifier",
        "summary": "  We consider the problem of learning reject option classifiers. The goodness\nof a reject option classifier is quantified using $0-d-1$ loss function wherein\na loss $d \\in (0,.5)$ is assigned for rejection. In this paper, we propose {\\em\ndouble ramp loss} function which gives a continuous upper bound for $(0-d-1)$\nloss. Our approach is based on minimizing regularized risk under the double\nramp loss using {\\em difference of convex (DC) programming}. We show the\neffectiveness of our approach through experiments on synthetic and benchmark\ndatasets. Our approach performs better than the state of the art reject option\nclassification approaches.\n",
        "published": "2013-11-26T05:13:18Z",
        "pdf_link": "http://arxiv.org/pdf/1311.6556v2"
    },
    {
        "id": "http://arxiv.org/abs/1311.6809v1",
        "title": "A Novel Family of Adaptive Filtering Algorithms Based on The Logarithmic\n  Cost",
        "summary": "  We introduce a novel family of adaptive filtering algorithms based on a\nrelative logarithmic cost. The new family intrinsically combines the higher and\nlower order measures of the error into a single continuous update based on the\nerror amount. We introduce important members of this family of algorithms such\nas the least mean logarithmic square (LMLS) and least logarithmic absolute\ndifference (LLAD) algorithms that improve the convergence performance of the\nconventional algorithms. However, our approach and analysis are generic such\nthat they cover other well-known cost functions as described in the paper. The\nLMLS algorithm achieves comparable convergence performance with the least mean\nfourth (LMF) algorithm and extends the stability bound on the step size. The\nLLAD and least mean square (LMS) algorithms demonstrate similar convergence\nperformance in impulse-free noise environments while the LLAD algorithm is\nrobust against impulsive interferences and outperforms the sign algorithm (SA).\nWe analyze the transient, steady state and tracking performance of the\nintroduced algorithms and demonstrate the match of the theoretical analyzes and\nsimulation results. We show the extended stability bound of the LMLS algorithm\nand analyze the robustness of the LLAD algorithm against impulsive\ninterferences. Finally, we demonstrate the performance of our algorithms in\ndifferent scenarios through numerical examples.\n",
        "published": "2013-11-26T10:02:20Z",
        "pdf_link": "http://arxiv.org/pdf/1311.6809v1"
    },
    {
        "id": "http://arxiv.org/abs/1311.7385v3",
        "title": "Algorithmic Identification of Probabilities",
        "summary": "  TThe problem is to identify a probability associated with a set of natural\nnumbers, given an infinite data sequence of elements from the set. If the given\nsequence is drawn i.i.d. and the probability mass function involved (the\ntarget) belongs to a computably enumerable (c.e.) or co-computably enumerable\n(co-c.e.) set of computable probability mass functions, then there is an\nalgorithm to almost surely identify the target in the limit. The technical tool\nis the strong law of large numbers. If the set is finite and the elements of\nthe sequence are dependent while the sequence is typical in the sense of\nMartin-L\\\"of for at least one measure belonging to a c.e. or co-c.e. set of\ncomputable measures, then there is an algorithm to identify in the limit a\ncomputable measure for which the sequence is typical (there may be more than\none such measure). The technical tool is the theory of Kolmogorov complexity.\nWe give the algorithms and consider the associated predictions.\n",
        "published": "2013-11-28T17:44:45Z",
        "pdf_link": "http://arxiv.org/pdf/1311.7385v3"
    },
    {
        "id": "http://arxiv.org/abs/1311.7679v1",
        "title": "Combination of Diverse Ranking Models for Personalized Expedia Hotel\n  Searches",
        "summary": "  The ICDM Challenge 2013 is to apply machine learning to the problem of hotel\nranking, aiming to maximize purchases according to given hotel characteristics,\nlocation attractiveness of hotels, user's aggregated purchase history and\ncompetitive online travel agency information for each potential hotel choice.\nThis paper describes the solution of team \"binghsu & MLRush & BrickMover\". We\nconduct simple feature engineering work and train different models by each\nindividual team member. Afterwards, we use listwise ensemble method to combine\neach model's output. Besides describing effective model and features, we will\ndiscuss about the lessons we learned while using deep learning in this\ncompetition.\n",
        "published": "2013-11-29T20:01:10Z",
        "pdf_link": "http://arxiv.org/pdf/1311.7679v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.0044v1",
        "title": "Approximating the Bethe partition function",
        "summary": "  When belief propagation (BP) converges, it does so to a stationary point of\nthe Bethe free energy $F$, and is often strikingly accurate. However, it may\nconverge only to a local optimum or may not converge at all. An algorithm was\nrecently introduced for attractive binary pairwise MRFs which is guaranteed to\nreturn an $\\epsilon$-approximation to the global minimum of $F$ in polynomial\ntime provided the maximum degree $\\Delta=O(\\log n)$, where $n$ is the number of\nvariables. Here we significantly improve this algorithm and derive several\nresults including a new approach based on analyzing first derivatives of $F$,\nwhich leads to performance that is typically far superior and yields a fully\npolynomial-time approximation scheme (FPTAS) for attractive models without any\ndegree restriction. Further, the method applies to general (non-attractive)\nmodels, though with no polynomial time guarantee in this case, leading to the\nimportant result that approximating $\\log$ of the Bethe partition function,\n$\\log Z_B=-\\min F$, for a general model to additive $\\epsilon$-accuracy may be\nreduced to a discrete MAP inference problem. We explore an application to\npredicting equipment failure on an urban power network and demonstrate that the\nBethe approximation can perform well even when BP fails to converge.\n",
        "published": "2013-12-30T22:40:50Z",
        "pdf_link": "http://arxiv.org/pdf/1401.0044v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.0116v1",
        "title": "Controlled Sparsity Kernel Learning",
        "summary": "  Multiple Kernel Learning(MKL) on Support Vector Machines(SVMs) has been a\npopular front of research in recent times due to its success in application\nproblems like Object Categorization. This success is due to the fact that MKL\nhas the ability to choose from a variety of feature kernels to identify the\noptimal kernel combination. But the initial formulation of MKL was only able to\nselect the best of the features and misses out many other informative kernels\npresented. To overcome this, the Lp norm based formulation was proposed by\nKloft et. al. This formulation is capable of choosing a non-sparse set of\nkernels through a control parameter p. Unfortunately, the parameter p does not\nhave a direct meaning to the number of kernels selected. We have observed that\nstricter control over the number of kernels selected gives us an edge over\nthese techniques in terms of accuracy of classification and also helps us to\nfine tune the algorithms to the time requirements at hand. In this work, we\npropose a Controlled Sparsity Kernel Learning (CSKL) formulation that can\nstrictly control the number of kernels which we wish to select. The CSKL\nformulation introduces a parameter t which directly corresponds to the number\nof kernels selected. It is important to note that a search in t space is finite\nand fast as compared to p. We have also provided an efficient Reduced Gradient\nDescent based algorithm to solve the CSKL formulation, which is proven to\nconverge. Through our experiments on the Caltech101 Object Categorization\ndataset, we have also shown that one can achieve better accuracies than the\nprevious formulations through the right choice of t.\n",
        "published": "2013-12-31T09:13:09Z",
        "pdf_link": "http://arxiv.org/pdf/1401.0116v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.0362v3",
        "title": "EigenGP: Gaussian Process Models with Adaptive Eigenfunctions",
        "summary": "  Gaussian processes (GPs) provide a nonparametric representation of functions.\nHowever, classical GP inference suffers from high computational cost for big\ndata. In this paper, we propose a new Bayesian approach, EigenGP, that learns\nboth basis dictionary elements--eigenfunctions of a GP prior--and prior\nprecisions in a sparse finite model. It is well known that, among all\northogonal basis functions, eigenfunctions can provide the most compact\nrepresentation. Unlike other sparse Bayesian finite models where the basis\nfunction has a fixed form, our eigenfunctions live in a reproducing kernel\nHilbert space as a finite linear combination of kernel functions. We learn the\ndictionary elements--eigenfunctions--and the prior precisions over these\nelements as well as all the other hyperparameters from data by maximizing the\nmodel marginal likelihood. We explore computational linear algebra to simplify\nthe gradient computation significantly. Our experimental results demonstrate\nimproved predictive performance of EigenGP over alternative sparse GP methods\nas well as relevance vector machine.\n",
        "published": "2014-01-02T03:12:28Z",
        "pdf_link": "http://arxiv.org/pdf/1401.0362v3"
    },
    {
        "id": "http://arxiv.org/abs/1401.1123v1",
        "title": "Exploration vs Exploitation vs Safety: Risk-averse Multi-Armed Bandits",
        "summary": "  Motivated by applications in energy management, this paper presents the\nMulti-Armed Risk-Aware Bandit (MARAB) algorithm. With the goal of limiting the\nexploration of risky arms, MARAB takes as arm quality its conditional value at\nrisk. When the user-supplied risk level goes to 0, the arm quality tends toward\nthe essential infimum of the arm distribution density, and MARAB tends toward\nthe MIN multi-armed bandit algorithm, aimed at the arm with maximal minimal\nvalue. As a first contribution, this paper presents a theoretical analysis of\nthe MIN algorithm under mild assumptions, establishing its robustness\ncomparatively to UCB. The analysis is supported by extensive experimental\nvalidation of MIN and MARAB compared to UCB and state-of-art risk-aware MAB\nalgorithms on artificial and real-world problems.\n",
        "published": "2014-01-06T15:53:25Z",
        "pdf_link": "http://arxiv.org/pdf/1401.1123v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.1880v2",
        "title": "DJ-MC: A Reinforcement-Learning Agent for Music Playlist Recommendation",
        "summary": "  In recent years, there has been growing focus on the study of automated\nrecommender systems. Music recommendation systems serve as a prominent domain\nfor such works, both from an academic and a commercial perspective. A\nfundamental aspect of music perception is that music is experienced in temporal\ncontext and in sequence. In this work we present DJ-MC, a novel\nreinforcement-learning framework for music recommendation that does not\nrecommend songs individually but rather song sequences, or playlists, based on\na model of preferences for both songs and song transitions. The model is\nlearned online and is uniquely adapted for each listener. To reduce exploration\ntime, DJ-MC exploits user feedback to initialize a model, which it subsequently\nupdates by reinforcement. We evaluate our framework with human participants\nusing both real song and playlist data. Our results indicate that DJ-MC's\nability to recommend sequences of songs provides a significant improvement over\nmore straightforward approaches, which do not take transitions into account.\n",
        "published": "2014-01-09T01:50:09Z",
        "pdf_link": "http://arxiv.org/pdf/1401.1880v2"
    },
    {
        "id": "http://arxiv.org/abs/1401.2411v2",
        "title": "Clustering, Coding, and the Concept of Similarity",
        "summary": "  This paper develops a theory of clustering and coding which combines a\ngeometric model with a probabilistic model in a principled way. The geometric\nmodel is a Riemannian manifold with a Riemannian metric, ${g}_{ij}({\\bf x})$,\nwhich we interpret as a measure of dissimilarity. The probabilistic model\nconsists of a stochastic process with an invariant probability measure which\nmatches the density of the sample input data. The link between the two models\nis a potential function, $U({\\bf x})$, and its gradient, $\\nabla U({\\bf x})$.\nWe use the gradient to define the dissimilarity metric, which guarantees that\nour measure of dissimilarity will depend on the probability measure. Finally,\nwe use the dissimilarity metric to define a coordinate system on the embedded\nRiemannian manifold, which gives us a low-dimensional encoding of our original\ndata.\n",
        "published": "2014-01-10T17:36:23Z",
        "pdf_link": "http://arxiv.org/pdf/1401.2411v2"
    },
    {
        "id": "http://arxiv.org/abs/1401.3429v1",
        "title": "Latent Tree Models and Approximate Inference in Bayesian Networks",
        "summary": "  We propose a novel method for approximate inference in Bayesian networks\n(BNs). The idea is to sample data from a BN, learn a latent tree model (LTM)\nfrom the data offline, and when online, make inference with the LTM instead of\nthe original BN. Because LTMs are tree-structured, inference takes linear time.\nIn the meantime, they can represent complex relationship among leaf nodes and\nhence the approximation accuracy is often good. Empirical evidence shows that\nour method can achieve good approximation accuracy at low online computational\ncost.\n",
        "published": "2014-01-15T04:46:37Z",
        "pdf_link": "http://arxiv.org/pdf/1401.3429v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.3434v1",
        "title": "Adaptive Stochastic Resource Control: A Machine Learning Approach",
        "summary": "  The paper investigates stochastic resource allocation problems with scarce,\nreusable resources and non-preemtive, time-dependent, interconnected tasks.\nThis approach is a natural generalization of several standard resource\nmanagement problems, such as scheduling and transportation problems. First,\nreactive solutions are considered and defined as control policies of suitably\nreformulated Markov decision processes (MDPs). We argue that this reformulation\nhas several favorable properties, such as it has finite state and action\nspaces, it is aperiodic, hence all policies are proper and the space of control\npolicies can be safely restricted. Next, approximate dynamic programming (ADP)\nmethods, such as fitted Q-learning, are suggested for computing an efficient\ncontrol policy. In order to compactly maintain the cost-to-go function, two\nrepresentations are studied: hash tables and support vector regression (SVR),\nparticularly, nu-SVRs. Several additional improvements, such as the application\nof limited-lookahead rollout algorithms in the initial phases, action space\ndecomposition, task clustering and distributed sampling are investigated, too.\nFinally, experimental results on both benchmark and industry-related data are\npresented.\n",
        "published": "2014-01-15T04:50:50Z",
        "pdf_link": "http://arxiv.org/pdf/1401.3434v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.3447v1",
        "title": "Anytime Induction of Low-cost, Low-error Classifiers: a Sampling-based\n  Approach",
        "summary": "  Machine learning techniques are gaining prevalence in the production of a\nwide range of classifiers for complex real-world applications with nonuniform\ntesting and misclassification costs. The increasing complexity of these\napplications poses a real challenge to resource management during learning and\nclassification. In this work we introduce ACT (anytime cost-sensitive tree\nlearner), a novel framework for operating in such complex environments. ACT is\nan anytime algorithm that allows learning time to be increased in return for\nlower classification costs. It builds a tree top-down and exploits additional\ntime resources to obtain better estimations for the utility of the different\ncandidate splits. Using sampling techniques, ACT approximates the cost of the\nsubtree under each candidate split and favors the one with a minimal cost. As a\nstochastic algorithm, ACT is expected to be able to escape local minima, into\nwhich greedy methods may be trapped. Experiments with a variety of datasets\nwere conducted to compare ACT to the state-of-the-art cost-sensitive tree\nlearners. The results show that for the majority of domains ACT produces\nsignificantly less costly trees. ACT also exhibits good anytime behavior with\ndiminishing returns.\n",
        "published": "2014-01-15T05:09:07Z",
        "pdf_link": "http://arxiv.org/pdf/1401.3447v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.3880v1",
        "title": "Regression Conformal Prediction with Nearest Neighbours",
        "summary": "  In this paper we apply Conformal Prediction (CP) to the k-Nearest Neighbours\nRegression (k-NNR) algorithm and propose ways of extending the typical\nnonconformity measure used for regression so far. Unlike traditional regression\nmethods which produce point predictions, Conformal Predictors output predictive\nregions that satisfy a given confidence level. The regions produced by any\nConformal Predictor are automatically valid, however their tightness and\ntherefore usefulness depends on the nonconformity measure used by each CP. In\neffect a nonconformity measure evaluates how strange a given example is\ncompared to a set of other examples based on some traditional machine learning\nalgorithm. We define six novel nonconformity measures based on the k-Nearest\nNeighbours Regression algorithm and develop the corresponding CPs following\nboth the original (transductive) and the inductive CP approaches. A comparison\nof the predictive regions produced by our measures with those of the typical\nregression measure suggests that a major improvement in terms of predictive\nregion tightness is achieved by the new measures.\n",
        "published": "2014-01-16T05:12:21Z",
        "pdf_link": "http://arxiv.org/pdf/1401.3880v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.4143v1",
        "title": "Convex Optimization for Binary Classifier Aggregation in Multiclass\n  Problems",
        "summary": "  Multiclass problems are often decomposed into multiple binary problems that\nare solved by individual binary classifiers whose results are integrated into a\nfinal answer. Various methods, including all-pairs (APs), one-versus-all (OVA),\nand error correcting output code (ECOC), have been studied, to decompose\nmulticlass problems into binary problems. However, little study has been made\nto optimally aggregate binary problems to determine a final answer to the\nmulticlass problem. In this paper we present a convex optimization method for\nan optimal aggregation of binary classifiers to estimate class membership\nprobabilities in multiclass problems. We model the class membership probability\nas a softmax function which takes a conic combination of discrepancies induced\nby individual binary classifiers, as an input. With this model, we formulate\nthe regularized maximum likelihood estimation as a convex optimization problem,\nwhich is solved by the primal-dual interior point method. Connections of our\nmethod to large margin classifiers are presented, showing that the large margin\nformulation can be considered as a limiting case of our convex formulation.\nNumerical experiments on synthetic and real-world data sets demonstrate that\nour method outperforms existing aggregation methods as well as direct methods,\nin terms of the classification accuracy and the quality of class membership\nprobability estimates.\n",
        "published": "2014-01-16T19:49:02Z",
        "pdf_link": "http://arxiv.org/pdf/1401.4143v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.5136v1",
        "title": "A Unifying Framework for Typical Multi-Task Multiple Kernel Learning\n  Problems",
        "summary": "  Over the past few years, Multi-Kernel Learning (MKL) has received significant\nattention among data-driven feature selection techniques in the context of\nkernel-based learning. MKL formulations have been devised and solved for a\nbroad spectrum of machine learning problems, including Multi-Task Learning\n(MTL). Solving different MKL formulations usually involves designing algorithms\nthat are tailored to the problem at hand, which is, typically, a non-trivial\naccomplishment.\n  In this paper we present a general Multi-Task Multi-Kernel Learning\n(Multi-Task MKL) framework that subsumes well-known Multi-Task MKL\nformulations, as well as several important MKL approaches on single-task\nproblems. We then derive a simple algorithm that can solve the unifying\nframework. To demonstrate the flexibility of the proposed framework, we\nformulate a new learning problem, namely Partially-Shared Common Space (PSCS)\nMulti-Task MKL, and demonstrate its merits through experimentation.\n",
        "published": "2014-01-21T01:16:44Z",
        "pdf_link": "http://arxiv.org/pdf/1401.5136v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.6240v1",
        "title": "Is Extreme Learning Machine Feasible? A Theoretical Assessment (Part II)",
        "summary": "  An extreme learning machine (ELM) can be regarded as a two stage feed-forward\nneural network (FNN) learning system which randomly assigns the connections\nwith and within hidden neurons in the first stage and tunes the connections\nwith output neurons in the second stage. Therefore, ELM training is essentially\na linear learning problem, which significantly reduces the computational\nburden. Numerous applications show that such a computation burden reduction\ndoes not degrade the generalization capability. It has, however, been open that\nwhether this is true in theory. The aim of our work is to study the theoretical\nfeasibility of ELM by analyzing the pros and cons of ELM. In the previous part\non this topic, we pointed out that via appropriate selection of the activation\nfunction, ELM does not degrade the generalization capability in the expectation\nsense. In this paper, we launch the study in a different direction and show\nthat the randomness of ELM also leads to certain negative consequences. On one\nhand, we find that the randomness causes an additional uncertainty problem of\nELM, both in approximation and learning. On the other hand, we theoretically\njustify that there also exists an activation function such that the\ncorresponding ELM degrades the generalization capability. In particular, we\nprove that the generalization capability of ELM with Gaussian kernel is\nessentially worse than that of FNN with Gaussian kernel. To facilitate the use\nof ELM, we also provide a remedy to such a degradation. We find that the\nwell-developed coefficient regularization technique can essentially improve the\ngeneralization capability. The obtained results reveal the essential\ncharacteristic of ELM and give theoretical guidance concerning how to use ELM.\n",
        "published": "2014-01-24T01:57:42Z",
        "pdf_link": "http://arxiv.org/pdf/1401.6240v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.6376v1",
        "title": "Steady-state performance of non-negative least-mean-square algorithm and\n  its variants",
        "summary": "  Non-negative least-mean-square (NNLMS) algorithm and its variants have been\nproposed for online estimation under non-negativity constraints. The transient\nbehavior of the NNLMS, Normalized NNLMS, Exponential NNLMS and Sign-Sign NNLMS\nalgorithms have been studied in our previous work. In this technical report, we\nderive closed-form expressions for the steady-state excess mean-square error\n(EMSE) for the four algorithms. Simulations results illustrate the accuracy of\nthe theoretical results. This is a complementary material to our previous work.\n",
        "published": "2014-01-24T15:36:09Z",
        "pdf_link": "http://arxiv.org/pdf/1401.6376v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.6421v1",
        "title": "Riffled Independence for Efficient Inference with Partial Rankings",
        "summary": "  Distributions over rankings are used to model data in a multitude of real\nworld settings such as preference analysis and political elections. Modeling\nsuch distributions presents several computational challenges, however, due to\nthe factorial size of the set of rankings over an item set. Some of these\nchallenges are quite familiar to the artificial intelligence community, such as\nhow to compactly represent a distribution over a combinatorially large space,\nand how to efficiently perform probabilistic inference with these\nrepresentations. With respect to ranking, however, there is the additional\nchallenge of what we refer to as human task complexity users are rarely willing\nto provide a full ranking over a long list of candidates, instead often\npreferring to provide partial ranking information. Simultaneously addressing\nall of these challenges i.e., designing a compactly representable model which\nis amenable to efficient inference and can be learned using partial ranking\ndata is a difficult task, but is necessary if we would like to scale to\nproblems with nontrivial size. In this paper, we show that the recently\nproposed riffled independence assumptions cleanly and efficiently address each\nof the above challenges. In particular, we establish a tight mathematical\nconnection between the concepts of riffled independence and of partial\nrankings. This correspondence not only allows us to then develop efficient and\nexact algorithms for performing inference tasks using riffled independence\nbased represen- tations with partial rankings, but somewhat surprisingly, also\nshows that efficient inference is not possible for riffle independent models\n(in a certain sense) with observations which do not take the form of partial\nrankings. Finally, using our inference algorithm, we introduce the first method\nfor learning riffled independence based models from partially ranked data.\n",
        "published": "2014-01-23T02:42:39Z",
        "pdf_link": "http://arxiv.org/pdf/1401.6421v1"
    },
    {
        "id": "http://arxiv.org/abs/1401.6424v1",
        "title": "Toward Supervised Anomaly Detection",
        "summary": "  Anomaly detection is being regarded as an unsupervised learning task as\nanomalies stem from adversarial or unlikely events with unknown distributions.\nHowever, the predictive performance of purely unsupervised anomaly detection\noften fails to match the required detection rates in many tasks and there\nexists a need for labeled data to guide the model generation. Our first\ncontribution shows that classical semi-supervised approaches, originating from\na supervised classifier, are inappropriate and hardly detect new and unknown\nanomalies. We argue that semi-supervised anomaly detection needs to ground on\nthe unsupervised learning paradigm and devise a novel algorithm that meets this\nrequirement. Although being intrinsically non-convex, we further show that the\noptimization problem has a convex equivalent under relatively mild assumptions.\nAdditionally, we propose an active learning strategy to automatically filter\ncandidates for labeling. In an empirical study on network intrusion detection\ndata, we observe that the proposed learning methodology requires much less\nlabeled data than the state-of-the-art, while achieving higher detection\naccuracies.\n",
        "published": "2014-01-23T02:46:53Z",
        "pdf_link": "http://arxiv.org/pdf/1401.6424v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.0452v1",
        "title": "A Lower Bound for the Variance of Estimators for Nakagami m Distribution",
        "summary": "  Recently, we have proposed a maximum likelihood iterative algorithm for\nestimation of the parameters of the Nakagami-m distribution. This technique\nperforms better than state of art estimation techniques for this distribution.\nThis could be of particular use in low data or block based estimation problems.\nIn these scenarios, the estimator should be able to give accurate estimates in\nthe mean square sense with less amounts of data. Also, the estimates should\nimprove with the increase in number of blocks received. In this paper, we see\nthrough our simulations, that our proposal is well designed for such\nrequirements. Further, it is well known in the literature that an efficient\nestimator does not exist for Nakagami-m distribution. In this paper, we derive\na theoretical expression for the variance of our proposed estimator. We find\nthat this expression clearly fits the experimental curve for the variance of\nthe proposed estimator. This expression is pretty close to the cramer-rao lower\nbound(CRLB).\n",
        "published": "2014-02-03T18:20:46Z",
        "pdf_link": "http://arxiv.org/pdf/1402.0452v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.0570v1",
        "title": "A Feature Subset Selection Algorithm Automatic Recommendation Method",
        "summary": "  Many feature subset selection (FSS) algorithms have been proposed, but not\nall of them are appropriate for a given feature selection problem. At the same\ntime, so far there is rarely a good way to choose appropriate FSS algorithms\nfor the problem at hand. Thus, FSS algorithm automatic recommendation is very\nimportant and practically useful. In this paper, a meta learning based FSS\nalgorithm automatic recommendation method is presented. The proposed method\nfirst identifies the data sets that are most similar to the one at hand by the\nk-nearest neighbor classification algorithm, and the distances among these data\nsets are calculated based on the commonly-used data set characteristics. Then,\nit ranks all the candidate FSS algorithms according to their performance on\nthese similar data sets, and chooses the algorithms with best performance as\nthe appropriate ones. The performance of the candidate FSS algorithms is\nevaluated by a multi-criteria metric that takes into account not only the\nclassification accuracy over the selected features, but also the runtime of\nfeature selection and the number of selected features. The proposed\nrecommendation method is extensively tested on 115 real world data sets with 22\nwell-known and frequently-used different FSS algorithms for five representative\nclassifiers. The results show the effectiveness of our proposed FSS algorithm\nrecommendation method.\n",
        "published": "2014-02-04T01:37:24Z",
        "pdf_link": "http://arxiv.org/pdf/1402.0570v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.0577v1",
        "title": "A Survey on Latent Tree Models and Applications",
        "summary": "  In data analysis, latent variables play a central role because they help\nprovide powerful insights into a wide variety of phenomena, ranging from\nbiological to human sciences. The latent tree model, a particular type of\nprobabilistic graphical models, deserves attention. Its simple structure - a\ntree - allows simple and efficient inference, while its latent variables\ncapture complex relationships. In the past decade, the latent tree model has\nbeen subject to significant theoretical and methodological developments. In\nthis review, we propose a comprehensive study of this model. First we summarize\nkey ideas underlying the model. Second we explain how it can be efficiently\nlearned from data. Third we illustrate its use within three types of\napplications: latent structure discovery, multidimensional clustering, and\nprobabilistic inference. Finally, we conclude and give promising directions for\nfuture researches in this field.\n",
        "published": "2014-02-04T01:40:28Z",
        "pdf_link": "http://arxiv.org/pdf/1402.0577v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.2092v4",
        "title": "Near-Optimally Teaching the Crowd to Classify",
        "summary": "  How should we present training examples to learners to teach them\nclassification rules? This is a natural problem when training workers for\ncrowdsourcing labeling tasks, and is also motivated by challenges in\ndata-driven online education. We propose a natural stochastic model of the\nlearners, modeling them as randomly switching among hypotheses based on\nobserved feedback. We then develop STRICT, an efficient algorithm for selecting\nexamples to teach to workers. Our solution greedily maximizes a submodular\nsurrogate objective function in order to select examples to show to the\nlearners. We prove that our strategy is competitive with the optimal teaching\npolicy. Moreover, for the special case of linear separators, we prove that an\nexponential reduction in error probability can be achieved. Our experiments on\nsimulated workers as well as three real image annotation tasks on Amazon\nMechanical Turk show the effectiveness of our teaching algorithm.\n",
        "published": "2014-02-10T10:36:49Z",
        "pdf_link": "http://arxiv.org/pdf/1402.2092v4"
    },
    {
        "id": "http://arxiv.org/abs/1402.3427v7",
        "title": "Indian Buffet Process Deep Generative Models for Semi-Supervised\n  Classification",
        "summary": "  Deep generative models (DGMs) have brought about a major breakthrough, as\nwell as renewed interest, in generative latent variable models. However, DGMs\ndo not allow for performing data-driven inference of the number of latent\nfeatures needed to represent the observed data. Traditional linear formulations\naddress this issue by resorting to tools from the field of nonparametric\nstatistics. Indeed, linear latent variable models imposed an Indian Buffet\nProcess (IBP) prior have been extensively studied by the machine learning\ncommunity; inference for such models can been performed either via exact\nsampling or via approximate variational techniques. Based on this inspiration,\nin this paper we examine whether similar ideas from the field of Bayesian\nnonparametrics can be utilized in the context of modern DGMs in order to\naddress the latent variable dimensionality inference problem. To this end, we\npropose a novel DGM formulation, based on the imposition of an IBP prior. We\ndevise an efficient Black-Box Variational inference algorithm for our model,\nand exhibit its efficacy in a number of semi-supervised classification\nexperiments. In all cases, we use popular benchmark datasets, and compare to\nstate-of-the-art DGMs.\n",
        "published": "2014-02-14T10:44:48Z",
        "pdf_link": "http://arxiv.org/pdf/1402.3427v7"
    },
    {
        "id": "http://arxiv.org/abs/1402.3902v4",
        "title": "Sparse Polynomial Learning and Graph Sketching",
        "summary": "  Let $f:\\{-1,1\\}^n$ be a polynomial with at most $s$ non-zero real\ncoefficients. We give an algorithm for exactly reconstructing f given random\nexamples from the uniform distribution on $\\{-1,1\\}^n$ that runs in time\npolynomial in $n$ and $2s$ and succeeds if the function satisfies the unique\nsign property: there is one output value which corresponds to a unique set of\nvalues of the participating parities. This sufficient condition is satisfied\nwhen every coefficient of f is perturbed by a small random noise, or satisfied\nwith high probability when s parity functions are chosen randomly or when all\nthe coefficients are positive. Learning sparse polynomials over the Boolean\ndomain in time polynomial in $n$ and $2s$ is considered notoriously hard in the\nworst-case. Our result shows that the problem is tractable for almost all\nsparse polynomials. Then, we show an application of this result to hypergraph\nsketching which is the problem of learning a sparse (both in the number of\nhyperedges and the size of the hyperedges) hypergraph from uniformly drawn\nrandom cuts. We also provide experimental results on a real world dataset.\n",
        "published": "2014-02-17T06:00:16Z",
        "pdf_link": "http://arxiv.org/pdf/1402.3902v4"
    },
    {
        "id": "http://arxiv.org/abs/1402.4084v1",
        "title": "Selective Sampling with Drift",
        "summary": "  Recently there has been much work on selective sampling, an online active\nlearning setting, in which algorithms work in rounds. On each round an\nalgorithm receives an input and makes a prediction. Then, it can decide whether\nto query a label, and if so to update its model, otherwise the input is\ndiscarded. Most of this work is focused on the stationary case, where it is\nassumed that there is a fixed target model, and the performance of the\nalgorithm is compared to a fixed model. However, in many real-world\napplications, such as spam prediction, the best target function may drift over\ntime, or have shifts from time to time. We develop a novel selective sampling\nalgorithm for the drifting setting, analyze it under no assumptions on the\nmechanism generating the sequence of instances, and derive new mistake bounds\nthat depend on the amount of drift in the problem. Simulations on synthetic and\nreal-world datasets demonstrate the superiority of our algorithms as a\nselective sampling algorithm in the drifting setting.\n",
        "published": "2014-02-17T17:53:57Z",
        "pdf_link": "http://arxiv.org/pdf/1402.4084v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.4322v1",
        "title": "On the properties of $α$-unchaining single linkage hierarchical\n  clustering",
        "summary": "  In the election of a hierarchical clustering method, theoretic properties may\ngive some insight to determine which method is the most suitable to treat a\nclustering problem. Herein, we study some basic properties of two hierarchical\nclustering methods: $\\alpha$-unchaining single linkage or $SL(\\alpha)$ and a\nmodified version of this one, $SL^*(\\alpha)$. We compare the results with the\nproperties satisfied by the classical linkage-based hierarchical clustering\nmethods.\n",
        "published": "2014-02-18T13:08:47Z",
        "pdf_link": "http://arxiv.org/pdf/1402.4322v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.4437v2",
        "title": "Learning the Irreducible Representations of Commutative Lie Groups",
        "summary": "  We present a new probabilistic model of compact commutative Lie groups that\nproduces invariant-equivariant and disentangled representations of data. To\ndefine the notion of disentangling, we borrow a fundamental principle from\nphysics that is used to derive the elementary particles of a system from its\nsymmetries. Our model employs a newfound Bayesian conjugacy relation that\nenables fully tractable probabilistic inference over compact commutative Lie\ngroups -- a class that includes the groups that describe the rotation and\ncyclic translation of images. We train the model on pairs of transformed image\npatches, and show that the learned invariant representation is highly effective\nfor classification.\n",
        "published": "2014-02-18T18:47:41Z",
        "pdf_link": "http://arxiv.org/pdf/1402.4437v2"
    },
    {
        "id": "http://arxiv.org/abs/1402.4645v1",
        "title": "A Survey on Semi-Supervised Learning Techniques",
        "summary": "  Semisupervised learning is a learning standard which deals with the study of\nhow computers and natural systems such as human beings acquire knowledge in the\npresence of both labeled and unlabeled data. Semisupervised learning based\nmethods are preferred when compared to the supervised and unsupervised learning\nbecause of the improved performance shown by the semisupervised approaches in\nthe presence of large volumes of data. Labels are very hard to attain while\nunlabeled data are surplus, therefore semisupervised learning is a noble\nindication to shrink human labor and improve accuracy. There has been a large\nspectrum of ideas on semisupervised learning. In this paper we bring out some\nof the key approaches for semisupervised learning.\n",
        "published": "2014-02-19T12:40:31Z",
        "pdf_link": "http://arxiv.org/pdf/1402.4645v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.4861v1",
        "title": "A Quasi-Newton Method for Large Scale Support Vector Machines",
        "summary": "  This paper adapts a recently developed regularized stochastic version of the\nBroyden, Fletcher, Goldfarb, and Shanno (BFGS) quasi-Newton method for the\nsolution of support vector machine classification problems. The proposed method\nis shown to converge almost surely to the optimal classifier at a rate that is\nlinear in expectation. Numerical results show that the proposed method exhibits\na convergence rate that degrades smoothly with the dimensionality of the\nfeature vectors.\n",
        "published": "2014-02-20T01:44:33Z",
        "pdf_link": "http://arxiv.org/pdf/1402.4861v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.5634v1",
        "title": "To go deep or wide in learning?",
        "summary": "  To achieve acceptable performance for AI tasks, one can either use\nsophisticated feature extraction methods as the first layer in a two-layered\nsupervised learning model, or learn the features directly using a deep\n(multi-layered) model. While the first approach is very problem-specific, the\nsecond approach has computational overheads in learning multiple layers and\nfine-tuning of the model. In this paper, we propose an approach called wide\nlearning based on arc-cosine kernels, that learns a single layer of infinite\nwidth. We propose exact and inexact learning strategies for wide learning and\nshow that wide learning with single layer outperforms single layer as well as\ndeep architectures of finite width for some benchmark datasets.\n",
        "published": "2014-02-23T16:51:51Z",
        "pdf_link": "http://arxiv.org/pdf/1402.5634v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.5758v1",
        "title": "Bandits with concave rewards and convex knapsacks",
        "summary": "  In this paper, we consider a very general model for exploration-exploitation\ntradeoff which allows arbitrary concave rewards and convex constraints on the\ndecisions across time, in addition to the customary limitation on the time\nhorizon. This model subsumes the classic multi-armed bandit (MAB) model, and\nthe Bandits with Knapsacks (BwK) model of Badanidiyuru et al.[2013]. We also\nconsider an extension of this model to allow linear contexts, similar to the\nlinear contextual extension of the MAB model. We demonstrate that a natural and\nsimple extension of the UCB family of algorithms for MAB provides a polynomial\ntime algorithm that has near-optimal regret guarantees for this substantially\nmore general model, and matches the bounds provided by Badanidiyuru et\nal.[2013] for the special case of BwK, which is quite surprising. We also\nprovide computationally more efficient algorithms by establishing interesting\nconnections between this problem and other well studied problems/algorithms\nsuch as the Blackwell approachability problem, online convex optimization, and\nthe Frank-Wolfe technique for convex optimization. We give examples of several\nconcrete applications, where this more general model of bandits allows for\nricher and/or more efficient formulations of the problem.\n",
        "published": "2014-02-24T09:27:18Z",
        "pdf_link": "http://arxiv.org/pdf/1402.5758v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.6552v1",
        "title": "Renewable Energy Prediction using Weather Forecasts for Optimal\n  Scheduling in HPC Systems",
        "summary": "  The objective of the GreenPAD project is to use green energy (wind, solar and\nbiomass) for powering data-centers that are used to run HPC jobs. As a part of\nthis it is important to predict the Renewable (Wind) energy for efficient\nscheduling (executing jobs that require higher energy when there is more green\nenergy available and vice-versa). For predicting the wind energy we first\nanalyze the historical data to find a statistical model that gives relation\nbetween wind energy and weather attributes. Then we use this model based on the\nweather forecast data to predict the green energy availability in the future.\nUsing the green energy prediction obtained from the statistical model we are\nable to precompute job schedules for maximizing the green energy utilization in\nthe future. We propose a model which uses live weather data in addition to\nmachine learning techniques (which can predict future deviations in weather\nconditions based on current deviations from the forecast) to make on-the-fly\nchanges to the precomputed schedule (based on green energy prediction).\n  For this we first analyze the data using histograms and simple statistical\ntools such as correlation. In addition we build (correlation) regression model\nfor finding the relation between wind energy availability and weather\nattributes (temperature, cloud cover, air pressure, wind speed / direction,\nprecipitation and sunshine). We also analyze different algorithms and machine\nlearning techniques for optimizing the job schedules for maximizing the green\nenergy utilization.\n",
        "published": "2014-02-26T14:29:33Z",
        "pdf_link": "http://arxiv.org/pdf/1402.6552v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.7001v1",
        "title": "Marginalizing Corrupted Features",
        "summary": "  The goal of machine learning is to develop predictors that generalize well to\ntest data. Ideally, this is achieved by training on an almost infinitely large\ntraining data set that captures all variations in the data distribution. In\npractical learning settings, however, we do not have infinite data and our\npredictors may overfit. Overfitting may be combatted, for example, by adding a\nregularizer to the training objective or by defining a prior over the model\nparameters and performing Bayesian inference. In this paper, we propose a\nthird, alternative approach to combat overfitting: we extend the training set\nwith infinitely many artificial training examples that are obtained by\ncorrupting the original training data. We show that this approach is practical\nand efficient for a range of predictors and corruption models. Our approach,\ncalled marginalized corrupted features (MCF), trains robust predictors by\nminimizing the expected value of the loss function under the corruption model.\nWe show empirically on a variety of data sets that MCF classifiers can be\ntrained efficiently, may generalize substantially better to test data, and are\nalso more robust to feature deletion at test time.\n",
        "published": "2014-02-27T18:31:33Z",
        "pdf_link": "http://arxiv.org/pdf/1402.7001v1"
    },
    {
        "id": "http://arxiv.org/abs/1402.7025v2",
        "title": "Exploiting the Statistics of Learning and Inference",
        "summary": "  When dealing with datasets containing a billion instances or with simulations\nthat require a supercomputer to execute, computational resources become part of\nthe equation. We can improve the efficiency of learning and inference by\nexploiting their inherent statistical nature. We propose algorithms that\nexploit the redundancy of data relative to a model by subsampling data-cases\nfor every update and reasoning about the uncertainty created in this process.\nIn the context of learning we propose to test for the probability that a\nstochastically estimated gradient points more than 180 degrees in the wrong\ndirection. In the context of MCMC sampling we use stochastic gradients to\nimprove the efficiency of MCMC updates, and hypothesis tests based on adaptive\nmini-batches to decide whether to accept or reject a proposed parameter update.\nFinally, we argue that in the context of likelihood free MCMC one needs to\nstore all the information revealed by all simulations, for instance in a\nGaussian process. We conclude that Bayesian methods will remain to play a\ncrucial role in the era of big data and big simulations, but only if we\novercome a number of computational challenges.\n",
        "published": "2014-02-26T10:47:09Z",
        "pdf_link": "http://arxiv.org/pdf/1402.7025v2"
    },
    {
        "id": "http://arxiv.org/abs/1403.0156v1",
        "title": "Sleep Analytics and Online Selective Anomaly Detection",
        "summary": "  We introduce a new problem, the Online Selective Anomaly Detection (OSAD), to\nmodel a specific scenario emerging from research in sleep science. Scientists\nhave segmented sleep into several stages and stage two is characterized by two\npatterns (or anomalies) in the EEG time series recorded on sleep subjects.\nThese two patterns are sleep spindle (SS) and K-complex. The OSAD problem was\nintroduced to design a residual system, where all anomalies (known and unknown)\nare detected but the system only triggers an alarm when non-SS anomalies\nappear. The solution of the OSAD problem required us to combine techniques from\nboth machine learning and control theory. Experiments on data from real\nsubjects attest to the effectiveness of our approach.\n",
        "published": "2014-03-02T04:14:23Z",
        "pdf_link": "http://arxiv.org/pdf/1403.0156v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.0598v1",
        "title": "The Structurally Smoothed Graphlet Kernel",
        "summary": "  A commonly used paradigm for representing graphs is to use a vector that\ncontains normalized frequencies of occurrence of certain motifs or sub-graphs.\nThis vector representation can be used in a variety of applications, such as,\nfor computing similarity between graphs. The graphlet kernel of Shervashidze et\nal. [32] uses induced sub-graphs of k nodes (christened as graphlets by Przulj\n[28]) as motifs in the vector representation, and computes the kernel via a dot\nproduct between these vectors. One can easily show that this is a valid kernel\nbetween graphs. However, such a vector representation suffers from a few\ndrawbacks. As k becomes larger we encounter the sparsity problem; most higher\norder graphlets will not occur in a given graph. This leads to diagonal\ndominance, that is, a given graph is similar to itself but not to any other\ngraph in the dataset. On the other hand, since lower order graphlets tend to be\nmore numerous, using lower values of k does not provide enough discrimination\nability. We propose a smoothing technique to tackle the above problems. Our\nmethod is based on a novel extension of Kneser-Ney and Pitman-Yor smoothing\ntechniques from natural language processing to graphs. We use the relationships\nbetween lower order and higher order graphlets in order to derive our method.\nConsequently, our smoothing algorithm not only respects the dependency between\nsub-graphs but also tackles the diagonal dominance problem by distributing the\nprobability mass across graphlets. In our experiments, the smoothed graphlet\nkernel outperforms graph kernels based on raw frequency counts.\n",
        "published": "2014-03-03T21:20:14Z",
        "pdf_link": "http://arxiv.org/pdf/1403.0598v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.0628v2",
        "title": "Unconstrained Online Linear Learning in Hilbert Spaces: Minimax\n  Algorithms and Normal Approximations",
        "summary": "  We study algorithms for online linear optimization in Hilbert spaces,\nfocusing on the case where the player is unconstrained. We develop a novel\ncharacterization of a large class of minimax algorithms, recovering, and even\nimproving, several previous results as immediate corollaries. Moreover, using\nour tools, we develop an algorithm that provides a regret bound of\n$\\mathcal{O}\\Big(U \\sqrt{T \\log(U \\sqrt{T} \\log^2 T +1)}\\Big)$, where $U$ is\nthe $L_2$ norm of an arbitrary comparator and both $T$ and $U$ are unknown to\nthe player. This bound is optimal up to $\\sqrt{\\log \\log T}$ terms. When $T$ is\nknown, we derive an algorithm with an optimal regret bound (up to constant\nfactors). For both the known and unknown $T$ case, a Normal approximation to\nthe conditional value of the game proves to be the key analysis tool.\n",
        "published": "2014-03-03T23:06:24Z",
        "pdf_link": "http://arxiv.org/pdf/1403.0628v2"
    },
    {
        "id": "http://arxiv.org/abs/1403.1329v1",
        "title": "Integer Programming Relaxations for Integrated Clustering and Outlier\n  Detection",
        "summary": "  In this paper we present methods for exemplar based clustering with outlier\nselection based on the facility location formulation. Given a distance function\nand the number of outliers to be found, the methods automatically determine the\nnumber of clusters and outliers. We formulate the problem as an integer program\nto which we present relaxations that allow for solutions that scale to large\ndata sets. The advantages of combining clustering and outlier selection\ninclude: (i) the resulting clusters tend to be compact and semantically\ncoherent (ii) the clusters are more robust against data perturbations and (iii)\nthe outliers are contextualised by the clusters and more interpretable, i.e. it\nis easier to distinguish between outliers which are the result of data errors\nfrom those that may be indicative of a new pattern emergent in the data. We\npresent and contrast three relaxations to the integer program formulation: (i)\na linear programming formulation (LP) (ii) an extension of affinity propagation\nto outlier detection (APOC) and (iii) a Lagrangian duality based formulation\n(LD). Evaluation on synthetic as well as real data shows the quality and\nscalability of these different methods.\n",
        "published": "2014-03-06T02:42:22Z",
        "pdf_link": "http://arxiv.org/pdf/1403.1329v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.1942v2",
        "title": "Predictive Overlapping Co-Clustering",
        "summary": "  In the past few years co-clustering has emerged as an important data mining\ntool for two way data analysis. Co-clustering is more advantageous over\ntraditional one dimensional clustering in many ways such as, ability to find\nhighly correlated sub-groups of rows and columns. However, one of the\noverlooked benefits of co-clustering is that, it can be used to extract\nmeaningful knowledge for various other knowledge extraction purposes. For\nexample, building predictive models with high dimensional data and\nheterogeneous population is a non-trivial task. Co-clusters extracted from such\ndata, which shows similar pattern in both the dimension, can be used for a more\naccurate predictive model building. Several applications such as finding\npatient-disease cohorts in health care analysis, finding user-genre groups in\nrecommendation systems and community detection problems can benefit from\nco-clustering technique that utilizes the predictive power of the data to\ngenerate co-clusters for improved data analysis.\n  In this paper, we present the novel idea of Predictive Overlapping\nCo-Clustering (POCC) as an optimization problem for a more effective and\nimproved predictive analysis. Our algorithm generates optimal co-clusters by\nmaximizing predictive power of the co-clusters subject to the constraints on\nthe number of row and column clusters. In this paper precision, recall and\nf-measure have been used as evaluation measures of the resulting co-clusters.\nResults of our algorithm has been compared with two other well-known techniques\n- K-means and Spectral co-clustering, over four real data set namely, Leukemia,\nInternet-Ads, Ovarian cancer and MovieLens data set. The results demonstrate\nthe effectiveness and utility of our algorithm POCC in practice.\n",
        "published": "2014-03-08T07:07:12Z",
        "pdf_link": "http://arxiv.org/pdf/1403.1942v2"
    },
    {
        "id": "http://arxiv.org/abs/1403.1946v1",
        "title": "Improving Performance of a Group of Classification Algorithms Using\n  Resampling and Feature Selection",
        "summary": "  In recent years the importance of finding a meaningful pattern from huge\ndatasets has become more challenging. Data miners try to adopt innovative\nmethods to face this problem by applying feature selection methods. In this\npaper we propose a new hybrid method in which we use a combination of\nresampling, filtering the sample domain and wrapper subset evaluation method\nwith genetic search to reduce dimensions of Lung-Cancer dataset that we\nreceived from UCI Repository of Machine Learning databases. Finally, we apply\nsome well- known classification algorithms (Na\\\"ive Bayes, Logistic, Multilayer\nPerceptron, Best First Decision Tree and JRIP) to the resulting dataset and\ncompare the results and prediction rates before and after the application of\nour feature selection method on that dataset. The results show a substantial\nprogress in the average performance of five classification algorithms\nsimultaneously and the classification error for these classifiers decreases\nconsiderably. The experiments also show that this method outperforms other\nfeature selection methods with a lower cost.\n",
        "published": "2014-03-08T07:47:44Z",
        "pdf_link": "http://arxiv.org/pdf/1403.1946v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.2065v8",
        "title": "Categorization Axioms for Clustering Results",
        "summary": "  Cluster analysis has attracted more and more attention in the field of\nmachine learning and data mining. Numerous clustering algorithms have been\nproposed and are being developed due to diverse theories and various\nrequirements of emerging applications. Therefore, it is very worth establishing\nan unified axiomatic framework for data clustering. In the literature, it is an\nopen problem and has been proved very challenging. In this paper, clustering\nresults are axiomatized by assuming that an proper clustering result should\nsatisfy categorization axioms. The proposed axioms not only introduce\nclassification of clustering results and inequalities of clustering results,\nbut also are consistent with prototype theory and exemplar theory of\ncategorization models in cognitive science. Moreover, the proposed axioms lead\nto three principles of designing clustering algorithm and cluster validity\nindex, which follow many popular clustering algorithms and cluster validity\nindices.\n",
        "published": "2014-03-09T14:51:53Z",
        "pdf_link": "http://arxiv.org/pdf/1403.2065v8"
    },
    {
        "id": "http://arxiv.org/abs/1403.2372v1",
        "title": "A Hybrid Feature Selection Method to Improve Performance of a Group of\n  Classification Algorithms",
        "summary": "  In this paper a hybrid feature selection method is proposed which takes\nadvantages of wrapper subset evaluation with a lower cost and improves the\nperformance of a group of classifiers. The method uses combination of sample\ndomain filtering and resampling to refine the sample domain and two feature\nsubset evaluation methods to select reliable features. This method utilizes\nboth feature space and sample domain in two phases. The first phase filters and\nresamples the sample domain and the second phase adopts a hybrid procedure by\ninformation gain, wrapper subset evaluation and genetic search to find the\noptimal feature space. Experiments carried out on different types of datasets\nfrom UCI Repository of Machine Learning databases and the results show a rise\nin the average performance of five classifiers (Naive Bayes, Logistic,\nMultilayer Perceptron, Best First Decision Tree and JRIP) simultaneously and\nthe classification error for these classifiers decreases considerably. The\nexperiments also show that this method outperforms other feature selection\nmethods with a lower cost.\n",
        "published": "2014-03-08T08:04:29Z",
        "pdf_link": "http://arxiv.org/pdf/1403.2372v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.2950v1",
        "title": "Cancer Prognosis Prediction Using Balanced Stratified Sampling",
        "summary": "  High accuracy in cancer prediction is important to improve the quality of the\ntreatment and to improve the rate of survivability of patients. As the data\nvolume is increasing rapidly in the healthcare research, the analytical\nchallenge exists in double. The use of effective sampling technique in\nclassification algorithms always yields good prediction accuracy. The SEER\npublic use cancer database provides various prominent class labels for\nprognosis prediction. The main objective of this paper is to find the effect of\nsampling techniques in classifying the prognosis variable and propose an ideal\nsampling method based on the outcome of the experimentation. In the first phase\nof this work the traditional random sampling and stratified sampling techniques\nhave been used. At the next level the balanced stratified sampling with\nvariations as per the choice of the prognosis class labels have been tested.\nMuch of the initial time has been focused on performing the pre_processing of\nthe SEER data set. The classification model for experimentation has been built\nusing the breast cancer, respiratory cancer and mixed cancer data sets with\nthree traditional classifiers namely Decision Tree, Naive Bayes and K-Nearest\nNeighbor. The three prognosis factors survival, stage and metastasis have been\nused as class labels for experimental comparisons. The results shows a steady\nincrease in the prediction accuracy of balanced stratified model as the sample\nsize increases, but the traditional approach fluctuates before the optimum\nresults.\n",
        "published": "2014-03-12T14:33:43Z",
        "pdf_link": "http://arxiv.org/pdf/1403.2950v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.3465v3",
        "title": "A Survey of Algorithms and Analysis for Adaptive Online Learning",
        "summary": "  We present tools for the analysis of Follow-The-Regularized-Leader (FTRL),\nDual Averaging, and Mirror Descent algorithms when the regularizer\n(equivalently, prox-function or learning rate schedule) is chosen adaptively\nbased on the data. Adaptivity can be used to prove regret bounds that hold on\nevery round, and also allows for data-dependent regret bounds as in\nAdaGrad-style algorithms (e.g., Online Gradient Descent with adaptive\nper-coordinate learning rates). We present results from a large number of prior\nworks in a unified manner, using a modular and tight analysis that isolates the\nkey arguments in easily re-usable lemmas. This approach strengthens pre-viously\nknown FTRL analysis techniques to produce bounds as tight as those achieved by\npotential functions or primal-dual analysis. Further, we prove a general and\nexact equivalence between an arbitrary adaptive Mirror Descent algorithm and a\ncorrespond- ing FTRL update, which allows us to analyze any Mirror Descent\nalgorithm in the same framework. The key to bridging the gap between Dual\nAveraging and Mirror Descent algorithms lies in an analysis of the\nFTRL-Proximal algorithm family. Our regret bounds are proved in the most\ngeneral form, holding for arbitrary norms and non-smooth regularizers with\ntime-varying weight.\n",
        "published": "2014-03-14T00:25:03Z",
        "pdf_link": "http://arxiv.org/pdf/1403.3465v3"
    },
    {
        "id": "http://arxiv.org/abs/1403.3610v2",
        "title": "Making Risk Minimization Tolerant to Label Noise",
        "summary": "  In many applications, the training data, from which one needs to learn a\nclassifier, is corrupted with label noise. Many standard algorithms such as SVM\nperform poorly in presence of label noise. In this paper we investigate the\nrobustness of risk minimization to label noise. We prove a sufficient condition\non a loss function for the risk minimization under that loss to be tolerant to\nuniform label noise. We show that the $0-1$ loss, sigmoid loss, ramp loss and\nprobit loss satisfy this condition though none of the standard convex loss\nfunctions satisfy it. We also prove that, by choosing a sufficiently large\nvalue of a parameter in the loss function, the sigmoid loss, ramp loss and\nprobit loss can be made tolerant to non-uniform label noise also if we can\nassume the classes to be separable under noise-free data distribution. Through\nextensive empirical studies, we show that risk minimization under the $0-1$\nloss, the sigmoid loss and the ramp loss has much better robustness to label\nnoise when compared to the SVM algorithm.\n",
        "published": "2014-03-14T15:30:23Z",
        "pdf_link": "http://arxiv.org/pdf/1403.3610v2"
    },
    {
        "id": "http://arxiv.org/abs/1403.3628v1",
        "title": "Mixed-norm Regularization for Brain Decoding",
        "summary": "  This work investigates the use of mixed-norm regularization for sensor\nselection in Event-Related Potential (ERP) based Brain-Computer Interfaces\n(BCI). The classification problem is cast as a discriminative optimization\nframework where sensor selection is induced through the use of mixed-norms.\nThis framework is extended to the multi-task learning situation where several\nsimilar classification tasks related to different subjects are learned\nsimultaneously. In this case, multi-task learning helps in leveraging data\nscarcity issue yielding to more robust classifiers. For this purpose, we have\nintroduced a regularizer that induces both sensor selection and classifier\nsimilarities. The different regularization approaches are compared on three ERP\ndatasets showing the interest of mixed-norm regularization in terms of sensor\nselection. The multi-task approaches are evaluated when a small number of\nlearning examples are available yielding to significant performance\nimprovements especially for subjects performing poorly.\n",
        "published": "2014-03-14T16:15:24Z",
        "pdf_link": "http://arxiv.org/pdf/1403.3628v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.4224v2",
        "title": "Learning Negative Mixture Models by Tensor Decompositions",
        "summary": "  This work considers the problem of estimating the parameters of negative\nmixture models, i.e. mixture models that possibly involve negative weights. The\ncontributions of this paper are as follows. (i) We show that every rational\nprobability distributions on strings, a representation which occurs naturally\nin spectral learning, can be computed by a negative mixture of at most two\nprobabilistic automata (or HMMs). (ii) We propose a method to estimate the\nparameters of negative mixture models having a specific tensor structure in\ntheir low order observable moments. Building upon a recent paper on tensor\ndecompositions for learning latent variable models, we extend this work to the\nbroader setting of tensors having a symmetric decomposition with positive and\nnegative weights. We introduce a generalization of the tensor power method for\ncomplex valued tensors, and establish theoretical convergence guarantees. (iii)\nWe show how our approach applies to negative Gaussian mixture models, for which\nwe provide some experiments.\n",
        "published": "2014-03-17T19:35:06Z",
        "pdf_link": "http://arxiv.org/pdf/1403.4224v2"
    },
    {
        "id": "http://arxiv.org/abs/1403.4378v1",
        "title": "Spectral Clustering with Jensen-type kernels and their multi-point\n  extensions",
        "summary": "  Motivated by multi-distribution divergences, which originate in information\ntheory, we propose a notion of `multi-point' kernels, and study their\napplications. We study a class of kernels based on Jensen type divergences and\nshow that these can be extended to measure similarity among multiple points. We\nstudy tensor flattening methods and develop a multi-point (kernel) spectral\nclustering (MSC) method. We further emphasize on a special case of the proposed\nkernels, which is a multi-point extension of the linear (dot-product) kernel\nand show the existence of cubic time tensor flattening algorithm in this case.\nFinally, we illustrate the usefulness of our contributions using standard data\nsets and image segmentation tasks.\n",
        "published": "2014-03-18T09:04:02Z",
        "pdf_link": "http://arxiv.org/pdf/1403.4378v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.5115v1",
        "title": "Unconfused Ultraconservative Multiclass Algorithms",
        "summary": "  We tackle the problem of learning linear classifiers from noisy datasets in a\nmulticlass setting. The two-class version of this problem was studied a few\nyears ago by, e.g. Bylander (1994) and Blum et al. (1996): in these\ncontributions, the proposed approaches to fight the noise revolve around a\nPerceptron learning scheme fed with peculiar examples computed through a\nweighted average of points from the noisy training set. We propose to build\nupon these approaches and we introduce a new algorithm called UMA (for\nUnconfused Multiclass additive Algorithm) which may be seen as a generalization\nto the multiclass setting of the previous approaches. In order to characterize\nthe noise we use the confusion matrix as a multiclass extension of the\nclassification noise studied in the aforementioned literature. Theoretically\nwell-founded, UMA furthermore displays very good empirical noise robustness, as\nevidenced by numerical simulations conducted on both synthetic and real data.\nKeywords: Multiclass classification, Perceptron, Noisy labels, Confusion Matrix\n",
        "published": "2014-03-20T12:46:33Z",
        "pdf_link": "http://arxiv.org/pdf/1403.5115v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.5287v1",
        "title": "Online Local Learning via Semidefinite Programming",
        "summary": "  In many online learning problems we are interested in predicting local\ninformation about some universe of items. For example, we may want to know\nwhether two items are in the same cluster rather than computing an assignment\nof items to clusters; we may want to know which of two teams will win a game\nrather than computing a ranking of teams. Although finding the optimal\nclustering or ranking is typically intractable, it may be possible to predict\nthe relationships between items as well as if you could solve the global\noptimization problem exactly.\n  Formally, we consider an online learning problem in which a learner\nrepeatedly guesses a pair of labels (l(x), l(y)) and receives an adversarial\npayoff depending on those labels. The learner's goal is to receive a payoff\nnearly as good as the best fixed labeling of the items. We show that a simple\nalgorithm based on semidefinite programming can obtain asymptotically optimal\nregret in the case where the number of possible labels is O(1), resolving an\nopen problem posed by Hazan, Kale, and Shalev-Schwartz. Our main technical\ncontribution is a novel use and analysis of the log determinant regularizer,\nexploiting the observation that log det(A + I) upper bounds the entropy of any\ndistribution with covariance matrix A.\n",
        "published": "2014-03-20T20:36:18Z",
        "pdf_link": "http://arxiv.org/pdf/1403.5287v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.5341v2",
        "title": "An Information-Theoretic Analysis of Thompson Sampling",
        "summary": "  We provide an information-theoretic analysis of Thompson sampling that\napplies across a broad range of online optimization problems in which a\ndecision-maker must learn from partial feedback. This analysis inherits the\nsimplicity and elegance of information theory and leads to regret bounds that\nscale with the entropy of the optimal-action distribution. This strengthens\npreexisting results and yields new insight into how information improves\nperformance.\n",
        "published": "2014-03-21T01:42:53Z",
        "pdf_link": "http://arxiv.org/pdf/1403.5341v2"
    },
    {
        "id": "http://arxiv.org/abs/1403.5556v7",
        "title": "Learning to Optimize via Information-Directed Sampling",
        "summary": "  We propose information-directed sampling -- a new approach to online\noptimization problems in which a decision-maker must balance between\nexploration and exploitation while learning from partial feedback. Each action\nis sampled in a manner that minimizes the ratio between squared expected\nsingle-period regret and a measure of information gain: the mutual information\nbetween the optimal action and the next observation. We establish an expected\nregret bound for information-directed sampling that applies across a very\ngeneral class of models and scales with the entropy of the optimal action\ndistribution. We illustrate through simple analytic examples how\ninformation-directed sampling accounts for kinds of information that\nalternative approaches do not adequately address and that this can lead to\ndramatic performance gains. For the widely studied Bernoulli, Gaussian, and\nlinear bandit problems, we demonstrate state-of-the-art simulation performance.\n",
        "published": "2014-03-21T02:02:25Z",
        "pdf_link": "http://arxiv.org/pdf/1403.5556v7"
    },
    {
        "id": "http://arxiv.org/abs/1403.6863v1",
        "title": "Online Learning of k-CNF Boolean Functions",
        "summary": "  This paper revisits the problem of learning a k-CNF Boolean function from\nexamples in the context of online learning under the logarithmic loss. In doing\nso, we give a Bayesian interpretation to one of Valiant's celebrated PAC\nlearning algorithms, which we then build upon to derive two efficient, online,\nprobabilistic, supervised learning algorithms for predicting the output of an\nunknown k-CNF Boolean function. We analyze the loss of our methods, and show\nthat the cumulative log-loss can be upper bounded, ignoring logarithmic\nfactors, by a polynomial function of the size of each example.\n",
        "published": "2014-03-26T21:17:05Z",
        "pdf_link": "http://arxiv.org/pdf/1403.6863v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.7100v1",
        "title": "A study on cost behaviors of binary classification measures in\n  class-imbalanced problems",
        "summary": "  This work investigates into cost behaviors of binary classification measures\nin a background of class-imbalanced problems. Twelve performance measures are\nstudied, such as F measure, G-means in terms of accuracy rates, and of recall\nand precision, balance error rate (BER), Matthews correlation coefficient\n(MCC), Kappa coefficient, etc. A new perspective is presented for those\nmeasures by revealing their cost functions with respect to the class imbalance\nratio. Basically, they are described by four types of cost functions. The\nfunctions provides a theoretical understanding why some measures are suitable\nfor dealing with class-imbalanced problems. Based on their cost functions, we\nare able to conclude that G-means of accuracy rates and BER are suitable\nmeasures because they show \"proper\" cost behaviors in terms of \"a\nmisclassification from a small class will cause a greater cost than that from a\nlarge class\". On the contrary, F1 measure, G-means of recall and precision, MCC\nand Kappa coefficient measures do not produce such behaviors so that they are\nunsuitable to serve our goal in dealing with the problems properly.\n",
        "published": "2014-03-26T05:43:12Z",
        "pdf_link": "http://arxiv.org/pdf/1403.7100v1"
    },
    {
        "id": "http://arxiv.org/abs/1403.7471v3",
        "title": "Approximate Decentralized Bayesian Inference",
        "summary": "  This paper presents an approximate method for performing Bayesian inference\nin models with conditional independence over a decentralized network of\nlearning agents. The method first employs variational inference on each\nindividual learning agent to generate a local approximate posterior, the agents\ntransmit their local posteriors to other agents in the network, and finally\neach agent combines its set of received local posteriors. The key insight in\nthis work is that, for many Bayesian models, approximate inference schemes\ndestroy symmetry and dependencies in the model that are crucial to the correct\napplication of Bayes' rule when combining the local posteriors. The proposed\nmethod addresses this issue by including an additional optimization step in the\ncombination procedure that accounts for these broken dependencies. Experiments\non synthetic and real data demonstrate that the decentralized method provides\nadvantages in computational performance and predictive test likelihood over\nprevious batch and distributed methods.\n",
        "published": "2014-03-28T18:07:21Z",
        "pdf_link": "http://arxiv.org/pdf/1403.7471v3"
    },
    {
        "id": "http://arxiv.org/abs/1404.0138v1",
        "title": "Efficient Algorithms and Error Analysis for the Modified Nystrom Method",
        "summary": "  Many kernel methods suffer from high time and space complexities and are thus\nprohibitive in big-data applications. To tackle the computational challenge,\nthe Nystr\\\"om method has been extensively used to reduce time and space\ncomplexities by sacrificing some accuracy. The Nystr\\\"om method speedups\ncomputation by constructing an approximation of the kernel matrix using only a\nfew columns of the matrix. Recently, a variant of the Nystr\\\"om method called\nthe modified Nystr\\\"om method has demonstrated significant improvement over the\nstandard Nystr\\\"om method in approximation accuracy, both theoretically and\nempirically.\n  In this paper, we propose two algorithms that make the modified Nystr\\\"om\nmethod practical. First, we devise a simple column selection algorithm with a\nprovable error bound. Our algorithm is more efficient and easier to implement\nthan and nearly as accurate as the state-of-the-art algorithm. Second, with the\nselected columns at hand, we propose an algorithm that computes the\napproximation in lower time complexity than the approach in the previous work.\nFurthermore, we prove that the modified Nystr\\\"om method is exact under certain\nconditions, and we establish a lower error bound for the modified Nystr\\\"om\nmethod.\n",
        "published": "2014-04-01T06:26:55Z",
        "pdf_link": "http://arxiv.org/pdf/1404.0138v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.0649v1",
        "title": "A probabilistic estimation and prediction technique for dynamic\n  continuous social science models: The evolution of the attitude of the Basque\n  Country population towards ETA as a case study",
        "summary": "  In this paper, we present a computational technique to deal with uncertainty\nin dynamic continuous models in Social Sciences. Considering data from surveys,\nthe method consists of determining the probability distribution of the survey\noutput and this allows to sample data and fit the model to the sampled data\nusing a goodness-of-fit criterion based on the chi-square-test. Taking the\nfitted parameters non-rejected by the chi-square-test, substituting them into\nthe model and computing their outputs, we build 95% confidence intervals in\neach time instant capturing uncertainty of the survey data (probabilistic\nestimation). Using the same set of obtained model parameters, we also provide a\nprediction over the next few years with 95% confidence intervals (probabilistic\nprediction). This technique is applied to a dynamic social model describing the\nevolution of the attitude of the Basque Country population towards the\nrevolutionary organization ETA.\n",
        "published": "2014-03-30T20:49:33Z",
        "pdf_link": "http://arxiv.org/pdf/1404.0649v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.0789v3",
        "title": "The Least Wrong Model Is Not in the Data",
        "summary": "  The true process that generated data cannot be determined when multiple\nexplanations are possible. Prediction requires a model of the probability that\na process, chosen randomly from the set of candidate explanations, generates\nsome future observation. The best model includes all of the information\ncontained in the minimal description of the data that is not contained in the\ndata. It is closely related to the Halting Problem and is logarithmic in the\nsize of the data. Prediction is difficult because the ideal model is not\ncomputable, and the best computable model is not \"findable.\" However, the error\nfrom any approximation can be bounded by the size of the description using the\nmodel.\n",
        "published": "2014-04-03T07:41:46Z",
        "pdf_link": "http://arxiv.org/pdf/1404.0789v3"
    },
    {
        "id": "http://arxiv.org/abs/1404.0933v1",
        "title": "Bayes and Naive Bayes Classifier",
        "summary": "  The Bayesian Classification represents a supervised learning method as well\nas a statistical method for classification. Assumes an underlying probabilistic\nmodel and it allows us to capture uncertainty about the model in a principled\nway by determining probabilities of the outcomes. This Classification is named\nafter Thomas Bayes (1702-1761), who proposed the Bayes Theorem. Bayesian\nclassification provides practical learning algorithms and prior knowledge and\nobserved data can be combined. Bayesian Classification provides a useful\nperspective for understanding and evaluating many learning algorithms. It\ncalculates explicit probabilities for hypothesis and it is robust to noise in\ninput data. In statistical classification the Bayes classifier minimises the\nprobability of misclassification. That was a visual intuition for a simple case\nof the Bayes classifier, also called: 1)Idiot Bayes 2)Naive Bayes 3)Simple\nBayes\n",
        "published": "2014-04-03T14:34:47Z",
        "pdf_link": "http://arxiv.org/pdf/1404.0933v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.1066v1",
        "title": "Parallel Support Vector Machines in Practice",
        "summary": "  In this paper, we evaluate the performance of various parallel optimization\nmethods for Kernel Support Vector Machines on multicore CPUs and GPUs. In\nparticular, we provide the first comparison of algorithms with explicit and\nimplicit parallelization. Most existing parallel implementations for multi-core\nor GPU architectures are based on explicit parallelization of Sequential\nMinimal Optimization (SMO)---the programmers identified parallelizable\ncomponents and hand-parallelized them, specifically tuned for a particular\narchitecture. We compare these approaches with each other and with implicitly\nparallelized algorithms---where the algorithm is expressed such that most of\nthe work is done within few iterations with large dense linear algebra\noperations. These can be computed with highly-optimized libraries, that are\ncarefully parallelized for a large variety of parallel platforms. We highlight\nthe advantages and disadvantages of both approaches and compare them on various\nbenchmark data sets. We find an approximate implicitly parallel algorithm which\nis surprisingly efficient, permits a much simpler implementation, and leads to\nunprecedented speedups in SVM training.\n",
        "published": "2014-04-03T19:49:57Z",
        "pdf_link": "http://arxiv.org/pdf/1404.1066v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.1282v3",
        "title": "Hierarchical Dirichlet Scaling Process",
        "summary": "  We present the \\textit{hierarchical Dirichlet scaling process} (HDSP), a\nBayesian nonparametric mixed membership model. The HDSP generalizes the\nhierarchical Dirichlet process (HDP) to model the correlation structure between\nmetadata in the corpus and mixture components. We construct the HDSP based on\nthe normalized gamma representation of the Dirichlet process, and this\nconstruction allows incorporating a scaling function that controls the\nmembership probabilities of the mixture components. We develop two scaling\nmethods to demonstrate that different modeling assumptions can be expressed in\nthe HDSP. We also derive the corresponding approximate posterior inference\nalgorithms using variational Bayes. Through experiments on datasets of\nnewswire, medical journal articles, conference proceedings, and product\nreviews, we show that the HDSP results in a better predictive performance than\nlabeled LDA, partially labeled LDA, and author topic model and a better\nnegative review classification performance than the supervised topic model and\nSVM.\n",
        "published": "2014-03-22T06:25:51Z",
        "pdf_link": "http://arxiv.org/pdf/1404.1282v3"
    },
    {
        "id": "http://arxiv.org/abs/1404.1491v1",
        "title": "An Efficient Feature Selection in Classification of Audio Files",
        "summary": "  In this paper we have focused on an efficient feature selection method in\nclassification of audio files. The main objective is feature selection and\nextraction. We have selected a set of features for further analysis, which\nrepresents the elements in feature vector. By extraction method we can compute\na numerical representation that can be used to characterize the audio using the\nexisting toolbox. In this study Gain Ratio (GR) is used as a feature selection\nmeasure. GR is used to select splitting attribute which will separate the\ntuples into different classes. The pulse clarity is considered as a subjective\nmeasure and it is used to calculate the gain of features of audio files. The\nsplitting criterion is employed in the application to identify the class or the\nmusic genre of a specific audio file from testing database. Experimental\nresults indicate that by using GR the application can produce a satisfactory\nresult for music genre classification. After dimensionality reduction best\nthree features have been selected out of various features of audio file and in\nthis technique we will get more than 90% successful classification result.\n",
        "published": "2014-03-24T16:05:26Z",
        "pdf_link": "http://arxiv.org/pdf/1404.1491v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.2948v1",
        "title": "Gradient-based Laplacian Feature Selection",
        "summary": "  Analysis of high dimensional noisy data is of essence across a variety of\nresearch fields. Feature selection techniques are designed to find the relevant\nfeature subset that can facilitate classification or pattern detection.\nTraditional (supervised) feature selection methods utilize label information to\nguide the identification of relevant feature subsets. In this paper, however,\nwe consider the unsupervised feature selection problem. Without the label\ninformation, it is particularly difficult to identify a small set of relevant\nfeatures due to the noisy nature of real-world data which corrupts the\nintrinsic structure of the data. Our Gradient-based Laplacian Feature Selection\n(GLFS) selects important features by minimizing the variance of the Laplacian\nregularized least squares regression model. With $\\ell_1$ relaxation, GLFS can\nfind a sparse subset of features that is relevant to the Laplacian manifolds.\nExtensive experiments on simulated, three real-world object recognition and two\ncomputational biology datasets, have illustrated the power and superior\nperformance of our approach over multiple state-of-the-art unsupervised feature\nselection methods. Additionally, we show that GLFS selects a sparser set of\nmore relevant features in a supervised setting outperforming the popular\nelastic net methodology.\n",
        "published": "2014-04-10T20:49:35Z",
        "pdf_link": "http://arxiv.org/pdf/1404.2948v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.3190v1",
        "title": "Pareto-Path Multi-Task Multiple Kernel Learning",
        "summary": "  A traditional and intuitively appealing Multi-Task Multiple Kernel Learning\n(MT-MKL) method is to optimize the sum (thus, the average) of objective\nfunctions with (partially) shared kernel function, which allows information\nsharing amongst tasks. We point out that the obtained solution corresponds to a\nsingle point on the Pareto Front (PF) of a Multi-Objective Optimization (MOO)\nproblem, which considers the concurrent optimization of all task objectives\ninvolved in the Multi-Task Learning (MTL) problem. Motivated by this last\nobservation and arguing that the former approach is heuristic, we propose a\nnovel Support Vector Machine (SVM) MT-MKL framework, that considers an\nimplicitly-defined set of conic combinations of task objectives. We show that\nsolving our framework produces solutions along a path on the aforementioned PF\nand that it subsumes the optimization of the average of objective functions as\na special case. Using algorithms we derived, we demonstrate through a series of\nexperimental results that the framework is capable of achieving better\nclassification performance, when compared to other similar MTL approaches.\n",
        "published": "2014-04-11T19:15:22Z",
        "pdf_link": "http://arxiv.org/pdf/1404.3190v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.4038v2",
        "title": "Discovering and Exploiting Entailment Relationships in Multi-Label\n  Learning",
        "summary": "  This work presents a sound probabilistic method for enforcing adherence of\nthe marginal probabilities of a multi-label model to automatically discovered\ndeterministic relationships among labels. In particular we focus on discovering\ntwo kinds of relationships among the labels. The first one concerns pairwise\npositive entailement: pairs of labels, where the presence of one implies the\npresence of the other in all instances of a dataset. The second concerns\nexclusion: sets of labels that do not coexist in the same instances of the\ndataset. These relationships are represented with a Bayesian network. Marginal\nprobabilities are entered as soft evidence in the network and adjusted through\nprobabilistic inference. Our approach offers robust improvements in mean\naverage precision compared to the standard binary relavance approach across all\n12 datasets involved in our experiments. The discovery process helps\ninteresting implicit knowledge to emerge, which could be useful in itself.\n",
        "published": "2014-04-15T19:47:15Z",
        "pdf_link": "http://arxiv.org/pdf/1404.4038v2"
    },
    {
        "id": "http://arxiv.org/abs/1404.4088v1",
        "title": "Ensemble Classifiers and Their Applications: A Review",
        "summary": "  Ensemble classifier refers to a group of individual classifiers that are\ncooperatively trained on data set in a supervised classification problem. In\nthis paper we present a review of commonly used ensemble classifiers in the\nliterature. Some ensemble classifiers are also developed targeting specific\napplications. We also present some application driven ensemble classifiers in\nthis paper.\n",
        "published": "2014-04-15T21:35:48Z",
        "pdf_link": "http://arxiv.org/pdf/1404.4088v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.4108v2",
        "title": "Representation as a Service",
        "summary": "  Consider a Machine Learning Service Provider (MLSP) designed to rapidly\ncreate highly accurate learners for a never-ending stream of new tasks. The\nchallenge is to produce task-specific learners that can be trained from few\nlabeled samples, even if tasks are not uniquely identified, and the number of\ntasks and input dimensionality are large. In this paper, we argue that the MLSP\nshould exploit knowledge from previous tasks to build a good representation of\nthe environment it is in, and more precisely, that useful representations for\nsuch a service are ones that minimize generalization error for a new hypothesis\ntrained on a new task. We formalize this intuition with a novel method that\nminimizes an empirical proxy of the intra-task small-sample generalization\nerror. We present several empirical results showing state-of-the art\nperformance on single-task transfer, multitask learning, and the full lifelong\nlearning problem.\n",
        "published": "2014-02-24T15:17:39Z",
        "pdf_link": "http://arxiv.org/pdf/1404.4108v2"
    },
    {
        "id": "http://arxiv.org/abs/1404.4114v3",
        "title": "Structured Stochastic Variational Inference",
        "summary": "  Stochastic variational inference makes it possible to approximate posterior\ndistributions induced by large datasets quickly using stochastic optimization.\nThe algorithm relies on the use of fully factorized variational distributions.\nHowever, this \"mean-field\" independence approximation limits the fidelity of\nthe posterior approximation, and introduces local optima. We show how to relax\nthe mean-field approximation to allow arbitrary dependencies between global\nparameters and local hidden variables, producing better parameter estimates by\nreducing bias, sensitivity to local optima, and sensitivity to hyperparameters.\n",
        "published": "2014-04-16T00:12:03Z",
        "pdf_link": "http://arxiv.org/pdf/1404.4114v3"
    },
    {
        "id": "http://arxiv.org/abs/1404.4171v1",
        "title": "Dropout Training for Support Vector Machines",
        "summary": "  Dropout and other feature noising schemes have shown promising results in\ncontrolling over-fitting by artificially corrupting the training data. Though\nextensive theoretical and empirical studies have been performed for generalized\nlinear models, little work has been done for support vector machines (SVMs),\none of the most successful approaches for supervised learning. This paper\npresents dropout training for linear SVMs. To deal with the intractable\nexpectation of the non-smooth hinge loss under corrupting distributions, we\ndevelop an iteratively re-weighted least square (IRLS) algorithm by exploring\ndata augmentation techniques. Our algorithm iteratively minimizes the\nexpectation of a re-weighted least square problem, where the re-weights have\nclosed-form solutions. The similar ideas are applied to develop a new IRLS\nalgorithm for the expected logistic loss under corrupting distributions. Our\nalgorithms offer insights on the connection and difference between the hinge\nloss and logistic loss in dropout training. Empirical results on several real\ndatasets demonstrate the effectiveness of dropout training on significantly\nboosting the classification accuracy of linear SVMs.\n",
        "published": "2014-04-16T08:54:01Z",
        "pdf_link": "http://arxiv.org/pdf/1404.4171v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.4960v2",
        "title": "Agent Behavior Prediction and Its Generalization Analysis",
        "summary": "  Machine learning algorithms have been applied to predict agent behaviors in\nreal-world dynamic systems, such as advertiser behaviors in sponsored search\nand worker behaviors in crowdsourcing. The behavior data in these systems are\ngenerated by live agents: once the systems change due to the adoption of the\nprediction models learnt from the behavior data, agents will observe and\nrespond to these changes by changing their own behaviors accordingly. As a\nresult, the behavior data will evolve and will not be identically and\nindependently distributed, posing great challenges to the theoretical analysis\non the machine learning algorithms for behavior prediction. To tackle this\nchallenge, in this paper, we propose to use Markov Chain in Random Environments\n(MCRE) to describe the behavior data, and perform generalization analysis of\nthe machine learning algorithms on its basis. Since the one-step transition\nprobability matrix of MCRE depends on both previous states and the random\nenvironment, conventional techniques for generalization analysis cannot be\ndirectly applied. To address this issue, we propose a novel technique that\ntransforms the original MCRE into a higher-dimensional time-homogeneous Markov\nchain. The new Markov chain involves more variables but is more regular, and\nthus easier to deal with. We prove the convergence of the new Markov chain when\ntime approaches infinity. Then we prove a generalization bound for the machine\nlearning algorithms on the behavior data generated by the new Markov chain,\nwhich depends on both the Markovian parameters and the covering number of the\nfunction class compounded by the loss function for behavior prediction and the\nbehavior prediction model. To the best of our knowledge, this is the first work\nthat performs the generalization analysis on data generated by complex\nprocesses in real-world dynamic systems.\n",
        "published": "2014-04-19T14:57:54Z",
        "pdf_link": "http://arxiv.org/pdf/1404.4960v2"
    },
    {
        "id": "http://arxiv.org/abs/1404.5065v1",
        "title": "Multi-Target Regression via Random Linear Target Combinations",
        "summary": "  Multi-target regression is concerned with the simultaneous prediction of\nmultiple continuous target variables based on the same set of input variables.\nIt arises in several interesting industrial and environmental application\ndomains, such as ecological modelling and energy forecasting. This paper\npresents an ensemble method for multi-target regression that constructs new\ntarget variables via random linear combinations of existing targets. We discuss\nthe connection of our approach with multi-label classification algorithms, in\nparticular RA$k$EL, which originally inspired this work, and a family of recent\nmulti-label classification algorithms that involve output coding. Experimental\nresults on 12 multi-target datasets show that it performs significantly better\nthan a strong baseline that learns a single model for each target using\ngradient boosting and compares favourably to multi-objective random forest\napproach, which is a state-of-the-art approach. The experiments further show\nthat our approach improves more when stronger unconditional dependencies exist\namong the targets.\n",
        "published": "2014-04-20T19:17:23Z",
        "pdf_link": "http://arxiv.org/pdf/1404.5065v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.5511v1",
        "title": "Coactive Learning for Locally Optimal Problem Solving",
        "summary": "  Coactive learning is an online problem solving setting where the solutions\nprovided by a solver are interactively improved by a domain expert, which in\nturn drives learning. In this paper we extend the study of coactive learning to\nproblems where obtaining a globally optimal or near-optimal solution may be\nintractable or where an expert can only be expected to make small, local\nimprovements to a candidate solution. The goal of learning in this new setting\nis to minimize the cost as measured by the expert effort over time. We first\nestablish theoretical bounds on the average cost of the existing coactive\nPerceptron algorithm. In addition, we consider new online algorithms that use\ncost-sensitive and Passive-Aggressive (PA) updates, showing similar or improved\ntheoretical bounds. We provide an empirical evaluation of the learners in\nvarious domains, which show that the Perceptron based algorithms are quite\neffective and that unlike the case for online classification, the PA algorithms\ndo not yield significant performance gains.\n",
        "published": "2014-04-18T21:17:04Z",
        "pdf_link": "http://arxiv.org/pdf/1404.5511v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.6163v2",
        "title": "Overlapping Trace Norms in Multi-View Learning",
        "summary": "  Multi-view learning leverages correlations between different sources of data\nto make predictions in one view based on observations in another view. A\npopular approach is to assume that, both, the correlations between the views\nand the view-specific covariances have a low-rank structure, leading to\ninter-battery factor analysis, a model closely related to canonical correlation\nanalysis. We propose a convex relaxation of this model using structured norm\nregularization. Further, we extend the convex formulation to a robust version\nby adding an l1-penalized matrix to our estimator, similarly to convex robust\nPCA. We develop and compare scalable algorithms for several convex multi-view\nmodels. We show experimentally that the view-specific correlations are\nimproving data imputation performances, as well as labeling accuracy in\nreal-world multi-label prediction tasks.\n",
        "published": "2014-04-24T15:50:02Z",
        "pdf_link": "http://arxiv.org/pdf/1404.6163v2"
    },
    {
        "id": "http://arxiv.org/abs/1404.6580v2",
        "title": "Multitask Learning for Sequence Labeling Tasks",
        "summary": "  In this paper, we present a learning method for sequence labeling tasks in\nwhich each example sequence has multiple label sequences. Our method learns\nmultiple models, one model for each label sequence. Each model computes the\njoint probability of all label sequences given the example sequence. Although\neach model considers all label sequences, its primary focus is only one label\nsequence, and therefore, each model becomes a task-specific model, for the task\nbelonging to that primary label. Such multiple models are learned {\\it\nsimultaneously} by facilitating the learning transfer among models through {\\it\nexplicit parameter sharing}. We experiment the proposed method on two\napplications and show that our method significantly outperforms the\nstate-of-the-art method.\n",
        "published": "2014-04-25T22:59:34Z",
        "pdf_link": "http://arxiv.org/pdf/1404.6580v2"
    },
    {
        "id": "http://arxiv.org/abs/1404.6674v1",
        "title": "A Comparison of First-order Algorithms for Machine Learning",
        "summary": "  Using an optimization algorithm to solve a machine learning problem is one of\nmainstreams in the field of science. In this work, we demonstrate a\ncomprehensive comparison of some state-of-the-art first-order optimization\nalgorithms for convex optimization problems in machine learning. We concentrate\non several smooth and non-smooth machine learning problems with a loss function\nplus a regularizer. The overall experimental results show the superiority of\nprimal-dual algorithms in solving a machine learning problem from the\nperspectives of the ease to construct, running time and accuracy.\n",
        "published": "2014-04-26T19:24:24Z",
        "pdf_link": "http://arxiv.org/pdf/1404.6674v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.7195v1",
        "title": "Fast Approximation of Rotations and Hessians matrices",
        "summary": "  A new method to represent and approximate rotation matrices is introduced.\nThe method represents approximations of a rotation matrix $Q$ with linearithmic\ncomplexity, i.e. with $\\frac{1}{2}n\\lg(n)$ rotations over pairs of coordinates,\narranged in an FFT-like fashion. The approximation is \"learned\" using gradient\ndescent. It allows to represent symmetric matrices $H$ as $QDQ^T$ where $D$ is\na diagonal matrix. It can be used to approximate covariance matrix of Gaussian\nmodels in order to speed up inference, or to estimate and track the inverse\nHessian of an objective function by relating changes in parameters to changes\nin gradient along the trajectory followed by the optimization procedure.\nExperiments were conducted to approximate synthetic matrices, covariance\nmatrices of real data, and Hessian matrices of objective functions involved in\nmachine learning problems.\n",
        "published": "2014-04-29T00:08:15Z",
        "pdf_link": "http://arxiv.org/pdf/1404.7195v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.7255v1",
        "title": "Meteorological time series forecasting based on MLP modelling using\n  heterogeneous transfer functions",
        "summary": "  In this paper, we propose to study four meteorological and seasonal time\nseries coupled with a multi-layer perceptron (MLP) modeling. We chose to\ncombine two transfer functions for the nodes of the hidden layer, and to use a\ntemporal indicator (time index as input) in order to take into account the\nseasonal aspect of the studied time series. The results of the prediction\nconcern two years of measurements and the learning step, eight independent\nyears. We show that this methodology can improve the accuracy of meteorological\ndata estimation compared to a classical MLP modelling with a homogenous\ntransfer function.\n",
        "published": "2014-04-29T06:43:19Z",
        "pdf_link": "http://arxiv.org/pdf/1404.7255v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.7472v1",
        "title": "Implementing spectral methods for hidden Markov models with real-valued\n  emissions",
        "summary": "  Hidden Markov models (HMMs) are widely used statistical models for modeling\nsequential data. The parameter estimation for HMMs from time series data is an\nimportant learning problem. The predominant methods for parameter estimation\nare based on local search heuristics, most notably the expectation-maximization\n(EM) algorithm. These methods are prone to local optima and oftentimes suffer\nfrom high computational and sample complexity. Recent years saw the emergence\nof spectral methods for the parameter estimation of HMMs, based on a method of\nmoments approach. Two spectral learning algorithms as proposed by Hsu, Kakade\nand Zhang 2012 (arXiv:0811.4413) and Anandkumar, Hsu and Kakade 2012\n(arXiv:1203.0683) are assessed in this work. Using experiments with synthetic\ndata, the algorithms are compared with each other. Furthermore, the spectral\nmethods are compared to the Baum-Welch algorithm, a well-established method\napplying the EM algorithm to HMMs. The spectral algorithms are found to have a\nmuch more favorable computational and sample complexity. Even though the\nalgorithms readily handle high dimensional observation spaces, instability\nissues are encountered in this regime. In view of learning from real-world\nexperimental data, the representation of real-valued observations for the use\nin spectral methods is discussed, presenting possible methods to represent data\nfor the use in the learning algorithms.\n",
        "published": "2014-04-29T19:28:09Z",
        "pdf_link": "http://arxiv.org/pdf/1404.7472v1"
    },
    {
        "id": "http://arxiv.org/abs/1404.7527v2",
        "title": "A Map of Update Constraints in Inductive Inference",
        "summary": "  We investigate how different learning restrictions reduce learning power and\nhow the different restrictions relate to one another. We give a complete map\nfor nine different restrictions both for the cases of complete information\nlearning and set-driven learning. This completes the picture for these\nwell-studied \\emph{delayable} learning restrictions. A further insight is\ngained by different characterizations of \\emph{conservative} learning in terms\nof variants of \\emph{cautious} learning.\n  Our analyses greatly benefit from general theorems we give, for example\nshowing that learners with exclusively delayable restrictions can always be\nassumed total.\n",
        "published": "2014-04-29T20:54:40Z",
        "pdf_link": "http://arxiv.org/pdf/1404.7527v2"
    },
    {
        "id": "http://arxiv.org/abs/1407.0107v3",
        "title": "Randomized Block Coordinate Descent for Online and Stochastic\n  Optimization",
        "summary": "  Two types of low cost-per-iteration gradient descent methods have been\nextensively studied in parallel. One is online or stochastic gradient descent\n(OGD/SGD), and the other is randomzied coordinate descent (RBCD). In this\npaper, we combine the two types of methods together and propose online\nrandomized block coordinate descent (ORBCD). At each iteration, ORBCD only\ncomputes the partial gradient of one block coordinate of one mini-batch\nsamples. ORBCD is well suited for the composite minimization problem where one\nfunction is the average of the losses of a large number of samples and the\nother is a simple regularizer defined on high dimensional variables. We show\nthat the iteration complexity of ORBCD has the same order as OGD or SGD. For\nstrongly convex functions, by reducing the variance of stochastic gradients, we\nshow that ORBCD can converge at a geometric rate in expectation, matching the\nconvergence rate of SGD with variance reduction and RBCD.\n",
        "published": "2014-07-01T05:57:43Z",
        "pdf_link": "http://arxiv.org/pdf/1407.0107v3"
    },
    {
        "id": "http://arxiv.org/abs/1407.1082v1",
        "title": "Online Submodular Maximization under a Matroid Constraint with\n  Application to Learning Assignments",
        "summary": "  Which ads should we display in sponsored search in order to maximize our\nrevenue? How should we dynamically rank information sources to maximize the\nvalue of the ranking? These applications exhibit strong diminishing returns:\nRedundancy decreases the marginal utility of each ad or information source. We\nshow that these and other problems can be formalized as repeatedly selecting an\nassignment of items to positions to maximize a sequence of monotone submodular\nfunctions that arrive one by one. We present an efficient algorithm for this\ngeneral problem and analyze it in the no-regret model. Our algorithm possesses\nstrong theoretical guarantees, such as a performance ratio that converges to\nthe optimal constant of 1 - 1/e. We empirically evaluate our algorithm on two\nreal-world online optimization problems on the web: ad allocation with\nsubmodular utilities, and dynamically ranking blogs to detect information\ncascades. Finally, we present a second algorithm that handles the more general\ncase in which the feasible sets are given by a matroid constraint, while still\nmaintaining a 1 - 1/e asymptotic performance ratio.\n",
        "published": "2014-07-03T23:06:10Z",
        "pdf_link": "http://arxiv.org/pdf/1407.1082v1"
    },
    {
        "id": "http://arxiv.org/abs/1407.1538v1",
        "title": "Large-Scale Multi-Label Learning with Incomplete Label Assignments",
        "summary": "  Multi-label learning deals with the classification problems where each\ninstance can be assigned with multiple labels simultaneously. Conventional\nmulti-label learning approaches mainly focus on exploiting label correlations.\nIt is usually assumed, explicitly or implicitly, that the label sets for\ntraining instances are fully labeled without any missing labels. However, in\nmany real-world multi-label datasets, the label assignments for training\ninstances can be incomplete. Some ground-truth labels can be missed by the\nlabeler from the label set. This problem is especially typical when the number\ninstances is very large, and the labeling cost is very high, which makes it\nalmost impossible to get a fully labeled training set. In this paper, we study\nthe problem of large-scale multi-label learning with incomplete label\nassignments. We propose an approach, called MPU, based upon positive and\nunlabeled stochastic gradient descent and stacked models. Unlike prior works,\nour method can effectively and efficiently consider missing labels and label\ncorrelations simultaneously, and is very scalable, that has linear time\ncomplexities over the size of the data. Extensive experiments on two real-world\nmulti-label datasets show that our MPU model consistently outperform other\ncommonly-used baselines.\n",
        "published": "2014-07-06T20:13:48Z",
        "pdf_link": "http://arxiv.org/pdf/1407.1538v1"
    },
    {
        "id": "http://arxiv.org/abs/1407.2538v3",
        "title": "Learning Deep Structured Models",
        "summary": "  Many problems in real-world applications involve predicting several random\nvariables which are statistically related. Markov random fields (MRFs) are a\ngreat mathematical tool to encode such relationships. The goal of this paper is\nto combine MRFs with deep learning algorithms to estimate complex\nrepresentations while taking into account the dependencies between the output\nrandom variables. Towards this goal, we propose a training algorithm that is\nable to learn structured models jointly with deep features that form the MRF\npotentials. Our approach is efficient as it blends learning and inference and\nmakes use of GPU acceleration. We demonstrate the effectiveness of our\nalgorithm in the tasks of predicting words from noisy images, as well as\nmulti-class classification of Flickr photographs. We show that joint learning\nof the deep features and the MRF parameters results in significant performance\ngains.\n",
        "published": "2014-07-09T15:54:27Z",
        "pdf_link": "http://arxiv.org/pdf/1407.2538v3"
    },
    {
        "id": "http://arxiv.org/abs/1407.2736v1",
        "title": "A multi-instance learning algorithm based on a stacked ensemble of lazy\n  learners",
        "summary": "  This document describes a novel learning algorithm that classifies \"bags\" of\ninstances rather than individual instances. A bag is labeled positive if it\ncontains at least one positive instance (which may or may not be specifically\nidentified), and negative otherwise. This class of problems is known as\nmulti-instance learning problems, and is useful in situations where the class\nlabel at an instance level may be unavailable or imprecise or difficult to\nobtain, or in situations where the problem is naturally posed as one of\nclassifying instance groups. The algorithm described here is an ensemble-based\nmethod, wherein the members of the ensemble are lazy learning classifiers\nlearnt using the Citation Nearest Neighbour method. Diversity among the\nensemble members is achieved by optimizing their parameters using a\nmulti-objective optimization method, with the objectives being to maximize\nClass 1 accuracy and minimize false positive rate. The method has been found to\nbe effective on the Musk1 benchmark dataset.\n",
        "published": "2014-07-10T09:39:24Z",
        "pdf_link": "http://arxiv.org/pdf/1407.2736v1"
    },
    {
        "id": "http://arxiv.org/abs/1407.4422v1",
        "title": "Subspace Restricted Boltzmann Machine",
        "summary": "  The subspace Restricted Boltzmann Machine (subspaceRBM) is a third-order\nBoltzmann machine where multiplicative interactions are between one visible and\ntwo hidden units. There are two kinds of hidden units, namely, gate units and\nsubspace units. The subspace units reflect variations of a pattern in data and\nthe gate unit is responsible for activating the subspace units. Additionally,\nthe gate unit can be seen as a pooling feature. We evaluate the behavior of\nsubspaceRBM through experiments with MNIST digit recognition task, measuring\nreconstruction error and classification error.\n",
        "published": "2014-07-16T18:50:40Z",
        "pdf_link": "http://arxiv.org/pdf/1407.4422v1"
    },
    {
        "id": "http://arxiv.org/abs/1407.4668v1",
        "title": "A feature construction framework based on outlier detection and\n  discriminative pattern mining",
        "summary": "  No matter the expressive power and sophistication of supervised learning\nalgorithms, their effectiveness is restricted by the features describing the\ndata. This is not a new insight in ML and many methods for feature selection,\ntransformation, and construction have been developed. But while this is\non-going for general techniques for feature selection and transformation, i.e.\ndimensionality reduction, work on feature construction, i.e. enriching the\ndata, is by now mainly the domain of image, particularly character,\nrecognition, and NLP.\n  In this work, we propose a new general framework for feature construction.\nThe need for feature construction in a data set is indicated by class outliers\nand discriminative pattern mining used to derive features on their\nk-neighborhoods. We instantiate the framework with LOF and C4.5-Rules, and\nevaluate the usefulness of the derived features on a diverse collection of UCI\ndata sets. The derived features are more often useful than ones derived by\nDC-Fringe, and our approach is much less likely to overfit. But while a weak\nlearner, Naive Bayes, benefits strongly from the feature construction, the\neffect is less pronounced for C4.5, and almost vanishes for an SVM leaner.\n  Keywords: feature construction, classification, outlier detection\n",
        "published": "2014-07-17T13:51:55Z",
        "pdf_link": "http://arxiv.org/pdf/1407.4668v1"
    },
    {
        "id": "http://arxiv.org/abs/1407.5908v1",
        "title": "Exploiting Smoothness in Statistical Learning, Sequential Prediction,\n  and Stochastic Optimization",
        "summary": "  In the last several years, the intimate connection between convex\noptimization and learning problems, in both statistical and sequential\nframeworks, has shifted the focus of algorithmic machine learning to examine\nthis interplay. In particular, on one hand, this intertwinement brings forward\nnew challenges in reassessment of the performance of learning algorithms\nincluding generalization and regret bounds under the assumptions imposed by\nconvexity such as analytical properties of loss functions (e.g., Lipschitzness,\nstrong convexity, and smoothness). On the other hand, emergence of datasets of\nan unprecedented size, demands the development of novel and more efficient\noptimization algorithms to tackle large-scale learning problems.\n  The overarching goal of this thesis is to reassess the smoothness of loss\nfunctions in statistical learning, sequential prediction/online learning, and\nstochastic optimization and explicate its consequences. In particular we\nexamine how smoothness of loss function could be beneficial or detrimental in\nthese settings in terms of sample complexity, statistical consistency, regret\nanalysis, and convergence rate, and investigate how smoothness can be leveraged\nto devise more efficient learning algorithms.\n",
        "published": "2014-07-19T15:16:40Z",
        "pdf_link": "http://arxiv.org/pdf/1407.5908v1"
    },
    {
        "id": "http://arxiv.org/abs/1407.7449v1",
        "title": "A Fast Synchronization Clustering Algorithm",
        "summary": "  This paper presents a Fast Synchronization Clustering algorithm (FSynC),\nwhich is an improved version of SynC algorithm. In order to decrease the time\ncomplexity of the original SynC algorithm, we combine grid cell partitioning\nmethod and Red-Black tree to construct the near neighbor point set of every\npoint. By simulated experiments of some artificial data sets and several real\ndata sets, we observe that FSynC algorithm can often get less time than SynC\nalgorithm for many kinds of data sets. At last, it gives some research\nexpectations to popularize this algorithm.\n",
        "published": "2014-07-23T09:14:49Z",
        "pdf_link": "http://arxiv.org/pdf/1407.7449v1"
    },
    {
        "id": "http://arxiv.org/abs/1407.7635v1",
        "title": "Chasing Ghosts: Competing with Stateful Policies",
        "summary": "  We consider sequential decision making in a setting where regret is measured\nwith respect to a set of stateful reference policies, and feedback is limited\nto observing the rewards of the actions performed (the so called \"bandit\"\nsetting). If either the reference policies are stateless rather than stateful,\nor the feedback includes the rewards of all actions (the so called \"expert\"\nsetting), previous work shows that the optimal regret grows like\n$\\Theta(\\sqrt{T})$ in terms of the number of decision rounds $T$.\n  The difficulty in our setting is that the decision maker unavoidably loses\ntrack of the internal states of the reference policies, and thus cannot\nreliably attribute rewards observed in a certain round to any of the reference\npolicies. In fact, in this setting it is impossible for the algorithm to\nestimate which policy gives the highest (or even approximately highest) total\nreward. Nevertheless, we design an algorithm that achieves expected regret that\nis sublinear in $T$, of the form $O( T/\\log^{1/4}{T})$. Our algorithm is based\non a certain local repetition lemma that may be of independent interest. We\nalso show that no algorithm can guarantee expected regret better than $O(\nT/\\log^{3/2} T)$.\n",
        "published": "2014-07-29T06:17:49Z",
        "pdf_link": "http://arxiv.org/pdf/1407.7635v1"
    },
    {
        "id": "http://arxiv.org/abs/1407.7753v1",
        "title": "A Hash-based Co-Clustering Algorithm for Categorical Data",
        "summary": "  Many real-life data are described by categorical attributes without a\npre-classification. A common data mining method used to extract information\nfrom this type of data is clustering. This method group together the samples\nfrom the data that are more similar than all other samples. But, categorical\ndata pose a challenge when extracting information because: the calculation of\ntwo objects similarity is usually done by measuring the number of common\nfeatures, but ignore a possible importance weighting; if the data may be\ndivided differently according to different subsets of the features, the\nalgorithm may find clusters with different meanings from each other,\ndifficulting the post analysis. Data Co-Clustering of categorical data is the\ntechnique that tries to find subsets of samples that share a subset of features\nin common. By doing so, not only a sample may belong to more than one cluster\nbut, the feature selection of each cluster describe its own characteristics. In\nthis paper a novel Co-Clustering technique for categorical data is proposed by\nusing Locality Sensitive Hashing technique in order to preprocess a list of\nCo-Clusters seeds based on a previous research. Results indicate this technique\nis capable of finding high quality Co-Clusters in many different categorical\ndata sets and scales linearly with the data set size.\n",
        "published": "2014-07-29T15:23:11Z",
        "pdf_link": "http://arxiv.org/pdf/1407.7753v1"
    },
    {
        "id": "http://arxiv.org/abs/1407.7906v3",
        "title": "How Auto-Encoders Could Provide Credit Assignment in Deep Networks via\n  Target Propagation",
        "summary": "  We propose to exploit {\\em reconstruction} as a layer-local training signal\nfor deep learning. Reconstructions can be propagated in a form of target\npropagation playing a role similar to back-propagation but helping to reduce\nthe reliance on derivatives in order to perform credit assignment across many\nlevels of possibly strong non-linearities (which is difficult for\nback-propagation). A regularized auto-encoder tends produce a reconstruction\nthat is a more likely version of its input, i.e., a small move in the direction\nof higher likelihood. By generalizing gradients, target propagation may also\nallow to train deep networks with discrete hidden units. If the auto-encoder\ntakes both a representation of input and target (or of any side information) in\ninput, then its reconstruction of input representation provides a target\ntowards a representation that is more likely, conditioned on all the side\ninformation. A deep auto-encoder decoding path generalizes gradient propagation\nin a learned way that can could thus handle not just infinitesimal changes but\nlarger, discrete changes, hopefully allowing credit assignment through a long\nchain of non-linear operations. In addition to each layer being a good\nauto-encoder, the encoder also learns to please the upper layers by\ntransforming the data into a space where it is easier to model by them,\nflattening manifolds and disentangling factors. The motivations and theoretical\njustifications for this approach are laid down in this paper, along with\nconjectures that will have to be verified either mathematically or\nexperimentally, including a hypothesis stating that such auto-encoder mediated\ntarget propagation could play in brains the role of credit assignment through\nmany non-linear, noisy and discrete transformations.\n",
        "published": "2014-07-29T23:32:44Z",
        "pdf_link": "http://arxiv.org/pdf/1407.7906v3"
    },
    {
        "id": "http://arxiv.org/abs/1407.8289v2",
        "title": "DuSK: A Dual Structure-preserving Kernel for Supervised Tensor Learning\n  with Applications to Neuroimages",
        "summary": "  With advances in data collection technologies, tensor data is assuming\nincreasing prominence in many applications and the problem of supervised tensor\nlearning has emerged as a topic of critical significance in the data mining and\nmachine learning community. Conventional methods for supervised tensor learning\nmainly focus on learning kernels by flattening the tensor into vectors or\nmatrices, however structural information within the tensors will be lost. In\nthis paper, we introduce a new scheme to design structure-preserving kernels\nfor supervised tensor learning. Specifically, we demonstrate how to leverage\nthe naturally available structure within the tensorial representation to encode\nprior knowledge in the kernel. We proposed a tensor kernel that can preserve\ntensor structures based upon dual-tensorial mapping. The dual-tensorial mapping\nfunction can map each tensor instance in the input space to another tensor in\nthe feature space while preserving the tensorial structure. Theoretically, our\napproach is an extension of the conventional kernels in the vector space to\ntensor space. We applied our novel kernel in conjunction with SVM to real-world\ntensor classification problems including brain fMRI classification for three\ndifferent diseases (i.e., Alzheimer's disease, ADHD and brain damage by HIV).\nExtensive empirical studies demonstrate that our proposed approach can\neffectively boost tensor classification performances, particularly with small\nsample sizes.\n",
        "published": "2014-07-31T06:33:42Z",
        "pdf_link": "http://arxiv.org/pdf/1407.8289v2"
    },
    {
        "id": "http://arxiv.org/abs/1407.8339v6",
        "title": "Combinatorial Multi-Armed Bandit and Its Extension to Probabilistically\n  Triggered Arms",
        "summary": "  We define a general framework for a large class of combinatorial multi-armed\nbandit (CMAB) problems, where subsets of base arms with unknown distributions\nform super arms. In each round, a super arm is played and the base arms\ncontained in the super arm are played and their outcomes are observed. We\nfurther consider the extension in which more based arms could be\nprobabilistically triggered based on the outcomes of already triggered arms.\nThe reward of the super arm depends on the outcomes of all played arms, and it\nonly needs to satisfy two mild assumptions, which allow a large class of\nnonlinear reward instances. We assume the availability of an offline\n(\\alpha,\\beta)-approximation oracle that takes the means of the outcome\ndistributions of arms and outputs a super arm that with probability {\\beta}\ngenerates an {\\alpha} fraction of the optimal expected reward. The objective of\nan online learning algorithm for CMAB is to minimize\n(\\alpha,\\beta)-approximation regret, which is the difference between the\n\\alpha{\\beta} fraction of the expected reward when always playing the optimal\nsuper arm, and the expected reward of playing super arms according to the\nalgorithm. We provide CUCB algorithm that achieves O(log n)\ndistribution-dependent regret, where n is the number of rounds played, and we\nfurther provide distribution-independent bounds for a large class of reward\nfunctions. Our regret analysis is tight in that it matches the bound of UCB1\nalgorithm (up to a constant factor) for the classical MAB problem, and it\nsignificantly improves the regret bound in a earlier paper on combinatorial\nbandits with linear rewards. We apply our CMAB framework to two new\napplications, probabilistic maximum coverage and social influence maximization,\nboth having nonlinear reward structures. In particular, application to social\ninfluence maximization requires our extension on probabilistically triggered\narms.\n",
        "published": "2014-07-31T10:09:11Z",
        "pdf_link": "http://arxiv.org/pdf/1407.8339v6"
    },
    {
        "id": "http://arxiv.org/abs/1408.2327v9",
        "title": "On the Consistency of Ordinal Regression Methods",
        "summary": "  Many of the ordinal regression models that have been proposed in the\nliterature can be seen as methods that minimize a convex surrogate of the\nzero-one, absolute, or squared loss functions. A key property that allows to\nstudy the statistical implications of such approximations is that of Fisher\nconsistency. Fisher consistency is a desirable property for surrogate loss\nfunctions and implies that in the population setting, i.e., if the probability\ndistribution that generates the data were available, then optimization of the\nsurrogate would yield the best possible model. In this paper we will\ncharacterize the Fisher consistency of a rich family of surrogate loss\nfunctions used in the context of ordinal regression, including support vector\nordinal regression, ORBoosting and least absolute deviation. We will see that,\nfor a family of surrogate loss functions that subsumes support vector ordinal\nregression and ORBoosting, consistency can be fully characterized by the\nderivative of a real-valued function at zero, as happens for convex\nmargin-based surrogates in binary classification. We also derive excess risk\nbounds for a surrogate of the absolute error that generalize existing risk\nbounds for binary classification. Finally, our analysis suggests a novel\nsurrogate of the squared error loss. We compare this novel surrogate with\ncompeting approaches on 9 different datasets. Our method shows to be highly\ncompetitive in practice, outperforming the least squares loss on 7 out of 9\ndatasets.\n",
        "published": "2014-08-11T06:52:46Z",
        "pdf_link": "http://arxiv.org/pdf/1408.2327v9"
    },
    {
        "id": "http://arxiv.org/abs/1408.2368v1",
        "title": "On the Complexity of Bandit Linear Optimization",
        "summary": "  We study the attainable regret for online linear optimization problems with\nbandit feedback, where unlike the full-information setting, the player can only\nobserve its own loss rather than the full loss vector. We show that the price\nof bandit information in this setting can be as large as $d$, disproving the\nwell-known conjecture that the regret for bandit linear optimization is at most\n$\\sqrt{d}$ times the full-information regret. Surprisingly, this is shown using\n\"trivial\" modifications of standard domains, which have no effect in the\nfull-information setting. This and other results we present highlight some\ninteresting differences between full-information and bandit learning, which\nwere not considered in previous literature.\n",
        "published": "2014-08-11T10:40:29Z",
        "pdf_link": "http://arxiv.org/pdf/1408.2368v1"
    },
    {
        "id": "http://arxiv.org/abs/1408.2803v2",
        "title": "Learning a hyperplane classifier by minimizing an exact bound on the VC\n  dimension",
        "summary": "  The VC dimension measures the capacity of a learning machine, and a low VC\ndimension leads to good generalization. While SVMs produce state-of-the-art\nlearning performance, it is well known that the VC dimension of a SVM can be\nunbounded; despite good results in practice, there is no guarantee of good\ngeneralization. In this paper, we show how to learn a hyperplane classifier by\nminimizing an exact, or \\boldmath{$\\Theta$} bound on its VC dimension. The\nproposed approach, termed as the Minimal Complexity Machine (MCM), involves\nsolving a simple linear programming problem. Experimental results show, that on\na number of benchmark datasets, the proposed approach learns classifiers with\nerror rates much less than conventional SVMs, while often using fewer support\nvectors. On many benchmark datasets, the number of support vectors is less than\none-tenth the number used by SVMs, indicating that the MCM does indeed learn\nsimpler representations.\n",
        "published": "2014-08-12T18:57:48Z",
        "pdf_link": "http://arxiv.org/pdf/1408.2803v2"
    },
    {
        "id": "http://arxiv.org/abs/1408.2890v1",
        "title": "Robust OS-ELM with a novel selective ensemble based on particle swarm\n  optimization",
        "summary": "  In this paper, a robust online sequential extreme learning machine (ROS-ELM)\nis proposed. It is based on the original OS-ELM with an adaptive selective\nensemble framework. Two novel insights are proposed in this paper. First, a\nnovel selective ensemble algorithm referred to as particle swarm optimization\nselective ensemble (PSOSEN) is proposed. Noting that PSOSEN is a general\nselective ensemble method which is applicable to any learning algorithms,\nincluding batch learning and online learning. Second, an adaptive selective\nensemble framework for online learning is designed to balance the robustness\nand complexity of the algorithm. Experiments for both regression and\nclassification problems with UCI data sets are carried out. Comparisons between\nOS-ELM, simple ensemble OS-ELM (EOS-ELM) and the proposed ROS-ELM empirically\nshow that ROS-ELM significantly improves the robustness and stability.\n",
        "published": "2014-08-13T00:41:01Z",
        "pdf_link": "http://arxiv.org/pdf/1408.2890v1"
    },
    {
        "id": "http://arxiv.org/abs/1408.3359v1",
        "title": "Linear Contour Learning: A Method for Supervised Dimension Reduction",
        "summary": "  We propose a novel approach to sufficient dimension reduction in regression,\nbased on estimating contour directions of negligible variation for the response\nsurface. These directions span the orthogonal complement of the minimal space\nrelevant for the regression, and can be extracted according to a measure of the\nvariation in the response, leading to General Contour Regression(GCR). In\ncomparison to exiisting sufficient dimension reduction techniques, this\nsontour-based mothology guarantees exhaustive estimation of the central space\nunder ellipticity of the predictoor distribution and very mild additional\nassumptions, while maintaining vn-consisytency and somputational ease.\nMoreover, it proves to be robust to departures from ellipticity. We also\nestablish some useful population properties for GCR. Simulations to compare\nperformance with that of standard techniques such as ordinary least squares,\nsliced inverse regression, principal hessian directions, and sliced average\nvariance estimation confirm the advntages anticipated by theoretical analyses.\nWe also demonstrate the use of contour-based methods on a data set concerning\ngrades of students from Massachusetts colleges.\n",
        "published": "2014-08-13T05:14:15Z",
        "pdf_link": "http://arxiv.org/pdf/1408.3359v1"
    },
    {
        "id": "http://arxiv.org/abs/1408.3733v1",
        "title": "Multi-Sensor Event Detection using Shape Histograms",
        "summary": "  Vehicular sensor data consists of multiple time-series arising from a number\nof sensors. Using such multi-sensor data we would like to detect occurrences of\nspecific events that vehicles encounter, e.g., corresponding to particular\nmaneuvers that a vehicle makes or conditions that it encounters. Events are\ncharacterized by similar waveform patterns re-appearing within one or more\nsensors. Further such patterns can be of variable duration. In this work, we\npropose a method for detecting such events in time-series data using a novel\nfeature descriptor motivated by similar ideas in image processing. We define\nthe shape histogram: a constant dimension descriptor that nevertheless captures\npatterns of variable duration. We demonstrate the efficacy of using shape\nhistograms as features to detect events in an SVM-based, multi-sensor,\nsupervised learning scenario, i.e., multiple time-series are used to detect an\nevent. We present results on real-life vehicular sensor data and show that our\ntechnique performs better than available pattern detection implementations on\nour data, and that it can also be used to combine features from multiple\nsensors resulting in better accuracy than using any single sensor. Since\nprevious work on pattern detection in time-series has been in the single series\ncontext, we also present results using our technique on multiple standard\ntime-series datasets and show that it is the most versatile in terms of how it\nranks compared to other published results.\n",
        "published": "2014-08-16T11:11:59Z",
        "pdf_link": "http://arxiv.org/pdf/1408.3733v1"
    },
    {
        "id": "http://arxiv.org/abs/1408.4673v2",
        "title": "AFP Algorithm and a Canonical Normal Form for Horn Formulas",
        "summary": "  AFP Algorithm is a learning algorithm for Horn formulas. We show that it does\nnot improve the complexity of AFP Algorithm, if after each negative\ncounterexample more that just one refinements are performed. Moreover, a\ncanonical normal form for Horn formulas is presented, and it is proved that the\noutput formula of AFP Algorithm is in this normal form.\n",
        "published": "2014-08-20T14:29:11Z",
        "pdf_link": "http://arxiv.org/pdf/1408.4673v2"
    },
    {
        "id": "http://arxiv.org/abs/1408.4714v1",
        "title": "Conic Multi-Task Classification",
        "summary": "  Traditionally, Multi-task Learning (MTL) models optimize the average of\ntask-related objective functions, which is an intuitive approach and which we\nwill be referring to as Average MTL. However, a more general framework,\nreferred to as Conic MTL, can be formulated by considering conic combinations\nof the objective functions instead; in this framework, Average MTL arises as a\nspecial case, when all combination coefficients equal 1. Although the advantage\nof Conic MTL over Average MTL has been shown experimentally in previous works,\nno theoretical justification has been provided to date. In this paper, we\nderive a generalization bound for the Conic MTL method, and demonstrate that\nthe tightest bound is not necessarily achieved, when all combination\ncoefficients equal 1; hence, Average MTL may not always be the optimal choice,\nand it is important to consider Conic MTL. As a byproduct of the generalization\nbound, it also theoretically explains the good experimental results of previous\nrelevant works. Finally, we propose a new Conic MTL model, whose conic\ncombination coefficients minimize the generalization bound, instead of choosing\nthem heuristically as has been done in previous methods. The rationale and\nadvantage of our model is demonstrated and verified via a series of experiments\nby comparing with several other methods.\n",
        "published": "2014-08-20T16:23:53Z",
        "pdf_link": "http://arxiv.org/pdf/1408.4714v1"
    },
    {
        "id": "http://arxiv.org/abs/1408.5823v5",
        "title": "Improved Distributed Principal Component Analysis",
        "summary": "  We study the distributed computing setting in which there are multiple\nservers, each holding a set of points, who wish to compute functions on the\nunion of their point sets. A key task in this setting is Principal Component\nAnalysis (PCA), in which the servers would like to compute a low dimensional\nsubspace capturing as much of the variance of the union of their point sets as\npossible. Given a procedure for approximate PCA, one can use it to\napproximately solve $\\ell_2$-error fitting problems such as $k$-means\nclustering and subspace clustering. The essential properties of an approximate\ndistributed PCA algorithm are its communication cost and computational\nefficiency for a given desired accuracy in downstream applications. We give new\nalgorithms and analyses for distributed PCA which lead to improved\ncommunication and computational costs for $k$-means clustering and related\nproblems. Our empirical study on real world data shows a speedup of orders of\nmagnitude, preserving communication with only a negligible degradation in\nsolution quality. Some of these techniques we develop, such as a general\ntransformation from a constant success probability subspace embedding to a high\nsuccess probability subspace embedding with a dimension and sparsity\nindependent of the success probability, may be of independent interest.\n",
        "published": "2014-08-25T16:24:43Z",
        "pdf_link": "http://arxiv.org/pdf/1408.5823v5"
    },
    {
        "id": "http://arxiv.org/abs/1408.6027v2",
        "title": "Label Distribution Learning",
        "summary": "  Although multi-label learning can deal with many problems with label\nambiguity, it does not fit some real applications well where the overall\ndistribution of the importance of the labels matters. This paper proposes a\nnovel learning paradigm named \\emph{label distribution learning} (LDL) for such\nkind of applications. The label distribution covers a certain number of labels,\nrepresenting the degree to which each label describes the instance. LDL is a\nmore general learning framework which includes both single-label and\nmulti-label learning as its special cases. This paper proposes six working LDL\nalgorithms in three ways: problem transformation, algorithm adaptation, and\nspecialized algorithm design. In order to compare the performance of the LDL\nalgorithms, six representative and diverse evaluation measures are selected via\na clustering analysis, and the first batch of label distribution datasets are\ncollected and made publicly available. Experimental results on one artificial\nand fifteen real-world datasets show clear advantages of the specialized\nalgorithms, which indicates the importance of special design for the\ncharacteristics of the LDL problem.\n",
        "published": "2014-08-26T06:48:58Z",
        "pdf_link": "http://arxiv.org/pdf/1408.6027v2"
    },
    {
        "id": "http://arxiv.org/abs/1408.6515v3",
        "title": "Large Scale Purchase Prediction with Historical User Actions on B2C\n  Online Retail Platform",
        "summary": "  This paper describes the solution of Bazinga Team for Tmall Recommendation\nPrize 2014. With real-world user action data provided by Tmall, one of the\nlargest B2C online retail platforms in China, this competition requires to\npredict future user purchases on Tmall website. Predictions are judged on\nF1Score, which considers both precision and recall for fair evaluation. The\ndata set provided by Tmall contains more than half billion action records from\nover ten million distinct users. Such massive data volume poses a big\nchallenge, and drives competitors to write every single program in MapReduce\nfashion and run it on distributed cluster. We model the purchase prediction\nproblem as standard machine learning problem, and mainly employ regression and\nclassification methods as single models. Individual models are then aggregated\nin a two-stage approach, using linear regression for blending, and finally a\nlinear ensemble of blended models. The competition is approaching the end but\nstill in running during writing this paper. In the end, our team achieves\nF1Score 6.11 and ranks 7th (out of 7,276 teams in total).\n",
        "published": "2014-08-27T06:32:21Z",
        "pdf_link": "http://arxiv.org/pdf/1408.6515v3"
    },
    {
        "id": "http://arxiv.org/abs/1408.6617v1",
        "title": "Task-group Relatedness and Generalization Bounds for Regularized\n  Multi-task Learning",
        "summary": "  In this paper, we study the generalization performance of regularized\nmulti-task learning (RMTL) in a vector-valued framework, where MTL is\nconsidered as a learning process for vector-valued functions. We are mainly\nconcerned with two theoretical questions: 1) under what conditions does RMTL\nperform better with a smaller task sample size than STL? 2) under what\nconditions is RMTL generalizable and can guarantee the consistency of each task\nduring simultaneous learning?\n  In particular, we investigate two types of task-group relatedness: the\nobserved discrepancy-dependence measure (ODDM) and the empirical\ndiscrepancy-dependence measure (EDDM), both of which detect the dependence\nbetween two groups of multiple related tasks (MRTs). We then introduce the\nCartesian product-based uniform entropy number (CPUEN) to measure the\ncomplexities of vector-valued function classes. By applying the specific\ndeviation and the symmetrization inequalities to the vector-valued framework,\nwe obtain the generalization bound for RMTL, which is the upper bound of the\njoint probability of the event that there is at least one task with a large\nempirical discrepancy between the expected and empirical risks. Finally, we\npresent a sufficient condition to guarantee the consistency of each task in the\nsimultaneous learning process, and we discuss how task relatedness affects the\ngeneralization performance of RMTL. Our theoretical findings answer the\naforementioned two questions.\n",
        "published": "2014-08-28T03:27:27Z",
        "pdf_link": "http://arxiv.org/pdf/1408.6617v1"
    },
    {
        "id": "http://arxiv.org/abs/1408.6804v2",
        "title": "A Multi-Plane Block-Coordinate Frank-Wolfe Algorithm for Training\n  Structural SVMs with a Costly max-Oracle",
        "summary": "  Structural support vector machines (SSVMs) are amongst the best performing\nmodels for structured computer vision tasks, such as semantic image\nsegmentation or human pose estimation. Training SSVMs, however, is\ncomputationally costly, because it requires repeated calls to a structured\nprediction subroutine (called \\emph{max-oracle}), which has to solve an\noptimization problem itself, e.g. a graph cut.\n  In this work, we introduce a new algorithm for SSVM training that is more\nefficient than earlier techniques when the max-oracle is computationally\nexpensive, as it is frequently the case in computer vision tasks. The main idea\nis to (i) combine the recent stochastic Block-Coordinate Frank-Wolfe algorithm\nwith efficient hyperplane caching, and (ii) use an automatic selection rule for\ndeciding whether to call the exact max-oracle or to rely on an approximate one\nbased on the cached hyperplanes.\n  We show experimentally that this strategy leads to faster convergence to the\noptimum with respect to the number of requires oracle calls, and that this\ntranslates into faster convergence with respect to the total runtime when the\nmax-oracle is slow compared to the other steps of the algorithm.\n  A publicly available C++ implementation is provided at\nhttp://pub.ist.ac.at/~vnk/papers/SVM.html .\n",
        "published": "2014-08-28T18:38:24Z",
        "pdf_link": "http://arxiv.org/pdf/1408.6804v2"
    },
    {
        "id": "http://arxiv.org/abs/1411.0602v1",
        "title": "Factorbird - a Parameter Server Approach to Distributed Matrix\n  Factorization",
        "summary": "  We present Factorbird, a prototype of a parameter server approach for\nfactorizing large matrices with Stochastic Gradient Descent-based algorithms.\nWe designed Factorbird to meet the following desiderata: (a) scalability to\ntall and wide matrices with dozens of billions of non-zeros, (b) extensibility\nto different kinds of models and loss functions as long as they can be\noptimized using Stochastic Gradient Descent (SGD), and (c) adaptability to both\nbatch and streaming scenarios. Factorbird uses a parameter server in order to\nscale to models that exceed the memory of an individual machine, and employs\nlock-free Hogwild!-style learning with a special partitioning scheme to\ndrastically reduce conflicting updates. We also discuss other aspects of the\ndesign of our system such as how to efficiently grid search for hyperparameters\nat scale. We present experiments of Factorbird on a matrix built from a subset\nof Twitter's interaction graph, consisting of more than 38 billion non-zeros\nand about 200 million rows and columns, which is to the best of our knowledge\nthe largest matrix on which factorization results have been reported in the\nliterature.\n",
        "published": "2014-11-03T18:49:25Z",
        "pdf_link": "http://arxiv.org/pdf/1411.0602v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.0860v1",
        "title": "CUR Algorithm for Partially Observed Matrices",
        "summary": "  CUR matrix decomposition computes the low rank approximation of a given\nmatrix by using the actual rows and columns of the matrix. It has been a very\nuseful tool for handling large matrices. One limitation with the existing\nalgorithms for CUR matrix decomposition is that they need an access to the {\\it\nfull} matrix, a requirement that can be difficult to fulfill in many real world\napplications. In this work, we alleviate this limitation by developing a CUR\ndecomposition algorithm for partially observed matrices. In particular, the\nproposed algorithm computes the low rank approximation of the target matrix\nbased on (i) the randomly sampled rows and columns, and (ii) a subset of\nobserved entries that are randomly sampled from the matrix. Our analysis shows\nthe relative error bound, measured by spectral norm, for the proposed algorithm\nwhen the target matrix is of full rank. We also show that only $O(n r\\ln r)$\nobserved entries are needed by the proposed algorithm to perfectly recover a\nrank $r$ matrix of size $n\\times n$, which improves the sample complexity of\nthe existing algorithms for matrix completion. Empirical studies on both\nsynthetic and real-world datasets verify our theoretical claims and demonstrate\nthe effectiveness of the proposed algorithm.\n",
        "published": "2014-11-04T11:03:50Z",
        "pdf_link": "http://arxiv.org/pdf/1411.0860v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.1420v6",
        "title": "Eigenvectors of Orthogonally Decomposable Functions",
        "summary": "  The Eigendecomposition of quadratic forms (symmetric matrices) guaranteed by\nthe spectral theorem is a foundational result in applied mathematics. Motivated\nby a shared structure found in inferential problems of recent interest---namely\northogonal tensor decompositions, Independent Component Analysis (ICA), topic\nmodels, spectral clustering, and Gaussian mixture learning---we generalize the\neigendecomposition from quadratic forms to a broad class of \"orthogonally\ndecomposable\" functions. We identify a key role of convexity in our extension,\nand we generalize two traditional characterizations of eigenvectors: First, the\neigenvectors of a quadratic form arise from the optima structure of the\nquadratic form on the sphere. Second, the eigenvectors are the fixed points of\nthe power iteration.\n  In our setting, we consider a simple first order generalization of the power\nmethod which we call gradient iteration. It leads to efficient and easily\nimplementable methods for basis recovery. It includes influential Machine\nLearning methods such as cumulant-based FastICA and the tensor power iteration\nfor orthogonally decomposable tensors as special cases.\n  We provide a complete theoretical analysis of gradient iteration using the\nstructure theory of discrete dynamical systems to show almost sure convergence\nand fast (super-linear) convergence rates. The analysis also extends to the\ncase when the observed function is only approximately orthogonally\ndecomposable, with bounds that are polynomial in dimension and other relevant\nparameters, such as perturbation size. Our perturbation results can be\nconsidered as a non-linear version of the classical Davis-Kahan theorem for\nperturbations of eigenvectors of symmetric matrices.\n",
        "published": "2014-11-05T21:07:20Z",
        "pdf_link": "http://arxiv.org/pdf/1411.1420v6"
    },
    {
        "id": "http://arxiv.org/abs/1411.1434v2",
        "title": "On the Information Theoretic Limits of Learning Ising Models",
        "summary": "  We provide a general framework for computing lower-bounds on the sample\ncomplexity of recovering the underlying graphs of Ising models, given i.i.d\nsamples. While there have been recent results for specific graph classes, these\ninvolve fairly extensive technical arguments that are specialized to each\nspecific graph class. In contrast, we isolate two key graph-structural\ningredients that can then be used to specify sample complexity lower-bounds.\nPresence of these structural properties makes the graph class hard to learn. We\nderive corollaries of our main result that not only recover existing recent\nresults, but also provide lower bounds for novel graph classes not considered\npreviously. We also extend our framework to the random graph setting and derive\ncorollaries for Erd\\H{o}s-R\\'{e}nyi graphs in a certain dense setting.\n",
        "published": "2014-11-05T22:28:00Z",
        "pdf_link": "http://arxiv.org/pdf/1411.1434v2"
    },
    {
        "id": "http://arxiv.org/abs/1411.1490v2",
        "title": "Efficient Representations for Life-Long Learning and Autoencoding",
        "summary": "  It has been a long-standing goal in machine learning, as well as in AI more\ngenerally, to develop life-long learning systems that learn many different\ntasks over time, and reuse insights from tasks learned, \"learning to learn\" as\nthey do so. In this work we pose and provide efficient algorithms for several\nnatural theoretical formulations of this goal. Specifically, we consider the\nproblem of learning many different target functions over time, that share\ncertain commonalities that are initially unknown to the learning algorithm. Our\naim is to learn new internal representations as the algorithm learns new target\nfunctions, that capture this commonality and allow subsequent learning tasks to\nbe solved more efficiently and from less data. We develop efficient algorithms\nfor two very different kinds of commonalities that target functions might\nshare: one based on learning common low-dimensional and unions of\nlow-dimensional subspaces and one based on learning nonlinear Boolean\ncombinations of features. Our algorithms for learning Boolean feature\ncombinations additionally have a dual interpretation, and can be viewed as\ngiving an efficient procedure for constructing near-optimal sparse Boolean\nautoencoders under a natural \"anchor-set\" assumption.\n",
        "published": "2014-11-06T03:51:39Z",
        "pdf_link": "http://arxiv.org/pdf/1411.1490v2"
    },
    {
        "id": "http://arxiv.org/abs/1411.1623v1",
        "title": "A Hybrid Recurrent Neural Network For Music Transcription",
        "summary": "  We investigate the problem of incorporating higher-level symbolic score-like\ninformation into Automatic Music Transcription (AMT) systems to improve their\nperformance. We use recurrent neural networks (RNNs) and their variants as\nmusic language models (MLMs) and present a generative architecture for\ncombining these models with predictions from a frame level acoustic classifier.\nWe also compare different neural network architectures for acoustic modeling.\nThe proposed model computes a distribution over possible output sequences given\nthe acoustic input signal and we present an algorithm for performing a global\nsearch for good candidate transcriptions. The performance of the proposed model\nis evaluated on piano music from the MAPS dataset and we observe that the\nproposed model consistently outperforms existing transcription methods.\n",
        "published": "2014-11-06T14:18:39Z",
        "pdf_link": "http://arxiv.org/pdf/1411.1623v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.2057v1",
        "title": "Online Collaborative-Filtering on Graphs",
        "summary": "  A common phenomena in modern recommendation systems is the use of feedback\nfrom one user to infer the `value' of an item to other users. This results in\nan exploration vs. exploitation trade-off, in which items of possibly low value\nhave to be presented to users in order to ascertain their value. Existing\napproaches to solving this problem focus on the case where the number of items\nare small, or admit some underlying structure -- it is unclear, however, if\ngood recommendation is possible when dealing with content-rich settings with\nunstructured content.\n  We consider this problem under a simple natural model, wherein the number of\nitems and the number of item-views are of the same order, and an `access-graph'\nconstrains which user is allowed to see which item. Our main insight is that\nthe presence of the access-graph in fact makes good recommendation possible --\nhowever this requires the exploration policy to be designed to take advantage\nof the access-graph. Our results demonstrate the importance of `serendipity' in\nexploration, and how higher graph-expansion translates to a higher quality of\nrecommendations; it also suggests a reason why in some settings, simple\npolicies like Twitter's `Latest-First' policy achieve a good performance.\n  From a technical perspective, our model presents a way to study\nexploration-exploitation tradeoffs in settings where the number of `trials' and\n`strategies' are large (potentially infinite), and more importantly, of the\nsame order. Our algorithms admit competitive-ratio guarantees which hold for\nthe worst-case user, under both finite-population and infinite-horizon\nsettings, and are parametrized in terms of properties of the underlying graph.\nConversely, we also demonstrate that improperly-designed policies can be highly\nsub-optimal, and that in many settings, our results are order-wise optimal.\n",
        "published": "2014-11-07T22:52:19Z",
        "pdf_link": "http://arxiv.org/pdf/1411.2057v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.2635v1",
        "title": "A chain rule for the expected suprema of Gaussian processes",
        "summary": "  The expected supremum of a Gaussian process indexed by the image of an index\nset under a function class is bounded in terms of separate properties of the\nindex set and the function class. The bound is relevant to the estimation of\nnonlinear transformations or the analysis of learning algorithms whenever\nhypotheses are chosen from composite classes, as is the case for multi-layer\nmodels.\n",
        "published": "2014-11-10T21:41:32Z",
        "pdf_link": "http://arxiv.org/pdf/1411.2635v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.2919v1",
        "title": "Bounded Regret for Finite-Armed Structured Bandits",
        "summary": "  We study a new type of K-armed bandit problem where the expected return of\none arm may depend on the returns of other arms. We present a new algorithm for\nthis general class of problems and show that under certain circumstances it is\npossible to achieve finite expected cumulative regret. We also give\nproblem-dependent lower bounds on the cumulative regret showing that at least\nin special cases the new algorithm is nearly optimal.\n",
        "published": "2014-11-11T18:55:35Z",
        "pdf_link": "http://arxiv.org/pdf/1411.2919v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.3553v1",
        "title": "Greedy metrics in orthogonal greedy learning",
        "summary": "  Orthogonal greedy learning (OGL) is a stepwise learning scheme that adds a\nnew atom from a dictionary via the steepest gradient descent and build the\nestimator via orthogonal projecting the target function to the space spanned by\nthe selected atoms in each greedy step. Here, \"greed\" means choosing a new atom\naccording to the steepest gradient descent principle. OGL then avoids the\noverfitting/underfitting by selecting an appropriate iteration number. In this\npaper, we point out that the overfitting/underfitting can also be avoided via\nredefining \"greed\" in OGL. To this end, we introduce a new greedy metric,\ncalled $\\delta$-greedy thresholds, to refine \"greed\" and theoretically verifies\nits feasibility. Furthermore, we reveals that such a greedy metric can bring an\nadaptive termination rule on the premise of maintaining the prominent learning\nperformance of OGL. Our results show that the steepest gradient descent is not\nthe unique greedy metric of OGL and some other more suitable metric may lessen\nthe hassle of model-selection of OGL.\n",
        "published": "2014-11-13T14:26:11Z",
        "pdf_link": "http://arxiv.org/pdf/1411.3553v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.3698v2",
        "title": "Minimal Realization Problems for Hidden Markov Models",
        "summary": "  Consider a stationary discrete random process with alphabet size d, which is\nassumed to be the output process of an unknown stationary Hidden Markov Model\n(HMM). Given the joint probabilities of finite length strings of the process,\nwe are interested in finding a finite state generative model to describe the\nentire process. In particular, we focus on two classes of models: HMMs and\nquasi-HMMs, which is a strictly larger class of models containing HMMs. In the\nmain theorem, we show that if the random process is generated by an HMM of\norder less or equal than k, and whose transition and observation probability\nmatrix are in general position, namely almost everywhere on the parameter\nspace, both the minimal quasi-HMM realization and the minimal HMM realization\ncan be efficiently computed based on the joint probabilities of all the length\nN strings, for N > 4 lceil log_d(k) rceil +1. In this paper, we also aim to\ncompare and connect the two lines of literature: realization theory of HMMs,\nand the recent development in learning latent variable models with tensor\ndecomposition techniques.\n",
        "published": "2014-11-13T20:30:06Z",
        "pdf_link": "http://arxiv.org/pdf/1411.3698v2"
    },
    {
        "id": "http://arxiv.org/abs/1411.3919v1",
        "title": "Sample-targeted clinical trial adaptation",
        "summary": "  Clinical trial adaptation refers to any adjustment of the trial protocol\nafter the onset of the trial. The main goal is to make the process of\nintroducing new medical interventions to patients more efficient by reducing\nthe cost and the time associated with evaluating their safety and efficacy. The\nprincipal question is how should adaptation be performed so as to minimize the\nchance of distorting the outcome of the trial. We propose a novel method for\nachieving this. Unlike previous work our approach focuses on trial adaptation\nby sample size adjustment. We adopt a recently proposed stratification\nframework based on collected auxiliary data and show that this information\ntogether with the primary measured variables can be used to make a\nprobabilistically informed choice of the particular sub-group a sample should\nbe removed from. Experiments on simulated data are used to illustrate the\neffectiveness of our method and its application in practice.\n",
        "published": "2014-11-14T14:30:27Z",
        "pdf_link": "http://arxiv.org/pdf/1411.3919v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.5428v2",
        "title": "Differentially Private Algorithms for Empirical Machine Learning",
        "summary": "  An important use of private data is to build machine learning classifiers.\nWhile there is a burgeoning literature on differentially private classification\nalgorithms, we find that they are not practical in real applications due to two\nreasons. First, existing differentially private classifiers provide poor\naccuracy on real world datasets. Second, there is no known differentially\nprivate algorithm for empirically evaluating the private classifier on a\nprivate test dataset.\n  In this paper, we develop differentially private algorithms that mirror real\nworld empirical machine learning workflows. We consider the private classifier\ntraining algorithm as a blackbox. We present private algorithms for selecting\nfeatures that are input to the classifier. Though adding a preprocessing step\ntakes away some of the privacy budget from the actual classification process\n(thus potentially making it noisier and less accurate), we show that our novel\npreprocessing techniques significantly increase classifier accuracy on three\nreal-world datasets. We also present the first private algorithms for\nempirically constructing receiver operating characteristic (ROC) curves on a\nprivate test set.\n",
        "published": "2014-11-20T03:10:47Z",
        "pdf_link": "http://arxiv.org/pdf/1411.5428v2"
    },
    {
        "id": "http://arxiv.org/abs/1411.5649v5",
        "title": "No-Regret Learnability for Piecewise Linear Losses",
        "summary": "  In the convex optimization approach to online regret minimization, many\nmethods have been developed to guarantee a $O(\\sqrt{T})$ bound on regret for\nsubdifferentiable convex loss functions with bounded subgradients, by using a\nreduction to linear loss functions. This suggests that linear loss functions\ntend to be the hardest ones to learn against, regardless of the underlying\ndecision spaces. We investigate this question in a systematic fashion looking\nat the interplay between the set of possible moves for both the decision maker\nand the adversarial environment. This allows us to highlight sharp distinctive\nbehaviors about the learnability of piecewise linear loss functions. On the one\nhand, when the decision set of the decision maker is a polyhedron, we establish\n$\\Omega(\\sqrt{T})$ lower bounds on regret for a large class of piecewise linear\nloss functions with important applications in online linear optimization,\nrepeated zero-sum Stackelberg games, online prediction with side information,\nand online two-stage optimization. On the other hand, we exhibit $o(\\sqrt{T})$\nlearning rates, achieved by the Follow-The-Leader algorithm, in online linear\noptimization when the boundary of the decision maker's decision set is curved\nand when $0$ does not lie in the convex hull of the environment's decision set.\nHence, the curvature of the decision maker's decision set is a determining\nfactor for the optimal learning rate. These results hold in a completely\nadversarial setting.\n",
        "published": "2014-11-20T19:38:11Z",
        "pdf_link": "http://arxiv.org/pdf/1411.5649v5"
    },
    {
        "id": "http://arxiv.org/abs/1411.6231v3",
        "title": "Compound Rank-k Projections for Bilinear Analysis",
        "summary": "  In many real-world applications, data are represented by matrices or\nhigh-order tensors. Despite the promising performance, the existing\ntwo-dimensional discriminant analysis algorithms employ a single projection\nmodel to exploit the discriminant information for projection, making the model\nless flexible. In this paper, we propose a novel Compound Rank-k Projection\n(CRP) algorithm for bilinear analysis. CRP deals with matrices directly without\ntransforming them into vectors, and it therefore preserves the correlations\nwithin the matrix and decreases the computation complexity. Different from the\nexisting two dimensional discriminant analysis algorithms, objective function\nvalues of CRP increase monotonically.In addition, CRP utilizes multiple rank-k\nprojection models to enable a larger search space in which the optimal solution\ncan be found. In this way, the discriminant ability is enhanced.\n",
        "published": "2014-11-23T12:50:20Z",
        "pdf_link": "http://arxiv.org/pdf/1411.6231v3"
    },
    {
        "id": "http://arxiv.org/abs/1411.6232v2",
        "title": "Semi-supervised Feature Analysis by Mining Correlations among Multiple\n  Tasks",
        "summary": "  In this paper, we propose a novel semi-supervised feature selection framework\nby mining correlations among multiple tasks and apply it to different\nmultimedia applications. Instead of independently computing the importance of\nfeatures for each task, our algorithm leverages shared knowledge from multiple\nrelated tasks, thus, improving the performance of feature selection. Note that\nwe build our algorithm on assumption that different tasks share common\nstructures. The proposed algorithm selects features in a batch mode, by which\nthe correlations between different features are taken into consideration.\nBesides, considering the fact that labeling a large amount of training data in\nreal world is both time-consuming and tedious, we adopt manifold learning which\nexploits both labeled and unlabeled training data for feature space analysis.\nSince the objective function is non-smooth and difficult to solve, we propose\nan iterative algorithm with fast convergence. Extensive experiments on\ndifferent applications demonstrate that our algorithm outperforms other\nstate-of-the-art feature selection algorithms.\n",
        "published": "2014-11-23T13:00:18Z",
        "pdf_link": "http://arxiv.org/pdf/1411.6232v2"
    },
    {
        "id": "http://arxiv.org/abs/1411.6233v1",
        "title": "A Convex Sparse PCA for Feature Analysis",
        "summary": "  Principal component analysis (PCA) has been widely applied to dimensionality\nreduction and data pre-processing for different applications in engineering,\nbiology and social science. Classical PCA and its variants seek for linear\nprojections of the original variables to obtain a low dimensional feature\nrepresentation with maximal variance. One limitation is that it is very\ndifficult to interpret the results of PCA. In addition, the classical PCA is\nvulnerable to certain noisy data. In this paper, we propose a convex sparse\nprincipal component analysis (CSPCA) algorithm and apply it to feature\nanalysis. First we show that PCA can be formulated as a low-rank regression\noptimization problem. Based on the discussion, the l 2 , 1 -norm minimization\nis incorporated into the objective function to make the regression coefficients\nsparse, thereby robust to the outliers. In addition, based on the sparse model\nused in CSPCA, an optimal weight is assigned to each of the original feature,\nwhich in turn provides the output with good interpretability. With the output\nof our CSPCA, we can effectively analyze the importance of each feature under\nthe PCA criteria. The objective function is convex, and we propose an iterative\nalgorithm to optimize it. We apply the CSPCA algorithm to feature selection and\nconduct extensive experiments on six different benchmark datasets. Experimental\nresults demonstrate that the proposed algorithm outperforms state-of-the-art\nunsupervised feature selection algorithms.\n",
        "published": "2014-11-23T13:06:43Z",
        "pdf_link": "http://arxiv.org/pdf/1411.6233v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.6235v1",
        "title": "Balanced k-Means and Min-Cut Clustering",
        "summary": "  Clustering is an effective technique in data mining to generate groups that\nare the matter of interest. Among various clustering approaches, the family of\nk-means algorithms and min-cut algorithms gain most popularity due to their\nsimplicity and efficacy. The classical k-means algorithm partitions a number of\ndata points into several subsets by iteratively updating the clustering centers\nand the associated data points. By contrast, a weighted undirected graph is\nconstructed in min-cut algorithms which partition the vertices of the graph\ninto two sets. However, existing clustering algorithms tend to cluster minority\nof data points into a subset, which shall be avoided when the target dataset is\nbalanced. To achieve more accurate clustering for balanced dataset, we propose\nto leverage exclusive lasso on k-means and min-cut to regulate the balance\ndegree of the clustering results. By optimizing our objective functions that\nbuild atop the exclusive lasso, we can make the clustering result as much\nbalanced as possible. Extensive experiments on several large-scale datasets\nvalidate the advantage of the proposed algorithms compared to the\nstate-of-the-art clustering algorithms.\n",
        "published": "2014-11-23T13:16:25Z",
        "pdf_link": "http://arxiv.org/pdf/1411.6235v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.6241v2",
        "title": "Improved Spectral Clustering via Embedded Label Propagation",
        "summary": "  Spectral clustering is a key research topic in the field of machine learning\nand data mining. Most of the existing spectral clustering algorithms are built\nupon Gaussian Laplacian matrices, which are sensitive to parameters. We propose\na novel parameter free, distance consistent Locally Linear Embedding. The\nproposed distance consistent LLE promises that edges between closer data points\nhave greater weight.Furthermore, we propose a novel improved spectral\nclustering via embedded label propagation. Our algorithm is built upon two\nadvancements of the state of the art:1) label propagation,which propagates a\nnode\\'s labels to neighboring nodes according to their proximity; and 2)\nmanifold learning, which has been widely used in its capacity to leverage the\nmanifold structure of data points. First we perform standard spectral\nclustering on original data and assign each cluster to k nearest data points.\nNext, we propagate labels through dense, unlabeled data regions. Extensive\nexperiments with various datasets validate the superiority of the proposed\nalgorithm compared to current state of the art spectral algorithms.\n",
        "published": "2014-11-23T13:35:29Z",
        "pdf_link": "http://arxiv.org/pdf/1411.6241v2"
    },
    {
        "id": "http://arxiv.org/abs/1411.6243v2",
        "title": "Structure Regularization for Structured Prediction: Theories and\n  Experiments",
        "summary": "  While there are many studies on weight regularization, the study on structure\nregularization is rare. Many existing systems on structured prediction focus on\nincreasing the level of structural dependencies within the model. However, this\ntrend could have been misdirected, because our study suggests that complex\nstructures are actually harmful to generalization ability in structured\nprediction. To control structure-based overfitting, we propose a structure\nregularization framework via \\emph{structure decomposition}, which decomposes\ntraining samples into mini-samples with simpler structures, deriving a model\nwith better generalization power. We show both theoretically and empirically\nthat structure regularization can effectively control overfitting risk and lead\nto better accuracy. As a by-product, the proposed method can also substantially\naccelerate the training speed. The method and the theoretical results can apply\nto general graphical models with arbitrary structures. Experiments on\nwell-known tasks demonstrate that our method can easily beat the benchmark\nsystems on those highly-competitive tasks, achieving state-of-the-art\naccuracies yet with substantially faster training speed.\n",
        "published": "2014-11-23T14:11:01Z",
        "pdf_link": "http://arxiv.org/pdf/1411.6243v2"
    },
    {
        "id": "http://arxiv.org/abs/1411.6305v1",
        "title": "Revenue Optimization in Posted-Price Auctions with Strategic Buyers",
        "summary": "  We study revenue optimization learning algorithms for posted-price auctions\nwith strategic buyers. We analyze a very broad family of monotone regret\nminimization algorithms for this problem, which includes the previously best\nknown algorithm, and show that no algorithm in that family admits a strategic\nregret more favorable than $\\Omega(\\sqrt{T})$. We then introduce a new\nalgorithm that achieves a strategic regret differing from the lower bound only\nby a factor in $O(\\log T)$, an exponential improvement upon the previous best\nalgorithm. Our new algorithm admits a natural analysis and simpler proofs, and\nthe ideas behind its design are general. We also report the results of\nempirical evaluations comparing our algorithm with the previous state of the\nart and show a consistent exponential improvement in several different\nscenarios.\n",
        "published": "2014-11-23T21:58:29Z",
        "pdf_link": "http://arxiv.org/pdf/1411.6305v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.6308v1",
        "title": "A Convex Formulation for Spectral Shrunk Clustering",
        "summary": "  Spectral clustering is a fundamental technique in the field of data mining\nand information processing. Most existing spectral clustering algorithms\nintegrate dimensionality reduction into the clustering process assisted by\nmanifold learning in the original space. However, the manifold in\nreduced-dimensional subspace is likely to exhibit altered properties in\ncontrast with the original space. Thus, applying manifold information obtained\nfrom the original space to the clustering process in a low-dimensional subspace\nis prone to inferior performance. Aiming to address this issue, we propose a\nnovel convex algorithm that mines the manifold structure in the low-dimensional\nsubspace. In addition, our unified learning process makes the manifold learning\nparticularly tailored for the clustering. Compared with other related methods,\nthe proposed algorithm results in more structured clustering result. To\nvalidate the efficacy of the proposed algorithm, we perform extensive\nexperiments on several benchmark datasets in comparison with some\nstate-of-the-art clustering approaches. The experimental results demonstrate\nthat the proposed algorithm has quite promising clustering performance.\n",
        "published": "2014-11-23T22:12:52Z",
        "pdf_link": "http://arxiv.org/pdf/1411.6308v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.6725v1",
        "title": "Accelerated Parallel Optimization Methods for Large Scale Machine\n  Learning",
        "summary": "  The growing amount of high dimensional data in different machine learning\napplications requires more efficient and scalable optimization algorithms. In\nthis work, we consider combining two techniques, parallelism and Nesterov's\nacceleration, to design faster algorithms for L1-regularized loss. We first\nsimplify BOOM, a variant of gradient descent, and study it in a unified\nframework, which allows us to not only propose a refined measurement of\nsparsity to improve BOOM, but also show that BOOM is provably slower than\nFISTA. Moving on to parallel coordinate descent methods, we then propose an\nefficient accelerated version of Shotgun, improving the convergence rate from\n$O(1/t)$ to $O(1/t^2)$. Our algorithm enjoys a concise form and analysis\ncompared to previous work, and also allows one to study several connected work\nin a unified way.\n",
        "published": "2014-11-25T04:36:35Z",
        "pdf_link": "http://arxiv.org/pdf/1411.6725v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.7450v1",
        "title": "Worst-Case Linear Discriminant Analysis as Scalable Semidefinite\n  Feasibility Problems",
        "summary": "  In this paper, we propose an efficient semidefinite programming (SDP)\napproach to worst-case linear discriminant analysis (WLDA). Compared with the\ntraditional LDA, WLDA considers the dimensionality reduction problem from the\nworst-case viewpoint, which is in general more robust for classification.\nHowever, the original problem of WLDA is non-convex and difficult to optimize.\nIn this paper, we reformulate the optimization problem of WLDA into a sequence\nof semidefinite feasibility problems. To efficiently solve the semidefinite\nfeasibility problems, we design a new scalable optimization method with\nquasi-Newton methods and eigen-decomposition being the core components. The\nproposed method is orders of magnitude faster than standard interior-point\nbased SDP solvers.\n  Experiments on a variety of classification problems demonstrate that our\napproach achieves better performance than standard LDA. Our method is also much\nfaster and more scalable than standard interior-point SDP solvers based WLDA.\nThe computational complexity for an SDP with $m$ constraints and matrices of\nsize $d$ by $d$ is roughly reduced from $\\mathcal{O}(m^3+md^3+m^2d^2)$ to\n$\\mathcal{O}(d^3)$ ($m>d$ in our case).\n",
        "published": "2014-11-27T02:52:56Z",
        "pdf_link": "http://arxiv.org/pdf/1411.7450v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.7582v1",
        "title": "Graph Sensitive Indices for Comparing Clusterings",
        "summary": "  This report discusses two new indices for comparing clusterings of a set of\npoints. The motivation for looking at new ways for comparing clusterings stems\nfrom the fact that the existing clustering indices are based on set cardinality\nalone and do not consider the positions of data points. The new indices,\nnamely, the Random Walk index (RWI) and Variation of Information with Neighbors\n(VIN), are both inspired by the clustering metric Variation of Information\n(VI). VI possesses some interesting theoretical properties which are also\ndesirable in a metric for comparing clusterings. We define our indices and\ndiscuss some of their explored properties which appear relevant for a\nclustering index. We also include the results of these indices on clusterings\nof some example data sets.\n",
        "published": "2014-11-27T13:19:15Z",
        "pdf_link": "http://arxiv.org/pdf/1411.7582v1"
    },
    {
        "id": "http://arxiv.org/abs/1411.8003v3",
        "title": "Guaranteed Matrix Completion via Non-convex Factorization",
        "summary": "  Matrix factorization is a popular approach for large-scale matrix completion.\nThe optimization formulation based on matrix factorization can be solved very\nefficiently by standard algorithms in practice. However, due to the\nnon-convexity caused by the factorization model, there is a limited theoretical\nunderstanding of this formulation. In this paper, we establish a theoretical\nguarantee for the factorization formulation to correctly recover the underlying\nlow-rank matrix. In particular, we show that under similar conditions to those\nin previous works, many standard optimization algorithms converge to the global\noptima of a factorization formulation, and recover the true low-rank matrix. We\nstudy the local geometry of a properly regularized factorization formulation\nand prove that any stationary point in a certain local region is globally\noptimal. A major difference of our work from the existing results is that we do\nnot need resampling in either the algorithm or its analysis. Compared to other\nworks on nonconvex optimization, one extra difficulty lies in analyzing\nnonconvex constrained optimization when the constraint (or the corresponding\nregularizer) is not \"consistent\" with the gradient direction. One technical\ncontribution is the perturbation analysis for non-symmetric matrix\nfactorization.\n",
        "published": "2014-11-28T20:52:47Z",
        "pdf_link": "http://arxiv.org/pdf/1411.8003v3"
    },
    {
        "id": "http://arxiv.org/abs/1412.0233v3",
        "title": "The Loss Surfaces of Multilayer Networks",
        "summary": "  We study the connection between the highly non-convex loss function of a\nsimple model of the fully-connected feed-forward neural network and the\nHamiltonian of the spherical spin-glass model under the assumptions of: i)\nvariable independence, ii) redundancy in network parametrization, and iii)\nuniformity. These assumptions enable us to explain the complexity of the fully\ndecoupled neural network through the prism of the results from random matrix\ntheory. We show that for large-size decoupled networks the lowest critical\nvalues of the random loss function form a layered structure and they are\nlocated in a well-defined band lower-bounded by the global minimum. The number\nof local minima outside that band diminishes exponentially with the size of the\nnetwork. We empirically verify that the mathematical model exhibits similar\nbehavior as the computer simulations, despite the presence of high dependencies\nin real networks. We conjecture that both simulated annealing and SGD converge\nto the band of low critical points, and that all critical points found there\nare local minima of high quality measured by the test error. This emphasizes a\nmajor difference between large- and small-size networks where for the latter\npoor quality local minima have non-zero probability of being recovered.\nFinally, we prove that recovering the global minimum becomes harder as the\nnetwork size increases and that it is in practice irrelevant as global minimum\noften leads to overfitting.\n",
        "published": "2014-11-30T15:48:16Z",
        "pdf_link": "http://arxiv.org/pdf/1412.0233v3"
    },
    {
        "id": "http://arxiv.org/abs/1412.1114v1",
        "title": "Easy Hyperparameter Search Using Optunity",
        "summary": "  Optunity is a free software package dedicated to hyperparameter optimization.\nIt contains various types of solvers, ranging from undirected methods to direct\nsearch, particle swarm and evolutionary optimization. The design focuses on\nease of use, flexibility, code clarity and interoperability with existing\nsoftware in all machine learning environments. Optunity is written in Python\nand contains interfaces to environments such as R and MATLAB. Optunity uses a\nBSD license and is freely available online at http://www.optunity.net.\n",
        "published": "2014-12-02T21:55:44Z",
        "pdf_link": "http://arxiv.org/pdf/1412.1114v1"
    },
    {
        "id": "http://arxiv.org/abs/1412.1619v3",
        "title": "Fast Rates by Transferring from Auxiliary Hypotheses",
        "summary": "  In this work we consider the learning setting where, in addition to the\ntraining set, the learner receives a collection of auxiliary hypotheses\noriginating from other tasks. We focus on a broad class of ERM-based linear\nalgorithms that can be instantiated with any non-negative smooth loss function\nand any strongly convex regularizer. We establish generalization and excess\nrisk bounds, showing that, if the algorithm is fed with a good combination of\nsource hypotheses, generalization happens at the fast rate $\\mathcal{O}(1/m)$\ninstead of the usual $\\mathcal{O}(1/\\sqrt{m})$. On the other hand, if the\nsource hypotheses combination is a misfit for the target task, we recover the\nusual learning rate. As a byproduct of our study, we also prove a new bound on\nthe Rademacher complexity of the smooth loss class under weaker assumptions\ncompared to previous works.\n",
        "published": "2014-12-04T11:01:11Z",
        "pdf_link": "http://arxiv.org/pdf/1412.1619v3"
    },
    {
        "id": "http://arxiv.org/abs/1412.1947v1",
        "title": "A parallel sampling based clustering",
        "summary": "  The problem of automatically clustering data is an age old problem. People\nhave created numerous algorithms to tackle this problem. The execution time of\nany of this algorithm grows with the number of input points and the number of\ncluster centers required. To reduce the number of input points we could average\nthe points locally and use the means or the local centers as the input for\nclustering. However since the required number of local centers is very high,\nrunning the clustering algorithm on the entire dataset to obtain these\nrepresentational points is very time consuming. To remedy this problem, in this\npaper we are proposing two subclustering schemes where by we subdivide the\ndataset into smaller sets and run the clustering algorithm on the smaller\ndatasets to obtain the required number of datapoints to run our clustering\nalgorithm with. As we are subdividing the given dataset, we could run\nclustering algorithm on each smaller piece of the dataset in parallel. We found\nthat both parallel and serial execution of this method to be much faster than\nthe original clustering algorithm and error in running the clustering algorithm\non a reduced set to be very less.\n",
        "published": "2014-12-05T10:50:31Z",
        "pdf_link": "http://arxiv.org/pdf/1412.1947v1"
    },
    {
        "id": "http://arxiv.org/abs/1412.2106v1",
        "title": "Consistent optimization of AMS by logistic loss minimization",
        "summary": "  In this paper, we theoretically justify an approach popular among\nparticipants of the Higgs Boson Machine Learning Challenge to optimize\napproximate median significance (AMS). The approach is based on the following\ntwo-stage procedure. First, a real-valued function is learned by minimizing a\nsurrogate loss for binary classification, such as logistic loss, on the\ntraining sample. Then, a threshold is tuned on a separate validation sample, by\ndirect optimization of AMS. We show that the regret of the resulting\n(thresholded) classifier measured with respect to the squared AMS, is\nupperbounded by the regret of the underlying real-valued function measured with\nrespect to the logistic loss. Hence, we prove that minimizing logistic\nsurrogate is a consistent method of optimizing AMS.\n",
        "published": "2014-12-05T19:28:15Z",
        "pdf_link": "http://arxiv.org/pdf/1412.2106v1"
    },
    {
        "id": "http://arxiv.org/abs/1412.2302v4",
        "title": "Theano-based Large-Scale Visual Recognition with Multiple GPUs",
        "summary": "  In this report, we describe a Theano-based AlexNet (Krizhevsky et al., 2012)\nimplementation and its naive data parallelism on multiple GPUs. Our performance\non 2 GPUs is comparable with the state-of-art Caffe library (Jia et al., 2014)\nrun on 1 GPU. To the best of our knowledge, this is the first open-source\nPython-based AlexNet implementation to-date.\n",
        "published": "2014-12-07T01:12:10Z",
        "pdf_link": "http://arxiv.org/pdf/1412.2302v4"
    },
    {
        "id": "http://arxiv.org/abs/1412.2485v1",
        "title": "Accurate Streaming Support Vector Machines",
        "summary": "  A widely-used tool for binary classification is the Support Vector Machine\n(SVM), a supervised learning technique that finds the \"maximum margin\" linear\nseparator between the two classes. While SVMs have been well studied in the\nbatch (offline) setting, there is considerably less work on the streaming\n(online) setting, which requires only a single pass over the data using\nsub-linear space. Existing streaming algorithms are not yet competitive with\nthe batch implementation. In this paper, we use the formulation of the SVM as a\nminimum enclosing ball (MEB) problem to provide a streaming SVM algorithm based\noff of the blurred ball cover originally proposed by Agarwal and Sharathkumar.\nOur implementation consistently outperforms existing streaming SVM approaches\nand provides higher accuracies than libSVM on several datasets, thus making it\ncompetitive with the standard SVM batch implementation.\n",
        "published": "2014-12-08T08:46:07Z",
        "pdf_link": "http://arxiv.org/pdf/1412.2485v1"
    },
    {
        "id": "http://arxiv.org/abs/1412.3397v3",
        "title": "Sequential Labeling with online Deep Learning",
        "summary": "  Deep learning has attracted great attention recently and yielded the state of\nthe art performance in dimension reduction and classification problems.\nHowever, it cannot effectively handle the structured output prediction, e.g.\nsequential labeling. In this paper, we propose a deep learning structure, which\ncan learn discriminative features for sequential labeling problems. More\nspecifically, we add the inter-relationship between labels in our deep learning\nstructure, in order to incorporate the context information from the sequential\ndata. Thus, our model is more powerful than linear Conditional Random Fields\n(CRFs) because the objective function learns latent non-linear features so that\ntarget labeling can be better predicted. We pretrain the deep structure with\nstacked restricted Boltzmann machines (RBMs) for feature learning and optimize\nour objective function with online learning algorithm, a mixture of perceptron\ntraining and stochastic gradient descent. We test our model on different\nchallenge tasks, and show that our model outperforms significantly over the\ncompletive baselines.\n",
        "published": "2014-12-10T18:16:12Z",
        "pdf_link": "http://arxiv.org/pdf/1412.3397v3"
    },
    {
        "id": "http://arxiv.org/abs/1412.4186v1",
        "title": "An Evaluation of Support Vector Machines as a Pattern Recognition Tool",
        "summary": "  The purpose of this report is in examining the generalization performance of\nSupport Vector Machines (SVM) as a tool for pattern recognition and object\nclassification. The work is motivated by the growing popularity of the method\nthat is claimed to guarantee a good generalization performance for the task in\nhand. The method is implemented in MATLAB. SVMs based on various kernels are\ntested for classifying data from various domains.\n",
        "published": "2014-12-13T03:33:13Z",
        "pdf_link": "http://arxiv.org/pdf/1412.4186v1"
    },
    {
        "id": "http://arxiv.org/abs/1412.4863v2",
        "title": "Max-Margin based Discriminative Feature Learning",
        "summary": "  In this paper, we propose a new max-margin based discriminative feature\nlearning method. Specifically, we aim at learning a low-dimensional feature\nrepresentation, so as to maximize the global margin of the data and make the\nsamples from the same class as close as possible. In order to enhance the\nrobustness to noise, a $l_{2,1}$ norm constraint is introduced to make the\ntransformation matrix in group sparsity. In addition, for multi-class\nclassification tasks, we further intend to learn and leverage the correlation\nrelationships among multiple class tasks for assisting in learning\ndiscriminative features. The experimental results demonstrate the power of the\nproposed method against the related state-of-the-art methods.\n",
        "published": "2014-12-16T02:55:01Z",
        "pdf_link": "http://arxiv.org/pdf/1412.4863v2"
    },
    {
        "id": "http://arxiv.org/abs/1412.5617v1",
        "title": "Learning from Data with Heterogeneous Noise using SGD",
        "summary": "  We consider learning from data of variable quality that may be obtained from\ndifferent heterogeneous sources. Addressing learning from heterogeneous data in\nits full generality is a challenging problem. In this paper, we adopt instead a\nmodel in which data is observed through heterogeneous noise, where the noise\nlevel reflects the quality of the data source. We study how to use stochastic\ngradient algorithms to learn in this model. Our study is motivated by two\nconcrete examples where this problem arises naturally: learning with local\ndifferential privacy based on data from multiple sources with different privacy\nrequirements, and learning from data with labels of variable quality.\n  The main contribution of this paper is to identify how heterogeneous noise\nimpacts performance. We show that given two datasets with heterogeneous noise,\nthe order in which to use them in standard SGD depends on the learning rate. We\npropose a method for changing the learning rate as a function of the\nheterogeneity, and prove new regret bounds for our method in two cases of\ninterest. Experiments on real data show that our method performs better than\nusing a single learning rate and using only the less noisy of the two datasets\nwhen the noise level is low to moderate.\n",
        "published": "2014-12-17T21:15:06Z",
        "pdf_link": "http://arxiv.org/pdf/1412.5617v1"
    },
    {
        "id": "http://arxiv.org/abs/1412.5732v2",
        "title": "Dynamic Structure Embedded Online Multiple-Output Regression for Stream\n  Data",
        "summary": "  Online multiple-output regression is an important machine learning technique\nfor modeling, predicting, and compressing multi-dimensional correlated data\nstreams. In this paper, we propose a novel online multiple-output regression\nmethod, called MORES, for stream data. MORES can \\emph{dynamically} learn the\nstructure of the coefficients change in each update step to facilitate the\nmodel's continuous refinement. We observe that limited expressive ability of\nthe regression model, especially in the preliminary stage of online update,\noften leads to the variables in the residual errors being dependent. In light\nof this point, MORES intends to \\emph{dynamically} learn and leverage the\nstructure of the residual errors to improve the prediction accuracy. Moreover,\nwe define three statistical variables to \\emph{exactly} represent all the seen\nsamples for \\emph{incrementally} calculating prediction loss in each online\nupdate round, which can avoid loading all the training data into memory for\nupdating model, and also effectively prevent drastic fluctuation of the model\nin the presence of noise. Furthermore, we introduce a forgetting factor to set\ndifferent weights on samples so as to track the data streams' evolving\ncharacteristics quickly from the latest samples. Experiments on one synthetic\ndataset and three real-world datasets validate the effectiveness of the\nproposed method. In addition, the update speed of MORES is at least 2000\nsamples processed per second on the three real-world datasets, more than 15\ntimes faster than the state-of-the-art online learning algorithm.\n",
        "published": "2014-12-18T06:37:50Z",
        "pdf_link": "http://arxiv.org/pdf/1412.5732v2"
    },
    {
        "id": "http://arxiv.org/abs/1412.5949v1",
        "title": "Large Scale Distributed Distance Metric Learning",
        "summary": "  In large scale machine learning and data mining problems with high feature\ndimensionality, the Euclidean distance between data points can be\nuninformative, and Distance Metric Learning (DML) is often desired to learn a\nproper similarity measure (using side information such as example data pairs\nbeing similar or dissimilar). However, high dimensionality and large volume of\npairwise constraints in modern big data can lead to prohibitive computational\ncost for both the original DML formulation in Xing et al. (2002) and later\nextensions. In this paper, we present a distributed algorithm for DML, and a\nlarge-scale implementation on a parameter server architecture. Our approach\nbuilds on a parallelizable reformulation of Xing et al. (2002), and an\nasynchronous stochastic gradient descent optimization procedure. To our\nknowledge, this is the first distributed solution to DML, and we show that, on\na system with 256 CPU cores, our program is able to complete a DML task on a\ndataset with 1 million data points, 22-thousand features, and 200 million\nlabeled data pairs, in 15 hours; and the learned metric shows great\neffectiveness in properly measuring distances.\n",
        "published": "2014-12-18T17:14:34Z",
        "pdf_link": "http://arxiv.org/pdf/1412.5949v1"
    },
    {
        "id": "http://arxiv.org/abs/1412.6452v3",
        "title": "Algorithmic Robustness for Learning via $(ε, γ, τ)$-Good\n  Similarity Functions",
        "summary": "  The notion of metric plays a key role in machine learning problems such as\nclassification, clustering or ranking. However, it is worth noting that there\nis a severe lack of theoretical guarantees that can be expected on the\ngeneralization capacity of the classifier associated to a given metric. The\ntheoretical framework of $(\\epsilon, \\gamma, \\tau)$-good similarity functions\n(Balcan et al., 2008) has been one of the first attempts to draw a link between\nthe properties of a similarity function and those of a linear classifier making\nuse of it. In this paper, we extend and complete this theory by providing a new\ngeneralization bound for the associated classifier based on the algorithmic\nrobustness framework.\n",
        "published": "2014-12-19T17:43:26Z",
        "pdf_link": "http://arxiv.org/pdf/1412.6452v3"
    },
    {
        "id": "http://arxiv.org/abs/1412.6547v7",
        "title": "Fast Label Embeddings via Randomized Linear Algebra",
        "summary": "  Many modern multiclass and multilabel problems are characterized by\nincreasingly large output spaces. For these problems, label embeddings have\nbeen shown to be a useful primitive that can improve computational and\nstatistical efficiency. In this work we utilize a correspondence between rank\nconstrained estimation and low dimensional label embeddings that uncovers a\nfast label embedding algorithm which works in both the multiclass and\nmultilabel settings. The result is a randomized algorithm whose running time is\nexponentially faster than naive algorithms. We demonstrate our techniques on\ntwo large-scale public datasets, from the Large Scale Hierarchical Text\nChallenge and the Open Directory Project, where we obtain state of the art\nresults.\n",
        "published": "2014-12-19T22:09:35Z",
        "pdf_link": "http://arxiv.org/pdf/1412.6547v7"
    },
    {
        "id": "http://arxiv.org/abs/1412.6599v3",
        "title": "Hot Swapping for Online Adaptation of Optimization Hyperparameters",
        "summary": "  We describe a general framework for online adaptation of optimization\nhyperparameters by `hot swapping' their values during learning. We investigate\nthis approach in the context of adaptive learning rate selection using an\nexplore-exploit strategy from the multi-armed bandit literature. Experiments on\na benchmark neural network show that the hot swapping approach leads to\nconsistently better solutions compared to well-known alternatives such as\nAdaDelta and stochastic gradient with exhaustive hyperparameter search.\n",
        "published": "2014-12-20T04:36:28Z",
        "pdf_link": "http://arxiv.org/pdf/1412.6599v3"
    },
    {
        "id": "http://arxiv.org/abs/1412.6617v6",
        "title": "Understanding Minimum Probability Flow for RBMs Under Various Kinds of\n  Dynamics",
        "summary": "  Energy-based models are popular in machine learning due to the elegance of\ntheir formulation and their relationship to statistical physics. Among these,\nthe Restricted Boltzmann Machine (RBM), and its staple training algorithm\ncontrastive divergence (CD), have been the prototype for some recent\nadvancements in the unsupervised training of deep neural networks. However, CD\nhas limited theoretical motivation, and can in some cases produce undesirable\nbehavior. Here, we investigate the performance of Minimum Probability Flow\n(MPF) learning for training RBMs. Unlike CD, with its focus on approximating an\nintractable partition function via Gibbs sampling, MPF proposes a tractable,\nconsistent, objective function defined in terms of a Taylor expansion of the KL\ndivergence with respect to sampling dynamics. Here we propose a more general\nform for the sampling dynamics in MPF, and explore the consequences of\ndifferent choices for these dynamics for training RBMs. Experimental results\nshow MPF outperforming CD for various RBM configurations.\n",
        "published": "2014-12-20T07:08:37Z",
        "pdf_link": "http://arxiv.org/pdf/1412.6617v6"
    },
    {
        "id": "http://arxiv.org/abs/1412.6980v9",
        "title": "Adam: A Method for Stochastic Optimization",
        "summary": "  We introduce Adam, an algorithm for first-order gradient-based optimization\nof stochastic objective functions, based on adaptive estimates of lower-order\nmoments. The method is straightforward to implement, is computationally\nefficient, has little memory requirements, is invariant to diagonal rescaling\nof the gradients, and is well suited for problems that are large in terms of\ndata and/or parameters. The method is also appropriate for non-stationary\nobjectives and problems with very noisy and/or sparse gradients. The\nhyper-parameters have intuitive interpretations and typically require little\ntuning. Some connections to related algorithms, on which Adam was inspired, are\ndiscussed. We also analyze the theoretical convergence properties of the\nalgorithm and provide a regret bound on the convergence rate that is comparable\nto the best known results under the online convex optimization framework.\nEmpirical results demonstrate that Adam works well in practice and compares\nfavorably to other stochastic optimization methods. Finally, we discuss AdaMax,\na variant of Adam based on the infinity norm.\n",
        "published": "2014-12-22T13:54:29Z",
        "pdf_link": "http://arxiv.org/pdf/1412.6980v9"
    },
    {
        "id": "http://arxiv.org/abs/1502.00064v1",
        "title": "A Batchwise Monotone Algorithm for Dictionary Learning",
        "summary": "  We propose a batchwise monotone algorithm for dictionary learning. Unlike the\nstate-of-the-art dictionary learning algorithms which impose sparsity\nconstraints on a sample-by-sample basis, we instead treat the samples as a\nbatch, and impose the sparsity constraint on the whole. The benefit of\nbatchwise optimization is that the non-zeros can be better allocated across the\nsamples, leading to a better approximation of the whole. To accomplish this, we\npropose procedures to switch non-zeros in both rows and columns in the support\nof the coefficient matrix to reduce the reconstruction error. We prove in the\nproposed support switching procedure the objective of the algorithm, i.e., the\nreconstruction error, decreases monotonically and converges. Furthermore, we\nintroduce a block orthogonal matching pursuit algorithm that also operates on\nsample batches to provide a warm start. Experiments on both natural image\npatches and UCI data sets show that the proposed algorithm produces a better\napproximation with the same sparsity levels compared to the state-of-the-art\nalgorithms.\n",
        "published": "2015-01-31T03:40:17Z",
        "pdf_link": "http://arxiv.org/pdf/1502.00064v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.00598v3",
        "title": "Lock in Feedback in Sequential Experiments",
        "summary": "  We often encounter situations in which an experimenter wants to find, by\nsequential experimentation, $x_{max} = \\arg\\max_{x} f(x)$, where $f(x)$ is a\n(possibly unknown) function of a well controllable variable $x$. Taking\ninspiration from physics and engineering, we have designed a new method to\naddress this problem. In this paper, we first introduce the method in\ncontinuous time, and then present two algorithms for use in sequential\nexperiments. Through a series of simulation studies, we show that the method is\neffective for finding maxima of unknown functions by experimentation, even when\nthe maximum of the functions drifts or when the signal to noise ratio is low.\n",
        "published": "2015-02-02T20:00:13Z",
        "pdf_link": "http://arxiv.org/pdf/1502.00598v3"
    },
    {
        "id": "http://arxiv.org/abs/1502.02158v1",
        "title": "Learning Parametric-Output HMMs with Two Aliased States",
        "summary": "  In various applications involving hidden Markov models (HMMs), some of the\nhidden states are aliased, having identical output distributions. The\nminimality, identifiability and learnability of such aliased HMMs have been\nlong standing problems, with only partial solutions provided thus far. In this\npaper we focus on parametric-output HMMs, whose output distributions come from\na parametric family, and that have exactly two aliased states. For this class,\nwe present a complete characterization of their minimality and identifiability.\nFurthermore, for a large family of parametric output distributions, we derive\ncomputationally efficient and statistically consistent algorithms to detect the\npresence of aliasing and learn the aliased HMM transition and emission\nparameters. We illustrate our theoretical analysis by several simulations.\n",
        "published": "2015-02-07T16:21:28Z",
        "pdf_link": "http://arxiv.org/pdf/1502.02158v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.02268v1",
        "title": "SDNA: Stochastic Dual Newton Ascent for Empirical Risk Minimization",
        "summary": "  We propose a new algorithm for minimizing regularized empirical loss:\nStochastic Dual Newton Ascent (SDNA). Our method is dual in nature: in each\niteration we update a random subset of the dual variables. However, unlike\nexisting methods such as stochastic dual coordinate ascent, SDNA is capable of\nutilizing all curvature information contained in the examples, which leads to\nstriking improvements in both theory and practice - sometimes by orders of\nmagnitude. In the special case when an L2-regularizer is used in the primal,\nthe dual problem is a concave quadratic maximization problem plus a separable\nterm. In this regime, SDNA in each step solves a proximal subproblem involving\na random principal submatrix of the Hessian of the quadratic function; whence\nthe name of the method. If, in addition, the loss functions are quadratic, our\nmethod can be interpreted as a novel variant of the recently introduced\nIterative Hessian Sketch.\n",
        "published": "2015-02-08T16:34:41Z",
        "pdf_link": "http://arxiv.org/pdf/1502.02268v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.02322v2",
        "title": "Rademacher Observations, Private Data, and Boosting",
        "summary": "  The minimization of the logistic loss is a popular approach to batch\nsupervised learning. Our paper starts from the surprising observation that,\nwhen fitting linear (or kernelized) classifiers, the minimization of the\nlogistic loss is \\textit{equivalent} to the minimization of an exponential\n\\textit{rado}-loss computed (i) over transformed data that we call Rademacher\nobservations (rados), and (ii) over the \\textit{same} classifier as the one of\nthe logistic loss. Thus, a classifier learnt from rados can be\n\\textit{directly} used to classify \\textit{observations}. We provide a learning\nalgorithm over rados with boosting-compliant convergence rates on the\n\\textit{logistic loss} (computed over examples). Experiments on domains with up\nto millions of examples, backed up by theoretical arguments, display that\nlearning over a small set of random rados can challenge the state of the art\nthat learns over the \\textit{complete} set of examples. We show that rados\ncomply with various privacy requirements that make them good candidates for\nmachine learning in a privacy framework. We give several algebraic, geometric\nand computational hardness results on reconstructing examples from rados. We\nalso show how it is possible to craft, and efficiently learn from, rados in a\ndifferential privacy framework. Tests reveal that learning from differentially\nprivate rados can compete with learning from random rados, and hence with batch\nlearning from examples, achieving non-trivial privacy vs accuracy tradeoffs.\n",
        "published": "2015-02-09T01:12:11Z",
        "pdf_link": "http://arxiv.org/pdf/1502.02322v2"
    },
    {
        "id": "http://arxiv.org/abs/1502.02476v4",
        "title": "An Infinite Restricted Boltzmann Machine",
        "summary": "  We present a mathematical construction for the restricted Boltzmann machine\n(RBM) that doesn't require specifying the number of hidden units. In fact, the\nhidden layer size is adaptive and can grow during training. This is obtained by\nfirst extending the RBM to be sensitive to the ordering of its hidden units.\nThen, thanks to a carefully chosen definition of the energy function, we show\nthat the limit of infinitely many hidden units is well defined. As with RBM,\napproximate maximum likelihood training can be performed, resulting in an\nalgorithm that naturally and adaptively adds trained hidden units during\nlearning. We empirically study the behaviour of this infinite RBM, showing that\nits performance is competitive to that of the RBM, while not requiring the\ntuning of a hidden layer size.\n",
        "published": "2015-02-09T13:18:24Z",
        "pdf_link": "http://arxiv.org/pdf/1502.02476v4"
    },
    {
        "id": "http://arxiv.org/abs/1502.02599v1",
        "title": "Adaptive Random SubSpace Learning (RSSL) Algorithm for Prediction",
        "summary": "  We present a novel adaptive random subspace learning algorithm (RSSL) for\nprediction purpose. This new framework is flexible where it can be adapted with\nany learning technique. In this paper, we tested the algorithm for regression\nand classification problems. In addition, we provide a variety of weighting\nschemes to increase the robustness of the developed algorithm. These different\nwighting flavors were evaluated on simulated as well as on real-world data sets\nconsidering the cases where the ratio between features (attributes) and\ninstances (samples) is large and vice versa. The framework of the new algorithm\nconsists of many stages: first, calculate the weights of all features on the\ndata set using the correlation coefficient and F-statistic statistical\nmeasurements. Second, randomly draw n samples with replacement from the data\nset. Third, perform regular bootstrap sampling (bagging). Fourth, draw without\nreplacement the indices of the chosen variables. The decision was taken based\non the heuristic subspacing scheme. Fifth, call base learners and build the\nmodel. Sixth, use the model for prediction purpose on test set of the data. The\nresults show the advancement of the adaptive RSSL algorithm in most of the\ncases compared with the synonym (conventional) machine learning algorithms.\n",
        "published": "2015-02-09T18:49:29Z",
        "pdf_link": "http://arxiv.org/pdf/1502.02599v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.02651v1",
        "title": "Optimal and Adaptive Algorithms for Online Boosting",
        "summary": "  We study online boosting, the task of converting any weak online learner into\na strong online learner. Based on a novel and natural definition of weak online\nlearnability, we develop two online boosting algorithms. The first algorithm is\nan online version of boost-by-majority. By proving a matching lower bound, we\nshow that this algorithm is essentially optimal in terms of the number of weak\nlearners and the sample complexity needed to achieve a specified accuracy. This\noptimal algorithm is not adaptive however. Using tools from online loss\nminimization, we derive an adaptive online boosting algorithm that is also\nparameter-free, but not optimal. Both algorithms work with base learners that\ncan handle example importance weights directly, as well as by rejection\nsampling examples with probability defined by the booster. Results are\ncomplemented with an extensive experimental study.\n",
        "published": "2015-02-09T20:58:38Z",
        "pdf_link": "http://arxiv.org/pdf/1502.02651v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.02704v1",
        "title": "Learning Reductions that Really Work",
        "summary": "  We provide a summary of the mathematical and computational techniques that\nhave enabled learning reductions to effectively address a wide class of\nproblems, and show that this approach to solving machine learning problems can\nbe broadly useful.\n",
        "published": "2015-02-09T22:05:25Z",
        "pdf_link": "http://arxiv.org/pdf/1502.02704v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.02710v2",
        "title": "Scalable Multilabel Prediction via Randomized Methods",
        "summary": "  Modeling the dependence between outputs is a fundamental challenge in\nmultilabel classification. In this work we show that a generic regularized\nnonlinearity mapping independent predictions to joint predictions is sufficient\nto achieve state-of-the-art performance on a variety of benchmark problems.\nCrucially, we compute the joint predictions without ever obtaining any\nindependent predictions, while incorporating low-rank and smoothness\nregularization. We achieve this by leveraging randomized algorithms for matrix\ndecomposition and kernel approximation. Furthermore, our techniques are\napplicable to the multiclass setting. We apply our method to a variety of\nmulticlass and multilabel data sets, obtaining state-of-the-art results.\n",
        "published": "2015-02-09T22:18:26Z",
        "pdf_link": "http://arxiv.org/pdf/1502.02710v2"
    },
    {
        "id": "http://arxiv.org/abs/1502.02791v2",
        "title": "Learning Transferable Features with Deep Adaptation Networks",
        "summary": "  Recent studies reveal that a deep neural network can learn transferable\nfeatures which generalize well to novel tasks for domain adaptation. However,\nas deep features eventually transition from general to specific along the\nnetwork, the feature transferability drops significantly in higher layers with\nincreasing domain discrepancy. Hence, it is important to formally reduce the\ndataset bias and enhance the transferability in task-specific layers. In this\npaper, we propose a new Deep Adaptation Network (DAN) architecture, which\ngeneralizes deep convolutional neural network to the domain adaptation\nscenario. In DAN, hidden representations of all task-specific layers are\nembedded in a reproducing kernel Hilbert space where the mean embeddings of\ndifferent domain distributions can be explicitly matched. The domain\ndiscrepancy is further reduced using an optimal multi-kernel selection method\nfor mean embedding matching. DAN can learn transferable features with\nstatistical guarantees, and can scale linearly by unbiased estimate of kernel\nembedding. Extensive empirical evidence shows that the proposed architecture\nyields state-of-the-art image classification error rates on standard domain\nadaptation benchmarks.\n",
        "published": "2015-02-10T06:01:30Z",
        "pdf_link": "http://arxiv.org/pdf/1502.02791v2"
    },
    {
        "id": "http://arxiv.org/abs/1502.03167v3",
        "title": "Batch Normalization: Accelerating Deep Network Training by Reducing\n  Internal Covariate Shift",
        "summary": "  Training Deep Neural Networks is complicated by the fact that the\ndistribution of each layer's inputs changes during training, as the parameters\nof the previous layers change. This slows down the training by requiring lower\nlearning rates and careful parameter initialization, and makes it notoriously\nhard to train models with saturating nonlinearities. We refer to this\nphenomenon as internal covariate shift, and address the problem by normalizing\nlayer inputs. Our method draws its strength from making normalization a part of\nthe model architecture and performing the normalization for each training\nmini-batch. Batch Normalization allows us to use much higher learning rates and\nbe less careful about initialization. It also acts as a regularizer, in some\ncases eliminating the need for Dropout. Applied to a state-of-the-art image\nclassification model, Batch Normalization achieves the same accuracy with 14\ntimes fewer training steps, and beats the original model by a significant\nmargin. Using an ensemble of batch-normalized networks, we improve upon the\nbest published result on ImageNet classification: reaching 4.9% top-5\nvalidation error (and 4.8% test error), exceeding the accuracy of human raters.\n",
        "published": "2015-02-11T01:44:18Z",
        "pdf_link": "http://arxiv.org/pdf/1502.03167v3"
    },
    {
        "id": "http://arxiv.org/abs/1502.03505v1",
        "title": "Supervised LogEuclidean Metric Learning for Symmetric Positive Definite\n  Matrices",
        "summary": "  Metric learning has been shown to be highly effective to improve the\nperformance of nearest neighbor classification. In this paper, we address the\nproblem of metric learning for Symmetric Positive Definite (SPD) matrices such\nas covariance matrices, which arise in many real-world applications. Naively\nusing standard Mahalanobis metric learning methods under the Euclidean geometry\nfor SPD matrices is not appropriate, because the difference of SPD matrices can\nbe a non-SPD matrix and thus the obtained solution can be uninterpretable. To\ncope with this problem, we propose to use a properly parameterized LogEuclidean\ndistance and optimize the metric with respect to kernel-target alignment, which\nis a supervised criterion for kernel learning. Then the resulting non-trivial\noptimization problem is solved by utilizing the Riemannian geometry. Finally,\nwe experimentally demonstrate the usefulness of our LogEuclidean metric\nlearning algorithm on real-world classification tasks for EEG signals and\ntexture patches.\n",
        "published": "2015-02-12T01:38:36Z",
        "pdf_link": "http://arxiv.org/pdf/1502.03505v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.03508v2",
        "title": "Adding vs. Averaging in Distributed Primal-Dual Optimization",
        "summary": "  Distributed optimization methods for large-scale machine learning suffer from\na communication bottleneck. It is difficult to reduce this bottleneck while\nstill efficiently and accurately aggregating partial work from different\nmachines. In this paper, we present a novel generalization of the recent\ncommunication-efficient primal-dual framework (CoCoA) for distributed\noptimization. Our framework, CoCoA+, allows for additive combination of local\nupdates to the global parameters at each iteration, whereas previous schemes\nwith convergence guarantees only allow conservative averaging. We give stronger\n(primal-dual) convergence rate guarantees for both CoCoA as well as our new\nvariants, and generalize the theory for both methods to cover non-smooth convex\nloss functions. We provide an extensive experimental comparison that shows the\nmarkedly improved performance of CoCoA+ on several real-world distributed\ndatasets, especially when scaling up the number of machines.\n",
        "published": "2015-02-12T01:51:08Z",
        "pdf_link": "http://arxiv.org/pdf/1502.03508v2"
    },
    {
        "id": "http://arxiv.org/abs/1502.03529v3",
        "title": "Scalable Stochastic Alternating Direction Method of Multipliers",
        "summary": "  Stochastic alternating direction method of multipliers (ADMM), which visits\nonly one sample or a mini-batch of samples each time, has recently been proved\nto achieve better performance than batch ADMM. However, most stochastic methods\ncan only achieve a convergence rate $O(1/\\sqrt T)$ on general convex\nproblems,where T is the number of iterations. Hence, these methods are not\nscalable with respect to convergence rate (computation cost). There exists only\none stochastic method, called SA-ADMM, which can achieve convergence rate\n$O(1/T)$ on general convex problems. However, an extra memory is needed for\nSA-ADMM to store the historic gradients on all samples, and thus it is not\nscalable with respect to storage cost. In this paper, we propose a novel\nmethod, called scalable stochastic ADMM(SCAS-ADMM), for large-scale\noptimization and learning problems. Without the need to store the historic\ngradients, SCAS-ADMM can achieve the same convergence rate $O(1/T)$ as the best\nstochastic method SA-ADMM and batch ADMM on general convex problems.\nExperiments on graph-guided fused lasso show that SCAS-ADMM can achieve\nstate-of-the-art performance in real applications\n",
        "published": "2015-02-12T04:01:46Z",
        "pdf_link": "http://arxiv.org/pdf/1502.03529v3"
    },
    {
        "id": "http://arxiv.org/abs/1502.03601v1",
        "title": "A Predictive System for detection of Bankruptcy using Machine Learning\n  techniques",
        "summary": "  Bankruptcy is a legal procedure that claims a person or organization as a\ndebtor. It is essential to ascertain the risk of bankruptcy at initial stages\nto prevent financial losses. In this perspective, different soft computing\ntechniques can be employed to ascertain bankruptcy. This study proposes a\nbankruptcy prediction system to categorize the companies based on extent of\nrisk. The prediction system acts as a decision support tool for detection of\nbankruptcy\n  Keywords: Bankruptcy, soft computing, decision support tool\n",
        "published": "2015-02-12T11:07:51Z",
        "pdf_link": "http://arxiv.org/pdf/1502.03601v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.04137v1",
        "title": "Non-Adaptive Learning a Hidden Hipergraph",
        "summary": "  We give a new deterministic algorithm that non-adaptively learns a hidden\nhypergraph from edge-detecting queries. All previous non-adaptive algorithms\neither run in exponential time or have non-optimal query complexity. We give\nthe first polynomial time non-adaptive learning algorithm for learning\nhypergraph that asks almost optimal number of queries.\n",
        "published": "2015-02-13T21:32:12Z",
        "pdf_link": "http://arxiv.org/pdf/1502.04137v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.04156v3",
        "title": "Towards Biologically Plausible Deep Learning",
        "summary": "  Neuroscientists have long criticised deep learning algorithms as incompatible\nwith current knowledge of neurobiology. We explore more biologically plausible\nversions of deep representation learning, focusing here mostly on unsupervised\nlearning but developing a learning mechanism that could account for supervised,\nunsupervised and reinforcement learning. The starting point is that the basic\nlearning rule believed to govern synaptic weight updates\n(Spike-Timing-Dependent Plasticity) arises out of a simple update rule that\nmakes a lot of sense from a machine learning point of view and can be\ninterpreted as gradient descent on some objective function so long as the\nneuronal dynamics push firing rates towards better values of the objective\nfunction (be it supervised, unsupervised, or reward-driven). The second main\nidea is that this corresponds to a form of the variational EM algorithm, i.e.,\nwith approximate rather than exact posteriors, implemented by neural dynamics.\nAnother contribution of this paper is that the gradients required for updating\nthe hidden states in the above variational interpretation can be estimated\nusing an approximation that only requires propagating activations forward and\nbackward, with pairs of layers learning to form a denoising auto-encoder.\nFinally, we extend the theory about the probabilistic interpretation of\nauto-encoders to justify improved sampling schemes based on the generative\ninterpretation of denoising auto-encoders, and we validate all these ideas on\ngenerative learning tasks.\n",
        "published": "2015-02-14T01:11:25Z",
        "pdf_link": "http://arxiv.org/pdf/1502.04156v3"
    },
    {
        "id": "http://arxiv.org/abs/1502.04187v2",
        "title": "Application of Deep Neural Network in Estimation of the Weld Bead\n  Parameters",
        "summary": "  We present a deep learning approach to estimation of the bead parameters in\nwelding tasks. Our model is based on a four-hidden-layer neural network\narchitecture. More specifically, the first three hidden layers of this\narchitecture utilize Sigmoid function to produce their respective intermediate\noutputs. On the other hand, the last hidden layer uses a linear transformation\nto generate the final output of this architecture. This transforms our deep\nnetwork architecture from a classifier to a non-linear regression model. We\ncompare the performance of our deep network with a selected number of results\nin the literature to show a considerable improvement in reducing the errors in\nestimation of these values. Furthermore, we show its scalability on estimating\nthe weld bead parameters with same level of accuracy on combination of datasets\nthat pertain to different welding techniques. This is a nontrivial result that\nis counter-intuitive to the general belief in this field of research.\n",
        "published": "2015-02-14T10:58:53Z",
        "pdf_link": "http://arxiv.org/pdf/1502.04187v2"
    },
    {
        "id": "http://arxiv.org/abs/1502.04585v1",
        "title": "The Ladder: A Reliable Leaderboard for Machine Learning Competitions",
        "summary": "  The organizer of a machine learning competition faces the problem of\nmaintaining an accurate leaderboard that faithfully represents the quality of\nthe best submission of each competing team. What makes this estimation problem\nparticularly challenging is its sequential and adaptive nature. As participants\nare allowed to repeatedly evaluate their submissions on the leaderboard, they\nmay begin to overfit to the holdout data that supports the leaderboard. Few\ntheoretical results give actionable advice on how to design a reliable\nleaderboard. Existing approaches therefore often resort to poorly understood\nheuristics such as limiting the bit precision of answers and the rate of\nre-submission.\n  In this work, we introduce a notion of \"leaderboard accuracy\" tailored to the\nformat of a competition. We introduce a natural algorithm called \"the Ladder\"\nand demonstrate that it simultaneously supports strong theoretical guarantees\nin a fully adaptive model of estimation, withstands practical adversarial\nattacks, and achieves high utility on real submission files from an actual\ncompetition hosted by Kaggle.\n  Notably, we are able to sidestep a powerful recent hardness result for\nadaptive risk estimation that rules out algorithms such as ours under a\nseemingly very similar notion of accuracy. On a practical note, we provide a\ncompletely parameter-free variant of our algorithm that can be deployed in a\nreal competition with no tuning required whatsoever.\n",
        "published": "2015-02-16T15:53:03Z",
        "pdf_link": "http://arxiv.org/pdf/1502.04585v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.04617v1",
        "title": "Deep Transform: Error Correction via Probabilistic Re-Synthesis",
        "summary": "  Errors in data are usually unwelcome and so some means to correct them is\nuseful. However, it is difficult to define, detect or correct errors in an\nunsupervised way. Here, we train a deep neural network to re-synthesize its\ninputs at its output layer for a given class of data. We then exploit the fact\nthat this abstract transformation, which we call a deep transform (DT),\ninherently rejects information (errors) existing outside of the abstract\nfeature space. Using the DT to perform probabilistic re-synthesis, we\ndemonstrate the recovery of data that has been subject to extreme degradation.\n",
        "published": "2015-02-16T16:41:26Z",
        "pdf_link": "http://arxiv.org/pdf/1502.04617v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.04843v2",
        "title": "Generalized Gradient Learning on Time Series under Elastic\n  Transformations",
        "summary": "  The majority of machine learning algorithms assumes that objects are\nrepresented as vectors. But often the objects we want to learn on are more\nnaturally represented by other data structures such as sequences and time\nseries. For these representations many standard learning algorithms are\nunavailable. We generalize gradient-based learning algorithms to time series\nunder dynamic time warping. To this end, we introduce elastic functions, which\nextend functions on time series to matrix spaces. Necessary conditions are\npresented under which generalized gradient learning on time series is\nconsistent. We indicate how results carry over to arbitrary elastic distance\nfunctions and to sequences consisting of symbolic elements. Specifically, four\nlinear classifiers are extended to time series under dynamic time warping and\napplied to benchmark datasets. Results indicate that generalized gradient\nlearning via elastic functions have the potential to complement the\nstate-of-the-art in statistical pattern recognition on time series.\n",
        "published": "2015-02-17T10:08:48Z",
        "pdf_link": "http://arxiv.org/pdf/1502.04843v2"
    },
    {
        "id": "http://arxiv.org/abs/1502.05090v1",
        "title": "Real time clustering of time series using triangular potentials",
        "summary": "  Motivated by the problem of computing investment portfolio weightings we\ninvestigate various methods of clustering as alternatives to traditional\nmean-variance approaches. Such methods can have significant benefits from a\npractical point of view since they remove the need to invert a sample\ncovariance matrix, which can suffer from estimation error and will almost\ncertainly be non-stationary. The general idea is to find groups of assets which\nshare similar return characteristics over time and treat each group as a single\ncomposite asset. We then apply inverse volatility weightings to these new\ncomposite assets. In the course of our investigation we devise a method of\nclustering based on triangular potentials and we present associated theoretical\nresults as well as various examples based on synthetic data.\n",
        "published": "2015-02-18T00:27:39Z",
        "pdf_link": "http://arxiv.org/pdf/1502.05090v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.05111v1",
        "title": "CSAL: Self-adaptive Labeling based Clustering Integrating Supervised\n  Learning on Unlabeled Data",
        "summary": "  Supervised classification approaches can predict labels for unknown data\nbecause of the supervised training process. The success of classification is\nheavily dependent on the labeled training data. Differently, clustering is\neffective in revealing the aggregation property of unlabeled data, but the\nperformance of most clustering methods is limited by the absence of labeled\ndata. In real applications, however, it is time-consuming and sometimes\nimpossible to obtain labeled data. The combination of clustering and\nclassification is a promising and active approach which can largely improve the\nperformance. In this paper, we propose an innovative and effective clustering\nframework based on self-adaptive labeling (CSAL) which integrates clustering\nand classification on unlabeled data. Clustering is first employed to partition\ndata and a certain proportion of clustered data are selected by our proposed\nlabeling approach for training classifiers. In order to refine the trained\nclassifiers, an iterative process of Expectation-Maximization algorithm is\ndevised into the proposed clustering framework CSAL. Experiments are conducted\non publicly data sets to test different combinations of clustering algorithms\nand classification models as well as various training data labeling methods.\nThe experimental results show that our approach along with the self-adaptive\nmethod outperforms other methods.\n",
        "published": "2015-02-18T04:04:45Z",
        "pdf_link": "http://arxiv.org/pdf/1502.05111v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.05134v2",
        "title": "Supervised cross-modal factor analysis for multiple modal data\n  classification",
        "summary": "  In this paper we study the problem of learning from multiple modal data for\npurpose of document classification. In this problem, each document is composed\ntwo different modals of data, i.e., an image and a text. Cross-modal factor\nanalysis (CFA) has been proposed to project the two different modals of data to\na shared data space, so that the classification of a image or a text can be\nperformed directly in this space. A disadvantage of CFA is that it has ignored\nthe supervision information. In this paper, we improve CFA by incorporating the\nsupervision information to represent and classify both image and text modals of\ndocuments. We project both image and text data to a shared data space by factor\nanalysis, and then train a class label predictor in the shared space to use the\nclass label information. The factor analysis parameter and the predictor\nparameter are learned jointly by solving one single objective function. With\nthis objective function, we minimize the distance between the projections of\nimage and text of the same document, and the classification error of the\nprojection measured by hinge loss function. The objective function is optimized\nby an alternate optimization strategy in an iterative algorithm. Experiments in\ntwo different multiple modal document data sets show the advantage of the\nproposed algorithm over other CFA methods.\n",
        "published": "2015-02-18T06:55:07Z",
        "pdf_link": "http://arxiv.org/pdf/1502.05134v2"
    },
    {
        "id": "http://arxiv.org/abs/1502.05477v5",
        "title": "Trust Region Policy Optimization",
        "summary": "  We describe an iterative procedure for optimizing policies, with guaranteed\nmonotonic improvement. By making several approximations to the\ntheoretically-justified procedure, we develop a practical algorithm, called\nTrust Region Policy Optimization (TRPO). This algorithm is similar to natural\npolicy gradient methods and is effective for optimizing large nonlinear\npolicies such as neural networks. Our experiments demonstrate its robust\nperformance on a wide variety of tasks: learning simulated robotic swimming,\nhopping, and walking gaits; and playing Atari games using images of the screen\nas input. Despite its approximations that deviate from the theory, TRPO tends\nto give monotonic improvement, with little tuning of hyperparameters.\n",
        "published": "2015-02-19T06:44:25Z",
        "pdf_link": "http://arxiv.org/pdf/1502.05477v5"
    },
    {
        "id": "http://arxiv.org/abs/1502.05934v1",
        "title": "Achieving All with No Parameters: Adaptive NormalHedge",
        "summary": "  We study the classic online learning problem of predicting with expert\nadvice, and propose a truly parameter-free and adaptive algorithm that achieves\nseveral objectives simultaneously without using any prior information. The main\ncomponent of this work is an improved version of the NormalHedge.DT algorithm\n(Luo and Schapire, 2014), called AdaNormalHedge. On one hand, this new\nalgorithm ensures small regret when the competitor has small loss and almost\nconstant regret when the losses are stochastic. On the other hand, the\nalgorithm is able to compete with any convex combination of the experts\nsimultaneously, with a regret in terms of the relative entropy of the prior and\nthe competitor. This resolves an open problem proposed by Chaudhuri et al.\n(2009) and Chernov and Vovk (2010). Moreover, we extend the results to the\nsleeping expert setting and provide two applications to illustrate the power of\nAdaNormalHedge: 1) competing with time-varying unknown competitors and 2)\npredicting almost as well as the best pruning tree. Our results on these\napplications significantly improve previous work from different aspects, and a\nspecial case of the first application resolves another open problem proposed by\nWarmuth and Koolen (2014) on whether one can simultaneously achieve optimal\nshifting regret for both adversarial and stochastic losses.\n",
        "published": "2015-02-20T16:58:36Z",
        "pdf_link": "http://arxiv.org/pdf/1502.05934v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.06177v1",
        "title": "SDCA without Duality",
        "summary": "  Stochastic Dual Coordinate Ascent is a popular method for solving regularized\nloss minimization for the case of convex losses. In this paper we show how a\nvariant of SDCA can be applied for non-convex losses. We prove linear\nconvergence rate even if individual loss functions are non-convex as long as\nthe expected loss is convex.\n",
        "published": "2015-02-22T04:42:01Z",
        "pdf_link": "http://arxiv.org/pdf/1502.06177v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.06187v2",
        "title": "Teaching and compressing for low VC-dimension",
        "summary": "  In this work we study the quantitative relation between VC-dimension and two\nother basic parameters related to learning and teaching. Namely, the quality of\nsample compression schemes and of teaching sets for classes of low\nVC-dimension. Let $C$ be a binary concept class of size $m$ and VC-dimension\n$d$. Prior to this work, the best known upper bounds for both parameters were\n$\\log(m)$, while the best lower bounds are linear in $d$. We present\nsignificantly better upper bounds on both as follows. Set $k = O(d 2^d \\log\n\\log |C|)$.\n  We show that there always exists a concept $c$ in $C$ with a teaching set\n(i.e. a list of $c$-labeled examples uniquely identifying $c$ in $C$) of size\n$k$. This problem was studied by Kuhlmann (1999). Our construction implies that\nthe recursive teaching (RT) dimension of $C$ is at most $k$ as well. The\nRT-dimension was suggested by Zilles et al. and Doliwa et al. (2010). The same\nnotion (under the name partial-ID width) was independently studied by Wigderson\nand Yehudayoff (2013). An upper bound on this parameter that depends only on\n$d$ is known just for the very simple case $d=1$, and is open even for $d=2$.\nWe also make small progress towards this seemingly modest goal.\n  We further construct sample compression schemes of size $k$ for $C$, with\nadditional information of $k \\log(k)$ bits. Roughly speaking, given any list of\n$C$-labelled examples of arbitrary length, we can retain only $k$ labeled\nexamples in a way that allows to recover the labels of all others examples in\nthe list, using additional $k\\log (k)$ information bits. This problem was first\nsuggested by Littlestone and Warmuth (1986).\n",
        "published": "2015-02-22T06:21:28Z",
        "pdf_link": "http://arxiv.org/pdf/1502.06187v2"
    },
    {
        "id": "http://arxiv.org/abs/1502.06362v2",
        "title": "Contextual Dueling Bandits",
        "summary": "  We consider the problem of learning to choose actions using contextual\ninformation when provided with limited feedback in the form of relative\npairwise comparisons. We study this problem in the dueling-bandits framework of\nYue et al. (2009), which we extend to incorporate context. Roughly, the\nlearner's goal is to find the best policy, or way of behaving, in some space of\npolicies, although \"best\" is not always so clearly defined. Here, we propose a\nnew and natural solution concept, rooted in game theory, called a von Neumann\nwinner, a randomized policy that beats or ties every other policy. We show that\nthis notion overcomes important limitations of existing solutions, particularly\nthe Condorcet winner which has typically been used in the past, but which\nrequires strong and often unrealistic assumptions. We then present three\nefficient algorithms for online learning in our setting, and for approximating\na von Neumann winner from batch-like data. The first of these algorithms\nachieves particularly low regret, even when data is adversarial, although its\ntime and space requirements are linear in the size of the policy space. The\nother two algorithms require time and space only logarithmic in the size of the\npolicy space when provided access to an oracle for solving classification\nproblems on the space.\n",
        "published": "2015-02-23T09:47:54Z",
        "pdf_link": "http://arxiv.org/pdf/1502.06362v2"
    },
    {
        "id": "http://arxiv.org/abs/1502.06665v1",
        "title": "Reified Context Models",
        "summary": "  A classic tension exists between exact inference in a simple model and\napproximate inference in a complex model. The latter offers expressivity and\nthus accuracy, but the former provides coverage of the space, an important\nproperty for confidence estimation and learning with indirect supervision. In\nthis work, we introduce a new approach, reified context models, to reconcile\nthis tension. Specifically, we let the amount of context (the arity of the\nfactors in a graphical model) be chosen \"at run-time\" by reifying it---that is,\nletting this choice itself be a random variable inside the model. Empirically,\nwe show that our approach obtains expressivity and coverage on three natural\nlanguage tasks.\n",
        "published": "2015-02-24T01:26:43Z",
        "pdf_link": "http://arxiv.org/pdf/1502.06665v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.06668v1",
        "title": "Learning Fast-Mixing Models for Structured Prediction",
        "summary": "  Markov Chain Monte Carlo (MCMC) algorithms are often used for approximate\ninference inside learning, but their slow mixing can be difficult to diagnose\nand the approximations can seriously degrade learning. To alleviate these\nissues, we define a new model family using strong Doeblin Markov chains, whose\nmixing times can be precisely controlled by a parameter. We also develop an\nalgorithm to learn such models, which involves maximizing the data likelihood\nunder the induced stationary distribution of these chains. We show empirical\nimprovements on two challenging inference tasks.\n",
        "published": "2015-02-24T01:42:09Z",
        "pdf_link": "http://arxiv.org/pdf/1502.06668v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.07073v3",
        "title": "Strongly Adaptive Online Learning",
        "summary": "  Strongly adaptive algorithms are algorithms whose performance on every time\ninterval is close to optimal. We present a reduction that can transform\nstandard low-regret algorithms to strongly adaptive. As a consequence, we\nderive simple, yet efficient, strongly adaptive algorithms for a handful of\nproblems.\n",
        "published": "2015-02-25T07:24:40Z",
        "pdf_link": "http://arxiv.org/pdf/1502.07073v3"
    },
    {
        "id": "http://arxiv.org/abs/1502.07143v1",
        "title": "The VC-Dimension of Similarity Hypotheses Spaces",
        "summary": "  Given a set $X$ and a function $h:X\\longrightarrow\\{0,1\\}$ which labels each\nelement of $X$ with either $0$ or $1$, we may define a function $h^{(s)}$ to\nmeasure the similarity of pairs of points in $X$ according to $h$.\nSpecifically, for $h\\in \\{0,1\\}^X$ we define $h^{(s)}\\in \\{0,1\\}^{X\\times X}$\nby $h^{(s)}(w,x):= \\mathbb{1}[h(w) = h(x)]$. This idea can be extended to a set\nof functions, or hypothesis space $\\mathcal{H} \\subseteq \\{0,1\\}^X$ by defining\na similarity hypothesis space $\\mathcal{H}^{(s)}:=\\{h^{(s)}:h\\in\\mathcal{H}\\}$.\nWe show that ${{vc-dimension}}(\\mathcal{H}^{(s)}) \\in\n\\Theta({{vc-dimension}}(\\mathcal{H}))$.\n",
        "published": "2015-02-25T12:14:04Z",
        "pdf_link": "http://arxiv.org/pdf/1502.07143v1"
    },
    {
        "id": "http://arxiv.org/abs/1502.07617v1",
        "title": "Online Learning with Feedback Graphs: Beyond Bandits",
        "summary": "  We study a general class of online learning problems where the feedback is\nspecified by a graph. This class includes online prediction with expert advice\nand the multi-armed bandit problem, but also several learning problems where\nthe online player does not necessarily observe his own loss. We analyze how the\nstructure of the feedback graph controls the inherent difficulty of the induced\n$T$-round learning problem. Specifically, we show that any feedback graph\nbelongs to one of three classes: strongly observable graphs, weakly observable\ngraphs, and unobservable graphs. We prove that the first class induces learning\nproblems with $\\widetilde\\Theta(\\alpha^{1/2} T^{1/2})$ minimax regret, where\n$\\alpha$ is the independence number of the underlying graph; the second class\ninduces problems with $\\widetilde\\Theta(\\delta^{1/3}T^{2/3})$ minimax regret,\nwhere $\\delta$ is the domination number of a certain portion of the graph; and\nthe third class induces problems with linear minimax regret. Our results\nsubsume much of the previous work on learning with feedback graphs and reveal\nnew connections to partial monitoring games. We also show how the regret is\naffected if the graphs are allowed to vary with time.\n",
        "published": "2015-02-26T16:18:53Z",
        "pdf_link": "http://arxiv.org/pdf/1502.07617v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.00424v2",
        "title": "Learning Mixtures of Gaussians in High Dimensions",
        "summary": "  Efficiently learning mixture of Gaussians is a fundamental problem in\nstatistics and learning theory. Given samples coming from a random one out of k\nGaussian distributions in Rn, the learning problem asks to estimate the means\nand the covariance matrices of these Gaussians. This learning problem arises in\nmany areas ranging from the natural sciences to the social sciences, and has\nalso found many machine learning applications. Unfortunately, learning mixture\nof Gaussians is an information theoretically hard problem: in order to learn\nthe parameters up to a reasonable accuracy, the number of samples required is\nexponential in the number of Gaussian components in the worst case. In this\nwork, we show that provided we are in high enough dimensions, the class of\nGaussian mixtures is learnable in its most general form under a smoothed\nanalysis framework, where the parameters are randomly perturbed from an\nadversarial starting point. In particular, given samples from a mixture of\nGaussians with randomly perturbed parameters, when n > {\\Omega}(k^2), we give\nan algorithm that learns the parameters with polynomial running time and using\npolynomial number of samples. The central algorithmic ideas consist of new ways\nto decompose the moment tensor of the Gaussian mixture by exploiting its\nstructural properties. The symmetries of this tensor are derived from the\ncombinatorial structure of higher order moments of Gaussian distributions\n(sometimes referred to as Isserlis' theorem or Wick's theorem). We also develop\nnew tools for bounding smallest singular values of structured random matrices,\nwhich could be useful in other smoothed analysis settings.\n",
        "published": "2015-03-02T06:59:06Z",
        "pdf_link": "http://arxiv.org/pdf/1503.00424v2"
    },
    {
        "id": "http://arxiv.org/abs/1503.00491v1",
        "title": "Utility-Theoretic Ranking for Semi-Automated Text Classification",
        "summary": "  \\emph{Semi-Automated Text Classification} (SATC) may be defined as the task\nof ranking a set $\\mathcal{D}$ of automatically labelled textual documents in\nsuch a way that, if a human annotator validates (i.e., inspects and corrects\nwhere appropriate) the documents in a top-ranked portion of $\\mathcal{D}$ with\nthe goal of increasing the overall labelling accuracy of $\\mathcal{D}$, the\nexpected increase is maximized. An obvious SATC strategy is to rank\n$\\mathcal{D}$ so that the documents that the classifier has labelled with the\nlowest confidence are top-ranked. In this work we show that this strategy is\nsuboptimal. We develop new utility-theoretic ranking methods based on the\nnotion of \\emph{validation gain}, defined as the improvement in classification\neffectiveness that would derive by validating a given automatically labelled\ndocument. We also propose a new effectiveness measure for SATC-oriented ranking\nmethods, based on the expected reduction in classification error brought about\nby partially validating a list generated by a given ranking method. We report\nthe results of experiments showing that, with respect to the baseline method\nabove, and according to the proposed measure, our utility-theoretic ranking\nmethods can achieve substantially higher expected reductions in classification\nerror.\n",
        "published": "2015-03-02T12:09:23Z",
        "pdf_link": "http://arxiv.org/pdf/1503.00491v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.00600v1",
        "title": "An $\\mathcal{O}(n\\log n)$ projection operator for weighted $\\ell_1$-norm\n  regularization with sum constraint",
        "summary": "  We provide a simple and efficient algorithm for the projection operator for\nweighted $\\ell_1$-norm regularization subject to a sum constraint, together\nwith an elementary proof. The implementation of the proposed algorithm can be\ndownloaded from the author's homepage.\n",
        "published": "2015-03-02T16:35:02Z",
        "pdf_link": "http://arxiv.org/pdf/1503.00600v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.01002v1",
        "title": "Projection onto the capped simplex",
        "summary": "  We provide a simple and efficient algorithm for computing the Euclidean\nprojection of a point onto the capped simplex---a simplex with an additional\nuniform bound on each coordinate---together with an elementary proof. Both the\nMATLAB and C++ implementations of the proposed algorithm can be downloaded at\nhttps://eng.ucmerced.edu/people/wwang5.\n",
        "published": "2015-03-03T16:40:17Z",
        "pdf_link": "http://arxiv.org/pdf/1503.01002v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.01239v4",
        "title": "Joint Active Learning with Feature Selection via CUR Matrix\n  Decomposition",
        "summary": "  This paper presents an unsupervised learning approach for simultaneous sample\nand feature selection, which is in contrast to existing works which mainly\ntackle these two problems separately. In fact the two tasks are often\ninterleaved with each other: noisy and high-dimensional features will bring\nadverse effect on sample selection, while informative or representative samples\nwill be beneficial to feature selection. Specifically, we propose a framework\nto jointly conduct active learning and feature selection based on the CUR\nmatrix decomposition. From the data reconstruction perspective, both the\nselected samples and features can best approximate the original dataset\nrespectively, such that the selected samples characterized by the features are\nhighly representative. In particular, our method runs in one-shot without the\nprocedure of iterative sample selection for progressive labeling. Thus, our\nmodel is especially suitable when there are few labeled samples or even in the\nabsence of supervision, which is a particular challenge for existing methods.\nAs the joint learning problem is NP-hard, the proposed formulation involves a\nconvex but non-smooth optimization problem. We solve it efficiently by an\niterative algorithm, and prove its global convergence. Experimental results on\npublicly available datasets corroborate the efficacy of our method compared\nwith the state-of-the-art.\n",
        "published": "2015-03-04T06:47:16Z",
        "pdf_link": "http://arxiv.org/pdf/1503.01239v4"
    },
    {
        "id": "http://arxiv.org/abs/1503.01428v3",
        "title": "Probabilistic Label Relation Graphs with Ising Models",
        "summary": "  We consider classification problems in which the label space has structure. A\ncommon example is hierarchical label spaces, corresponding to the case where\none label subsumes another (e.g., animal subsumes dog). But labels can also be\nmutually exclusive (e.g., dog vs cat) or unrelated (e.g., furry, carnivore). To\njointly model hierarchy and exclusion relations, the notion of a HEX (hierarchy\nand exclusion) graph was introduced in [7]. This combined a conditional random\nfield (CRF) with a deep neural network (DNN), resulting in state of the art\nresults when applied to visual object classification problems where the\ntraining labels were drawn from different levels of the ImageNet hierarchy\n(e.g., an image might be labeled with the basic level category \"dog\", rather\nthan the more specific label \"husky\"). In this paper, we extend the HEX model\nto allow for soft or probabilistic relations between labels, which is useful\nwhen there is uncertainty about the relationship between two labels (e.g., an\nantelope is \"sort of\" furry, but not to the same degree as a grizzly bear). We\ncall our new model pHEX, for probabilistic HEX. We show that the pHEX graph can\nbe converted to an Ising model, which allows us to use existing off-the-shelf\ninference methods (in contrast to the HEX method, which needed specialized\ninference algorithms). Experimental results show significant improvements in a\nnumber of large-scale visual object classification tasks, outperforming the\nprevious HEX model.\n",
        "published": "2015-03-04T19:23:55Z",
        "pdf_link": "http://arxiv.org/pdf/1503.01428v3"
    },
    {
        "id": "http://arxiv.org/abs/1503.01883v1",
        "title": "Ranking and significance of variable-length similarity-based time series\n  motifs",
        "summary": "  The detection of very similar patterns in a time series, commonly called\nmotifs, has received continuous and increasing attention from diverse\nscientific communities. In particular, recent approaches for discovering\nsimilar motifs of different lengths have been proposed. In this work, we show\nthat such variable-length similarity-based motifs cannot be directly compared,\nand hence ranked, by their normalized dissimilarities. Specifically, we find\nthat length-normalized motif dissimilarities still have intrinsic dependencies\non the motif length, and that lowest dissimilarities are particularly affected\nby this dependency. Moreover, we find that such dependencies are generally\nnon-linear and change with the considered data set and dissimilarity measure.\nBased on these findings, we propose a solution to rank those motifs and measure\ntheir significance. This solution relies on a compact but accurate model of the\ndissimilarity space, using a beta distribution with three parameters that\ndepend on the motif length in a non-linear way. We believe the incomparability\nof variable-length dissimilarities could go beyond the field of time series,\nand that similar modeling strategies as the one used here could be of help in a\nmore broad context.\n",
        "published": "2015-03-06T09:10:34Z",
        "pdf_link": "http://arxiv.org/pdf/1503.01883v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.02143v2",
        "title": "Model selection of polynomial kernel regression",
        "summary": "  Polynomial kernel regression is one of the standard and state-of-the-art\nlearning strategies. However, as is well known, the choices of the degree of\npolynomial kernel and the regularization parameter are still open in the realm\nof model selection. The first aim of this paper is to develop a strategy to\nselect these parameters. On one hand, based on the worst-case learning rate\nanalysis, we show that the regularization term in polynomial kernel regression\nis not necessary. In other words, the regularization parameter can decrease\narbitrarily fast when the degree of the polynomial kernel is suitable tuned. On\nthe other hand,taking account of the implementation of the algorithm, the\nregularization term is required. Summarily, the effect of the regularization\nterm in polynomial kernel regression is only to circumvent the \" ill-condition\"\nof the kernel matrix. Based on this, the second purpose of this paper is to\npropose a new model selection strategy, and then design an efficient learning\nalgorithm. Both theoretical and experimental analysis show that the new\nstrategy outperforms the previous one. Theoretically, we prove that the new\nlearning strategy is almost optimal if the regression function is smooth.\nExperimentally, it is shown that the new strategy can significantly reduce the\ncomputational burden without loss of generalization capability.\n",
        "published": "2015-03-07T08:39:15Z",
        "pdf_link": "http://arxiv.org/pdf/1503.02143v2"
    },
    {
        "id": "http://arxiv.org/abs/1503.02193v2",
        "title": "Label optimal regret bounds for online local learning",
        "summary": "  We resolve an open question from (Christiano, 2014b) posed in COLT'14\nregarding the optimal dependency of the regret achievable for online local\nlearning on the size of the label set. In this framework the algorithm is shown\na pair of items at each step, chosen from a set of $n$ items. The learner then\npredicts a label for each item, from a label set of size $L$ and receives a\nreal valued payoff. This is a natural framework which captures many interesting\nscenarios such as collaborative filtering, online gambling, and online max cut\namong others. (Christiano, 2014a) designed an efficient online learning\nalgorithm for this problem achieving a regret of $O(\\sqrt{nL^3T})$, where $T$\nis the number of rounds. Information theoretically, one can achieve a regret of\n$O(\\sqrt{n \\log L T})$. One of the main open questions left in this framework\nconcerns closing the above gap.\n  In this work, we provide a complete answer to the question above via two main\nresults. We show, via a tighter analysis, that the semi-definite programming\nbased algorithm of (Christiano, 2014a), in fact achieves a regret of\n$O(\\sqrt{nLT})$. Second, we show a matching computational lower bound. Namely,\nwe show that a polynomial time algorithm for online local learning with lower\nregret would imply a polynomial time algorithm for the planted clique problem\nwhich is widely believed to be hard. We prove a similar hardness result under a\nrelated conjecture concerning planted dense subgraphs that we put forth. Unlike\nplanted clique, the planted dense subgraph problem does not have any known\nquasi-polynomial time algorithms.\n  Computational lower bounds for online learning are relatively rare, and we\nhope that the ideas developed in this work will lead to lower bounds for other\nonline learning scenarios as well.\n",
        "published": "2015-03-07T17:36:08Z",
        "pdf_link": "http://arxiv.org/pdf/1503.02193v2"
    },
    {
        "id": "http://arxiv.org/abs/1503.02406v1",
        "title": "Deep Learning and the Information Bottleneck Principle",
        "summary": "  Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the\ninformation bottleneck (IB) principle. We first show that any DNN can be\nquantified by the mutual information between the layers and the input and\noutput variables. Using this representation we can calculate the optimal\ninformation theoretic limits of the DNN and obtain finite sample generalization\nbounds. The advantage of getting closer to the theoretical limit is\nquantifiable both by the generalization bound and by the network's simplicity.\nWe argue that both the optimal architecture, number of layers and\nfeatures/connections at each layer, are related to the bifurcation points of\nthe information bottleneck tradeoff, namely, relevant compression of the input\nlayer with respect to the output layer. The hierarchical representations at the\nlayered network naturally correspond to the structural phase transitions along\nthe information curve. We believe that this new insight can lead to new\noptimality bounds and deep learning algorithms.\n",
        "published": "2015-03-09T09:39:41Z",
        "pdf_link": "http://arxiv.org/pdf/1503.02406v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.02946v2",
        "title": "apsis - Framework for Automated Optimization of Machine Learning Hyper\n  Parameters",
        "summary": "  The apsis toolkit presented in this paper provides a flexible framework for\nhyperparameter optimization and includes both random search and a bayesian\noptimizer. It is implemented in Python and its architecture features\nadaptability to any desired machine learning code. It can easily be used with\ncommon Python ML frameworks such as scikit-learn. Published under the MIT\nLicense other researchers are heavily encouraged to check out the code,\ncontribute or raise any suggestions. The code can be found at\ngithub.com/FrederikDiehl/apsis.\n",
        "published": "2015-03-10T15:09:25Z",
        "pdf_link": "http://arxiv.org/pdf/1503.02946v2"
    },
    {
        "id": "http://arxiv.org/abs/1503.03238v1",
        "title": "Scalable Discovery of Time-Series Shapelets",
        "summary": "  Time-series classification is an important problem for the data mining\ncommunity due to the wide range of application domains involving time-series\ndata. A recent paradigm, called shapelets, represents patterns that are highly\npredictive for the target variable. Shapelets are discovered by measuring the\nprediction accuracy of a set of potential (shapelet) candidates. The candidates\ntypically consist of all the segments of a dataset, therefore, the discovery of\nshapelets is computationally expensive. This paper proposes a novel method that\navoids measuring the prediction accuracy of similar candidates in Euclidean\ndistance space, through an online clustering pruning technique. In addition,\nour algorithm incorporates a supervised shapelet selection that filters out\nonly those candidates that improve classification accuracy. Empirical evidence\non 45 datasets from the UCR collection demonstrate that our method is 3-4\norders of magnitudes faster than the fastest existing shapelet-discovery\nmethod, while providing better prediction accuracy.\n",
        "published": "2015-03-11T09:38:49Z",
        "pdf_link": "http://arxiv.org/pdf/1503.03238v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.03488v2",
        "title": "Estimating the Mean Number of K-Means Clusters to Form",
        "summary": "  Utilizing the sample size of a dataset, the random cluster model is employed\nin order to derive an estimate of the mean number of K-Means clusters to form\nduring classification of a dataset.\n",
        "published": "2015-03-07T22:45:54Z",
        "pdf_link": "http://arxiv.org/pdf/1503.03488v2"
    },
    {
        "id": "http://arxiv.org/abs/1503.03578v1",
        "title": "LINE: Large-scale Information Network Embedding",
        "summary": "  This paper studies the problem of embedding very large information networks\ninto low-dimensional vector spaces, which is useful in many tasks such as\nvisualization, node classification, and link prediction. Most existing graph\nembedding methods do not scale for real world information networks which\nusually contain millions of nodes. In this paper, we propose a novel network\nembedding method called the \"LINE,\" which is suitable for arbitrary types of\ninformation networks: undirected, directed, and/or weighted. The method\noptimizes a carefully designed objective function that preserves both the local\nand global network structures. An edge-sampling algorithm is proposed that\naddresses the limitation of the classical stochastic gradient descent and\nimproves both the effectiveness and the efficiency of the inference. Empirical\nexperiments prove the effectiveness of the LINE on a variety of real-world\ninformation networks, including language networks, social networks, and\ncitation networks. The algorithm is very efficient, which is able to learn the\nembedding of a network with millions of vertices and billions of edges in a few\nhours on a typical single machine. The source code of the LINE is available\nonline.\n",
        "published": "2015-03-12T04:07:32Z",
        "pdf_link": "http://arxiv.org/pdf/1503.03578v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.04269v2",
        "title": "An Emphatic Approach to the Problem of Off-policy Temporal-Difference\n  Learning",
        "summary": "  In this paper we introduce the idea of improving the performance of\nparametric temporal-difference (TD) learning algorithms by selectively\nemphasizing or de-emphasizing their updates on different time steps. In\nparticular, we show that varying the emphasis of linear TD($\\lambda$)'s updates\nin a particular way causes its expected update to become stable under\noff-policy training. The only prior model-free TD methods to achieve this with\nper-step computation linear in the number of function approximation parameters\nare the gradient-TD family of methods including TDC, GTD($\\lambda$), and\nGQ($\\lambda$). Compared to these methods, our _emphatic TD($\\lambda$)_ is\nsimpler and easier to use; it has only one learned parameter vector and one\nstep-size parameter. Our treatment includes general state-dependent discounting\nand bootstrapping functions, and a way of specifying varying degrees of\ninterest in accurately valuing different states.\n",
        "published": "2015-03-14T04:44:20Z",
        "pdf_link": "http://arxiv.org/pdf/1503.04269v2"
    },
    {
        "id": "http://arxiv.org/abs/1503.04996v1",
        "title": "On Extreme Pruning of Random Forest Ensembles for Real-time Predictive\n  Applications",
        "summary": "  Random Forest (RF) is an ensemble supervised machine learning technique that\nwas developed by Breiman over a decade ago. Compared with other ensemble\ntechniques, it has proved its accuracy and superiority. Many researchers,\nhowever, believe that there is still room for enhancing and improving its\nperformance accuracy. This explains why, over the past decade, there have been\nmany extensions of RF where each extension employed a variety of techniques and\nstrategies to improve certain aspect(s) of RF. Since it has been proven\nempiricallthat ensembles tend to yield better results when there is a\nsignificant diversity among the constituent models, the objective of this paper\nis twofold. First, it investigates how data clustering (a well known diversity\ntechnique) can be applied to identify groups of similar decision trees in an RF\nin order to eliminate redundant trees by selecting a representative from each\ngroup (cluster). Second, these likely diverse representatives are then used to\nproduce an extension of RF termed CLUB-DRF that is much smaller in size than\nRF, and yet performs at least as good as RF, and mostly exhibits higher\nperformance in terms of accuracy. The latter refers to a known technique called\nensemble pruning. Experimental results on 15 real datasets from the UCI\nrepository prove the superiority of our proposed extension over the traditional\nRF. Most of our experiments achieved at least 95% or above pruning level while\nretaining or outperforming the RF accuracy.\n",
        "published": "2015-03-17T11:01:37Z",
        "pdf_link": "http://arxiv.org/pdf/1503.04996v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.05018v1",
        "title": "Ultra-Fast Shapelets for Time Series Classification",
        "summary": "  Time series shapelets are discriminative subsequences and their similarity to\na time series can be used for time series classification. Since the discovery\nof time series shapelets is costly in terms of time, the applicability on long\nor multivariate time series is difficult. In this work we propose Ultra-Fast\nShapelets that uses a number of random shapelets. It is shown that Ultra-Fast\nShapelets yield the same prediction quality as current state-of-the-art\nshapelet-based time series classifiers that carefully select the shapelets by\nbeing by up to three orders of magnitudes. Since this method allows a\nultra-fast shapelet discovery, using shapelets for long multivariate time\nseries classification becomes feasible.\n  A method for using shapelets for multivariate time series is proposed and\nUltra-Fast Shapelets is proven to be successful in comparison to\nstate-of-the-art multivariate time series classifiers on 15 multivariate time\nseries datasets from various domains. Finally, time series derivatives that\nhave proven to be useful for other time series classifiers are investigated for\nthe shapelet-based classifiers. It is shown that they have a positive impact\nand that they are easy to integrate with a simple preprocessing step, without\nthe need of adapting the shapelet discovery algorithm.\n",
        "published": "2015-03-17T12:41:30Z",
        "pdf_link": "http://arxiv.org/pdf/1503.05018v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.05187v1",
        "title": "An Outlier Detection-based Tree Selection Approach to Extreme Pruning of\n  Random Forests",
        "summary": "  Random Forest (RF) is an ensemble classification technique that was developed\nby Breiman over a decade ago. Compared with other ensemble techniques, it has\nproved its accuracy and superiority. Many researchers, however, believe that\nthere is still room for enhancing and improving its performance in terms of\npredictive accuracy. This explains why, over the past decade, there have been\nmany extensions of RF where each extension employed a variety of techniques and\nstrategies to improve certain aspect(s) of RF. Since it has been proven\nempirically that ensembles tend to yield better results when there is a\nsignificant diversity among the constituent models, the objective of this paper\nis twofolds. First, it investigates how an unsupervised learning technique,\nnamely, Local Outlier Factor (LOF) can be used to identify diverse trees in the\nRF. Second, trees with the highest LOF scores are then used to produce an\nextension of RF termed LOFB-DRF that is much smaller in size than RF, and yet\nperforms at least as good as RF, but mostly exhibits higher performance in\nterms of accuracy. The latter refers to a known technique called ensemble\npruning. Experimental results on 10 real datasets prove the superiority of our\nproposed extension over the traditional RF. Unprecedented pruning levels\nreaching 99% have been achieved at the time of boosting the predictive accuracy\nof the ensemble. The notably high pruning level makes the technique a good\ncandidate for real-time applications.\n",
        "published": "2015-03-17T11:05:31Z",
        "pdf_link": "http://arxiv.org/pdf/1503.05187v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.05571v2",
        "title": "GSNs : Generative Stochastic Networks",
        "summary": "  We introduce a novel training principle for probabilistic models that is an\nalternative to maximum likelihood. The proposed Generative Stochastic Networks\n(GSN) framework is based on learning the transition operator of a Markov chain\nwhose stationary distribution estimates the data distribution. Because the\ntransition distribution is a conditional distribution generally involving a\nsmall move, it has fewer dominant modes, being unimodal in the limit of small\nmoves. Thus, it is easier to learn, more like learning to perform supervised\nfunction approximation, with gradients that can be obtained by\nback-propagation. The theorems provided here generalize recent work on the\nprobabilistic interpretation of denoising auto-encoders and provide an\ninteresting justification for dependency networks and generalized\npseudolikelihood (along with defining an appropriate joint distribution and\nsampling mechanism, even when the conditionals are not consistent). We study\nhow GSNs can be used with missing inputs and can be used to sample subsets of\nvariables given the rest. Successful experiments are conducted, validating\nthese theoretical results, on two image datasets and with a particular\narchitecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows\ntraining to proceed with backprop, without the need for layerwise pretraining.\n",
        "published": "2015-03-18T20:06:07Z",
        "pdf_link": "http://arxiv.org/pdf/1503.05571v2"
    },
    {
        "id": "http://arxiv.org/abs/1503.05938v1",
        "title": "On Invariance and Selectivity in Representation Learning",
        "summary": "  We discuss data representation which can be learned automatically from data,\nare invariant to transformations, and at the same time selective, in the sense\nthat two points have the same representation only if they are one the\ntransformation of the other. The mathematical results here sharpen some of the\nkey claims of i-theory -- a recent theory of feedforward processing in sensory\ncortex.\n",
        "published": "2015-03-19T20:30:46Z",
        "pdf_link": "http://arxiv.org/pdf/1503.05938v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.06169v1",
        "title": "Networked Stochastic Multi-Armed Bandits with Combinatorial Strategies",
        "summary": "  In this paper, we investigate a largely extended version of classical MAB\nproblem, called networked combinatorial bandit problems. In particular, we\nconsider the setting of a decision maker over a networked bandits as follows:\neach time a combinatorial strategy, e.g., a group of arms, is chosen, and the\ndecision maker receives a reward resulting from her strategy and also receives\na side bonus resulting from that strategy for each arm's neighbor. This is\nmotivated by many real applications such as on-line social networks where\nfriends can provide their feedback on shared content, therefore if we promote a\nproduct to a user, we can also collect feedback from her friends on that\nproduct. To this end, we consider two types of side bonus in this study: side\nobservation and side reward. Upon the number of arms pulled at each time slot,\nwe study two cases: single-play and combinatorial-play. Consequently, this\nleaves us four scenarios to investigate in the presence of side bonus:\nSingle-play with Side Observation, Combinatorial-play with Side Observation,\nSingle-play with Side Reward, and Combinatorial-play with Side Reward. For each\ncase, we present and analyze a series of \\emph{zero regret} polices where the\nexpect of regret over time approaches zero as time goes to infinity. Extensive\nsimulations validate the effectiveness of our results.\n",
        "published": "2015-03-20T17:21:12Z",
        "pdf_link": "http://arxiv.org/pdf/1503.06169v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.06549v1",
        "title": "Optimum Reject Options for Prototype-based Classification",
        "summary": "  We analyse optimum reject strategies for prototype-based classifiers and\nreal-valued rejection measures, using the distance of a data point to the\nclosest prototype or probabilistic counterparts. We compare reject schemes with\nglobal thresholds, and local thresholds for the Voronoi cells of the\nclassifier. For the latter, we develop a polynomial-time algorithm to compute\noptimum thresholds based on a dynamic programming scheme, and we propose an\nintuitive linear time, memory efficient approximation thereof with competitive\naccuracy. Evaluating the performance in various benchmarks, we conclude that\nlocal reject options are beneficial in particular for simple prototype-based\nclassifiers, while the improvement is less pronounced for advanced models. For\nthe latter, an accuracy-reject curve which is comparable to support vector\nmachine classifiers with state of the art reject options can be reached.\n",
        "published": "2015-03-23T08:19:17Z",
        "pdf_link": "http://arxiv.org/pdf/1503.06549v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.06608v1",
        "title": "Proficiency Comparison of LADTree and REPTree Classifiers for Credit\n  Risk Forecast",
        "summary": "  Predicting the Credit Defaulter is a perilous task of Financial Industries\nlike Banks. Ascertaining non-payer before giving loan is a significant and\nconflict-ridden task of the Banker. Classification techniques are the better\nchoice for predictive analysis like finding the claimant, whether he/she is an\nunpretentious customer or a cheat. Defining the outstanding classifier is a\nrisky assignment for any industrialist like a banker. This allow computer\nscience researchers to drill down efficient research works through evaluating\ndifferent classifiers and finding out the best classifier for such predictive\nproblems. This research work investigates the productivity of LADTree\nClassifier and REPTree Classifier for the credit risk prediction and compares\ntheir fitness through various measures. German credit dataset has been taken\nand used to predict the credit risk with a help of open source machine learning\ntool.\n",
        "published": "2015-03-23T11:47:05Z",
        "pdf_link": "http://arxiv.org/pdf/1503.06608v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.06619v2",
        "title": "Fusing Continuous-valued Medical Labels using a Bayesian Model",
        "summary": "  With the rapid increase in volume of time series medical data available\nthrough wearable devices, there is a need to employ automated algorithms to\nlabel data. Examples of labels include interventions, changes in activity (e.g.\nsleep) and changes in physiology (e.g. arrhythmias). However, automated\nalgorithms tend to be unreliable resulting in lower quality care. Expert\nannotations are scarce, expensive, and prone to significant inter- and\nintra-observer variance. To address these problems, a Bayesian\nContinuous-valued Label Aggregator(BCLA) is proposed to provide a reliable\nestimation of label aggregation while accurately infer the precision and bias\nof each algorithm. The BCLA was applied to QT interval (pro-arrhythmic\nindicator) estimation from the electrocardiogram using labels from the 2006\nPhysioNet/Computing in Cardiology Challenge database. It was compared to the\nmean, median, and a previously proposed Expectation Maximization (EM) label\naggregation approaches. While accurately predicting each labelling algorithm's\nbias and precision, the root-mean-square error of the BCLA was\n11.78$\\pm$0.63ms, significantly outperforming the best Challenge entry\n(15.37$\\pm$2.13ms) as well as the EM, mean, and median voting strategies\n(14.76$\\pm$0.52ms, 17.61$\\pm$0.55ms, and 14.43$\\pm$0.57ms respectively with\n$p<0.0001$).\n",
        "published": "2015-03-23T12:31:18Z",
        "pdf_link": "http://arxiv.org/pdf/1503.06619v2"
    },
    {
        "id": "http://arxiv.org/abs/1503.06629v1",
        "title": "A Probabilistic Interpretation of Sampling Theory of Graph Signals",
        "summary": "  We give a probabilistic interpretation of sampling theory of graph signals.\nTo do this, we first define a generative model for the data using a pairwise\nGaussian random field (GRF) which depends on the graph. We show that, under\ncertain conditions, reconstructing a graph signal from a subset of its samples\nby least squares is equivalent to performing MAP inference on an approximation\nof this GRF which has a low rank covariance matrix. We then show that a\nsampling set of given size with the largest associated cut-off frequency, which\nis optimal from a sampling theoretic point of view, minimizes the worst case\npredictive covariance of the MAP estimate on the GRF. This interpretation also\ngives an intuitive explanation for the superior performance of the sampling\ntheoretic approach to active semi-supervised classification.\n",
        "published": "2015-03-23T13:20:22Z",
        "pdf_link": "http://arxiv.org/pdf/1503.06629v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.06745v1",
        "title": "Online classifier adaptation for cost-sensitive learning",
        "summary": "  In this paper, we propose the problem of online cost-sensitive clas- sifier\nadaptation and the first algorithm to solve it. We assume we have a base\nclassifier for a cost-sensitive classification problem, but it is trained with\nrespect to a cost setting different to the desired one. Moreover, we also have\nsome training data samples streaming to the algorithm one by one. The prob- lem\nis to adapt the given base classifier to the desired cost setting using the\nsteaming training samples online. To solve this problem, we propose to learn a\nnew classifier by adding an adaptation function to the base classifier, and\nupdate the adaptation function parameter according to the streaming data\nsamples. Given a input data sample and the cost of misclassifying it, we up-\ndate the adaptation function parameter by minimizing cost weighted hinge loss\nand respecting previous learned parameter simultaneously. The proposed\nalgorithm is compared to both online and off-line cost-sensitive algorithms on\ntwo cost-sensitive classification problems, and the experiments show that it\nnot only outperforms them one classification performances, but also requires\nsignificantly less running time.\n",
        "published": "2015-03-23T17:47:00Z",
        "pdf_link": "http://arxiv.org/pdf/1503.06745v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.06858v4",
        "title": "Communication Efficient Distributed Kernel Principal Component Analysis",
        "summary": "  Kernel Principal Component Analysis (KPCA) is a key machine learning\nalgorithm for extracting nonlinear features from data. In the presence of a\nlarge volume of high dimensional data collected in a distributed fashion, it\nbecomes very costly to communicate all of this data to a single data center and\nthen perform kernel PCA. Can we perform kernel PCA on the entire dataset in a\ndistributed and communication efficient fashion while maintaining provable and\nstrong guarantees in solution quality?\n  In this paper, we give an affirmative answer to the question by developing a\ncommunication efficient algorithm to perform kernel PCA in the distributed\nsetting. The algorithm is a clever combination of subspace embedding and\nadaptive sampling techniques, and we show that the algorithm can take as input\nan arbitrary configuration of distributed datasets, and compute a set of global\nkernel principal components with relative error guarantees independent of the\ndimension of the feature space or the total number of data points. In\nparticular, computing $k$ principal components with relative error $\\epsilon$\nover $s$ workers has communication cost $\\tilde{O}(s \\rho k/\\epsilon+s\nk^2/\\epsilon^3)$ words, where $\\rho$ is the average number of nonzero entries\nin each data point. Furthermore, we experimented the algorithm with large-scale\nreal world datasets and showed that the algorithm produces a high quality\nkernel PCA solution while using significantly less communication than\nalternative approaches.\n",
        "published": "2015-03-23T22:00:51Z",
        "pdf_link": "http://arxiv.org/pdf/1503.06858v4"
    },
    {
        "id": "http://arxiv.org/abs/1503.06952v1",
        "title": "Comparing published multi-label classifier performance measures to the\n  ones obtained by a simple multi-label baseline classifier",
        "summary": "  In supervised learning, simple baseline classifiers can be constructed by\nonly looking at the class, i.e., ignoring any other information from the\ndataset. The single-label learning community frequently uses as a reference the\none which always predicts the majority class. Although a classifier might\nperform worse than this simple baseline classifier, this behaviour requires a\nspecial explanation. Aiming to motivate the community to compare experimental\nresults with the ones provided by a multi-label baseline classifier, calling\nthe attention about the need of special explanations related to classifiers\nwhich perform worse than the baseline, in this work we propose the use of\nGeneral_B, a multi-label baseline classifier. General_B was evaluated in\ncontrast to results published in the literature which were carefully selected\nusing a systematic review process. It was found that a considerable number of\npublished results on 10 frequently used datasets are worse than or equal to the\nones obtained by General_B, and for one dataset it reaches up to 43% of the\ndataset published results. Moreover, although a simple baseline classifier was\nnot considered in these publications, it was observed that even for very poor\nresults no special explanations were provided in most of them. We hope that the\nfindings of this work would encourage the multi-label community to consider the\nidea of using a simple baseline classifier, such that further explanations are\nprovided when a classifiers performs worse than a baseline.\n",
        "published": "2015-03-24T08:57:25Z",
        "pdf_link": "http://arxiv.org/pdf/1503.06952v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.06960v2",
        "title": "Sample compression schemes for VC classes",
        "summary": "  Sample compression schemes were defined by Littlestone and Warmuth (1986) as\nan abstraction of the structure underlying many learning algorithms. Roughly\nspeaking, a sample compression scheme of size $k$ means that given an arbitrary\nlist of labeled examples, one can retain only $k$ of them in a way that allows\nto recover the labels of all other examples in the list. They showed that\ncompression implies PAC learnability for binary-labeled classes, and asked\nwhether the other direction holds. We answer their question and show that every\nconcept class $C$ with VC dimension $d$ has a sample compression scheme of size\nexponential in $d$. The proof uses an approximate minimax phenomenon for binary\nmatrices of low VC dimension, which may be of interest in the context of game\ntheory.\n",
        "published": "2015-03-24T09:30:33Z",
        "pdf_link": "http://arxiv.org/pdf/1503.06960v2"
    },
    {
        "id": "http://arxiv.org/abs/1503.07477v1",
        "title": "A Survey of Classification Techniques in the Area of Big Data",
        "summary": "  Big Data concern large-volume, growing data sets that are complex and have\nmultiple autonomous sources. Earlier technologies were not able to handle\nstorage and processing of huge data thus Big Data concept comes into existence.\nThis is a tedious job for users unstructured data. So, there should be some\nmechanism which classify unstructured data into organized form which helps user\nto easily access required data. Classification techniques over big\ntransactional database provide required data to the users from large datasets\nmore simple way. There are two main classification techniques, supervised and\nunsupervised. In this paper we focused on to study of different supervised\nclassification techniques. Further this paper shows a advantages and\nlimitations.\n",
        "published": "2015-03-25T17:56:19Z",
        "pdf_link": "http://arxiv.org/pdf/1503.07477v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.07795v1",
        "title": "Multi-Labeled Classification of Demographic Attributes of Patients: a\n  case study of diabetics patients",
        "summary": "  Automated learning of patients demographics can be seen as multi-label\nproblem where a patient model is based on different race and gender groups. The\nresulting model can be further integrated into Privacy-Preserving Data Mining,\nwhere it can be used to assess risk of identification of different patient\ngroups. Our project considers relations between diabetes and demographics of\npatients as a multi-labelled problem. Most research in this area has been done\nas binary classification, where the target class is finding if a person has\ndiabetes or not. But very few, and maybe no work has been done in multi-labeled\nanalysis of the demographics of patients who are likely to be diagnosed with\ndiabetes. To identify such groups, we applied ensembles of several multi-label\nlearning algorithms.\n",
        "published": "2015-03-26T17:22:26Z",
        "pdf_link": "http://arxiv.org/pdf/1503.07795v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.08316v4",
        "title": "A Variance Reduced Stochastic Newton Method",
        "summary": "  Quasi-Newton methods are widely used in practise for convex loss minimization\nproblems. These methods exhibit good empirical performance on a wide variety of\ntasks and enjoy super-linear convergence to the optimal solution. For\nlarge-scale learning problems, stochastic Quasi-Newton methods have been\nrecently proposed. However, these typically only achieve sub-linear convergence\nrates and have not been shown to consistently perform well in practice since\nnoisy Hessian approximations can exacerbate the effect of high-variance\nstochastic gradient estimates. In this work we propose Vite, a novel stochastic\nQuasi-Newton algorithm that uses an existing first-order technique to reduce\nthis variance. Without exploiting the specific form of the approximate Hessian,\nwe show that Vite reaches the optimum at a geometric rate with a constant\nstep-size when dealing with smooth strongly convex functions. Empirically, we\ndemonstrate improvements over existing stochastic Quasi-Newton and variance\nreduced stochastic gradient methods.\n",
        "published": "2015-03-28T15:51:48Z",
        "pdf_link": "http://arxiv.org/pdf/1503.08316v4"
    },
    {
        "id": "http://arxiv.org/abs/1503.08370v3",
        "title": "Global Bandits",
        "summary": "  Multi-armed bandits (MAB) model sequential decision making problems, in which\na learner sequentially chooses arms with unknown reward distributions in order\nto maximize its cumulative reward. Most of the prior work on MAB assumes that\nthe reward distributions of each arm are independent. But in a wide variety of\ndecision problems -- from drug dosage to dynamic pricing -- the expected\nrewards of different arms are correlated, so that selecting one arm provides\ninformation about the expected rewards of other arms as well. We propose and\nanalyze a class of models of such decision problems, which we call {\\em global\nbandits}. In the case in which rewards of all arms are deterministic functions\nof a single unknown parameter, we construct a greedy policy that achieves {\\em\nbounded regret}, with a bound that depends on the single true parameter of the\nproblem. Hence, this policy selects suboptimal arms only finitely many times\nwith probability one. For this case we also obtain a bound on regret that is\n{\\em independent of the true parameter}; this bound is sub-linear, with an\nexponent that depends on the informativeness of the arms. We also propose a\nvariant of the greedy policy that achieves $\\tilde{\\mathcal{O}}(\\sqrt{T})$\nworst-case and $\\mathcal{O}(1)$ parameter dependent regret. Finally, we perform\nexperiments on dynamic pricing and show that the proposed algorithms achieve\nsignificant gains with respect to the well-known benchmarks.\n",
        "published": "2015-03-29T00:16:58Z",
        "pdf_link": "http://arxiv.org/pdf/1503.08370v3"
    },
    {
        "id": "http://arxiv.org/abs/1503.08395v6",
        "title": "Towards More Efficient SPSD Matrix Approximation and CUR Matrix\n  Decomposition",
        "summary": "  Symmetric positive semi-definite (SPSD) matrix approximation methods have\nbeen extensively used to speed up large-scale eigenvalue computation and kernel\nlearning methods. The standard sketch based method, which we call the prototype\nmodel, produces relatively accurate approximations, but is inefficient on large\nsquare matrices. The Nystr\\\"om method is highly efficient, but can only achieve\nlow accuracy. In this paper we propose a novel model that we call the {\\it fast\nSPSD matrix approximation model}. The fast model is nearly as efficient as the\nNystr\\\"om method and as accurate as the prototype model. We show that the fast\nmodel can potentially solve eigenvalue problems and kernel learning problems in\nlinear time with respect to the matrix size $n$ to achieve $1+\\epsilon$\nrelative-error, whereas both the prototype model and the Nystr\\\"om method cost\nat least quadratic time to attain comparable error bound. Empirical comparisons\namong the prototype model, the Nystr\\\"om method, and our fast model demonstrate\nthe superiority of the fast model. We also contribute new understandings of the\nNystr\\\"om method. The Nystr\\\"om method is a special instance of our fast model\nand is approximation to the prototype model. Our technique can be\nstraightforwardly applied to make the CUR matrix decomposition more efficiently\ncomputed without much affecting the accuracy.\n",
        "published": "2015-03-29T07:25:32Z",
        "pdf_link": "http://arxiv.org/pdf/1503.08395v6"
    },
    {
        "id": "http://arxiv.org/abs/1503.08873v1",
        "title": "Fast Label Embeddings for Extremely Large Output Spaces",
        "summary": "  Many modern multiclass and multilabel problems are characterized by\nincreasingly large output spaces. For these problems, label embeddings have\nbeen shown to be a useful primitive that can improve computational and\nstatistical efficiency. In this work we utilize a correspondence between rank\nconstrained estimation and low dimensional label embeddings that uncovers a\nfast label embedding algorithm which works in both the multiclass and\nmultilabel settings. The result is a randomized algorithm for partial least\nsquares, whose running time is exponentially faster than naive algorithms. We\ndemonstrate our techniques on two large-scale public datasets, from the Large\nScale Hierarchical Text Challenge and the Open Directory Project, where we\nobtain state of the art results.\n",
        "published": "2015-03-30T23:29:46Z",
        "pdf_link": "http://arxiv.org/pdf/1503.08873v1"
    },
    {
        "id": "http://arxiv.org/abs/1503.09082v11",
        "title": "Generalized Categorization Axioms",
        "summary": "  Categorization axioms have been proposed to axiomatizing clustering results,\nwhich offers a hint of bridging the difference between human recognition system\nand machine learning through an intuitive observation: an object should be\nassigned to its most similar category. However, categorization axioms cannot be\ngeneralized into a general machine learning system as categorization axioms\nbecome trivial when the number of categories becomes one. In order to\ngeneralize categorization axioms into general cases, categorization input and\ncategorization output are reinterpreted by inner and outer category\nrepresentation. According to the categorization reinterpretation, two category\nrepresentation axioms are presented. Category representation axioms and\ncategorization axioms can be combined into a generalized categorization\naxiomatic framework, which accurately delimit the theoretical categorization\nconstraints and overcome the shortcoming of categorization axioms. The proposed\naxiomatic framework not only discuses categorization test issue but also\nreinterprets many results in machine learning in a unified way, such as\ndimensionality reduction,density estimation, regression, clustering and\nclassification.\n",
        "published": "2015-03-31T15:17:57Z",
        "pdf_link": "http://arxiv.org/pdf/1503.09082v11"
    },
    {
        "id": "http://arxiv.org/abs/1507.00500v1",
        "title": "Non-convex Regularizations for Feature Selection in Ranking With Sparse\n  SVM",
        "summary": "  Feature selection in learning to rank has recently emerged as a crucial\nissue. Whereas several preprocessing approaches have been proposed, only a few\nworks have been focused on integrating the feature selection into the learning\nprocess. In this work, we propose a general framework for feature selection in\nlearning to rank using SVM with a sparse regularization term. We investigate\nboth classical convex regularizations such as $\\ell\\_1$ or weighted $\\ell\\_1$\nand non-convex regularization terms such as log penalty, Minimax Concave\nPenalty (MCP) or $\\ell\\_p$ pseudo norm with $p\\textless{}1$. Two algorithms are\nproposed, first an accelerated proximal approach for solving the convex\nproblems, second a reweighted $\\ell\\_1$ scheme to address the non-convex\nregularizations. We conduct intensive experiments on nine datasets from Letor\n3.0 and Letor 4.0 corpora. Numerical results show that the use of non-convex\nregularizations we propose leads to more sparsity in the resulting models while\nprediction performance is preserved. The number of features is decreased by up\nto a factor of six compared to the $\\ell\\_1$ regularization. In addition, the\nsoftware is publicly available on the web.\n",
        "published": "2015-07-02T10:06:02Z",
        "pdf_link": "http://arxiv.org/pdf/1507.00500v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.00504v2",
        "title": "Optimal Transport for Domain Adaptation",
        "summary": "  Domain adaptation from one data space (or domain) to another is one of the\nmost challenging tasks of modern data analytics. If the adaptation is done\ncorrectly, models built on a specific data space become more robust when\nconfronted to data depicting the same semantic concepts (the classes), but\nobserved by another observation system with its own specificities. Among the\nmany strategies proposed to adapt a domain to another, finding a common\nrepresentation has shown excellent properties: by finding a common\nrepresentation for both domains, a single classifier can be effective in both\nand use labelled samples from the source domain to predict the unlabelled\nsamples of the target domain. In this paper, we propose a regularized\nunsupervised optimal transportation model to perform the alignment of the\nrepresentations in the source and target domains. We learn a transportation\nplan matching both PDFs, which constrains labelled samples in the source domain\nto remain close during transport. This way, we exploit at the same time the few\nlabeled information in the source and the unlabelled distributions observed in\nboth domains. Experiments in toy and challenging real visual adaptation\nexamples show the interest of the method, that consistently outperforms state\nof the art approaches.\n",
        "published": "2015-07-02T10:15:11Z",
        "pdf_link": "http://arxiv.org/pdf/1507.00504v2"
    },
    {
        "id": "http://arxiv.org/abs/1507.01215v2",
        "title": "Combining Models of Approximation with Partial Learning",
        "summary": "  In Gold's framework of inductive inference, the model of partial learning\nrequires the learner to output exactly one correct index for the target object\nand only the target object infinitely often. Since infinitely many of the\nlearner's hypotheses may be incorrect, it is not obvious whether a partial\nlearner can be modifed to \"approximate\" the target object.\n  Fulk and Jain (Approximate inference and scientific method. Information and\nComputation 114(2):179--191, 1994) introduced a model of approximate learning\nof recursive functions. The present work extends their research and solves an\nopen problem of Fulk and Jain by showing that there is a learner which\napproximates and partially identifies every recursive function by outputting a\nsequence of hypotheses which, in addition, are also almost all finite variants\nof the target function.\n  The subsequent study is dedicated to the question how these findings\ngeneralise to the learning of r.e. languages from positive data. Here three\nvariants of approximate learning will be introduced and investigated with\nrespect to the question whether they can be combined with partial learning.\nFollowing the line of Fulk and Jain's research, further investigations provide\nconditions under which partial language learners can eventually output only\nfinite variants of the target language. The combinabilities of other partial\nlearning criteria will also be briefly studied.\n",
        "published": "2015-07-05T12:49:20Z",
        "pdf_link": "http://arxiv.org/pdf/1507.01215v2"
    },
    {
        "id": "http://arxiv.org/abs/1507.01563v1",
        "title": "A Simple Algorithm for Maximum Margin Classification, Revisited",
        "summary": "  In this note, we revisit the algorithm of Har-Peled et. al. [HRZ07] for\ncomputing a linear maximum margin classifier. Our presentation is self\ncontained, and the algorithm itself is slightly simpler than the original\nalgorithm. The algorithm itself is a simple Perceptron like iterative\nalgorithm. For more details and background, the reader is referred to the\noriginal paper.\n",
        "published": "2015-07-06T18:53:09Z",
        "pdf_link": "http://arxiv.org/pdf/1507.01563v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.02011v1",
        "title": "A Bayesian Approach for Online Classifier Ensemble",
        "summary": "  We propose a Bayesian approach for recursively estimating the classifier\nweights in online learning of a classifier ensemble. In contrast with past\nmethods, such as stochastic gradient descent or online boosting, our approach\nestimates the weights by recursively updating its posterior distribution. For a\nspecified class of loss functions, we show that it is possible to formulate a\nsuitably defined likelihood function and hence use the posterior distribution\nas an approximation to the global empirical loss minimizer. If the stream of\ntraining data is sampled from a stationary process, we can also show that our\napproach admits a superior rate of convergence to the expected loss minimizer\nthan is possible with standard stochastic gradient descent. In experiments with\nreal-world datasets, our formulation often performs better than\nstate-of-the-art stochastic gradient descent and online boosting algorithms.\n",
        "published": "2015-07-08T03:35:58Z",
        "pdf_link": "http://arxiv.org/pdf/1507.02011v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.02158v2",
        "title": "An Empirical Study on Budget-Aware Online Kernel Algorithms for Streams\n  of Graphs",
        "summary": "  Kernel methods are considered an effective technique for on-line learning.\nMany approaches have been developed for compactly representing the dual\nsolution of a kernel method when the problem imposes memory constraints.\nHowever, in literature no work is specifically tailored to streams of graphs.\nMotivated by the fact that the size of the feature space representation of many\nstate-of-the-art graph kernels is relatively small and thus it is explicitly\ncomputable, we study whether executing kernel algorithms in the feature space\ncan be more effective than the classical dual approach. We study three\ndifferent algorithms and various strategies for managing the budget. Efficiency\nand efficacy of the proposed approaches are experimentally assessed on\nrelatively large graph streams exhibiting concept drift. It turns out that,\nwhen strict memory budget constraints have to be enforced, working in feature\nspace, given the current state of the art on graph kernels, is more than a\nviable alternative to dual approaches, both in terms of speed and\nclassification performance.\n",
        "published": "2015-07-08T13:58:19Z",
        "pdf_link": "http://arxiv.org/pdf/1507.02158v2"
    },
    {
        "id": "http://arxiv.org/abs/1507.02186v2",
        "title": "Extending local features with contextual information in graph kernels",
        "summary": "  Graph kernels are usually defined in terms of simpler kernels over local\nsubstructures of the original graphs. Different kernels consider different\ntypes of substructures. However, in some cases they have similar predictive\nperformances, probably because the substructures can be interpreted as\napproximations of the subgraphs they induce. In this paper, we propose to\nassociate to each feature a piece of information about the context in which the\nfeature appears in the graph. A substructure appearing in two different graphs\nwill match only if it appears with the same context in both graphs. We propose\na kernel based on this idea that considers trees as substructures, and where\nthe contexts are features too. The kernel is inspired from the framework in\n[6], even if it is not part of it. We give an efficient algorithm for computing\nthe kernel and show promising results on real-world graph classification\ndatasets.\n",
        "published": "2015-07-08T14:58:49Z",
        "pdf_link": "http://arxiv.org/pdf/1507.02186v2"
    },
    {
        "id": "http://arxiv.org/abs/1507.02750v2",
        "title": "Utility-based Dueling Bandits as a Partial Monitoring Game",
        "summary": "  Partial monitoring is a generic framework for sequential decision-making with\nincomplete feedback. It encompasses a wide class of problems such as dueling\nbandits, learning with expect advice, dynamic pricing, dark pools, and label\nefficient prediction. We study the utility-based dueling bandit problem as an\ninstance of partial monitoring problem and prove that it fits the time-regret\npartial monitoring hierarchy as an easy - i.e. Theta (sqrt{T})- instance. We\nsurvey some partial monitoring algorithms and see how they could be used to\nsolve dueling bandits efficiently. Keywords: Online learning, Dueling Bandits,\nPartial Monitoring, Partial Feedback, Multiarmed Bandits\n",
        "published": "2015-07-10T00:05:38Z",
        "pdf_link": "http://arxiv.org/pdf/1507.02750v2"
    },
    {
        "id": "http://arxiv.org/abs/1507.03032v2",
        "title": "Spectral Smoothing via Random Matrix Perturbations",
        "summary": "  We consider stochastic smoothing of spectral functions of matrices using\nperturbations commonly studied in random matrix theory. We show that a spectral\nfunction remains spectral when smoothed using a unitarily invariant\nperturbation distribution. We then derive state-of-the-art smoothing bounds for\nthe maximum eigenvalue function using the Gaussian Orthogonal Ensemble (GOE).\nSmoothing the maximum eigenvalue function is important for applications in\nsemidefinite optimization and online learning. As a direct consequence of our\nGOE smoothing results, we obtain an $O((N \\log N)^{1/4} \\sqrt{T})$ expected\nregret bound for the online variance minimization problem using an algorithm\nthat performs only a single maximum eigenvector computation per time step. Here\n$T$ is the number of rounds and $N$ is the matrix dimension. Our algorithm and\nits analysis also extend to the more general online PCA problem where the\nlearner has to output a rank $k$ subspace. The algorithm just requires\ncomputing $k$ maximum eigenvectors per step and enjoys an $O(k (N \\log N)^{1/4}\n\\sqrt{T})$ expected regret bound.\n",
        "published": "2015-07-10T20:52:35Z",
        "pdf_link": "http://arxiv.org/pdf/1507.03032v2"
    },
    {
        "id": "http://arxiv.org/abs/1507.03125v1",
        "title": "A new boosting algorithm based on dual averaging scheme",
        "summary": "  The fields of machine learning and mathematical optimization increasingly\nintertwined. The special topic on supervised learning and convex optimization\nexamines this interplay. The training part of most supervised learning\nalgorithms can usually be reduced to an optimization problem that minimizes a\nloss between model predictions and training data. While most optimization\ntechniques focus on accuracy and speed of convergence, the qualities of good\noptimization algorithm from the machine learning perspective can be quite\ndifferent since machine learning is more than fitting the data. Better\noptimization algorithms that minimize the training loss can possibly give very\npoor generalization performance. In this paper, we examine a particular kind of\nmachine learning algorithm, boosting, whose training process can be viewed as\nfunctional coordinate descent on the exponential loss. We study the relation\nbetween optimization techniques and machine learning by implementing a new\nboosting algorithm. DABoost, based on dual-averaging scheme and study its\ngeneralization performance. We show that DABoost, although slower in reducing\nthe training error, in general enjoys a better generalization error than\nAdaBoost.\n",
        "published": "2015-07-11T16:46:37Z",
        "pdf_link": "http://arxiv.org/pdf/1507.03125v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.03292v4",
        "title": "Cluster-Aided Mobility Predictions",
        "summary": "  Predicting the future location of users in wireless net- works has numerous\napplications, and can help service providers to improve the quality of service\nperceived by their clients. The location predictors proposed so far estimate\nthe next location of a specific user by inspecting the past individual\ntrajectories of this user. As a consequence, when the training data collected\nfor a given user is limited, the resulting prediction is inaccurate. In this\npaper, we develop cluster-aided predictors that exploit past trajectories\ncollected from all users to predict the next location of a given user. These\npredictors rely on clustering techniques and extract from the training data\nsimilarities among the mobility patterns of the various users to improve the\nprediction accuracy. Specifically, we present CAMP (Cluster-Aided Mobility\nPredictor), a cluster-aided predictor whose design is based on recent\nnon-parametric bayesian statistical tools. CAMP is robust and adaptive in the\nsense that it exploits similarities in users' mobility only if such\nsimilarities are really present in the training data. We analytically prove the\nconsistency of the predictions provided by CAMP, and investigate its\nperformance using two large-scale datasets. CAMP significantly outperforms\nexisting predictors, and in particular those that only exploit individual past\ntrajectories.\n",
        "published": "2015-07-12T23:27:50Z",
        "pdf_link": "http://arxiv.org/pdf/1507.03292v4"
    },
    {
        "id": "http://arxiv.org/abs/1507.03372v2",
        "title": "Ordered Decompositional DAG Kernels Enhancements",
        "summary": "  In this paper, we show how the Ordered Decomposition DAGs (ODD) kernel\nframework, a framework that allows the definition of graph kernels from tree\nkernels, allows to easily define new state-of-the-art graph kernels. Here we\nconsider a fast graph kernel based on the Subtree kernel (ST), and we propose\nvarious enhancements to increase its expressiveness. The proposed DAG kernel\nhas the same worst-case complexity as the one based on ST, but an improved\nexpressivity due to an augmented set of features. Moreover, we propose a novel\nweighting scheme for the features, which can be applied to other kernels of the\nODD framework. These improvements allow the proposed kernels to improve on the\nclassification performances of the ST-based kernel for several real-world\ndatasets, reaching state-of-the-art performances.\n",
        "published": "2015-07-13T09:50:41Z",
        "pdf_link": "http://arxiv.org/pdf/1507.03372v2"
    },
    {
        "id": "http://arxiv.org/abs/1507.04029v1",
        "title": "Training artificial neural networks to learn a nondeterministic game",
        "summary": "  It is well known that artificial neural networks (ANNs) can learn\ndeterministic automata. Learning nondeterministic automata is another matter.\nThis is important because much of the world is nondeterministic, taking the\nform of unpredictable or probabilistic events that must be acted upon. If ANNs\nare to engage such phenomena, then they must be able to learn how to deal with\nnondeterminism. In this project the game of Pong poses a nondeterministic\nenvironment. The learner is given an incomplete view of the game state and\nunderlying deterministic physics, resulting in a nondeterministic game. Three\nmodels were trained and tested on the game: Mona, Elman, and Numenta's NuPIC.\n",
        "published": "2015-07-14T21:16:23Z",
        "pdf_link": "http://arxiv.org/pdf/1507.04029v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.04502v1",
        "title": "Towards Predicting First Daily Departure Times: a Gaussian Modeling\n  Approach for Load Shift Forecasting",
        "summary": "  This work provides two statistical Gaussian forecasting methods for\npredicting First Daily Departure Times (FDDTs) of everyday use electric\nvehicles. This is important in smart grid applications to understand\ndisconnection times of such mobile storage units, for instance to forecast\nstorage of non dispatchable loads (e.g. wind and solar power). We provide a\nreview of the relevant state-of-the-art driving behavior features towards FDDT\nprediction, to then propose an approximated Gaussian method which qualitatively\nforecasts how many vehicles will depart within a given time frame, by assuming\nthat departure times follow a normal distribution. This method considers\nsampling sessions as Poisson distributions which are superimposed to obtain a\nsingle approximated Gaussian model. Given the Gaussian distribution assumption\nof the departure times, we also model the problem with Gaussian Mixture Models\n(GMM), in which the priorly set number of clusters represents the desired time\ngranularity. Evaluation has proven that for the dataset tested, low error and\nhigh confidence ($\\approx 95\\%$) is possible for 15 and 10 minute intervals,\nand that GMM outperforms traditional modeling but is less generalizable across\ndatasets, as it is a closer fit to the sampling data. Conclusively we discuss\nfuture possibilities and practical applications of the discussed model.\n",
        "published": "2015-07-16T09:28:27Z",
        "pdf_link": "http://arxiv.org/pdf/1507.04502v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.04523v1",
        "title": "Upper-Confidence-Bound Algorithms for Active Learning in Multi-Armed\n  Bandits",
        "summary": "  In this paper, we study the problem of estimating uniformly well the mean\nvalues of several distributions given a finite budget of samples. If the\nvariance of the distributions were known, one could design an optimal sampling\nstrategy by collecting a number of independent samples per distribution that is\nproportional to their variance. However, in the more realistic case where the\ndistributions are not known in advance, one needs to design adaptive sampling\nstrategies in order to select which distribution to sample from according to\nthe previously observed samples. We describe two strategies based on pulling\nthe distributions a number of times that is proportional to a high-probability\nupper-confidence-bound on their variance (built from previous observed samples)\nand report a finite-sample performance analysis on the excess estimation error\ncompared to the optimal allocation. We show that the performance of these\nallocation strategies depends not only on the variances but also on the full\nshape of the distributions.\n",
        "published": "2015-07-16T11:02:13Z",
        "pdf_link": "http://arxiv.org/pdf/1507.04523v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.04888v3",
        "title": "Maximum Entropy Deep Inverse Reinforcement Learning",
        "summary": "  This paper presents a general framework for exploiting the representational\ncapacity of neural networks to approximate complex, nonlinear reward functions\nin the context of solving the inverse reinforcement learning (IRL) problem. We\nshow in this context that the Maximum Entropy paradigm for IRL lends itself\nnaturally to the efficient training of deep architectures. At test time, the\napproach leads to a computational complexity independent of the number of\ndemonstrations, which makes it especially well-suited for applications in\nlife-long learning scenarios. Our approach achieves performance commensurate to\nthe state-of-the-art on existing benchmarks while exceeding on an alternative\nbenchmark based on highly varying reward structures. Finally, we extend the\nbasic architecture - which is equivalent to a simplified subclass of Fully\nConvolutional Neural Networks (FCNNs) with width one - to include larger\nconvolutions in order to eliminate dependency on precomputed spatial features\nand work on raw input representations.\n",
        "published": "2015-07-17T09:30:03Z",
        "pdf_link": "http://arxiv.org/pdf/1507.04888v3"
    },
    {
        "id": "http://arxiv.org/abs/1507.04910v1",
        "title": "Lower Bounds for Multi-armed Bandit with Non-equivalent Multiple Plays",
        "summary": "  We study the stochastic multi-armed bandit problem with non-equivalent\nmultiple plays where, at each step, an agent chooses not only a set of arms,\nbut also their order, which influences reward distribution. In several problem\nformulations with different assumptions, we provide lower bounds for regret\nwith standard asymptotics $O(\\log{t})$ but novel coefficients and provide\noptimal algorithms, thus proving that these bounds cannot be improved.\n",
        "published": "2015-07-17T10:39:52Z",
        "pdf_link": "http://arxiv.org/pdf/1507.04910v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.05307v1",
        "title": "2 Notes on Classes with Vapnik-Chervonenkis Dimension 1",
        "summary": "  The Vapnik-Chervonenkis dimension is a combinatorial parameter that reflects\nthe \"complexity\" of a set of sets (a.k.a. concept classes). It has been\nintroduced by Vapnik and Chervonenkis in their seminal 1971 paper and has since\nfound many applications, most notably in machine learning theory and in\ncomputational geometry. Arguably the most influential consequence of the VC\nanalysis is the fundamental theorem of statistical machine learning, stating\nthat a concept class is learnable (in some precise sense) if and only if its\nVC-dimension is finite. Furthermore, for such classes a most simple learning\nrule - empirical risk minimization (ERM) - is guaranteed to succeed.\n  The simplest non-trivial structures, in terms of the VC-dimension, are the\nclasses (i.e., sets of subsets) for which that dimension is 1.\n  In this note we show a couple of curious results concerning such classes. The\nfirst result shows that such classes share a very simple structure, and, as a\ncorollary, the labeling information contained in any sample labeled by such a\nclass can be compressed into a single instance.\n  The second result shows that due to some subtle measurability issues, in\nspite of the above mentioned fundamental theorem, there are classes of\ndimension 1 for which an ERM learning rule fails miserably.\n",
        "published": "2015-07-19T16:55:08Z",
        "pdf_link": "http://arxiv.org/pdf/1507.05307v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.05455v2",
        "title": "AMP: a new time-frequency feature extraction method for intermittent\n  time-series data",
        "summary": "  The characterisation of time-series data via their most salient features is\nextremely important in a range of machine learning task, not least of all with\nregards to classification and clustering. While there exist many feature\nextraction techniques suitable for non-intermittent time-series data, these\napproaches are not always appropriate for intermittent time-series data, where\nintermittency is characterized by constant values for large periods of time\npunctuated by sharp and transient increases or decreases in value.\n  Motivated by this, we present aggregation, mode decomposition and projection\n(AMP) a feature extraction technique particularly suited to intermittent\ntime-series data which contain time-frequency patterns. For our method all\nindividual time-series within a set are combined to form a non-intermittent\naggregate. This is decomposed into a set of components which represent the\nintrinsic time-frequency signals within the data set. Individual time-series\ncan then be fit to these components to obtain a set of numerical features that\nrepresent their intrinsic time-frequency patterns. To demonstrate the\neffectiveness of AMP, we evaluate against the real word task of clustering\nintermittent time-series data. Using synthetically generated data we show that\na clustering approach which uses the features derived from AMP significantly\noutperforms traditional clustering methods. Our technique is further\nexemplified on a real world data set where AMP can be used to discover\ngroupings of individuals which correspond to real world sub-populations.\n",
        "published": "2015-07-20T11:48:01Z",
        "pdf_link": "http://arxiv.org/pdf/1507.05455v2"
    },
    {
        "id": "http://arxiv.org/abs/1507.05800v1",
        "title": "Bandit-Based Task Assignment for Heterogeneous Crowdsourcing",
        "summary": "  We consider a task assignment problem in crowdsourcing, which is aimed at\ncollecting as many reliable labels as possible within a limited budget. A\nchallenge in this scenario is how to cope with the diversity of tasks and the\ntask-dependent reliability of workers, e.g., a worker may be good at\nrecognizing the name of sports teams, but not be familiar with cosmetics\nbrands. We refer to this practical setting as heterogeneous crowdsourcing. In\nthis paper, we propose a contextual bandit formulation for task assignment in\nheterogeneous crowdsourcing, which is able to deal with the\nexploration-exploitation trade-off in worker selection. We also theoretically\ninvestigate the regret bounds for the proposed method, and demonstrate its\npractical usefulness experimentally.\n",
        "published": "2015-07-21T12:17:58Z",
        "pdf_link": "http://arxiv.org/pdf/1507.05800v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.05880v3",
        "title": "A study of the classification of low-dimensional data with supervised\n  manifold learning",
        "summary": "  Supervised manifold learning methods learn data representations by preserving\nthe geometric structure of data while enhancing the separation between data\nsamples from different classes. In this work, we propose a theoretical study of\nsupervised manifold learning for classification. We consider nonlinear\ndimensionality reduction algorithms that yield linearly separable embeddings of\ntraining data and present generalization bounds for this type of algorithms. A\nnecessary condition for satisfactory generalization performance is that the\nembedding allow the construction of a sufficiently regular interpolation\nfunction in relation with the separation margin of the embedding. We show that\nfor supervised embeddings satisfying this condition, the classification error\ndecays at an exponential rate with the number of training samples. Finally, we\nexamine the separability of supervised nonlinear embeddings that aim to\npreserve the low-dimensional geometric structure of data based on graph\nrepresentations. The proposed analysis is supported by experiments on several\nreal data sets.\n",
        "published": "2015-07-21T15:55:46Z",
        "pdf_link": "http://arxiv.org/pdf/1507.05880v3"
    },
    {
        "id": "http://arxiv.org/abs/1507.06527v4",
        "title": "Deep Recurrent Q-Learning for Partially Observable MDPs",
        "summary": "  Deep Reinforcement Learning has yielded proficient controllers for complex\ntasks. However, these controllers have limited memory and rely on being able to\nperceive the complete game screen at each decision point. To address these\nshortcomings, this article investigates the effects of adding recurrency to a\nDeep Q-Network (DQN) by replacing the first post-convolutional fully-connected\nlayer with a recurrent LSTM. The resulting \\textit{Deep Recurrent Q-Network}\n(DRQN), although capable of seeing only a single frame at each timestep,\nsuccessfully integrates information through time and replicates DQN's\nperformance on standard Atari games and partially observed equivalents\nfeaturing flickering game screens. Additionally, when trained with partial\nobservations and evaluated with incrementally more complete observations,\nDRQN's performance scales as a function of observability. Conversely, when\ntrained with full observations and evaluated with partial observations, DRQN's\nperformance degrades less than DQN's. Thus, given the same length of history,\nrecurrency is a viable alternative to stacking a history of frames in the DQN's\ninput layer and while recurrency confers no systematic advantage when learning\nto play the game, the recurrent net can better adapt at evaluation time if the\nquality of observations changes.\n",
        "published": "2015-07-23T15:16:46Z",
        "pdf_link": "http://arxiv.org/pdf/1507.06527v4"
    },
    {
        "id": "http://arxiv.org/abs/1507.06923v1",
        "title": "A Reinforcement Learning Approach to Online Learning of Decision Trees",
        "summary": "  Online decision tree learning algorithms typically examine all features of a\nnew data point to update model parameters. We propose a novel alternative,\nReinforcement Learning- based Decision Trees (RLDT), that uses Reinforcement\nLearning (RL) to actively examine a minimal number of features of a data point\nto classify it with high accuracy. Furthermore, RLDT optimizes a long term\nreturn, providing a better alternative to the traditional myopic greedy\napproach to growing decision trees. We demonstrate that this approach performs\nas well as batch learning algorithms and other online decision tree learning\nalgorithms, while making significantly fewer queries about the features of the\ndata points. We also show that RLDT can effectively handle concept drift.\n",
        "published": "2015-07-24T17:22:17Z",
        "pdf_link": "http://arxiv.org/pdf/1507.06923v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.07146v1",
        "title": "A Framework of Sparse Online Learning and Its Applications",
        "summary": "  The amount of data in our society has been exploding in the era of big data\ntoday. In this paper, we address several open challenges of big data stream\nclassification, including high volume, high velocity, high dimensionality, high\nsparsity, and high class-imbalance. Many existing studies in data mining\nliterature solve data stream classification tasks in a batch learning setting,\nwhich suffers from poor efficiency and scalability when dealing with big data.\nTo overcome the limitations, this paper investigates an online learning\nframework for big data stream classification tasks. Unlike some existing online\ndata stream classification techniques that are often based on first-order\nonline learning, we propose a framework of Sparse Online Classification (SOC)\nfor data stream classification, which includes some state-of-the-art\nfirst-order sparse online learning algorithms as special cases and allows us to\nderive a new effective second-order online learning algorithm for data stream\nclassification. In addition, we also propose a new cost-sensitive sparse online\nlearning algorithm by extending the framework with application to tackle online\nanomaly detection tasks where class distribution of data could be very\nimbalanced. We also analyze the theoretical bounds of the proposed method, and\nfinally conduct an extensive set of experiments, in which encouraging results\nvalidate the efficacy of the proposed algorithms in comparison to a family of\nstate-of-the-art techniques on a variety of data stream classification tasks.\n",
        "published": "2015-07-25T22:53:31Z",
        "pdf_link": "http://arxiv.org/pdf/1507.07146v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.07147v1",
        "title": "True Online Emphatic TD($λ$): Quick Reference and Implementation\n  Guide",
        "summary": "  This document is a guide to the implementation of true online emphatic\nTD($\\lambda$), a model-free temporal-difference algorithm for learning to make\nlong-term predictions which combines the emphasis idea (Sutton, Mahmood & White\n2015) and the true-online idea (van Seijen & Sutton 2014). The setting used\nhere includes linear function approximation, the possibility of off-policy\ntraining, and all the generality of general value functions, as well as the\nemphasis algorithm's notion of \"interest\".\n",
        "published": "2015-07-25T22:56:29Z",
        "pdf_link": "http://arxiv.org/pdf/1507.07147v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.07199v1",
        "title": "Task Selection for Bandit-Based Task Assignment in Heterogeneous\n  Crowdsourcing",
        "summary": "  Task selection (picking an appropriate labeling task) and worker selection\n(assigning the labeling task to a suitable worker) are two major challenges in\ntask assignment for crowdsourcing. Recently, worker selection has been\nsuccessfully addressed by the bandit-based task assignment (BBTA) method, while\ntask selection has not been thoroughly investigated yet. In this paper, we\nexperimentally compare several task selection strategies borrowed from active\nlearning literature, and show that the least confidence strategy significantly\nimproves the performance of task assignment in crowdsourcing.\n",
        "published": "2015-07-26T13:26:57Z",
        "pdf_link": "http://arxiv.org/pdf/1507.07199v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.07955v1",
        "title": "Sparse Multidimensional Patient Modeling using Auxiliary Confidence\n  Labels",
        "summary": "  In this work, we focus on the problem of learning a classification model that\nperforms inference on patient Electronic Health Records (EHRs). Often, a large\namount of costly expert supervision is required to learn such a model. To\nreduce this cost, we obtain confidence labels that indicate how sure an expert\nis in the class labels she provides. If meaningful confidence information can\nbe incorporated into a learning method, fewer patient instances may need to be\nlabeled to learn an accurate model. In addition, while accuracy of predictions\nis important for any inference model, a model of patients must be interpretable\nso that clinicians can understand how the model is making decisions. To these\nends, we develop a novel metric learning method called Confidence bAsed MEtric\nLearning (CAMEL) that supports inclusion of confidence labels, but also\nemphasizes interpretability in three ways. First, our method induces sparsity,\nthus producing simple models that use only a few features from patient EHRs.\nSecond, CAMEL naturally produces confidence scores that can be taken into\nconsideration when clinicians make treatment decisions. Third, the metrics\nlearned by CAMEL induce multidimensional spaces where each dimension represents\na different \"factor\" that clinicians can use to assess patients. In our\nexperimental evaluation, we show on a real-world clinical data set that our\nCAMEL methods are able to learn models that are as or more accurate as other\nmethods that use the same supervision. Furthermore, we show that when CAMEL\nuses confidence scores it is able to learn models as or more accurate as others\nwe tested while using only 10% of the training instances. Finally, we perform\nqualitative assessments on the metrics learned by CAMEL and show that they\nidentify and clearly articulate important factors in how the model performs\ninference.\n",
        "published": "2015-07-28T20:54:56Z",
        "pdf_link": "http://arxiv.org/pdf/1507.07955v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.08104v1",
        "title": "Learning Representations for Outlier Detection on a Budget",
        "summary": "  The problem of detecting a small number of outliers in a large dataset is an\nimportant task in many fields from fraud detection to high-energy physics. Two\napproaches have emerged to tackle this problem: unsupervised and supervised.\nSupervised approaches require a sufficient amount of labeled data and are\nchallenged by novel types of outliers and inherent class imbalance, whereas\nunsupervised methods do not take advantage of available labeled training\nexamples and often exhibit poorer predictive performance. We propose BORE (a\nBagged Outlier Representation Ensemble) which uses unsupervised outlier scoring\nfunctions (OSFs) as features in a supervised learning framework. BORE is able\nto adapt to arbitrary OSF feature representations, to the imbalance in labeled\ndata as well as to prediction-time constraints on computational cost. We\ndemonstrate the good performance of BORE compared to a variety of competing\nmethods in the non-budgeted and the budgeted outlier detection problem on 12\nreal-world datasets.\n",
        "published": "2015-07-29T11:28:41Z",
        "pdf_link": "http://arxiv.org/pdf/1507.08104v1"
    },
    {
        "id": "http://arxiv.org/abs/1507.08379v1",
        "title": "VMF-SNE: Embedding for Spherical Data",
        "summary": "  T-SNE is a well-known approach to embedding high-dimensional data and has\nbeen widely used in data visualization. The basic assumption of t-SNE is that\nthe data are non-constrained in the Euclidean space and the local proximity can\nbe modelled by Gaussian distributions. This assumption does not hold for a wide\nrange of data types in practical applications, for instance spherical data for\nwhich the local proximity is better modelled by the von Mises-Fisher (vMF)\ndistribution instead of the Gaussian. This paper presents a vMF-SNE embedding\nalgorithm to embed spherical data. An iterative process is derived to produce\nan efficient embedding. The results on a simulation data set demonstrated that\nvMF-SNE produces better embeddings than t-SNE for spherical data.\n",
        "published": "2015-07-30T05:09:03Z",
        "pdf_link": "http://arxiv.org/pdf/1507.08379v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.00088v1",
        "title": "Turnover Prediction Of Shares using Data Mining techniques : A Case\n  Study",
        "summary": "  Predicting the turnover of a company in the ever fluctuating Stock market has\nalways proved to be a precarious situation and most certainly a difficult task\nin hand. Data mining is a well-known sphere of Computer Science that aims on\nextracting meaningful information from large databases. However, despite the\nexistence of many algorithms for the purpose of predicting the future trends,\ntheir efficiency is questionable as their predictions suffer from a high error\nrate. The objective of this paper is to investigate various classification\nalgorithms to predict the turnover of different companies based on the Stock\nprice. The authorized dataset for predicting the turnover was taken from\nwww.bsc.com and included the stock market values of various companies over the\npast 10 years. The algorithms were investigated using the \"R\" tool. The feature\nselection algorithm, Boruta, was run on this dataset to extract the important\nand influential features for classification. With these extracted features, the\nTotal Turnover of the company was predicted using various classification\nalgorithms like Random Forest, Decision Tree, SVM and Multinomial Regression.\nThis prediction mechanism was implemented to predict the turnover of a company\non an everyday basis and hence could help navigate through dubious stock market\ntrades. An accuracy rate of 95% was achieved by the above prediction process.\nMoreover, the importance of stock market attributes was established as well.\n",
        "published": "2015-08-01T06:50:01Z",
        "pdf_link": "http://arxiv.org/pdf/1508.00088v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.00181v1",
        "title": "An Analytic Framework for Maritime Situation Analysis",
        "summary": "  Maritime domain awareness is critical for protecting sea lanes, ports,\nharbors, offshore structures and critical infrastructures against common\nthreats and illegal activities. Limited surveillance resources constrain\nmaritime domain awareness and compromise full security coverage at all times.\nThis situation calls for innovative intelligent systems for interactive\nsituation analysis to assist marine authorities and security personal in their\nroutine surveillance operations. In this article, we propose a novel situation\nanalysis framework to analyze marine traffic data and differentiate various\nscenarios of vessel engagement for the purpose of detecting anomalies of\ninterest for marine vessels that operate over some period of time in relative\nproximity to each other. The proposed framework views vessel behavior as\nprobabilistic processes and uses machine learning to model common vessel\ninteraction patterns. We represent patterns of interest as left-to-right Hidden\nMarkov Models and classify such patterns using Support Vector Machines.\n",
        "published": "2015-08-02T01:36:37Z",
        "pdf_link": "http://arxiv.org/pdf/1508.00181v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.00792v2",
        "title": "Fixed-point algorithms for learning determinantal point processes",
        "summary": "  Determinantal point processes (DPPs) offer an elegant tool for encoding\nprobabilities over subsets of a ground set. Discrete DPPs are parametrized by a\npositive semidefinite matrix (called the DPP kernel), and estimating this\nkernel is key to learning DPPs from observed data. We consider the task of\nlearning the DPP kernel, and develop for it a surprisingly simple yet effective\nnew algorithm. Our algorithm offers the following benefits over previous\napproaches: (a) it is much simpler; (b) it yields equally good and sometimes\neven better local maxima; and (c) it runs an order of magnitude faster on large\nproblems. We present experimental results on both real and simulated data to\nillustrate the numerical performance of our technique.\n",
        "published": "2015-08-04T14:58:45Z",
        "pdf_link": "http://arxiv.org/pdf/1508.00792v2"
    },
    {
        "id": "http://arxiv.org/abs/1508.02268v1",
        "title": "Dropout Training for SVMs with Data Augmentation",
        "summary": "  Dropout and other feature noising schemes have shown promising results in\ncontrolling over-fitting by artificially corrupting the training data. Though\nextensive theoretical and empirical studies have been performed for generalized\nlinear models, little work has been done for support vector machines (SVMs),\none of the most successful approaches for supervised learning. This paper\npresents dropout training for both linear SVMs and the nonlinear extension with\nlatent representation learning. For linear SVMs, to deal with the intractable\nexpectation of the non-smooth hinge loss under corrupting distributions, we\ndevelop an iteratively re-weighted least square (IRLS) algorithm by exploring\ndata augmentation techniques. Our algorithm iteratively minimizes the\nexpectation of a re-weighted least square problem, where the re-weights are\nanalytically updated. For nonlinear latent SVMs, we consider learning one layer\nof latent representations in SVMs and extend the data augmentation technique in\nconjunction with first-order Taylor-expansion to deal with the intractable\nexpected non-smooth hinge loss and the nonlinearity of latent representations.\nFinally, we apply the similar data augmentation ideas to develop a new IRLS\nalgorithm for the expected logistic loss under corrupting distributions, and we\nfurther develop a non-linear extension of logistic regression by incorporating\none layer of latent representations. Our algorithms offer insights on the\nconnection and difference between the hinge loss and logistic loss in dropout\ntraining. Empirical results on several real datasets demonstrate the\neffectiveness of dropout training on significantly boosting the classification\naccuracy of both linear and nonlinear SVMs. In addition, the nonlinear SVMs\nfurther improve the prediction performance on several image datasets.\n",
        "published": "2015-08-10T14:57:30Z",
        "pdf_link": "http://arxiv.org/pdf/1508.02268v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.02373v1",
        "title": "Training Conditional Random Fields with Natural Gradient Descent",
        "summary": "  We propose a novel parameter estimation procedure that works efficiently for\nconditional random fields (CRF). This algorithm is an extension to the maximum\nlikelihood estimation (MLE), using loss functions defined by Bregman\ndivergences which measure the proximity between the model expectation and the\nempirical mean of the feature vectors. This leads to a flexible training\nframework from which multiple update strategies can be derived using natural\ngradient descent (NGD). We carefully choose the convex function inducing the\nBregman divergence so that the types of updates are reduced, while making the\noptimization procedure more effective by transforming the gradients of the\nlog-likelihood loss function. The derived algorithms are very simple and can be\neasily implemented on top of the existing stochastic gradient descent (SGD)\noptimization procedure, yet it is very effective as illustrated by experimental\nresults.\n",
        "published": "2015-08-10T19:46:50Z",
        "pdf_link": "http://arxiv.org/pdf/1508.02373v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.02479v2",
        "title": "Normalized Hierarchical SVM",
        "summary": "  We present improved methods of using structured SVMs in a large-scale\nhierarchical classification problem, that is when labels are leaves, or sets of\nleaves, in a tree or a DAG. We examine the need to normalize both the\nregularization and the margin and show how doing so significantly improves\nperformance, including allowing achieving state-of-the-art results where\nunnormalized structured SVMs do not perform better than flat models. We also\ndescribe a further extension of hierarchical SVMs that highlight the connection\nbetween hierarchical SVMs and matrix factorization models.\n",
        "published": "2015-08-11T03:34:33Z",
        "pdf_link": "http://arxiv.org/pdf/1508.02479v2"
    },
    {
        "id": "http://arxiv.org/abs/1508.02986v1",
        "title": "From Cutting Planes Algorithms to Compression Schemes and Active\n  Learning",
        "summary": "  Cutting-plane methods are well-studied localization(and optimization)\nalgorithms. We show that they provide a natural framework to perform\nmachinelearning ---and not just to solve optimization problems posed by\nmachinelearning--- in addition to their intended optimization use. In\nparticular, theyallow one to learn sparse classifiers and provide good\ncompression schemes.Moreover, we show that very little effort is required to\nturn them intoeffective active learning methods. This last property provides a\ngeneric way todesign a whole family of active learning algorithms from existing\npassivemethods. We present numerical simulations testifying of the relevance\nofcutting-plane methods for passive and active learning tasks.\n",
        "published": "2015-08-12T16:46:29Z",
        "pdf_link": "http://arxiv.org/pdf/1508.02986v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.03130v1",
        "title": "Probabilistic Dependency Networks for Prediction and Diagnostics",
        "summary": "  Research in transportation frequently involve modelling and predicting\nattributes of events that occur at regular intervals. The event could be\narrival of a bus at a bus stop, the volume of a traffic at a particular point,\nthe demand at a particular bus stop etc. In this work, we propose a specific\nimplementation of probabilistic graphical models to learn the probabilistic\ndependency between the events that occur in a network. A dependency graph is\nbuilt from the past observed instances of the event and we use the graph to\nunderstand the causal effects of some events on others in the system. The\ndependency graph is also used to predict the attributes of future events and is\nshown to have a good prediction accuracy compared to the state of the art.\n",
        "published": "2015-08-13T06:42:25Z",
        "pdf_link": "http://arxiv.org/pdf/1508.03130v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.03285v2",
        "title": "Hash Function Learning via Codewords",
        "summary": "  In this paper we introduce a novel hash learning framework that has two main\ndistinguishing features, when compared to past approaches. First, it utilizes\ncodewords in the Hamming space as ancillary means to accomplish its hash\nlearning task. These codewords, which are inferred from the data, attempt to\ncapture similarity aspects of the data's hash codes. Secondly and more\nimportantly, the same framework is capable of addressing supervised,\nunsupervised and, even, semi-supervised hash learning tasks in a natural\nmanner. A series of comparative experiments focused on content-based image\nretrieval highlights its performance advantages.\n",
        "published": "2015-08-13T17:55:57Z",
        "pdf_link": "http://arxiv.org/pdf/1508.03285v2"
    },
    {
        "id": "http://arxiv.org/abs/1508.03326v2",
        "title": "A Survey on Contextual Multi-armed Bandits",
        "summary": "  In this survey we cover a few stochastic and adversarial contextual bandit\nalgorithms. We analyze each algorithm's assumption and regret bound.\n",
        "published": "2015-08-13T19:49:08Z",
        "pdf_link": "http://arxiv.org/pdf/1508.03326v2"
    },
    {
        "id": "http://arxiv.org/abs/1508.03329v1",
        "title": "Multi-Task Learning with Group-Specific Feature Space Sharing",
        "summary": "  When faced with learning a set of inter-related tasks from a limited amount\nof usable data, learning each task independently may lead to poor\ngeneralization performance. Multi-Task Learning (MTL) exploits the latent\nrelations between tasks and overcomes data scarcity limitations by co-learning\nall these tasks simultaneously to offer improved performance. We propose a\nnovel Multi-Task Multiple Kernel Learning framework based on Support Vector\nMachines for binary classification tasks. By considering pair-wise task\naffinity in terms of similarity between a pair's respective feature spaces, the\nnew framework, compared to other similar MTL approaches, offers a high degree\nof flexibility in determining how similar feature spaces should be, as well as\nwhich pairs of tasks should share a common feature space in order to benefit\noverall performance. The associated optimization problem is solved via a block\ncoordinate descent, which employs a consensus-form Alternating Direction Method\nof Multipliers algorithm to optimize the Multiple Kernel Learning weights and,\nhence, to determine task affinities. Empirical evaluation on seven data sets\nexhibits a statistically significant improvement of our framework's results\ncompared to the ones of several other Clustered Multi-Task Learning methods.\n",
        "published": "2015-08-13T19:58:59Z",
        "pdf_link": "http://arxiv.org/pdf/1508.03329v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.03398v2",
        "title": "End-to-end Learning of LDA by Mirror-Descent Back Propagation over a\n  Deep Architecture",
        "summary": "  We develop a fully discriminative learning approach for supervised Latent\nDirichlet Allocation (LDA) model using Back Propagation (i.e., BP-sLDA), which\nmaximizes the posterior probability of the prediction variable given the input\ndocument. Different from traditional variational learning or Gibbs sampling\napproaches, the proposed learning method applies (i) the mirror descent\nalgorithm for maximum a posterior inference and (ii) back propagation over a\ndeep architecture together with stochastic gradient/mirror descent for model\nparameter estimation, leading to scalable and end-to-end discriminative\nlearning of the model. As a byproduct, we also apply this technique to develop\na new learning method for the traditional unsupervised LDA model (i.e.,\nBP-LDA). Experimental results on three real-world regression and classification\ntasks show that the proposed methods significantly outperform the previous\nsupervised topic models, neural networks, and is on par with deep neural\nnetworks.\n",
        "published": "2015-08-14T01:32:27Z",
        "pdf_link": "http://arxiv.org/pdf/1508.03398v2"
    },
    {
        "id": "http://arxiv.org/abs/1508.03865v2",
        "title": "Predicting Grades",
        "summary": "  To increase efficacy in traditional classroom courses as well as in Massive\nOpen Online Courses (MOOCs), automated systems supporting the instructor are\nneeded. One important problem is to automatically detect students that are\ngoing to do poorly in a course early enough to be able to take remedial\nactions. Existing grade prediction systems focus on maximizing the accuracy of\nthe prediction while overseeing the importance of issuing timely and\npersonalized predictions. This paper proposes an algorithm that predicts the\nfinal grade of each student in a class. It issues a prediction for each student\nindividually, when the expected accuracy of the prediction is sufficient. The\nalgorithm learns online what is the optimal prediction and time to issue a\nprediction based on past history of students' performance in a course. We\nderive a confidence estimate for the prediction accuracy and demonstrate the\nperformance of our algorithm on a dataset obtained based on the performance of\napproximately 700 UCLA undergraduate students who have taken an introductory\ndigital signal processing over the past 7 years. We demonstrate that for 85% of\nthe students we can predict with 76% accuracy whether they are going do well or\npoorly in the class after the 4th course week. Using data obtained from a pilot\ncourse, our methodology suggests that it is effective to perform early in-class\nassessments such as quizzes, which result in timely performance prediction for\neach student, thereby enabling timely interventions by the instructor (at the\nstudent or class level) when necessary.\n",
        "published": "2015-08-16T20:53:09Z",
        "pdf_link": "http://arxiv.org/pdf/1508.03865v2"
    },
    {
        "id": "http://arxiv.org/abs/1508.04333v1",
        "title": "ESDF: Ensemble Selection using Diversity and Frequency",
        "summary": "  Recently ensemble selection for consensus clustering has emerged as a\nresearch problem in Machine Intelligence. Normally consensus clustering\nalgorithms take into account the entire ensemble of clustering, where there is\na tendency of generating a very large size ensemble before computing its\nconsensus. One can avoid considering the entire ensemble and can judiciously\nselect few partitions in the ensemble without compromising on the quality of\nthe consensus. This may result in an efficient consensus computation technique\nand may save unnecessary computational overheads. The ensemble selection\nproblem addresses this issue of consensus clustering. In this paper, we propose\nan efficient method of ensemble selection for a large ensemble. We prioritize\nthe partitions in the ensemble based on diversity and frequency. Our method\nselects top K of the partitions in order of priority, where K is decided by the\nuser. We observe that considering jointly the diversity and frequency helps in\nidentifying few representative partitions whose consensus is qualitatively\nbetter than the consensus of the entire ensemble. Experimental analysis on a\nlarge number of datasets shows our method gives better results than earlier\nensemble selection methods.\n",
        "published": "2015-08-18T14:43:57Z",
        "pdf_link": "http://arxiv.org/pdf/1508.04333v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.04582v1",
        "title": "Learning to Predict Independent of Span",
        "summary": "  We consider how to learn multi-step predictions efficiently. Conventional\nalgorithms wait until observing actual outcomes before performing the\ncomputations to update their predictions. If predictions are made at a high\nrate or span over a large amount of time, substantial computation can be\nrequired to store all relevant observations and to update all predictions when\nthe outcome is finally observed. We show that the exact same predictions can be\nlearned in a much more computationally congenial way, with uniform per-step\ncomputation that does not depend on the span of the predictions. We apply this\nidea to various settings of increasing generality, repeatedly adding desired\nproperties and each time deriving an equivalent span-independent algorithm for\nthe conventional algorithm that satisfies these desiderata. Interestingly,\nalong the way several known algorithmic constructs emerge spontaneously from\nour derivations, including dutch eligibility traces, temporal difference\nerrors, and averaging. This allows us to link these constructs one-to-one to\nthe corresponding desiderata, unambiguously connecting the `how' to the `why'.\nEach step, we make sure that the derived algorithm subsumes the previous\nalgorithms, thereby retaining their properties. Ultimately we arrive at a\nsingle general temporal-difference algorithm that is applicable to the full\nsetting of reinforcement learning.\n",
        "published": "2015-08-19T09:37:25Z",
        "pdf_link": "http://arxiv.org/pdf/1508.04582v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.04734v1",
        "title": "Fault Diagnosis of Helical Gear Box using Large Margin K-Nearest\n  Neighbors Classifier using Sound Signals",
        "summary": "  Gear drives are one of the most widely used transmission system in many\nmachinery. Sound signals of a rotating machine contain the dynamic information\nabout its health conditions. Not much information available in the literature\nreporting suitability of sound signals for fault diagnosis applications.\nMaximum numbers of literature are based on FFT (Fast Fourier Transform)\nanalysis and have its own limitations with non-stationary signals like the ones\nfrom gears. In this paper, attempt has been made in using sound signals\nacquired from gears in good and simulated faulty conditions for the purpose of\nfault diagnosis through a machine learning approach. The descriptive\nstatistical features were extracted from the acquired sound signals and the\npredominant features were selected using J48 decision tree technique. The\nselected features were then used for classification using Large Margin\nK-nearest neighbor approach. The paper also discusses the effect of various\nparameters on classification accuracy.\n",
        "published": "2015-08-19T18:33:07Z",
        "pdf_link": "http://arxiv.org/pdf/1508.04734v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.04826v2",
        "title": "Dither is Better than Dropout for Regularising Deep Neural Networks",
        "summary": "  Regularisation of deep neural networks (DNN) during training is critical to\nperformance. By far the most popular method is known as dropout. Here, cast\nthrough the prism of signal processing theory, we compare and contrast the\nregularisation effects of dropout with those of dither. We illustrate some\nserious inherent limitations of dropout and demonstrate that dither provides a\nmore effective regulariser.\n",
        "published": "2015-08-19T23:02:37Z",
        "pdf_link": "http://arxiv.org/pdf/1508.04826v2"
    },
    {
        "id": "http://arxiv.org/abs/1508.04906v1",
        "title": "Semi-supervised Learning with Regularized Laplacian",
        "summary": "  We study a semi-supervised learning method based on the similarity graph and\nRegularizedLaplacian. We give convenient optimization formulation of the\nRegularized Laplacian method and establishits various properties. In\nparticular, we show that the kernel of the methodcan be interpreted in terms of\ndiscrete and continuous time random walks and possesses several\nimportantproperties of proximity measures. Both optimization and linear algebra\nmethods can be used for efficientcomputation of the classification functions.\nWe demonstrate on numerical examples that theRegularized Laplacian method is\ncompetitive with respect to the other state of the art semi-supervisedlearning\nmethods.\n",
        "published": "2015-08-20T08:01:42Z",
        "pdf_link": "http://arxiv.org/pdf/1508.04906v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.06477v2",
        "title": "Greedy methods, randomization approaches and multi-arm bandit algorithms\n  for efficient sparsity-constrained optimization",
        "summary": "  Several sparsity-constrained algorithms such as Orthogonal Matching Pursuit\nor the Frank-Wolfe algorithm with sparsity constraints work by iteratively\nselecting a novel atom to add to the current non-zero set of variables. This\nselection step is usually performed by computing the gradient and then by\nlooking for the gradient component with maximal absolute entry. This step can\nbe computationally expensive especially for large-scale and high-dimensional\ndata. In this work, we aim at accelerating these sparsity-constrained\noptimization algorithms by exploiting the key observation that, for these\nalgorithms to work, one only needs the coordinate of the gradient's top entry.\nHence, we introduce algorithms based on greedy methods and randomization\napproaches that aim at cheaply estimating the gradient and its top entry.\nAnother of our contribution is to cast the problem of finding the best gradient\nentry as a best arm identification in a multi-armed bandit problem. Owing to\nthis novel insight, we are able to provide a bandit-based algorithm that\ndirectly estimates the top entry in a very efficient way. Theoretical\nobservations stating that the resulting inexact Frank-Wolfe or Orthogonal\nMatching Pursuit algorithms act, with high probability, similarly to their\nexact versions are also given. We have carried out several experiments showing\nthat the greedy deterministic and the bandit approaches we propose can achieve\nan acceleration of an order of magnitude while being as efficient as the exact\ngradient when used in algorithms such as OMP, Frank-Wolfe or CoSaMP.\n",
        "published": "2015-08-26T13:01:36Z",
        "pdf_link": "http://arxiv.org/pdf/1508.06477v2"
    },
    {
        "id": "http://arxiv.org/abs/1508.06717v1",
        "title": "Online Anomaly Detection via Class-Imbalance Learning",
        "summary": "  Anomaly detection is an important task in many real world applications such\nas fraud detection, suspicious activity detection, health care monitoring etc.\nIn this paper, we tackle this problem from supervised learning perspective in\nonline learning setting. We maximize well known \\emph{Gmean} metric for\nclass-imbalance learning in online learning framework. Specifically, we show\nthat maximizing \\emph{Gmean} is equivalent to minimizing a convex surrogate\nloss function and based on that we propose novel online learning algorithm for\nanomaly detection. We then show, by extensive experiments, that the performance\nof the proposed algorithm with respect to $sum$ metric is as good as a recently\nproposed Cost-Sensitive Online Classification(CSOC) algorithm for\nclass-imbalance learning over various benchmarked data sets while keeping\nrunning time close to the perception algorithm. Our another conclusion is that\nother competitive online algorithms do not perform consistently over data sets\nof varying size. This shows the potential applicability of our proposed\napproach.\n",
        "published": "2015-08-27T03:39:39Z",
        "pdf_link": "http://arxiv.org/pdf/1508.06717v1"
    },
    {
        "id": "http://arxiv.org/abs/1508.07091v4",
        "title": "Multi-armed Bandit Problem with Known Trend",
        "summary": "  We consider a variant of the multi-armed bandit model, which we call\nmulti-armed bandit problem with known trend, where the gambler knows the shape\nof the reward function of each arm but not its distribution. This new problem\nis motivated by different online problems like active learning, music and\ninterface recommendation applications, where when an arm is sampled by the\nmodel the received reward change according to a known trend. By adapting the\nstandard multi-armed bandit algorithm UCB1 to take advantage of this setting,\nwe propose the new algorithm named A-UCB that assumes a stochastic model. We\nprovide upper bounds of the regret which compare favourably with the ones of\nUCB1. We also confirm that experimentally with different simulations\n",
        "published": "2015-08-28T04:35:28Z",
        "pdf_link": "http://arxiv.org/pdf/1508.07091v4"
    },
    {
        "id": "http://arxiv.org/abs/1508.07175v3",
        "title": "Competitive and Penalized Clustering Auto-encoder",
        "summary": "  The paper has been withdrawn since more effective experiments should be\ncompleted.\n  Auto-encoders (AE) has been widely applied in different fields of machine\nlearning. However, as a deep model, there are a large amount of learnable\nparameters in the AE, which would cause over-fitting and slow learning speed in\npractice. Many researchers have been study the intrinsic structure of AE and\nshowed different useful methods to regularize those parameters. In this paper,\nwe present a novel regularization method based on a clustering algorithm which\nis able to classify the parameters into different groups. With this\nregularization, parameters in a given group have approximate equivalent values\nand over-fitting problem could be alleviated. Moreover, due to the competitive\nbehavior of clustering algorithm, this model also overcomes some intrinsic\nproblems of clustering algorithms like the determination of number of clusters.\nExperiments on handwritten digits recognition verify the effectiveness of our\nnovel model.\n",
        "published": "2015-08-28T12:03:16Z",
        "pdf_link": "http://arxiv.org/pdf/1508.07175v3"
    },
    {
        "id": "http://arxiv.org/abs/1509.00181v7",
        "title": "Differentially Private Online Learning for Cloud-Based Video\n  Recommendation with Multimedia Big Data in Social Networks",
        "summary": "  With the rapid growth in multimedia services and the enormous offers of video\ncontents in online social networks, users have difficulty in obtaining their\ninterests. Therefore, various personalized recommendation systems have been\nproposed. However, they ignore that the accelerated proliferation of social\nmedia data has led to the big data era, which has greatly impeded the process\nof video recommendation. In addition, none of them has considered both the\nprivacy of users' contexts (e,g., social status, ages and hobbies) and video\nservice vendors' repositories, which are extremely sensitive and of significant\ncommercial value. To handle the problems, we propose a cloud-assisted\ndifferentially private video recommendation system based on distributed online\nlearning. In our framework, service vendors are modeled as distributed\ncooperative learners, recommending videos according to user's context, while\nsimultaneously adapting the video-selection strategy based on user-click\nfeedback to maximize total user clicks (reward). Considering the sparsity and\nheterogeneity of big social media data, we also propose a novel geometric\ndifferentially private model, which can greatly reduce the performance\n(recommendation accuracy) loss. Our simulation shows the proposed algorithms\noutperform other existing methods and keep a delicate balance between computing\naccuracy and privacy preserving level.\n",
        "published": "2015-09-01T09:01:07Z",
        "pdf_link": "http://arxiv.org/pdf/1509.00181v7"
    },
    {
        "id": "http://arxiv.org/abs/1509.00498v1",
        "title": "Sensor-Type Classification in Buildings",
        "summary": "  Many sensors/meters are deployed in commercial buildings to monitor and\noptimize their performance. However, because sensor metadata is inconsistent\nacross buildings, software-based solutions are tightly coupled to the sensor\nmetadata conventions (i.e. schemas and naming) for each building. Running the\nsame software across buildings requires significant integration effort.\n  Metadata normalization is critical for scaling the deployment process and\nallows us to decouple building-specific conventions from the code written for\nbuilding applications. It also allows us to deal with missing metadata. One\nimportant aspect of normalization is to differentiate sensors by the typeof\nphenomena being observed. In this paper, we propose a general, simple, yet\neffective classification scheme to differentiate sensors in buildings by type.\nWe perform ensemble learning on data collected from over 2000 sensor streams in\ntwo buildings. Our approach is able to achieve more than 92% accuracy for\nclassification within buildings and more than 82% accuracy for across\nbuildings. We also introduce a method for identifying potential misclassified\nstreams. This is important because it allows us to identify opportunities to\nattain more input from experts -- input that could help improve classification\naccuracy when ground truth is unavailable. We show that by adjusting a\nthreshold value we are able to identify at least 30% of the misclassified\ninstances.\n",
        "published": "2015-09-01T20:46:19Z",
        "pdf_link": "http://arxiv.org/pdf/1509.00498v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.00913v3",
        "title": "On-the-Fly Learning in a Perpetual Learning Machine",
        "summary": "  Despite the promise of brain-inspired machine learning, deep neural networks\n(DNN) have frustratingly failed to bridge the deceptively large gap between\nlearning and memory. Here, we introduce a Perpetual Learning Machine; a new\ntype of DNN that is capable of brain-like dynamic 'on the fly' learning because\nit exists in a self-supervised state of Perpetual Stochastic Gradient Descent.\nThus, we provide the means to unify learning and memory within a machine\nlearning framework. We also explore the elegant duality of abstraction and\nsynthesis: the Yin and Yang of deep learning.\n",
        "published": "2015-09-03T01:30:29Z",
        "pdf_link": "http://arxiv.org/pdf/1509.00913v3"
    },
    {
        "id": "http://arxiv.org/abs/1509.01053v1",
        "title": "Training a Restricted Boltzmann Machine for Classification by Labeling\n  Model Samples",
        "summary": "  We propose an alternative method for training a classification model. Using\nthe MNIST set of handwritten digits and Restricted Boltzmann Machines, it is\npossible to reach a classification performance competitive to semi-supervised\nlearning if we first train a model in an unsupervised fashion on unlabeled data\nonly, and then manually add labels to model samples instead of training data\nsamples with the help of a GUI. This approach can benefit from the fact that\nmodel samples can be presented to the human labeler in a video-like fashion,\nresulting in a higher number of labeled examples. Also, after some initial\ntraining, hard-to-classify examples can be distinguished from easy ones\nautomatically, saving manual work.\n",
        "published": "2015-09-03T12:13:37Z",
        "pdf_link": "http://arxiv.org/pdf/1509.01053v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.01116v2",
        "title": "A tree-based kernel for graphs with continuous attributes",
        "summary": "  The availability of graph data with node attributes that can be either\ndiscrete or real-valued is constantly increasing. While existing kernel methods\nare effective techniques for dealing with graphs having discrete node labels,\ntheir adaptation to non-discrete or continuous node attributes has been\nlimited, mainly for computational issues. Recently, a few kernels especially\ntailored for this domain, and that trade predictive performance for\ncomputational efficiency, have been proposed. In this paper, we propose a graph\nkernel for complex and continuous nodes' attributes, whose features are tree\nstructures extracted from specific graph visits. The kernel manages to keep the\nsame complexity of state-of-the-art kernels while implicitly using a larger\nfeature space. We further present an approximated variant of the kernel which\nreduces its complexity significantly. Experimental results obtained on six\nreal-world datasets show that the kernel is the best performing one on most of\nthem. Moreover, in most cases the approximated version reaches comparable\nperformances to current state-of-the-art kernels in terms of classification\naccuracy while greatly shortening the running times.\n",
        "published": "2015-09-03T14:59:10Z",
        "pdf_link": "http://arxiv.org/pdf/1509.01116v2"
    },
    {
        "id": "http://arxiv.org/abs/1509.01270v1",
        "title": "Machine Learning Methods to Analyze Arabidopsis Thaliana Plant Root\n  Growth",
        "summary": "  One of the challenging problems in biology is to classify plants based on\ntheir reaction on genetic mutation. Arabidopsis Thaliana is a plant that is so\ninteresting, because its genetic structure has some similarities with that of\nhuman beings. Biologists classify the type of this plant to mutated and not\nmutated (wild) types. Phenotypic analysis of these types is a time-consuming\nand costly effort by individuals. In this paper, we propose a modified feature\nextraction step by using velocity and acceleration of root growth. In the\nsecond step, for plant classification, we employed different Support Vector\nMachine (SVM) kernels and two hybrid systems of neural networks. Gated Negative\nCorrelation Learning (GNCL) and Mixture of Negatively Correlated Experts (MNCE)\nare two ensemble methods based on complementary feature of classical\nclassifiers; Mixture of Expert (ME) and Negative Correlation Learning (NCL).\nThe hybrid systems conserve of advantages and decrease the effects of\ndisadvantages of NCL and ME. Our Experimental shows that MNCE and GNCL improve\nthe efficiency of classical classifiers, however, some SVM kernels function has\nbetter performance than classifiers based on neural network ensemble method.\nMoreover, kernels consume less time to obtain a classification rate.\n",
        "published": "2015-09-03T20:22:43Z",
        "pdf_link": "http://arxiv.org/pdf/1509.01270v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.01271v1",
        "title": "Probabilistic Neural Network Training for Semi-Supervised Classifiers",
        "summary": "  In this paper, we propose another version of help-training approach by\nemploying a Probabilistic Neural Network (PNN) that improves the performance of\nthe main discriminative classifier in the semi-supervised strategy. We\nintroduce the PNN-training algorithm and use it for training the support vector\nmachine (SVM) with a few numbers of labeled data and a large number of\nunlabeled data. We try to find the best labels for unlabeled data and then use\nSVM to enhance the classification rate. We test our method on two famous\nbenchmarks and show the efficiency of our method in comparison with pervious\nmethods.\n",
        "published": "2015-09-03T20:30:19Z",
        "pdf_link": "http://arxiv.org/pdf/1509.01271v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.01346v1",
        "title": "Deep Broad Learning - Big Models for Big Data",
        "summary": "  Deep learning has demonstrated the power of detailed modeling of complex\nhigh-order (multivariate) interactions in data. For some learning tasks there\nis power in learning models that are not only Deep but also Broad. By Broad, we\nmean models that incorporate evidence from large numbers of features. This is\nof especial value in applications where many different features and\ncombinations of features all carry small amounts of information about the\nclass. The most accurate models will integrate all that information. In this\npaper, we propose an algorithm for Deep Broad Learning called DBL. The proposed\nalgorithm has a tunable parameter $n$, that specifies the depth of the model.\nIt provides straightforward paths towards out-of-core learning for large data.\nWe demonstrate that DBL learns models from large quantities of data with\naccuracy that is highly competitive with the state-of-the-art.\n",
        "published": "2015-09-04T06:01:11Z",
        "pdf_link": "http://arxiv.org/pdf/1509.01346v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.01349v1",
        "title": "Parallel and Distributed Approaches for Graph Based Semi-supervised\n  Learning",
        "summary": "  Two approaches for graph based semi-supervised learning are proposed. The\nfirstapproach is based on iteration of an affine map. A key element of the\naffine map iteration is sparsematrix-vector multiplication, which has several\nvery efficient parallel implementations. The secondapproach belongs to the\nclass of Markov Chain Monte Carlo (MCMC) algorithms. It is based onsampling of\nnodes by performing a random walk on the graph. The latter approach is\ndistributedby its nature and can be easily implemented on several processors or\nover the network. Boththeoretical and practical evaluations are provided. It is\nfound that the nodes are classified intotheir class with very small error. The\nsampling algorithm's ability to track new incoming nodesand to classify them is\nalso demonstrated.\n",
        "published": "2015-09-04T06:35:55Z",
        "pdf_link": "http://arxiv.org/pdf/1509.01349v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.01618v2",
        "title": "Efficient Sampling for k-Determinantal Point Processes",
        "summary": "  Determinantal Point Processes (DPPs) are elegant probabilistic models of\nrepulsion and diversity over discrete sets of items. But their applicability to\nlarge sets is hindered by expensive cubic-complexity matrix operations for\nbasic tasks such as sampling. In light of this, we propose a new method for\napproximate sampling from discrete $k$-DPPs. Our method takes advantage of the\ndiversity property of subsets sampled from a DPP, and proceeds in two stages:\nfirst it constructs coresets for the ground set of items; thereafter, it\nefficiently samples subsets based on the constructed coresets. As opposed to\nprevious approaches, our algorithm aims to minimize the total variation\ndistance to the original distribution. Experiments on both synthetic and real\ndatasets indicate that our sampling algorithm works efficiently on large data\nsets, and yields more accurate samples than previous approaches.\n",
        "published": "2015-09-04T21:38:17Z",
        "pdf_link": "http://arxiv.org/pdf/1509.01618v2"
    },
    {
        "id": "http://arxiv.org/abs/1509.01659v1",
        "title": "Gravitational Clustering",
        "summary": "  The downfall of many supervised learning algorithms, such as neural networks,\nis the inherent need for a large amount of training data. Although there is a\nlot of buzz about big data, there is still the problem of doing classification\nfrom a small dataset. Other methods such as support vector machines, although\ncapable of dealing with few samples, are inherently binary classifiers, and are\nin need of learning strategies such as One vs All in the case of\nmulti-classification. In the presence of a large number of classes this can\nbecome problematic. In this paper we present, a novel approach to supervised\nlearning through the method of clustering. Unlike traditional methods such as\nK-Means, Gravitational Clustering does not require the initial number of\nclusters, and automatically builds the clusters, individual samples can be\narbitrarily weighted and it requires only few samples while staying resilient\nto over-fitting.\n",
        "published": "2015-09-05T03:37:50Z",
        "pdf_link": "http://arxiv.org/pdf/1509.01659v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.01710v2",
        "title": "Theoretic Analysis and Extremely Easy Algorithms for Domain Adaptive\n  Feature Learning",
        "summary": "  Domain adaptation problems arise in a variety of applications, where a\ntraining dataset from the \\textit{source} domain and a test dataset from the\n\\textit{target} domain typically follow different distributions. The primary\ndifficulty in designing effective learning models to solve such problems lies\nin how to bridge the gap between the source and target distributions. In this\npaper, we provide comprehensive analysis of feature learning algorithms used in\nconjunction with linear classifiers for domain adaptation. Our analysis shows\nthat in order to achieve good adaptation performance, the second moments of the\nsource domain distribution and target domain distribution should be similar.\nBased on our new analysis, a novel extremely easy feature learning algorithm\nfor domain adaptation is proposed. Furthermore, our algorithm is extended by\nleveraging multiple layers, leading to a deep linear model. We evaluate the\neffectiveness of the proposed algorithms in terms of domain adaptation tasks on\nthe Amazon review dataset and the spam dataset from the ECML/PKDD 2006\ndiscovery challenge.\n",
        "published": "2015-09-05T15:44:33Z",
        "pdf_link": "http://arxiv.org/pdf/1509.01710v2"
    },
    {
        "id": "http://arxiv.org/abs/1509.03185v1",
        "title": "Use it or Lose it: Selective Memory and Forgetting in a Perpetual\n  Learning Machine",
        "summary": "  In a recent article we described a new type of deep neural network - a\nPerpetual Learning Machine (PLM) - which is capable of learning 'on the fly'\nlike a brain by existing in a state of Perpetual Stochastic Gradient Descent\n(PSGD). Here, by simulating the process of practice, we demonstrate both\nselective memory and selective forgetting when we introduce statistical recall\nbiases during PSGD. Frequently recalled memories are remembered, whilst\nmemories recalled rarely are forgotten. This results in a 'use it or lose it'\nstimulus driven memory process that is similar to human memory.\n",
        "published": "2015-09-10T15:12:00Z",
        "pdf_link": "http://arxiv.org/pdf/1509.03185v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.03200v1",
        "title": "A new Initial Centroid finding Method based on Dissimilarity Tree for\n  K-means Algorithm",
        "summary": "  Cluster analysis is one of the primary data analysis technique in data mining\nand K-means is one of the commonly used partitioning clustering algorithm. In\nK-means algorithm, resulting set of clusters depend on the choice of initial\ncentroids. If we can find initial centroids which are coherent with the\narrangement of data, the better set of clusters can be obtained. This paper\nproposes a method based on the Dissimilarity Tree to find, the better initial\ncentroid as well as every bit more accurate cluster with less computational\ntime. Theory analysis and experimental results indicate that the proposed\nmethod can effectively improve the accuracy of clusters and reduce the\ncomputational complexity of the K-means algorithm.\n",
        "published": "2015-06-19T11:43:14Z",
        "pdf_link": "http://arxiv.org/pdf/1509.03200v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.03755v2",
        "title": "Toward better feature weighting algorithms: a focus on Relief",
        "summary": "  Feature weighting algorithms try to solve a problem of great importance\nnowadays in machine learning: The search of a relevance measure for the\nfeatures of a given domain. This relevance is primarily used for feature\nselection as feature weighting can be seen as a generalization of it, but it is\nalso useful to better understand a problem's domain or to guide an inductor in\nits learning process. Relief family of algorithms are proven to be very\neffective in this task. Some other feature weighting methods are reviewed in\norder to give some context and then the different existing extensions to the\noriginal algorithm are explained.\n  One of Relief's known issues is the performance degradation of its estimates\nwhen redundant features are present. A novel theoretical definition of\nredundancy level is given in order to guide the work towards an extension of\nthe algorithm that is more robust against redundancy. A new extension is\npresented that aims for improving the algorithms performance. Some experiments\nwere driven to test this new extension against the existing ones with a set of\nartificial and real datasets and denoted that in certain cases it improves the\nweight's estimation accuracy.\n",
        "published": "2015-09-12T15:10:15Z",
        "pdf_link": "http://arxiv.org/pdf/1509.03755v2"
    },
    {
        "id": "http://arxiv.org/abs/1509.04340v1",
        "title": "Voted Kernel Regularization",
        "summary": "  This paper presents an algorithm, Voted Kernel Regularization , that provides\nthe flexibility of using potentially very complex kernel functions such as\npredictors based on much higher-degree polynomial kernels, while benefitting\nfrom strong learning guarantees. The success of our algorithm arises from\nderived bounds that suggest a new regularization penalty in terms of the\nRademacher complexities of the corresponding families of kernel maps. In a\nseries of experiments we demonstrate the improved performance of our algorithm\nas compared to baselines. Furthermore, the algorithm enjoys several favorable\nproperties. The optimization problem is convex, it allows for learning with\nnon-PDS kernels, and the solutions are highly sparse, resulting in improved\nclassification speed and memory requirements.\n",
        "published": "2015-09-14T21:58:43Z",
        "pdf_link": "http://arxiv.org/pdf/1509.04340v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.04355v1",
        "title": "Towards Making High Dimensional Distance Metric Learning Practical",
        "summary": "  In this work, we study distance metric learning (DML) for high dimensional\ndata. A typical approach for DML with high dimensional data is to perform the\ndimensionality reduction first before learning the distance metric. The main\nshortcoming of this approach is that it may result in a suboptimal solution due\nto the subspace removed by the dimensionality reduction method. In this work,\nwe present a dual random projection frame for DML with high dimensional data\nthat explicitly addresses the limitation of dimensionality reduction for DML.\nThe key idea is to first project all the data points into a low dimensional\nspace by random projection, and compute the dual variables using the projected\nvectors. It then reconstructs the distance metric in the original space using\nthe estimated dual variables. The proposed method, on one hand, enjoys the\nlight computation of random projection, and on the other hand, alleviates the\nlimitation of most dimensionality reduction methods. We verify both empirically\nand theoretically the effectiveness of the proposed algorithm for high\ndimensional DML.\n",
        "published": "2015-09-15T00:04:24Z",
        "pdf_link": "http://arxiv.org/pdf/1509.04355v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.04705v1",
        "title": "Forecasting Method for Grouped Time Series with the Use of k-Means\n  Algorithm",
        "summary": "  The paper is focused on the forecasting method for time series groups with\nthe use of algorithms for cluster analysis. $K$-means algorithm is suggested to\nbe a basic one for clustering. The coordinates of the centers of clusters have\nbeen put in correspondence with summarizing time series data the centroids of\nthe clusters. A description of time series, the centroids of the clusters, is\nimplemented with the use of forecasting models. They are based on strict binary\ntrees and a modified clonal selection algorithm. With the help of such\nforecasting models, the possibility of forming analytic dependences is shown.\nIt is suggested to use a common forecasting model, which is constructed for\ntime series the centroid of the cluster, in forecasting the private\n(individual) time series in the cluster. The promising application of the\nsuggested method for grouped time series forecasting is demonstrated.\n",
        "published": "2015-09-15T17:15:08Z",
        "pdf_link": "http://arxiv.org/pdf/1509.04705v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.05173v1",
        "title": "Taming the ReLU with Parallel Dither in a Deep Neural Network",
        "summary": "  Rectified Linear Units (ReLU) seem to have displaced traditional 'smooth'\nnonlinearities as activation-function-du-jour in many - but not all - deep\nneural network (DNN) applications. However, nobody seems to know why. In this\narticle, we argue that ReLU are useful because they are ideal demodulators -\nthis helps them perform fast abstract learning. However, this fast learning\ncomes at the expense of serious nonlinear distortion products - decoy features.\nWe show that Parallel Dither acts to suppress the decoy features, preventing\noverfitting and leaving the true features cleanly demodulated for rapid,\nreliable learning.\n",
        "published": "2015-09-17T09:04:30Z",
        "pdf_link": "http://arxiv.org/pdf/1509.05173v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.05472v1",
        "title": "Learning to Hash for Indexing Big Data - A Survey",
        "summary": "  The explosive growth in big data has attracted much attention in designing\nefficient indexing and search methods recently. In many critical applications\nsuch as large-scale search and pattern matching, finding the nearest neighbors\nto a query is a fundamental research problem. However, the straightforward\nsolution using exhaustive comparison is infeasible due to the prohibitive\ncomputational complexity and memory requirement. In response, Approximate\nNearest Neighbor (ANN) search based on hashing techniques has become popular\ndue to its promising performance in both efficiency and accuracy. Prior\nrandomized hashing methods, e.g., Locality-Sensitive Hashing (LSH), explore\ndata-independent hash functions with random projections or permutations.\nAlthough having elegant theoretic guarantees on the search quality in certain\nmetric spaces, performance of randomized hashing has been shown insufficient in\nmany real-world applications. As a remedy, new approaches incorporating\ndata-driven learning methods in development of advanced hash functions have\nemerged. Such learning to hash methods exploit information such as data\ndistributions or class labels when optimizing the hash codes or functions.\nImportantly, the learned hash codes are able to preserve the proximity of\nneighboring data in the original feature spaces in the hash code spaces. The\ngoal of this paper is to provide readers with systematic understanding of\ninsights, pros and cons of the emerging techniques. We provide a comprehensive\nsurvey of the learning to hash framework and representative techniques of\nvarious types, including unsupervised, semi-supervised, and supervised. In\naddition, we also summarize recent hashing approaches utilizing the deep\nlearning models. Finally, we discuss the future direction and trends of\nresearch in this area.\n",
        "published": "2015-09-17T23:19:07Z",
        "pdf_link": "http://arxiv.org/pdf/1509.05472v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.05765v1",
        "title": "\"Oddball SGD\": Novelty Driven Stochastic Gradient Descent for Training\n  Deep Neural Networks",
        "summary": "  Stochastic Gradient Descent (SGD) is arguably the most popular of the machine\nlearning methods applied to training deep neural networks (DNN) today. It has\nrecently been demonstrated that SGD can be statistically biased so that certain\nelements of the training set are learned more rapidly than others. In this\narticle, we place SGD into a feedback loop whereby the probability of selection\nis proportional to error magnitude. This provides a novelty-driven oddball SGD\nprocess that learns more rapidly than traditional SGD by prioritising those\nelements of the training set with the largest novelty (error). In our DNN\nexample, oddball SGD trains some 50x faster than regular SGD.\n",
        "published": "2015-09-18T19:58:24Z",
        "pdf_link": "http://arxiv.org/pdf/1509.05765v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.06163v1",
        "title": "The Utility of Clustering in Prediction Tasks",
        "summary": "  We explore the utility of clustering in reducing error in various prediction\ntasks. Previous work has hinted at the improvement in prediction accuracy\nattributed to clustering algorithms if used to pre-process the data. In this\nwork we more deeply investigate the direct utility of using clustering to\nimprove prediction accuracy and provide explanations for why this may be so. We\nlook at a number of datasets, run k-means at different scales and for each\nscale we train predictors. This produces k sets of predictions. These\npredictions are then combined by a na\\\"ive ensemble. We observed that this use\nof a predictor in conjunction with clustering improved the prediction accuracy\nin most datasets. We believe this indicates the predictive utility of\nexploiting structure in the data and the data compression handed over by\nclustering. We also found that using this method improves upon the prediction\nof even a Random Forests predictor which suggests this method is providing a\nnovel, and useful source of variance in the prediction process.\n",
        "published": "2015-09-21T09:42:50Z",
        "pdf_link": "http://arxiv.org/pdf/1509.06163v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.06461v3",
        "title": "Deep Reinforcement Learning with Double Q-learning",
        "summary": "  The popular Q-learning algorithm is known to overestimate action values under\ncertain conditions. It was not previously known whether, in practice, such\noverestimations are common, whether they harm performance, and whether they can\ngenerally be prevented. In this paper, we answer all these questions\naffirmatively. In particular, we first show that the recent DQN algorithm,\nwhich combines Q-learning with a deep neural network, suffers from substantial\noverestimations in some games in the Atari 2600 domain. We then show that the\nidea behind the Double Q-learning algorithm, which was introduced in a tabular\nsetting, can be generalized to work with large-scale function approximation. We\npropose a specific adaptation to the DQN algorithm and show that the resulting\nalgorithm not only reduces the observed overestimations, as hypothesized, but\nthat this also leads to much better performance on several games.\n",
        "published": "2015-09-22T04:40:22Z",
        "pdf_link": "http://arxiv.org/pdf/1509.06461v3"
    },
    {
        "id": "http://arxiv.org/abs/1509.06812v1",
        "title": "Learning Wake-Sleep Recurrent Attention Models",
        "summary": "  Despite their success, convolutional neural networks are computationally\nexpensive because they must examine all image locations. Stochastic\nattention-based models have been shown to improve computational efficiency at\ntest time, but they remain difficult to train because of intractable posterior\ninference and high variance in the stochastic gradient estimates. Borrowing\ntechniques from the literature on training deep generative models, we present\nthe Wake-Sleep Recurrent Attention Model, a method for training stochastic\nattention networks which improves posterior inference and which reduces the\nvariability in the stochastic gradients. We show that our method can greatly\nspeed up the training time for stochastic attention networks in the domains of\nimage classification and caption generation.\n",
        "published": "2015-09-22T23:52:30Z",
        "pdf_link": "http://arxiv.org/pdf/1509.06812v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.07107v3",
        "title": "On The Direct Maximization of Quadratic Weighted Kappa",
        "summary": "  In recent years, quadratic weighted kappa has been growing in popularity in\nthe machine learning community as an evaluation metric in domains where the\ntarget labels to be predicted are drawn from integer ratings, usually obtained\nfrom human experts. For example, it was the metric of choice in several recent,\nhigh profile machine learning contests hosted on Kaggle :\nhttps://www.kaggle.com/c/asap-aes , https://www.kaggle.com/c/asap-sas ,\nhttps://www.kaggle.com/c/diabetic-retinopathy-detection . Yet, little is\nunderstood about the nature of this metric, its underlying mathematical\nproperties, where it fits among other common evaluation metrics such as mean\nsquared error (MSE) and correlation, or if it can be optimized analytically,\nand if so, how. Much of this is due to the cumbersome way that this metric is\ncommonly defined. In this paper we first derive an equivalent but much simpler,\nand more useful, definition for quadratic weighted kappa, and then employ this\nalternate form to address the above issues.\n",
        "published": "2015-09-23T19:39:39Z",
        "pdf_link": "http://arxiv.org/pdf/1509.07107v3"
    },
    {
        "id": "http://arxiv.org/abs/1509.07234v1",
        "title": "Sparsity-based Correction of Exponential Artifacts",
        "summary": "  This paper describes an exponential transient excision algorithm (ETEA). In\nbiomedical time series analysis, e.g., in vivo neural recording and\nelectrocorticography (ECoG), some measurement artifacts take the form of\npiecewise exponential transients. The proposed method is formulated as an\nunconstrained convex optimization problem, regularized by smoothed l1-norm\npenalty function, which can be solved by majorization-minimization (MM) method.\nWith a slight modification of the regularizer, ETEA can also suppress more\nirregular piecewise smooth artifacts, especially, ocular artifacts (OA) in\nelectroencephalog- raphy (EEG) data. Examples of synthetic signal, EEG data,\nand ECoG data are presented to illustrate the proposed algorithms.\n",
        "published": "2015-09-24T04:50:00Z",
        "pdf_link": "http://arxiv.org/pdf/1509.07234v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.07481v1",
        "title": "Spatially Encoding Temporal Correlations to Classify Temporal Data Using\n  Convolutional Neural Networks",
        "summary": "  We propose an off-line approach to explicitly encode temporal patterns\nspatially as different types of images, namely, Gramian Angular Fields and\nMarkov Transition Fields. This enables the use of techniques from computer\nvision for feature learning and classification. We used Tiled Convolutional\nNeural Networks to learn high-level features from individual GAF, MTF, and\nGAF-MTF images on 12 benchmark time series datasets and two real\nspatial-temporal trajectory datasets. The classification results of our\napproach are competitive with state-of-the-art approaches on both types of\ndata. An analysis of the features and weights learned by the CNNs explains why\nthe approach works.\n",
        "published": "2015-09-24T19:14:20Z",
        "pdf_link": "http://arxiv.org/pdf/1509.07481v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.07728v1",
        "title": "Online Stochastic Linear Optimization under One-bit Feedback",
        "summary": "  In this paper, we study a special bandit setting of online stochastic linear\noptimization, where only one-bit of information is revealed to the learner at\neach round. This problem has found many applications including online\nadvertisement and online recommendation. We assume the binary feedback is a\nrandom variable generated from the logit model, and aim to minimize the regret\ndefined by the unknown linear function. Although the existing method for\ngeneralized linear bandit can be applied to our problem, the high computational\ncost makes it impractical for real-world problems. To address this challenge,\nwe develop an efficient online learning algorithm by exploiting particular\nstructures of the observation model. Specifically, we adopt online Newton step\nto estimate the unknown parameter and derive a tight confidence region based on\nthe exponential concavity of the logistic loss. Our analysis shows that the\nproposed algorithm achieves a regret bound of $O(d\\sqrt{T})$, which matches the\noptimal result of stochastic linear bandits.\n",
        "published": "2015-09-25T14:05:09Z",
        "pdf_link": "http://arxiv.org/pdf/1509.07728v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.07755v1",
        "title": "A Mathematical Theory for Clustering in Metric Spaces",
        "summary": "  Clustering is one of the most fundamental problems in data analysis and it\nhas been studied extensively in the literature. Though many clustering\nalgorithms have been proposed, clustering theories that justify the use of\nthese clustering algorithms are still unsatisfactory. In particular, one of the\nfundamental challenges is to address the following question:\n  What is a cluster in a set of data points?\n  In this paper, we make an attempt to address such a question by considering a\nset of data points associated with a distance measure (metric). We first\npropose a new cohesion measure in terms of the distance measure. Using the\ncohesion measure, we define a cluster as a set of points that are cohesive to\nthemselves. For such a definition, we show there are various equivalent\nstatements that have intuitive explanations. We then consider the second\nquestion:\n  How do we find clusters and good partitions of clusters under such a\ndefinition?\n  For such a question, we propose a hierarchical agglomerative algorithm and a\npartitional algorithm. Unlike standard hierarchical agglomerative algorithms,\nour hierarchical agglomerative algorithm has a specific stopping criterion and\nit stops with a partition of clusters. Our partitional algorithm, called the\nK-sets algorithm in the paper, appears to be a new iterative algorithm. Unlike\nthe Lloyd iteration that needs two-step minimization, our K-sets algorithm only\ntakes one-step minimization.\n  One of the most interesting findings of our paper is the duality result\nbetween a distance measure and a cohesion measure. Such a duality result leads\nto a dual K-sets algorithm for clustering a set of data points with a cohesion\nmeasure. The dual K-sets algorithm converges in the same way as a sequential\nversion of the classical kernel K-means algorithm. The key difference is that a\ncohesion measure does not need to be positive semi-definite.\n",
        "published": "2015-09-25T15:30:18Z",
        "pdf_link": "http://arxiv.org/pdf/1509.07755v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.07927v1",
        "title": "Algorithms for Linear Bandits on Polyhedral Sets",
        "summary": "  We study stochastic linear optimization problem with bandit feedback. The set\nof arms take values in an $N$-dimensional space and belong to a bounded\npolyhedron described by finitely many linear inequalities. We provide a lower\nbound for the expected regret that scales as $\\Omega(N\\log T)$. We then provide\na nearly optimal algorithm and show that its expected regret scales as\n$O(N\\log^{1+\\epsilon}(T))$ for an arbitrary small $\\epsilon >0$. The algorithm\nalternates between exploration and exploitation intervals sequentially where\ndeterministic set of arms are played in the exploration intervals and greedily\nselected arm is played in the exploitation intervals. We also develop an\nalgorithm that achieves the optimal regret when sub-Gaussianity parameter of\nthe noise term is known. Our key insight is that for a polyhedron the optimal\narm is robust to small perturbations in the reward function. Consequently, a\ngreedily selected arm is guaranteed to be optimal when the estimation error\nfalls below some suitable threshold. Our solution resolves a question posed by\nRusmevichientong and Tsitsiklis (2011) that left open the possibility of\nefficient algorithms with asymptotic logarithmic regret bounds. We also show\nthat the regret upper bounds hold with probability $1$. Our numerical\ninvestigations show that while theoretical results are asymptotic the\nperformance of our algorithms compares favorably to state-of-the-art algorithms\nin finite time as well.\n",
        "published": "2015-09-26T00:17:38Z",
        "pdf_link": "http://arxiv.org/pdf/1509.07927v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.07943v1",
        "title": "Super-Resolution Off the Grid",
        "summary": "  Super-resolution is the problem of recovering a superposition of point\nsources using bandlimited measurements, which may be corrupted with noise. This\nsignal processing problem arises in numerous imaging problems, ranging from\nastronomy to biology to spectroscopy, where it is common to take (coarse)\nFourier measurements of an object. Of particular interest is in obtaining\nestimation procedures which are robust to noise, with the following desirable\nstatistical and computational properties: we seek to use coarse Fourier\nmeasurements (bounded by some cutoff frequency); we hope to take a\n(quantifiably) small number of measurements; we desire our algorithm to run\nquickly.\n  Suppose we have k point sources in d dimensions, where the points are\nseparated by at least \\Delta from each other (in Euclidean distance). This work\nprovides an algorithm with the following favorable guarantees: - The algorithm\nuses Fourier measurements, whose frequencies are bounded by O(1/\\Delta) (up to\nlog factors). Previous algorithms require a cutoff frequency which may be as\nlarge as {\\Omega}( d/\\Delta). - The number of measurements taken by and the\ncomputational complexity of our algorithm are bounded by a polynomial in both\nthe number of points k and the dimension d, with no dependence on the\nseparation \\Delta. In contrast, previous algorithms depended inverse\npolynomially on the minimal separation and exponentially on the dimension for\nboth of these quantities.\n  Our estimation procedure itself is simple: we take random bandlimited\nmeasurements (as opposed to taking an exponential number of measurements on the\nhyper-grid). Furthermore, our analysis and algorithm are elementary (based on\nconcentration bounds for sampling and the singular value decomposition).\n",
        "published": "2015-09-26T03:49:27Z",
        "pdf_link": "http://arxiv.org/pdf/1509.07943v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.08102v6",
        "title": "Discriminative Learning of the Prototype Set for Nearest Neighbor\n  Classification",
        "summary": "  The nearest neighbor rule is a classic yet essential classification model,\nparticularly in problems where the supervising information is given by pairwise\ndissimilarities and the embedding function are not easily obtained. Prototype\nselection provides means of generalization and improving efficiency of the\nnearest neighbor model, but many existing methods assume and rely on the\nanalyses of the input vector space. In this paper, we explore a\ndissimilarity-based, parametrized model of the nearest neighbor rule. In the\nproposed model, the selection of the nearest prototypes is influenced by the\nparameters of the respective prototypes. It provides a formulation for\nminimizing the violation of the extended nearest neighbor rule over the\ntraining set in a tractable form to exploit numerical techniques. We show that\nthe minimization problem reduces to a large-margin principle learning and\ndemonstrate its advantage by empirical comparisons with other prototype\nselection methods.\n",
        "published": "2015-09-27T15:43:33Z",
        "pdf_link": "http://arxiv.org/pdf/1509.08102v6"
    },
    {
        "id": "http://arxiv.org/abs/1509.08112v1",
        "title": "Feature Selection for classification of hyperspectral data by minimizing\n  a tight bound on the VC dimension",
        "summary": "  Hyperspectral data consists of large number of features which require\nsophisticated analysis to be extracted. A popular approach to reduce\ncomputational cost, facilitate information representation and accelerate\nknowledge discovery is to eliminate bands that do not improve the\nclassification and analysis methods being applied. In particular, algorithms\nthat perform band elimination should be designed to take advantage of the\nspecifics of the classification method being used. This paper employs a\nrecently proposed filter-feature-selection algorithm based on minimizing a\ntight bound on the VC dimension. We have successfully applied this algorithm to\ndetermine a reasonable subset of bands without any user-defined stopping\ncriteria on widely used hyperspectral images and demonstrate that this method\noutperforms state-of-the-art methods in terms of both sparsity of feature set\nas well as accuracy of classification.\\end{abstract}\n",
        "published": "2015-09-27T17:36:18Z",
        "pdf_link": "http://arxiv.org/pdf/1509.08112v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.08830v1",
        "title": "How to Formulate and Solve Statistical Recognition and Learning Problems",
        "summary": "  We formulate problems of statistical recognition and learning in a common\nframework of complex hypothesis testing. Based on arguments from multi-criteria\noptimization, we identify strategies that are improper for solving these\nproblems and derive a common form of the remaining strategies. We show that\nsome widely used approaches to recognition and learning are improper in this\nsense. We then propose a generalized formulation of the recognition and\nlearning problem which embraces the whole range of sizes of the learning\nsample, including the zero size. Learning becomes a special case of recognition\nwithout learning. We define the concept of closest to optimal strategy, being a\nsolution to the formulated problem, and describe a technique for finding such a\nstrategy. On several illustrative cases, the strategy is shown to be superior\nto the widely used learning methods based on maximal likelihood estimation.\n",
        "published": "2015-09-29T16:23:28Z",
        "pdf_link": "http://arxiv.org/pdf/1509.08830v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.08888v1",
        "title": "A Semi-Supervised Method for Predicting Cancer Survival Using Incomplete\n  Clinical Data",
        "summary": "  Prediction of survival for cancer patients is an open area of research.\nHowever, many of these studies focus on datasets with a large number of\npatients. We present a novel method that is specifically designed to address\nthe challenge of data scarcity, which is often the case for cancer datasets.\nOur method is able to use unlabeled data to improve classification by adopting\na semi-supervised training approach to learn an ensemble classifier. The\nresults of applying our method to three cancer datasets show the promise of\nsemi-supervised learning for prediction of cancer survival.\n",
        "published": "2015-09-29T18:53:04Z",
        "pdf_link": "http://arxiv.org/pdf/1509.08888v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.09030v1",
        "title": "Distributed Weighted Parameter Averaging for SVM Training on Big Data",
        "summary": "  Two popular approaches for distributed training of SVMs on big data are\nparameter averaging and ADMM. Parameter averaging is efficient but suffers from\nloss of accuracy with increase in number of partitions, while ADMM in the\nfeature space is accurate but suffers from slow convergence. In this paper, we\nreport a hybrid approach called weighted parameter averaging (WPA), which\noptimizes the regularized hinge loss with respect to weights on parameters. The\nproblem is shown to be same as solving SVM in a projected space. We also\ndemonstrate an $O(\\frac{1}{N})$ stability bound on final hypothesis given by\nWPA, using novel proof techniques. Experimental results on a variety of toy and\nreal world datasets show that our approach is significantly more accurate than\nparameter averaging for high number of partitions. It is also seen the proposed\nmethod enjoys much faster convergence compared to ADMM in features space.\n",
        "published": "2015-09-30T06:59:31Z",
        "pdf_link": "http://arxiv.org/pdf/1509.09030v1"
    },
    {
        "id": "http://arxiv.org/abs/1509.09187v1",
        "title": "Deep Haar Scattering Networks",
        "summary": "  An orthogonal Haar scattering transform is a deep network, computed with a\nhierarchy of additions, subtractions and absolute values, over pairs of\ncoefficients. It provides a simple mathematical model for unsupervised deep\nnetwork learning. It implements non-linear contractions, which are optimized\nfor classification, with an unsupervised pair matching algorithm, of polynomial\ncomplexity. A structured Haar scattering over graph data computes permutation\ninvariant representations of groups of connected points in the graph. If the\ngraph connectivity is unknown, unsupervised Haar pair learning can provide a\nconsistent estimation of connected dyadic groups of points. Classification\nresults are given on image data bases, defined on regular grids or graphs, with\na connectivity which may be known or unknown.\n",
        "published": "2015-09-30T14:20:29Z",
        "pdf_link": "http://arxiv.org/pdf/1509.09187v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.00048v1",
        "title": "The Pareto Regret Frontier for Bandits",
        "summary": "  Given a multi-armed bandit problem it may be desirable to achieve a\nsmaller-than-usual worst-case regret for some special actions. I show that the\nprice for such unbalanced worst-case regret guarantees is rather high.\nSpecifically, if an algorithm enjoys a worst-case regret of B with respect to\nsome action, then there must exist another action for which the worst-case\nregret is at least {\\Omega}(nK/B), where n is the horizon and K the number of\nactions. I also give upper bounds in both the stochastic and adversarial\nsettings showing that this result cannot be improved. For the stochastic case\nthe pareto regret frontier is characterised exactly up to constant factors.\n",
        "published": "2015-10-30T23:30:30Z",
        "pdf_link": "http://arxiv.org/pdf/1511.00048v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.00213v2",
        "title": "Large-scale probabilistic predictors with and without guarantees of\n  validity",
        "summary": "  This paper studies theoretically and empirically a method of turning\nmachine-learning algorithms into probabilistic predictors that automatically\nenjoys a property of validity (perfect calibration) and is computationally\nefficient. The price to pay for perfect calibration is that these probabilistic\npredictors produce imprecise (in practice, almost precise for large data sets)\nprobabilities. When these imprecise probabilities are merged into precise\nprobabilities, the resulting predictors, while losing the theoretical property\nof perfect calibration, are consistently more accurate than the existing\nmethods in empirical studies.\n",
        "published": "2015-11-01T07:16:04Z",
        "pdf_link": "http://arxiv.org/pdf/1511.00213v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.00792v10",
        "title": "Fast Collaborative Filtering from Implicit Feedback with Provable\n  Guarantees",
        "summary": "  Building recommendation algorithms is one of the most challenging tasks in\nMachine Learning. Although most of the recommendation systems are built on\nexplicit feedback available from the users in terms of rating or text, a\nmajority of the applications do not receive such feedback. Here we consider the\nrecommendation task where the only available data is the records of user-item\ninteraction over web applications over time, in terms of subscription or\npurchase of items; this is known as implicit feedback recommendation. There is\nusually a massive amount of such user-item interaction available for any web\napplications. Algorithms like PLSI or Matrix Factorization runs several\niterations through the dataset, and may prove very expensive for large\ndatasets. Here we propose a recommendation algorithm based on Method of Moment,\nwhich involves factorization of second and third order moments of the dataset.\nOur algorithm can be proven to be globally convergent using PAC learning\ntheory. Further, we show how to extract the parameters using only three passes\nthrough the entire dataset. This results in a highly scalable algorithm that\nscales up to million of users even on a machine with a single-core processor\nand 8 GB RAM and produces competitive performance in comparison with existing\nalgorithms.\n",
        "published": "2015-11-03T06:43:54Z",
        "pdf_link": "http://arxiv.org/pdf/1511.00792v10"
    },
    {
        "id": "http://arxiv.org/abs/1511.01258v2",
        "title": "Learn on Source, Refine on Target:A Model Transfer Learning Framework\n  with Random Forests",
        "summary": "  We propose novel model transfer-learning methods that refine a decision\nforest model M learned within a \"source\" domain using a training set sampled\nfrom a \"target\" domain, assumed to be a variation of the source. We present two\nrandom forest transfer algorithms. The first algorithm searches greedily for\nlocally optimal modifications of each tree structure by trying to locally\nexpand or reduce the tree around individual nodes. The second algorithm does\nnot modify structure, but only the parameter (thresholds) associated with\ndecision nodes. We also propose to combine both methods by considering an\nensemble that contains the union of the two forests. The proposed methods\nexhibit impressive experimental results over a range of problems.\n",
        "published": "2015-11-04T09:41:12Z",
        "pdf_link": "http://arxiv.org/pdf/1511.01258v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.01664v2",
        "title": "Stochastic Proximal Gradient Descent for Nuclear Norm Regularization",
        "summary": "  In this paper, we utilize stochastic optimization to reduce the space\ncomplexity of convex composite optimization with a nuclear norm regularizer,\nwhere the variable is a matrix of size $m \\times n$. By constructing a low-rank\nestimate of the gradient, we propose an iterative algorithm based on stochastic\nproximal gradient descent (SPGD), and take the last iterate of SPGD as the\nfinal solution. The main advantage of the proposed algorithm is that its space\ncomplexity is $O(m+n)$, in contrast, most of previous algorithms have a $O(mn)$\nspace complexity. Theoretical analysis shows that it achieves $O(\\log\nT/\\sqrt{T})$ and $O(\\log T/T)$ convergence rates for general convex functions\nand strongly convex functions, respectively.\n",
        "published": "2015-11-05T09:24:13Z",
        "pdf_link": "http://arxiv.org/pdf/1511.01664v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.01764v1",
        "title": "Discrete Rényi Classifiers",
        "summary": "  Consider the binary classification problem of predicting a target variable\n$Y$ from a discrete feature vector $X = (X_1,...,X_d)$. When the probability\ndistribution $\\mathbb{P}(X,Y)$ is known, the optimal classifier, leading to the\nminimum misclassification rate, is given by the Maximum A-posteriori\nProbability decision rule. However, estimating the complete joint distribution\n$\\mathbb{P}(X,Y)$ is computationally and statistically impossible for large\nvalues of $d$. An alternative approach is to first estimate some low order\nmarginals of $\\mathbb{P}(X,Y)$ and then design the classifier based on the\nestimated low order marginals. This approach is also helpful when the complete\ntraining data instances are not available due to privacy concerns. In this\nwork, we consider the problem of finding the optimum classifier based on some\nestimated low order marginals of $(X,Y)$. We prove that for a given set of\nmarginals, the minimum Hirschfeld-Gebelein-Renyi (HGR) correlation principle\nintroduced in [1] leads to a randomized classification rule which is shown to\nhave a misclassification rate no larger than twice the misclassification rate\nof the optimal classifier. Then, under a separability condition, we show that\nthe proposed algorithm is equivalent to a randomized linear regression\napproach. In addition, this method naturally results in a robust feature\nselection method selecting a subset of features having the maximum worst case\nHGR correlation with the target variable. Our theoretical upper-bound is\nsimilar to the recent Discrete Chebyshev Classifier (DCC) approach [2], while\nthe proposed algorithm has significant computational advantages since it only\nrequires solving a least square optimization problem. Finally, we numerically\ncompare our proposed algorithm with the DCC classifier and show that the\nproposed algorithm results in better misclassification rate over various\ndatasets.\n",
        "published": "2015-11-05T14:47:04Z",
        "pdf_link": "http://arxiv.org/pdf/1511.01764v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.02136v6",
        "title": "Diffusion-Convolutional Neural Networks",
        "summary": "  We present diffusion-convolutional neural networks (DCNNs), a new model for\ngraph-structured data. Through the introduction of a diffusion-convolution\noperation, we show how diffusion-based representations can be learned from\ngraph-structured data and used as an effective basis for node classification.\nDCNNs have several attractive qualities, including a latent representation for\ngraphical data that is invariant under isomorphism, as well as polynomial-time\nprediction and learning that can be represented as tensor operations and\nefficiently implemented on the GPU. Through several experiments with real\nstructured datasets, we demonstrate that DCNNs are able to outperform\nprobabilistic relational models and kernel-on-graph methods at relational node\nclassification tasks.\n",
        "published": "2015-11-06T16:09:32Z",
        "pdf_link": "http://arxiv.org/pdf/1511.02136v6"
    },
    {
        "id": "http://arxiv.org/abs/1511.02196v1",
        "title": "Evaluating Protein-protein Interaction Predictors with a Novel\n  3-Dimensional Metric",
        "summary": "  In order for the predicted interactions to be directly adopted by biologists,\nthe ma- chine learning predictions have to be of high precision, regardless of\nrecall. This aspect cannot be evaluated or numerically represented well by\ntraditional metrics like accuracy, ROC, or precision-recall curve. In this\nwork, we start from the alignment in sensitivity of ROC and recall of\nprecision-recall curve, and propose an evaluation metric focusing on the\nability of a model to be adopted by biologists. This metric evaluates the\nability of a machine learning algorithm to predict only new interactions,\nmeanwhile, it eliminates the influence of test dataset. In the experiment of\nevaluating different classifiers with a same data set and evaluating the same\npredictor with different datasets, our new metric fulfills the evaluation task\nof our interest while two widely recognized metrics, ROC and precision-recall\ncurve fail the tasks for different reasons.\n",
        "published": "2015-11-06T19:14:09Z",
        "pdf_link": "http://arxiv.org/pdf/1511.02196v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.02352v2",
        "title": "Performance Analysis of Multiclass Support Vector Machine Classification\n  for Diagnosis of Coronary Heart Diseases",
        "summary": "  Automatic diagnosis of coronary heart disease helps the doctor to support in\ndecision making a diagnosis. Coronary heart disease have some types or levels.\nReferring to the UCI Repository dataset, it divided into 4 types or levels that\nare labeled numbers 1-4 (low, medium, high and serious). The diagnosis models\ncan be analyzed with multiclass classification approach. One of multiclass\nclassification approach used, one of which is a support vector machine (SVM).\nThe SVM use due to strong performance of SVM in binary classification. This\nresearch study multiclass performance classification support vector machine to\ndiagnose the type or level of coronary heart disease. Coronary heart disease\npatient data taken from the UCI Repository. Stages in this study is\npreprocessing, which consist of, to normalizing the data, divide the data into\ndata training and testing. The next stage of multiclass classification and\nperformance analysis. This study uses multiclass SVM algorithm, namely: Binary\nTree Support Vector Machine (BTSVM), One-Against-One (OAO), One-Against-All\n(OAA), Decision Direct Acyclic Graph (DDAG) and Exhaustive Output Error\nCorrection Code (ECOC). Performance parameter used is recall, precision,\nF-measure and Overall accuracy.\n",
        "published": "2015-11-07T13:09:57Z",
        "pdf_link": "http://arxiv.org/pdf/1511.02352v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.02402v1",
        "title": "Max-Sum Diversification, Monotone Submodular Functions and Semi-metric\n  Spaces",
        "summary": "  In many applications such as web-based search, document summarization,\nfacility location and other applications, the results are preferable to be both\nrepresentative and diversified subsets of documents. The goal of this study is\nto select a good \"quality\", bounded-size subset of a given set of items, while\nmaintaining their diversity relative to a semi-metric distance function. This\nproblem was first studied by Borodin et al\\cite{borodin}, but a crucial\nproperty used throughout their proof is the triangle inequality. In this\nmodified proof, we want to relax the triangle inequality and relate the\napproximation ratio of max-sum diversification problem to the parameter of the\nrelaxed triangle inequality in the normal form of the problem (i.e., a uniform\nmatroid) and also in an arbitrary matroid.\n",
        "published": "2015-11-07T20:56:51Z",
        "pdf_link": "http://arxiv.org/pdf/1511.02402v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.02900v1",
        "title": "Neighbourhood NILM: A Big-data Approach to Household Energy\n  Disaggregation",
        "summary": "  In this paper, we investigate whether \"big-data\" is more valuable than\n\"precise\" data for the problem of energy disaggregation: the process of\nbreaking down aggregate energy usage on a per-appliance basis. Existing\ntechniques for disaggregation rely on energy metering at a resolution of 1\nminute or higher, but most power meters today only provide a reading once per\nmonth, and at most once every 15 minutes. In this paper, we propose a new\ntechnique called Neighbourhood NILM that leverages data from 'neighbouring'\nhomes to disaggregate energy given only a single energy reading per month. The\nkey intuition behind our approach is that 'similar' homes have 'similar' energy\nconsumption on a per-appliance basis. Neighbourhood NILM matches every home\nwith a set of 'neighbours' that have direct submetering infrastructure, i.e.\npower meters on individual circuits or loads. Many such homes already exist.\nThen, it estimates the appliance-level energy consumption of the target home to\nbe the average of its K neighbours. We evaluate this approach using 25 homes\nand results show that our approach gives comparable or better disaggregation in\ncomparison to state-of-the-art accuracy reported in the literature that depend\non manual model training, high frequency power metering, or both. Results show\nthat Neighbourhood NILM can achieve 83% and 79% accuracy disaggregating fridge\nand heating/cooling loads, compared to 74% and 73% for a technique called FHMM.\nFurthermore, it achieves up to 64% accuracy on washing machine, dryer,\ndishwasher, and lighting loads, which is higher than previously reported\nresults. Many existing techniques are not able to disaggregate these loads at\nall. These results indicate a potentially substantial advantage to installing\nsubmetering infrastructure in a select few homes rather than installing new\nhigh-frequency smart metering infrastructure in all homes.\n",
        "published": "2015-10-26T07:22:01Z",
        "pdf_link": "http://arxiv.org/pdf/1511.02900v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.02909v1",
        "title": "Efficient Construction of Local Parametric Reduced Order Models Using\n  Machine Learning Techniques",
        "summary": "  Reduced order models are computationally inexpensive approximations that\ncapture the important dynamical characteristics of large, high-fidelity\ncomputer models of physical systems. This paper applies machine learning\ntechniques to improve the design of parametric reduced order models.\nSpecifically, machine learning is used to develop feasible regions in the\nparameter space where the admissible target accuracy is achieved with a\npredefined reduced order basis, to construct parametric maps, to chose the best\ntwo already existing bases for a new parameter configuration from accuracy\npoint of view and to pre-select the optimal dimension of the reduced basis such\nas to meet the desired accuracy. By combining available information using bases\nconcatenation and interpolation as well as high-fidelity solutions\ninterpolation we are able to build accurate reduced order models associated\nwith new parameter settings. Promising numerical results with a viscous Burgers\nmodel illustrate the potential of machine learning approaches to help design\nbetter reduced order models.\n",
        "published": "2015-11-09T22:12:14Z",
        "pdf_link": "http://arxiv.org/pdf/1511.02909v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.03034v6",
        "title": "Learning with a Strong Adversary",
        "summary": "  The robustness of neural networks to intended perturbations has recently\nattracted significant attention. In this paper, we propose a new method,\n\\emph{learning with a strong adversary}, that learns robust classifiers from\nsupervised data. The proposed method takes finding adversarial examples as an\nintermediate step. A new and simple way of finding adversarial examples is\npresented and experimentally shown to be efficient. Experimental results\ndemonstrate that resulting learning method greatly improves the robustness of\nthe classification models produced.\n",
        "published": "2015-11-10T09:44:33Z",
        "pdf_link": "http://arxiv.org/pdf/1511.03034v6"
    },
    {
        "id": "http://arxiv.org/abs/1511.03225v4",
        "title": "Label Efficient Learning by Exploiting Multi-class Output Codes",
        "summary": "  We present a new perspective on the popular multi-class algorithmic\ntechniques of one-vs-all and error correcting output codes. Rather than\nstudying the behavior of these techniques for supervised learning, we establish\na connection between the success of these methods and the existence of\nlabel-efficient learning procedures. We show that in both the realizable and\nagnostic cases, if output codes are successful at learning from labeled data,\nthey implicitly assume structure on how the classes are related. By making that\nstructure explicit, we design learning algorithms to recover the classes with\nlow label complexity. We provide results for the commonly studied cases of\none-vs-all learning and when the codewords of the classes are well separated.\nWe additionally consider the more challenging case where the codewords are not\nwell separated, but satisfy a boundary features condition that captures the\nnatural intuition that every bit of the codewords should be significant.\n",
        "published": "2015-11-10T18:50:03Z",
        "pdf_link": "http://arxiv.org/pdf/1511.03225v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.03677v7",
        "title": "Learning to Diagnose with LSTM Recurrent Neural Networks",
        "summary": "  Clinical medical data, especially in the intensive care unit (ICU), consist\nof multivariate time series of observations. For each patient visit (or\nepisode), sensor data and lab test results are recorded in the patient's\nElectronic Health Record (EHR). While potentially containing a wealth of\ninsights, the data is difficult to mine effectively, owing to varying length,\nirregular sampling and missing data. Recurrent Neural Networks (RNNs),\nparticularly those using Long Short-Term Memory (LSTM) hidden units, are\npowerful and increasingly popular models for learning from sequence data. They\neffectively model varying length sequences and capture long range dependencies.\nWe present the first study to empirically evaluate the ability of LSTMs to\nrecognize patterns in multivariate time series of clinical measurements.\nSpecifically, we consider multilabel classification of diagnoses, training a\nmodel to classify 128 diagnoses given 13 frequently but irregularly sampled\nclinical measurements. First, we establish the effectiveness of a simple LSTM\nnetwork for modeling clinical data. Then we demonstrate a straightforward and\neffective training strategy in which we replicate targets at each sequence\nstep. Trained only on raw time series, our models outperform several strong\nbaselines, including a multilayer perceptron trained on hand-engineered\nfeatures.\n",
        "published": "2015-11-11T21:01:28Z",
        "pdf_link": "http://arxiv.org/pdf/1511.03677v7"
    },
    {
        "id": "http://arxiv.org/abs/1511.03719v7",
        "title": "Universum Prescription: Regularization using Unlabeled Data",
        "summary": "  This paper shows that simply prescribing \"none of the above\" labels to\nunlabeled data has a beneficial regularization effect to supervised learning.\nWe call it universum prescription by the fact that the prescribed labels cannot\nbe one of the supervised labels. In spite of its simplicity, universum\nprescription obtained competitive results in training deep convolutional\nnetworks for CIFAR-10, CIFAR-100, STL-10 and ImageNet datasets. A qualitative\njustification of these approaches using Rademacher complexity is presented. The\neffect of a regularization parameter -- probability of sampling from unlabeled\ndata -- is also studied empirically.\n",
        "published": "2015-11-11T22:46:46Z",
        "pdf_link": "http://arxiv.org/pdf/1511.03719v7"
    },
    {
        "id": "http://arxiv.org/abs/1511.03766v2",
        "title": "Sparse Learning for Large-scale and High-dimensional Data: A Randomized\n  Convex-concave Optimization Approach",
        "summary": "  In this paper, we develop a randomized algorithm and theory for learning a\nsparse model from large-scale and high-dimensional data, which is usually\nformulated as an empirical risk minimization problem with a sparsity-inducing\nregularizer. Under the assumption that there exists a (approximately) sparse\nsolution with high classification accuracy, we argue that the dual solution is\nalso sparse or approximately sparse. The fact that both primal and dual\nsolutions are sparse motivates us to develop a randomized approach for a\ngeneral convex-concave optimization problem. Specifically, the proposed\napproach combines the strength of random projection with that of sparse\nlearning: it utilizes random projection to reduce the dimensionality, and\nintroduces $\\ell_1$-norm regularization to alleviate the approximation error\ncaused by random projection. Theoretical analysis shows that under favored\nconditions, the randomized algorithm can accurately recover the optimal\nsolutions to the convex-concave optimization problem (i.e., recover both the\nprimal and dual solutions).\n",
        "published": "2015-11-12T03:11:48Z",
        "pdf_link": "http://arxiv.org/pdf/1511.03766v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.04707v5",
        "title": "Deep Linear Discriminant Analysis",
        "summary": "  We introduce Deep Linear Discriminant Analysis (DeepLDA) which learns\nlinearly separable latent representations in an end-to-end fashion. Classic LDA\nextracts features which preserve class separability and is used for\ndimensionality reduction for many classification problems. The central idea of\nthis paper is to put LDA on top of a deep neural network. This can be seen as a\nnon-linear extension of classic LDA. Instead of maximizing the likelihood of\ntarget labels for individual samples, we propose an objective function that\npushes the network to produce feature distributions which: (a) have low\nvariance within the same class and (b) high variance between different classes.\nOur objective is derived from the general LDA eigenvalue problem and still\nallows to train with stochastic gradient descent and back-propagation. For\nevaluation we test our approach on three different benchmark datasets (MNIST,\nCIFAR-10 and STL-10). DeepLDA produces competitive results on MNIST and\nCIFAR-10 and outperforms a network trained with categorical cross entropy (same\narchitecture) on a supervised setting of STL-10.\n",
        "published": "2015-11-15T14:33:26Z",
        "pdf_link": "http://arxiv.org/pdf/1511.04707v5"
    },
    {
        "id": "http://arxiv.org/abs/1511.04773v4",
        "title": "Large-Scale Approximate Kernel Canonical Correlation Analysis",
        "summary": "  Kernel canonical correlation analysis (KCCA) is a nonlinear multi-view\nrepresentation learning technique with broad applicability in statistics and\nmachine learning. Although there is a closed-form solution for the KCCA\nobjective, it involves solving an $N\\times N$ eigenvalue system where $N$ is\nthe training set size, making its computational requirements in both memory and\ntime prohibitive for large-scale problems. Various approximation techniques\nhave been developed for KCCA. A commonly used approach is to first transform\nthe original inputs to an $M$-dimensional random feature space so that inner\nproducts in the feature space approximate kernel evaluations, and then apply\nlinear CCA to the transformed inputs. In many applications, however, the\ndimensionality $M$ of the random feature space may need to be very large in\norder to obtain a sufficiently good approximation; it then becomes challenging\nto perform the linear CCA step on the resulting very high-dimensional data\nmatrices. We show how to use a stochastic optimization algorithm, recently\nproposed for linear CCA and its neural-network extension, to further alleviate\nthe computation requirements of approximate KCCA. This approach allows us to\nrun approximate KCCA on a speech dataset with $1.4$ million training samples\nand a random feature space of dimensionality $M=100000$ on a typical\nworkstation.\n",
        "published": "2015-11-15T22:20:02Z",
        "pdf_link": "http://arxiv.org/pdf/1511.04773v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.04813v2",
        "title": "Budget Online Multiple Kernel Learning",
        "summary": "  Online learning with multiple kernels has gained increasing interests in\nrecent years and found many applications. For classification tasks, Online\nMultiple Kernel Classification (OMKC), which learns a kernel based classifier\nby seeking the optimal linear combination of a pool of single kernel\nclassifiers in an online fashion, achieves superior accuracy and enjoys great\nflexibility compared with traditional single-kernel classifiers. Despite being\nstudied extensively, existing OMKC algorithms suffer from high computational\ncost due to their unbounded numbers of support vectors. To overcome this\ndrawback, we present a novel framework of Budget Online Multiple Kernel\nLearning (BOMKL) and propose a new Sparse Passive Aggressive learning to\nperform effective budget online learning. Specifically, we adopt a simple yet\neffective Bernoulli sampling to decide if an incoming instance should be added\nto the current set of support vectors. By limiting the number of support\nvectors, our method can significantly accelerate OMKC while maintaining\nsatisfactory accuracy that is comparable to that of the existing OMKC\nalgorithms. We theoretically prove that our new method achieves an optimal\nregret bound in expectation, and empirically found that the proposed algorithm\noutperforms various OMKC algorithms and can easily scale up to large-scale\ndatasets.\n",
        "published": "2015-11-16T03:40:50Z",
        "pdf_link": "http://arxiv.org/pdf/1511.04813v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.05082v1",
        "title": "Topic Modeling of Behavioral Modes Using Sensor Data",
        "summary": "  The field of Movement Ecology, like so many other fields, is experiencing a\nperiod of rapid growth in availability of data. As the volume rises,\ntraditional methods are giving way to machine learning and data science, which\nare playing an increasingly large part it turning this data into\nscience-driving insights. One rich and interesting source is the bio-logger.\nThese small electronic wearable devices are attached to animals free to roam in\ntheir natural habitats, and report back readings from multiple sensors,\nincluding GPS and accelerometer bursts. A common use of accelerometer data is\nfor supervised learning of behavioral modes. However, we need unsupervised\nanalysis tools as well, in order to overcome the inherent difficulties of\nobtaining a labeled dataset, which in some cases is either infeasible or does\nnot successfully encompass the full repertoire of behavioral modes of interest.\nHere we present a matrix factorization based topic-model method for\naccelerometer bursts, derived using a linear mixture property of patch\nfeatures. Our method is validated via comparison to a labeled dataset, and is\nfurther compared to standard clustering algorithms.\n",
        "published": "2015-11-16T18:42:04Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05082v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.05176v3",
        "title": "MuProp: Unbiased Backpropagation for Stochastic Neural Networks",
        "summary": "  Deep neural networks are powerful parametric models that can be trained\nefficiently using the backpropagation algorithm. Stochastic neural networks\ncombine the power of large parametric functions with that of graphical models,\nwhich makes it possible to learn very complex distributions. However, as\nbackpropagation is not directly applicable to stochastic networks that include\ndiscrete sampling operations within their computational graph, training such\nnetworks remains difficult. We present MuProp, an unbiased gradient estimator\nfor stochastic networks, designed to make this task easier. MuProp improves on\nthe likelihood-ratio estimator by reducing its variance using a control variate\nbased on the first-order Taylor expansion of a mean-field network. Crucially,\nunlike prior attempts at using backpropagation for training stochastic\nnetworks, the resulting estimator is unbiased and well behaved. Our experiments\non structured output prediction and discrete latent variable modeling\ndemonstrate that MuProp yields consistently good performance across a range of\ndifficult tasks.\n",
        "published": "2015-11-16T21:08:25Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05176v3"
    },
    {
        "id": "http://arxiv.org/abs/1511.05212v5",
        "title": "Binary embeddings with structured hashed projections",
        "summary": "  We consider the hashing mechanism for constructing binary embeddings, that\ninvolves pseudo-random projections followed by nonlinear (sign function)\nmappings. The pseudo-random projection is described by a matrix, where not all\nentries are independent random variables but instead a fixed \"budget of\nrandomness\" is distributed across the matrix. Such matrices can be efficiently\nstored in sub-quadratic or even linear space, provide reduction in randomness\nusage (i.e. number of required random values), and very often lead to\ncomputational speed ups. We prove several theoretical results showing that\nprojections via various structured matrices followed by nonlinear mappings\naccurately preserve the angular distance between input high-dimensional\nvectors. To the best of our knowledge, these results are the first that give\ntheoretical ground for the use of general structured matrices in the nonlinear\nsetting. In particular, they generalize previous extensions of the\nJohnson-Lindenstrauss lemma and prove the plausibility of the approach that was\nso far only heuristically confirmed for some special structured matrices.\nConsequently, we show that many structured matrices can be used as an efficient\ninformation compression mechanism. Our findings build a better understanding of\ncertain deep architectures, which contain randomly weighted and untrained\nlayers, and yet achieve high performance on different learning tasks. We\nempirically verify our theoretical findings and show the dependence of learning\nvia structured hashed projections on the performance of neural network as well\nas nearest neighbor classifier.\n",
        "published": "2015-11-16T23:01:12Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05212v5"
    },
    {
        "id": "http://arxiv.org/abs/1511.05371v1",
        "title": "Constant Time EXPected Similarity Estimation using Stochastic\n  Optimization",
        "summary": "  A new algorithm named EXPected Similarity Estimation (EXPoSE) was recently\nproposed to solve the problem of large-scale anomaly detection. It is a\nnon-parametric and distribution free kernel method based on the Hilbert space\nembedding of probability measures. Given a dataset of $n$ samples, EXPoSE needs\nonly $\\mathcal{O}(n)$ (linear time) to build a model and $\\mathcal{O}(1)$\n(constant time) to make a prediction. In this work we improve the linear\ncomputational complexity and show that an $\\epsilon$-accurate model can be\nestimated in constant time, which has significant implications for large-scale\nlearning problems. To achieve this goal, we cast the original EXPoSE\nformulation into a stochastic optimization problem. It is crucial that this\napproach allows us to determine the number of iteration based on a desired\naccuracy $\\epsilon$, independent of the dataset size $n$. We will show that the\nproposed stochastic gradient descent algorithm works in general (possible\ninfinite-dimensional) Hilbert spaces, is easy to implement and requires no\nadditional step-size parameters.\n",
        "published": "2015-11-17T12:10:03Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05371v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.05641v4",
        "title": "Net2Net: Accelerating Learning via Knowledge Transfer",
        "summary": "  We introduce techniques for rapidly transferring the information stored in\none neural net into another neural net. The main purpose is to accelerate the\ntraining of a significantly larger neural net. During real-world workflows, one\noften trains very many different neural networks during the experimentation and\ndesign process. This is a wasteful process in which each new model is trained\nfrom scratch. Our Net2Net technique accelerates the experimentation process by\ninstantaneously transferring the knowledge from a previous network to each new\ndeeper or wider network. Our techniques are based on the concept of\nfunction-preserving transformations between neural network specifications. This\ndiffers from previous approaches to pre-training that altered the function\nrepresented by a neural net when adding layers to it. Using our knowledge\ntransfer mechanism to add depth to Inception modules, we demonstrate a new\nstate of the art accuracy rating on the ImageNet dataset.\n",
        "published": "2015-11-18T02:09:20Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05641v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.05644v2",
        "title": "Adversarial Autoencoders",
        "summary": "  In this paper, we propose the \"adversarial autoencoder\" (AAE), which is a\nprobabilistic autoencoder that uses the recently proposed generative\nadversarial networks (GAN) to perform variational inference by matching the\naggregated posterior of the hidden code vector of the autoencoder with an\narbitrary prior distribution. Matching the aggregated posterior to the prior\nensures that generating from any part of prior space results in meaningful\nsamples. As a result, the decoder of the adversarial autoencoder learns a deep\ngenerative model that maps the imposed prior to the data distribution. We show\nhow the adversarial autoencoder can be used in applications such as\nsemi-supervised classification, disentangling style and content of images,\nunsupervised clustering, dimensionality reduction and data visualization. We\nperformed experiments on MNIST, Street View House Numbers and Toronto Face\ndatasets and show that adversarial autoencoders achieve competitive results in\ngenerative modeling and semi-supervised classification tasks.\n",
        "published": "2015-11-18T02:32:39Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05644v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.05653v2",
        "title": "Why are deep nets reversible: A simple theory, with implications for\n  training",
        "summary": "  Generative models for deep learning are promising both to improve\nunderstanding of the model, and yield training methods requiring fewer labeled\nsamples.\n  Recent works use generative model approaches to produce the deep net's input\ngiven the value of a hidden layer several levels above. However, there is no\naccompanying \"proof of correctness\" for the generative model, showing that the\nfeedforward deep net is the correct inference method for recovering the hidden\nlayer given the input. Furthermore, these models are complicated.\n  The current paper takes a more theoretical tack. It presents a very simple\ngenerative model for RELU deep nets, with the following characteristics: (i)\nThe generative model is just the reverse of the feedforward net: if the forward\ntransformation at a layer is $A$ then the reverse transformation is $A^T$.\n(This can be seen as an explanation of the old weight tying idea for denoising\nautoencoders.) (ii) Its correctness can be proven under a clean theoretical\nassumption: the edge weights in real-life deep nets behave like random numbers.\nUnder this assumption ---which is experimentally tested on real-life nets like\nAlexNet--- it is formally proved that feed forward net is a correct inference\nmethod for recovering the hidden layer.\n  The generative model suggests a simple modification for training: use the\ngenerative model to produce synthetic data with labels and include it in the\ntraining set. Experiments are shown to support this theory of random-like deep\nnets; and that it helps the training.\n",
        "published": "2015-11-18T04:33:09Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05653v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.05678v3",
        "title": "Expressiveness of Rectifier Networks",
        "summary": "  Rectified Linear Units (ReLUs) have been shown to ameliorate the vanishing\ngradient problem, allow for efficient backpropagation, and empirically promote\nsparsity in the learned parameters. They have led to state-of-the-art results\nin a variety of applications. However, unlike threshold and sigmoid networks,\nReLU networks are less explored from the perspective of their expressiveness.\nThis paper studies the expressiveness of ReLU networks. We characterize the\ndecision boundary of two-layer ReLU networks by constructing functionally\nequivalent threshold networks. We show that while the decision boundary of a\ntwo-layer ReLU network can be captured by a threshold network, the latter may\nrequire an exponentially larger number of hidden units. We also formulate\nsufficient conditions for a corresponding logarithmic reduction in the number\nof hidden units to represent a sign network as a ReLU network. Finally, we\nexperimentally compare threshold networks and their much smaller ReLU\ncounterparts with respect to their ability to learn from synthetically\ngenerated data.\n",
        "published": "2015-11-18T07:26:12Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05678v3"
    },
    {
        "id": "http://arxiv.org/abs/1511.05688v2",
        "title": "A Distribution Adaptive Framework for Prediction Interval Estimation\n  Using Nominal Variables",
        "summary": "  Proposed methods for prediction interval estimation so far focus on cases\nwhere input variables are numerical. In datasets with solely nominal input\nvariables, we observe records with the exact same input $x^u$, but different\nreal valued outputs due to the inherent noise in the system. Existing\nprediction interval estimation methods do not use representations that can\naccurately model such inherent noise in the case of nominal inputs. We propose\na new prediction interval estimation method tailored for this type of data,\nwhich is prevalent in biology and medicine. We call this method Distribution\nAdaptive Prediction Interval Estimation given Nominal inputs (DAPIEN) and has\nfour main phases. First, we select a distribution function that can best\nrepresent the inherent noise of the system for all unique inputs. Then we infer\nthe parameters $\\theta_i$ (e.g. $\\theta_i=[mean_i, variance_i]$) of the\nselected distribution function for all unique input vectors $x^u_i$ and\ngenerate a new corresponding training set using pairs of $x^u_i, \\theta_i$.\nIII). Then, we train a model to predict $\\theta$ given a new $x_u$. Finally, we\ncalculate the prediction interval for a new sample using the inverse of the\ncumulative distribution function once the parameters $\\theta$ is predicted by\nthe trained model. We compared DAPIEN to the commonly used Bootstrap method on\nthree synthetic datasets. Our results show that DAPIEN provides tighter\nprediction intervals while preserving the requested coverage when compared to\nBootstrap. This work can facilitate broader usage of regression methods in\nmedicine and biology where it is necessary to provide tight prediction\nintervals while preserving coverage when input variables are nominal.\n",
        "published": "2015-11-18T08:13:35Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05688v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.05710v2",
        "title": "Complex-Valued Gaussian Processes for Regression",
        "summary": "  In this paper we propose a novel Bayesian solution for nonlinear regression\nin complex fields. Previous solutions for kernels methods usually assume a\ncomplexification approach, where the real-valued kernel is replaced by a\ncomplex-valued one. This approach is limited. Based on results in\ncomplex-valued linear theory and Gaussian random processes we show that a\npseudo-kernel must be included. This is the starting point to develop the new\ncomplex-valued formulation for Gaussian process for regression (CGPR). We face\nthe design of the covariance and pseudo-covariance based on a convolution\napproach and for several scenarios. Just in the particular case where the\noutputs are proper, the pseudo-kernel cancels. Also, the hyperparameters of the\ncovariance {can be learnt} maximizing the marginal likelihood using Wirtinger's\ncalculus and patterned complex-valued matrix derivatives. In the experiments\nincluded, we show how CGPR successfully solve systems where real and imaginary\nparts are correlated. Besides, we successfully solve the nonlinear channel\nequalization problem by developing a recursive solution with basis removal. We\nreport remarkable improvements compared to previous solutions: a 2-4 dB\nreduction of the MSE with {just a quarter} of the training samples used by\nprevious approaches.\n",
        "published": "2015-11-18T09:49:22Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05710v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.05743v1",
        "title": "Sparse learning of maximum likelihood model for optimization of complex\n  loss function",
        "summary": "  Traditional machine learning methods usually minimize a simple loss function\nto learn a predictive model, and then use a complex performance measure to\nmeasure the prediction performance. However, minimizing a simple loss function\ncannot guarantee that an optimal performance. In this paper, we study the\nproblem of optimizing the complex performance measure directly to obtain a\npredictive model. We proposed to construct a maximum likelihood model for this\nproblem, and to learn the model parameter, we minimize a com- plex loss\nfunction corresponding to the desired complex performance measure. To optimize\nthe loss function, we approximate the upper bound of the complex loss. We also\npropose impose the sparsity to the model parameter to obtain a sparse model. An\nobjective is constructed by combining the upper bound of the loss function and\nthe sparsity of the model parameter, and we develop an iterative algorithm to\nminimize it by using the fast iterative shrinkage- thresholding algorithm\nframework. The experiments on optimization on three different complex\nperformance measures, including F-score, receiver operating characteristic\ncurve, and recall precision curve break even point, over three real-world\napplications, aircraft event recognition of civil aviation safety, in- trusion\ndetection in wireless mesh networks, and image classification, show the\nadvantages of the proposed method over state-of-the-art methods.\n",
        "published": "2015-11-18T11:40:02Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05743v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.05789v6",
        "title": "Metric learning approach for graph-based label propagation",
        "summary": "  The efficiency of graph-based semi-supervised algorithms depends on the graph\nof instances on which they are applied. The instances are often in a vectorial\nform before a graph linking them is built. The construction of the graph relies\non a metric over the vectorial space that help define the weight of the\nconnection between entities. The classic choice for this metric is usually a\ndistance measure or a similarity measure based on the euclidean norm. We claim\nthat in some cases the euclidean norm on the initial vectorial space might not\nbe the more appropriate to solve the task efficiently. We propose an algorithm\nthat aims at learning the most appropriate vectorial representation for\nbuilding a graph on which the task at hand is solved efficiently.\n",
        "published": "2015-11-18T14:04:55Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05789v6"
    },
    {
        "id": "http://arxiv.org/abs/1511.05933v8",
        "title": "Seeding K-Means using Method of Moments",
        "summary": "  K-means is one of the most widely used algorithms for clustering in Data\nMining applications, which attempts to minimize the sum of the square of the\nEuclidean distance of the points in the clusters from the respective means of\nthe clusters. However, K-means suffers from local minima problem and is not\nguaranteed to converge to the optimal cost. K-means++ tries to address the\nproblem by seeding the means using a distance-based sampling scheme. However,\nseeding the means in K-means++ needs $O\\left(K\\right)$ sequential passes\nthrough the entire dataset, and this can be very costly for large datasets.\nHere we propose a method of seeding the initial means based on factorizations\nof higher order moments for bounded data. Our method takes $O\\left(1\\right)$\npasses through the entire dataset to extract the initial set of means, and its\nfinal cost can be proven to be within $O(\\sqrt{K})$ of the optimal cost. We\ndemonstrate the performance of our algorithm in comparison with the existing\nalgorithms on various benchmark datasets.\n",
        "published": "2015-11-18T20:26:42Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05933v8"
    },
    {
        "id": "http://arxiv.org/abs/1511.05942v11",
        "title": "Doctor AI: Predicting Clinical Events via Recurrent Neural Networks",
        "summary": "  Leveraging large historical data in electronic health record (EHR), we\ndeveloped Doctor AI, a generic predictive model that covers observed medical\nconditions and medication uses. Doctor AI is a temporal model using recurrent\nneural networks (RNN) and was developed and applied to longitudinal time\nstamped EHR data from 260K patients over 8 years. Encounter records (e.g.\ndiagnosis codes, medication codes or procedure codes) were input to RNN to\npredict (all) the diagnosis and medication categories for a subsequent visit.\nDoctor AI assesses the history of patients to make multilabel predictions (one\nlabel for each diagnosis or medication category). Based on separate blind test\nset evaluation, Doctor AI can perform differential diagnosis with up to 79%\nrecall@30, significantly higher than several baselines. Moreover, we\ndemonstrate great generalizability of Doctor AI by adapting the resulting\nmodels from one institution to another without losing substantial accuracy.\n",
        "published": "2015-11-18T20:47:44Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05942v11"
    },
    {
        "id": "http://arxiv.org/abs/1511.05950v5",
        "title": "Staleness-aware Async-SGD for Distributed Deep Learning",
        "summary": "  Deep neural networks have been shown to achieve state-of-the-art performance\nin several machine learning tasks. Stochastic Gradient Descent (SGD) is the\npreferred optimization algorithm for training these networks and asynchronous\nSGD (ASGD) has been widely adopted for accelerating the training of large-scale\ndeep networks in a distributed computing environment. However, in practice it\nis quite challenging to tune the training hyperparameters (such as learning\nrate) when using ASGD so as achieve convergence and linear speedup, since the\nstability of the optimization algorithm is strongly influenced by the\nasynchronous nature of parameter updates. In this paper, we propose a variant\nof the ASGD algorithm in which the learning rate is modulated according to the\ngradient staleness and provide theoretical guarantees for convergence of this\nalgorithm. Experimental verification is performed on commonly-used image\nclassification benchmarks: CIFAR10 and Imagenet to demonstrate the superior\neffectiveness of the proposed approach, compared to SSGD (Synchronous SGD) and\nthe conventional ASGD algorithm.\n",
        "published": "2015-11-18T20:53:33Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05950v5"
    },
    {
        "id": "http://arxiv.org/abs/1511.05952v4",
        "title": "Prioritized Experience Replay",
        "summary": "  Experience replay lets online reinforcement learning agents remember and\nreuse experiences from the past. In prior work, experience transitions were\nuniformly sampled from a replay memory. However, this approach simply replays\ntransitions at the same frequency that they were originally experienced,\nregardless of their significance. In this paper we develop a framework for\nprioritizing experience, so as to replay important transitions more frequently,\nand therefore learn more efficiently. We use prioritized experience replay in\nDeep Q-Networks (DQN), a reinforcement learning algorithm that achieved\nhuman-level performance across many Atari games. DQN with prioritized\nexperience replay achieves a new state-of-the-art, outperforming DQN with\nuniform replay on 41 out of 49 games.\n",
        "published": "2015-11-18T20:54:44Z",
        "pdf_link": "http://arxiv.org/pdf/1511.05952v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.06267v5",
        "title": "Asymmetrically Weighted CCA And Hierarchical Kernel Sentence Embedding\n  For Image & Text Retrieval",
        "summary": "  Joint modeling of language and vision has been drawing increasing interest. A\nmultimodal data representation allowing for bidirectional retrieval of images\nby sentences and vice versa is a key aspect. In this paper we present three\ncontributions in canonical correlation analysis (CCA) based multimodal\nretrieval. Firstly, we show that an asymmetric weighting of the canonical\nweights, while achieving a cross view mapping from the search to the query\nspace, improves the retrieval performance. Secondly, we devise a\ncomputationally efficient model selection, crucial to generalization and\nstability, in the framework of the Bj\\\"ork Golub algorithm for regularized CCA\nvia spectral filtering. Finally, we introduce a Hierarchical Kernel Sentence\nEmbedding (HKSE) that approximates Kernel CCA for a special similarity kernel\nbetween distribution of words embedded in a vector space. State of the art\nresults are obtained on MSCOCO and Flickr benchmarks when these three\ntechniques are used in conjunction.\n",
        "published": "2015-11-19T17:29:00Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06267v5"
    },
    {
        "id": "http://arxiv.org/abs/1511.06295v2",
        "title": "Policy Distillation",
        "summary": "  Policies for complex visual tasks have been successfully learned with deep\nreinforcement learning, using an approach called deep Q-networks (DQN), but\nrelatively large (task-specific) networks and extensive training are needed to\nachieve good performance. In this work, we present a novel method called policy\ndistillation that can be used to extract the policy of a reinforcement learning\nagent and train a new network that performs at the expert level while being\ndramatically smaller and more efficient. Furthermore, the same method can be\nused to consolidate multiple task-specific policies into a single policy. We\ndemonstrate these claims using the Atari domain and show that the multi-task\ndistilled agent outperforms the single-task teachers as well as a\njointly-trained DQN agent.\n",
        "published": "2015-11-19T18:38:47Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06295v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.06297v2",
        "title": "Conditional Computation in Neural Networks for faster models",
        "summary": "  Deep learning has become the state-of-art tool in many applications, but the\nevaluation and training of deep models can be time-consuming and\ncomputationally expensive. The conditional computation approach has been\nproposed to tackle this problem (Bengio et al., 2013; Davis & Arel, 2013). It\noperates by selectively activating only parts of the network at a time. In this\npaper, we use reinforcement learning as a tool to optimize conditional\ncomputation policies. More specifically, we cast the problem of learning\nactivation-dependent policies for dropping out blocks of units as a\nreinforcement learning problem. We propose a learning scheme motivated by\ncomputation speed, capturing the idea of wanting to have parsimonious\nactivations while maintaining prediction accuracy. We apply a policy gradient\nalgorithm for learning policies that optimize this loss function and propose a\nregularization mechanism that encourages diversification of the dropout policy.\nWe present encouraging empirical results showing that this approach improves\nthe speed of computation without impacting the quality of the approximation.\n",
        "published": "2015-11-19T18:40:22Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06297v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.06328v3",
        "title": "Manifold Regularized Discriminative Neural Networks",
        "summary": "  Unregularized deep neural networks (DNNs) can be easily overfit with a\nlimited sample size. We argue that this is mostly due to the disriminative\nnature of DNNs which directly model the conditional probability (or score) of\nlabels given the input. The ignorance of input distribution makes DNNs\ndifficult to generalize to unseen data. Recent advances in regularization\ntechniques, such as pretraining and dropout, indicate that modeling input data\ndistribution (either explicitly or implicitly) greatly improves the\ngeneralization ability of a DNN. In this work, we explore the manifold\nhypothesis which assumes that instances within the same class lie in a smooth\nmanifold. We accordingly propose two simple regularizers to a standard\ndiscriminative DNN. The first one, named Label-Aware Manifold Regularization,\nassumes the availability of labels and penalizes large norms of the loss\nfunction w.r.t. data points. The second one, named Label-Independent Manifold\nRegularization, does not use label information and instead penalizes the\nFrobenius norm of the Jacobian matrix of prediction scores w.r.t. data points,\nwhich makes semi-supervised learning possible. We perform extensive control\nexperiments on fully supervised and semi-supervised tasks using the MNIST,\nCIFAR10 and SVHN datasets and achieve excellent results.\n",
        "published": "2015-11-19T19:46:39Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06328v3"
    },
    {
        "id": "http://arxiv.org/abs/1511.06333v4",
        "title": "Efficient Sum of Outer Products Dictionary Learning (SOUP-DIL) and Its\n  Application to Inverse Problems",
        "summary": "  The sparsity of signals in a transform domain or dictionary has been\nexploited in applications such as compression, denoising and inverse problems.\nMore recently, data-driven adaptation of synthesis dictionaries has shown\npromise compared to analytical dictionary models. However, dictionary learning\nproblems are typically non-convex and NP-hard, and the usual alternating\nminimization approaches for these problems are often computationally expensive,\nwith the computations dominated by the NP-hard synthesis sparse coding step.\nThis paper exploits the ideas that drive algorithms such as K-SVD, and\ninvestigates in detail efficient methods for aggregate sparsity penalized\ndictionary learning by first approximating the data with a sum of sparse\nrank-one matrices (outer products) and then using a block coordinate descent\napproach to estimate the unknowns. The resulting block coordinate descent\nalgorithms involve efficient closed-form solutions. Furthermore, we consider\nthe problem of dictionary-blind image reconstruction, and propose novel and\nefficient algorithms for adaptive image reconstruction using block coordinate\ndescent and sum of outer products methodologies. We provide a convergence study\nof the algorithms for dictionary learning and dictionary-blind image\nreconstruction. Our numerical experiments show the promising performance and\nspeed-ups provided by the proposed methods over previous schemes in sparse data\nrepresentation and compressed sensing-based image reconstruction.\n",
        "published": "2015-11-19T20:01:24Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06333v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.06342v4",
        "title": "Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning",
        "summary": "  The ability to act in multiple environments and transfer previous knowledge\nto new situations can be considered a critical aspect of any intelligent agent.\nTowards this goal, we define a novel method of multitask and transfer learning\nthat enables an autonomous agent to learn how to behave in multiple tasks\nsimultaneously, and then generalize its knowledge to new domains. This method,\ntermed \"Actor-Mimic\", exploits the use of deep reinforcement learning and model\ncompression techniques to train a single policy network that learns how to act\nin a set of distinct tasks by using the guidance of several expert teachers. We\nthen show that the representations learnt by the deep policy network are\ncapable of generalizing to new tasks with no prior expert guidance, speeding up\nlearning in novel environments. Although our method can in general be applied\nto a wide range of problems, we use Atari games as a testing environment to\ndemonstrate these methods.\n",
        "published": "2015-11-19T20:17:27Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06342v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.06393v3",
        "title": "Fixed Point Quantization of Deep Convolutional Networks",
        "summary": "  In recent years increasingly complex architectures for deep convolution\nnetworks (DCNs) have been proposed to boost the performance on image\nrecognition tasks. However, the gains in performance have come at a cost of\nsubstantial increase in computation and model storage resources. Fixed point\nimplementation of DCNs has the potential to alleviate some of these\ncomplexities and facilitate potential deployment on embedded hardware. In this\npaper, we propose a quantizer design for fixed point implementation of DCNs. We\nformulate and solve an optimization problem to identify optimal fixed point\nbit-width allocation across DCN layers. Our experiments show that in comparison\nto equal bit-width settings, the fixed point DCNs with optimized bit width\nallocation offer >20% reduction in the model size without any loss in accuracy\non CIFAR-10 benchmark. We also demonstrate that fine-tuning can further enhance\nthe accuracy of fixed point DCNs beyond that of the original floating point\nmodel. In doing so, we report a new state-of-the-art fixed point performance of\n6.78% error-rate on CIFAR-10 benchmark.\n",
        "published": "2015-11-19T21:37:06Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06393v3"
    },
    {
        "id": "http://arxiv.org/abs/1511.06406v2",
        "title": "Denoising Criterion for Variational Auto-Encoding Framework",
        "summary": "  Denoising autoencoders (DAE) are trained to reconstruct their clean inputs\nwith noise injected at the input level, while variational autoencoders (VAE)\nare trained with noise injected in their stochastic hidden layer, with a\nregularizer that encourages this noise injection. In this paper, we show that\ninjecting noise both in input and in the stochastic hidden layer can be\nadvantageous and we propose a modified variational lower bound as an improved\nobjective function in this setup. When input is corrupted, then the standard\nVAE lower bound involves marginalizing the encoder conditional distribution\nover the input noise, which makes the training criterion intractable. Instead,\nwe propose a modified training criterion which corresponds to a tractable bound\nwhen input is corrupted. Experimentally, we find that the proposed denoising\nvariational autoencoder (DVAE) yields better average log-likelihood than the\nVAE and the importance weighted autoencoder on the MNIST and Frey Face\ndatasets.\n",
        "published": "2015-11-19T21:56:21Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06406v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.06411v2",
        "title": "Training Deep Neural Networks via Direct Loss Minimization",
        "summary": "  Supervised training of deep neural nets typically relies on minimizing\ncross-entropy. However, in many domains, we are interested in performing well\non metrics specific to the application. In this paper we propose a direct loss\nminimization approach to train deep neural networks, which provably minimizes\nthe application-specific loss function. This is often non-trivial, since these\nfunctions are neither smooth nor decomposable and thus are not amenable to\noptimization with standard gradient-based methods. We demonstrate the\neffectiveness of our approach in the context of maximizing average precision\nfor ranking problems. Towards this goal, we develop a novel dynamic programming\nalgorithm that can efficiently compute the weight updates. Our approach proves\nsuperior to a variety of baselines in the context of action classification and\nobject detection, especially in the presence of label noise.\n",
        "published": "2015-11-19T22:02:26Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06411v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.06422v7",
        "title": "All you need is a good init",
        "summary": "  Layer-sequential unit-variance (LSUV) initialization - a simple method for\nweight initialization for deep net learning - is proposed. The method consists\nof the two steps. First, pre-initialize weights of each convolution or\ninner-product layer with orthonormal matrices. Second, proceed from the first\nto the final layer, normalizing the variance of the output of each layer to be\nequal to one.\n  Experiment with different activation functions (maxout, ReLU-family, tanh)\nshow that the proposed initialization leads to learning of very deep nets that\n(i) produces networks with test accuracy better or equal to standard methods\nand (ii) is at least as fast as the complex schemes proposed specifically for\nvery deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava\net al. (2015)).\n  Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual nets\nand the state-of-the-art, or very close to it, is achieved on the MNIST,\nCIFAR-10/100 and ImageNet datasets.\n",
        "published": "2015-11-19T22:19:15Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06422v7"
    },
    {
        "id": "http://arxiv.org/abs/1511.06430v4",
        "title": "Deconstructing the Ladder Network Architecture",
        "summary": "  The Manual labeling of data is and will remain a costly endeavor. For this\nreason, semi-supervised learning remains a topic of practical importance. The\nrecently proposed Ladder Network is one such approach that has proven to be\nvery successful. In addition to the supervised objective, the Ladder Network\nalso adds an unsupervised objective corresponding to the reconstruction costs\nof a stack of denoising autoencoders. Although the empirical results are\nimpressive, the Ladder Network has many components intertwined, whose\ncontributions are not obvious in such a complex architecture. In order to help\nelucidate and disentangle the different ingredients in the Ladder Network\nrecipe, this paper presents an extensive experimental investigation of variants\nof the Ladder Network in which we replace or remove individual components to\ngain more insight into their relative importance. We find that all of the\ncomponents are necessary for achieving optimal performance, but they do not\ncontribute equally. For semi-supervised tasks, we conclude that the most\nimportant contribution is made by the lateral connection, followed by the\napplication of noise, and finally the choice of what we refer to as the\n`combinator function' in the decoder path. We also find that as the number of\nlabeled training examples increases, the lateral connections and reconstruction\ncriterion become less important, with most of the improvement in generalization\nbeing due to the injection of noise in each layer. Furthermore, we present a\nnew type of combinator function that outperforms the original design in both\nfully- and semi-supervised tasks, reducing record test error rates on\nPermutation-Invariant MNIST to 0.57% for the supervised setting, and to 0.97%\nand 1.0% for semi-supervised settings with 1000 and 100 labeled examples\nrespectively.\n",
        "published": "2015-11-19T22:45:20Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06430v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.06433v3",
        "title": "Blending LSTMs into CNNs",
        "summary": "  We consider whether deep convolutional networks (CNNs) can represent decision\nfunctions with similar accuracy as recurrent networks such as LSTMs. First, we\nshow that a deep CNN with an architecture inspired by the models recently\nintroduced in image recognition can yield better accuracy than previous\nconvolutional and LSTM networks on the standard 309h Switchboard automatic\nspeech recognition task. Then we show that even more accurate CNNs can be\ntrained under the guidance of LSTMs using a variant of model compression, which\nwe call model blending because the teacher and student models are similar in\ncomplexity but different in inductive bias. Blending further improves the\naccuracy of our CNN, yielding a computationally efficient model of accuracy\nhigher than any of the other individual models. Examining the effect of \"dark\nknowledge\" in this model compression task, we find that less than 1% of the\nhighest probability labels are needed for accurate model compression.\n",
        "published": "2015-11-19T22:48:59Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06433v3"
    },
    {
        "id": "http://arxiv.org/abs/1511.06435v3",
        "title": "Comparative Study of Deep Learning Software Frameworks",
        "summary": "  Deep learning methods have resulted in significant performance improvements\nin several application domains and as such several software frameworks have\nbeen developed to facilitate their implementation. This paper presents a\ncomparative study of five deep learning frameworks, namely Caffe, Neon,\nTensorFlow, Theano, and Torch, on three aspects: extensibility, hardware\nutilization, and speed. The study is performed on several types of deep\nlearning architectures and we evaluate the performance of the above frameworks\nwhen employed on a single machine for both (multi-threaded) CPU and GPU (Nvidia\nTitan X) settings. The speed performance metrics used here include the gradient\ncomputation time, which is important during the training phase of deep\nnetworks, and the forward time, which is important from the deployment\nperspective of trained networks. For convolutional networks, we also report how\neach of these frameworks support various convolutional algorithms and their\ncorresponding performance. From our experiments, we observe that Theano and\nTorch are the most easily extensible frameworks. We observe that Torch is best\nsuited for any deep architecture on CPU, followed by Theano. It also achieves\nthe best performance on the GPU for large convolutional and fully connected\nnetworks, followed closely by Neon. Theano achieves the best performance on GPU\nfor training and deployment of LSTM networks. Caffe is the easiest for\nevaluating the performance of standard deep architectures. Finally, TensorFlow\nis a very flexible framework, similar to Theano, but its performance is\ncurrently not competitive compared to the other studied frameworks.\n",
        "published": "2015-11-19T22:51:38Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06435v3"
    },
    {
        "id": "http://arxiv.org/abs/1511.06440v2",
        "title": "Towards Principled Unsupervised Learning",
        "summary": "  General unsupervised learning is a long-standing conceptual problem in\nmachine learning. Supervised learning is successful because it can be solved by\nthe minimization of the training error cost function. Unsupervised learning is\nnot as successful, because the unsupervised objective may be unrelated to the\nsupervised task of interest. For an example, density modelling and\nreconstruction have often been used for unsupervised learning, but they did not\nproduced the sought-after performance gains, because they have no knowledge of\nthe supervised tasks.\n  In this paper, we present an unsupervised cost function which we name the\nOutput Distribution Matching (ODM) cost, which measures a divergence between\nthe distribution of predictions and distributions of labels. The ODM cost is\nappealing because it is consistent with the supervised cost in the following\nsense: a perfect supervised classifier is also perfect according to the ODM\ncost. Therefore, by aggressively optimizing the ODM cost, we are almost\nguaranteed to improve our supervised performance whenever the space of possible\npredictions is exponentially large.\n  We demonstrate that the ODM cost works well on number of small and\nsemi-artificial datasets using no (or almost no) labelled training cases.\nFinally, we show that the ODM cost can be used for one-shot domain adaptation,\nwhich allows the model to classify inputs that differ from the input\ndistribution in significant ways without the need for prior exposure to the new\ndomain.\n",
        "published": "2015-11-19T23:04:23Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06440v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.06456v4",
        "title": "Task Loss Estimation for Sequence Prediction",
        "summary": "  Often, the performance on a supervised machine learning task is evaluated\nwith a emph{task loss} function that cannot be optimized directly. Examples of\nsuch loss functions include the classification error, the edit distance and the\nBLEU score. A common workaround for this problem is to instead optimize a\nemph{surrogate loss} function, such as for instance cross-entropy or hinge\nloss. In order for this remedy to be effective, it is important to ensure that\nminimization of the surrogate loss results in minimization of the task loss, a\ncondition that we call emph{consistency with the task loss}. In this work, we\npropose another method for deriving differentiable surrogate losses that\nprovably meet this requirement. We focus on the broad class of models that\ndefine a score for every input-output pair. Our idea is that this score can be\ninterpreted as an estimate of the task loss, and that the estimation error may\nbe used as a consistent surrogate loss. A distinct feature of such an approach\nis that it defines the desirable value of the score for every input-output\npair. We use this property to design specialized surrogate losses for\nEncoder-Decoder models often used for sequence prediction tasks. In our\nexperiment, we benchmark on the task of speech recognition. Using a new\nsurrogate loss instead of cross-entropy to train an Encoder-Decoder speech\nrecognizer brings a significant ~13% relative improvement in terms of Character\nError Rate (CER) in the case when no extra corpora are used for language\nmodeling.\n",
        "published": "2015-11-19T23:51:31Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06456v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.06485v5",
        "title": "On the energy landscape of deep networks",
        "summary": "  We introduce \"AnnealSGD\", a regularized stochastic gradient descent algorithm\nmotivated by an analysis of the energy landscape of a particular class of deep\nnetworks with sparse random weights. The loss function of such networks can be\napproximated by the Hamiltonian of a spherical spin glass with Gaussian\ncoupling. While different from currently-popular architectures such as\nconvolutional ones, spin glasses are amenable to analysis, which provides\ninsights on the topology of the loss function and motivates algorithms to\nminimize it. Specifically, we show that a regularization term akin to a\nmagnetic field can be modulated with a single scalar parameter to transition\nthe loss function from a complex, non-convex landscape with exponentially many\nlocal minima, to a phase with a polynomial number of minima, all the way down\nto a trivial landscape with a unique minimum. AnnealSGD starts training in the\nrelaxed polynomial regime and gradually tightens the regularization parameter\nto steer the energy towards the original exponential regime. Even for\nconvolutional neural networks, which are quite unlike sparse random networks,\nwe empirically show that AnnealSGD improves the generalization error using\ncompetitive baselines on MNIST and CIFAR-10.\n",
        "published": "2015-11-20T04:31:05Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06485v5"
    },
    {
        "id": "http://arxiv.org/abs/1511.06581v3",
        "title": "Dueling Network Architectures for Deep Reinforcement Learning",
        "summary": "  In recent years there have been many successes of using deep representations\nin reinforcement learning. Still, many of these applications use conventional\narchitectures, such as convolutional networks, LSTMs, or auto-encoders. In this\npaper, we present a new neural network architecture for model-free\nreinforcement learning. Our dueling network represents two separate estimators:\none for the state value function and one for the state-dependent action\nadvantage function. The main benefit of this factoring is to generalize\nlearning across actions without imposing any change to the underlying\nreinforcement learning algorithm. Our results show that this architecture leads\nto better policy evaluation in the presence of many similar-valued actions.\nMoreover, the dueling architecture enables our RL agent to outperform the\nstate-of-the-art on the Atari 2600 domain.\n",
        "published": "2015-11-20T13:07:54Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06581v3"
    },
    {
        "id": "http://arxiv.org/abs/1511.06606v5",
        "title": "Data Representation and Compression Using Linear-Programming\n  Approximations",
        "summary": "  We propose `Dracula', a new framework for unsupervised feature selection from\nsequential data such as text. Dracula learns a dictionary of $n$-grams that\nefficiently compresses a given corpus and recursively compresses its own\ndictionary; in effect, Dracula is a `deep' extension of Compressive Feature\nLearning. It requires solving a binary linear program that may be relaxed to a\nlinear program. Both problems exhibit considerable structure, their solution\npaths are well behaved, and we identify parameters which control the depth and\ndiversity of the dictionary. We also discuss how to derive features from the\ncompressed documents and show that while certain unregularized linear models\nare invariant to the structure of the compressed dictionary, this structure may\nbe used to regularize learning. Experiments are presented that demonstrate the\nefficacy of Dracula's features.\n",
        "published": "2015-11-20T14:21:44Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06606v5"
    },
    {
        "id": "http://arxiv.org/abs/1511.06660v5",
        "title": "Modeling the Temporal Nature of Human Behavior for Demographics\n  Prediction",
        "summary": "  Mobile phone metadata is increasingly used for humanitarian purposes in\ndeveloping countries as traditional data is scarce. Basic demographic\ninformation is however often absent from mobile phone datasets, limiting the\noperational impact of the datasets. For these reasons, there has been a growing\ninterest in predicting demographic information from mobile phone metadata.\nPrevious work focused on creating increasingly advanced features to be modeled\nwith standard machine learning algorithms. We here instead model the raw mobile\nphone metadata directly using deep learning, exploiting the temporal nature of\nthe patterns in the data. From high-level assumptions we design a data\nrepresentation and convolutional network architecture for modeling patterns\nwithin a week. We then examine three strategies for aggregating patterns across\nweeks and show that our method reaches state-of-the-art accuracy on both age\nand gender prediction using only the temporal modality in mobile metadata. We\nfinally validate our method on low activity users and evaluate the modeling\nassumptions.\n",
        "published": "2015-11-20T16:07:21Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06660v5"
    },
    {
        "id": "http://arxiv.org/abs/1511.06727v3",
        "title": "Scalable Gradient-Based Tuning of Continuous Regularization\n  Hyperparameters",
        "summary": "  Hyperparameter selection generally relies on running multiple full training\ntrials, with selection based on validation set performance. We propose a\ngradient-based approach for locally adjusting hyperparameters during training\nof the model. Hyperparameters are adjusted so as to make the model parameter\ngradients, and hence updates, more advantageous for the validation cost. We\nexplore the approach for tuning regularization hyperparameters and find that in\nexperiments on MNIST, SVHN and CIFAR-10, the resulting regularization levels\nare within the optimal regions. The additional computational cost depends on\nhow frequently the hyperparameters are trained, but the tested scheme adds only\n30% computational overhead regardless of the model size. Since the method is\nsignificantly less computationally demanding compared to similar gradient-based\napproaches to hyperparameter optimization, and consistently finds good\nhyperparameter values, it can be a useful tool for training neural network\nmodels.\n",
        "published": "2015-11-20T19:10:16Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06727v3"
    },
    {
        "id": "http://arxiv.org/abs/1511.06747v4",
        "title": "Data-Dependent Path Normalization in Neural Networks",
        "summary": "  We propose a unified framework for neural net normalization, regularization\nand optimization, which includes Path-SGD and Batch-Normalization and\ninterpolates between them across two different dimensions. Through this\nframework we investigate issue of invariance of the optimization, data\ndependence and the connection with natural gradients.\n",
        "published": "2015-11-20T20:27:45Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06747v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.06964v7",
        "title": "Online Semi-Supervised Learning with Deep Hybrid Boltzmann Machines and\n  Denoising Autoencoders",
        "summary": "  Two novel deep hybrid architectures, the Deep Hybrid Boltzmann Machine and\nthe Deep Hybrid Denoising Auto-encoder, are proposed for handling\nsemi-supervised learning problems. The models combine experts that model\nrelevant distributions at different levels of abstraction to improve overall\npredictive performance on discriminative tasks. Theoretical motivations and\nalgorithms for joint learning for each are presented. We apply the new models\nto the domain of data-streams in work towards life-long learning. The proposed\narchitectures show improved performance compared to a pseudo-labeled, drop-out\nrectifier network.\n",
        "published": "2015-11-22T04:53:43Z",
        "pdf_link": "http://arxiv.org/pdf/1511.06964v7"
    },
    {
        "id": "http://arxiv.org/abs/1511.07085v1",
        "title": "Multiple--Instance Learning: Christoffel Function Approach to\n  Distribution Regression Problem",
        "summary": "  A two--step Christoffel function based solution is proposed to distribution\nregression problem. On the first step, to model distribution of observations\ninside a bag, build Christoffel function for each bag of observations. Then, on\nthe second step, build outcome variable Christoffel function, but use the bag's\nChristoffel function value at given point as the weight for the bag's outcome.\nThe approach allows the result to be obtained in closed form and then to be\nevaluated numerically. While most of existing approaches minimize some kind an\nerror between outcome and prediction, the proposed approach is conceptually\ndifferent, because it uses Christoffel function for knowledge representation,\nwhat is conceptually equivalent working with probabilities only. To receive\npossible outcomes and their probabilities Gauss quadrature for second--step\nmeasure can be built, then the nodes give possible outcomes and normalized\nweights -- outcome probabilities. A library providing numerically stable\npolynomial basis for these calculations is available, what make the proposed\napproach practical.\n",
        "published": "2015-11-22T23:19:23Z",
        "pdf_link": "http://arxiv.org/pdf/1511.07085v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.07110v1",
        "title": "On the Generalization Error Bounds of Neural Networks under\n  Diversity-Inducing Mutual Angular Regularization",
        "summary": "  Recently diversity-inducing regularization methods for latent variable models\n(LVMs), which encourage the components in LVMs to be diverse, have been studied\nto address several issues involved in latent variable modeling: (1) how to\ncapture long-tail patterns underlying data; (2) how to reduce model complexity\nwithout sacrificing expressivity; (3) how to improve the interpretability of\nlearned patterns. While the effectiveness of diversity-inducing regularizers\nsuch as the mutual angular regularizer has been demonstrated empirically, a\nrigorous theoretical analysis of them is still missing. In this paper, we aim\nto bridge this gap and analyze how the mutual angular regularizer (MAR) affects\nthe generalization performance of supervised LVMs. We use neural network (NN)\nas a model instance to carry out the study and the analysis shows that\nincreasing the diversity of hidden units in NN would reduce estimation error\nand increase approximation error. In addition to theoretical analysis, we also\npresent empirical study which demonstrates that the MAR can greatly improve the\nperformance of NN and the empirical observations are in accordance with the\ntheoretical analysis.\n",
        "published": "2015-11-23T04:51:49Z",
        "pdf_link": "http://arxiv.org/pdf/1511.07110v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.07118v2",
        "title": "Cascading Denoising Auto-Encoder as a Deep Directed Generative Model",
        "summary": "  Recent work (Bengio et al., 2013) has shown howDenoising Auto-Encoders(DAE)\nbecome gener-ative models as a density estimator. However,in practice, the\nframework suffers from a mixingproblem in the MCMC sampling process and\nnodirect method to estimate the test log-likelihood.We consider a directed\nmodel with an stochas-tic identity mapping (simple corruption pro-cess) as an\ninference model and a DAE as agenerative model. By cascading these mod-els, we\npropose Cascading Denoising Auto-Encoders(CDAE) which can generate samples\nofdata distribution from tractable prior distributionunder the assumption that\nprobabilistic distribu-tion of corrupted data approaches tractable\npriordistribution as the level of corruption increases.This work tries to\nanswer two questions. On theone hand, can deep directed models be success-fully\ntrained without intractable posterior infer-ence and difficult optimization of\nvery deep neu-ral networks in inference and generative mod-els? These are\nunavoidable when recent suc-cessful directed model like VAE (Kingma &Welling,\n2014) is trained on complex dataset likereal images. On the other hand, can\nDAEs getclean samples of data distribution from heavilycorrupted samples which\ncan be considered oftractable prior distribution far from data mani-fold?\nso-called global denoising scheme.Our results show positive responses of\nthesequestions and this work can provide fairly simpleframework for generative\nmodels of very com-plex dataset.\n",
        "published": "2015-11-23T06:32:57Z",
        "pdf_link": "http://arxiv.org/pdf/1511.07118v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.07289v5",
        "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units\n  (ELUs)",
        "summary": "  We introduce the \"exponential linear unit\" (ELU) which speeds up learning in\ndeep neural networks and leads to higher classification accuracies. Like\nrectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs\n(PReLUs), ELUs alleviate the vanishing gradient problem via the identity for\npositive values. However, ELUs have improved learning characteristics compared\nto the units with other activation functions. In contrast to ReLUs, ELUs have\nnegative values which allows them to push mean unit activations closer to zero\nlike batch normalization but with lower computational complexity. Mean shifts\ntoward zero speed up learning by bringing the normal gradient closer to the\nunit natural gradient because of a reduced bias shift effect. While LReLUs and\nPReLUs have negative values, too, they do not ensure a noise-robust\ndeactivation state. ELUs saturate to a negative value with smaller inputs and\nthereby decrease the forward propagated variation and information. Therefore,\nELUs code the degree of presence of particular phenomena in the input, while\nthey do not quantitatively model the degree of their absence. In experiments,\nELUs lead not only to faster learning, but also to significantly better\ngeneralization performance than ReLUs and LReLUs on networks with more than 5\nlayers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with\nbatch normalization while batch normalization does not improve ELU networks.\nELU networks are among the top 10 reported CIFAR-10 results and yield the best\npublished result on CIFAR-100, without resorting to multi-view evaluation or\nmodel averaging. On ImageNet, ELU networks considerably speed up learning\ncompared to a ReLU network with the same architecture, obtaining less than 10%\nclassification error for a single crop, single model network.\n",
        "published": "2015-11-23T15:58:05Z",
        "pdf_link": "http://arxiv.org/pdf/1511.07289v5"
    },
    {
        "id": "http://arxiv.org/abs/1511.07340v1",
        "title": "Modular Autoencoders for Ensemble Feature Extraction",
        "summary": "  We introduce the concept of a Modular Autoencoder (MAE), capable of learning\na set of diverse but complementary representations from unlabelled data, that\ncan later be used for supervised tasks. The learning of the representations is\ncontrolled by a trade off parameter, and we show on six benchmark datasets the\noptimum lies between two extremes: a set of smaller, independent autoencoders\neach with low capacity, versus a single monolithic encoding, outperforming an\nappropriate baseline. In the present paper we explore the special case of\nlinear MAE, and derive an SVD-based algorithm which converges several orders of\nmagnitude faster than gradient descent.\n",
        "published": "2015-11-23T17:51:18Z",
        "pdf_link": "http://arxiv.org/pdf/1511.07340v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.07471v3",
        "title": "Weak Convergence Properties of Constrained Emphatic Temporal-difference\n  Learning with Constant and Slowly Diminishing Stepsize",
        "summary": "  We consider the emphatic temporal-difference (TD) algorithm, ETD($\\lambda$),\nfor learning the value functions of stationary policies in a discounted, finite\nstate and action Markov decision process. The ETD($\\lambda$) algorithm was\nrecently proposed by Sutton, Mahmood, and White to solve a long-standing\ndivergence problem of the standard TD algorithm when it is applied to\noff-policy training, where data from an exploratory policy are used to evaluate\nother policies of interest. The almost sure convergence of ETD($\\lambda$) has\nbeen proved in our recent work under general off-policy training conditions,\nbut for a narrow range of diminishing stepsize. In this paper we present\nconvergence results for constrained versions of ETD($\\lambda$) with constant\nstepsize and with diminishing stepsize from a broad range. Our results\ncharacterize the asymptotic behavior of the trajectory of iterates produced by\nthose algorithms, and are derived by combining key properties of ETD($\\lambda$)\nwith powerful convergence theorems from the weak convergence methods in\nstochastic approximation theory. For the case of constant stepsize, in addition\nto analyzing the behavior of the algorithms in the limit as the stepsize\nparameter approaches zero, we also analyze their behavior for a fixed stepsize\nand bound the deviations of their averaged iterates from the desired solution.\nThese results are obtained by exploiting the weak Feller property of the Markov\nchains associated with the algorithms, and by using ergodic theorems for weak\nFeller Markov chains, in conjunction with the convergence results we get from\nthe weak convergence methods. Besides ETD($\\lambda$), our analysis also applies\nto the off-policy TD($\\lambda$) algorithm, when the divergence issue is avoided\nby setting $\\lambda$ sufficiently large.\n",
        "published": "2015-11-23T21:29:43Z",
        "pdf_link": "http://arxiv.org/pdf/1511.07471v3"
    },
    {
        "id": "http://arxiv.org/abs/1511.07938v4",
        "title": "Temporal Convolutional Neural Networks for Diagnosis from Lab Tests",
        "summary": "  Early diagnosis of treatable diseases is essential for improving healthcare,\nand many diseases' onsets are predictable from annual lab tests and their\ntemporal trends. We introduce a multi-resolution convolutional neural network\nfor early detection of multiple diseases from irregularly measured sparse lab\nvalues. Our novel architecture takes as input both an imputed version of the\ndata and a binary observation matrix. For imputing the temporal sparse\nobservations, we develop a flexible, fast to train method for differentiable\nmultivariate kernel regression. Our experiments on data from 298K individuals\nover 8 years, 18 common lab measurements, and 171 diseases show that the\ntemporal signatures learned via convolution are significantly more predictive\nthan baselines commonly used for early disease diagnosis.\n",
        "published": "2015-11-25T02:56:33Z",
        "pdf_link": "http://arxiv.org/pdf/1511.07938v4"
    },
    {
        "id": "http://arxiv.org/abs/1511.07948v1",
        "title": "Learning Halfspaces and Neural Networks with Random Initialization",
        "summary": "  We study non-convex empirical risk minimization for learning halfspaces and\nneural networks. For loss functions that are $L$-Lipschitz continuous, we\npresent algorithms to learn halfspaces and multi-layer neural networks that\nachieve arbitrarily small excess risk $\\epsilon>0$. The time complexity is\npolynomial in the input dimension $d$ and the sample size $n$, but exponential\nin the quantity $(L/\\epsilon^2)\\log(L/\\epsilon)$. These algorithms run multiple\nrounds of random initialization followed by arbitrary optimization steps. We\nfurther show that if the data is separable by some neural network with constant\nmargin $\\gamma>0$, then there is a polynomial-time algorithm for learning a\nneural network that separates the training data with margin $\\Omega(\\gamma)$.\nAs a consequence, the algorithm achieves arbitrary generalization error\n$\\epsilon>0$ with ${\\rm poly}(d,1/\\epsilon)$ sample and time complexity. We\nestablish the same learnability result when the labels are randomly flipped\nwith probability $\\eta<1/2$.\n",
        "published": "2015-11-25T04:41:20Z",
        "pdf_link": "http://arxiv.org/pdf/1511.07948v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.08842v2",
        "title": "Efficient Sum of Outer Products Dictionary Learning (SOUP-DIL) - The\n  $\\ell_0$ Method",
        "summary": "  The sparsity of natural signals and images in a transform domain or\ndictionary has been extensively exploited in several applications such as\ncompression, denoising and inverse problems. More recently, data-driven\nadaptation of synthesis dictionaries has shown promise in many applications\ncompared to fixed or analytical dictionary models. However, dictionary learning\nproblems are typically non-convex and NP-hard, and the usual alternating\nminimization approaches for these problems are often computationally expensive,\nwith the computations dominated by the NP-hard synthesis sparse coding step. In\nthis work, we investigate an efficient method for $\\ell_{0}$ \"norm\"-based\ndictionary learning by first approximating the training data set with a sum of\nsparse rank-one matrices and then using a block coordinate descent approach to\nestimate the unknowns. The proposed block coordinate descent algorithm involves\nefficient closed-form solutions. In particular, the sparse coding step involves\na simple form of thresholding. We provide a convergence analysis for the\nproposed block coordinate descent approach. Our numerical experiments show the\npromising performance and significant speed-ups provided by our method over the\nclassical K-SVD scheme in sparse signal representation and image denoising.\n",
        "published": "2015-11-27T22:32:43Z",
        "pdf_link": "http://arxiv.org/pdf/1511.08842v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.08987v1",
        "title": "How do the naive Bayes classifier and the Support Vector Machine compare\n  in their ability to forecast the Stock Exchange of Thailand?",
        "summary": "  This essay investigates the question of how the naive Bayes classifier and\nthe support vector machine compare in their ability to forecast the Stock\nExchange of Thailand. The theory behind the SVM and the naive Bayes classifier\nis explored. The algorithms are trained using data from the month of January\n2010, extracted from the MarketWatch.com website. Input features are selected\nbased on previous studies of the SET100 Index. The Weka 3 software is used to\ncreate models from the labeled training data. Mean squared error and proportion\nof correctly classified instances, and a number of other error measurements are\nthe used to compare the two algorithms. This essay shows that these two\nalgorithms are currently not advanced enough to accurately model the stock\nexchange. Nevertheless, the naive Bayes is better than the support vector\nmachine at predicting the Stock Exchange of Thailand.\n",
        "published": "2015-11-29T09:57:42Z",
        "pdf_link": "http://arxiv.org/pdf/1511.08987v1"
    },
    {
        "id": "http://arxiv.org/abs/1511.09058v2",
        "title": "Multiple-Instance Learning: Radon-Nikodym Approach to Distribution\n  Regression Problem",
        "summary": "  For distribution regression problem, where a bag of $x$--observations is\nmapped to a single $y$ value, a one--step solution is proposed. The problem of\nrandom distribution to random value is transformed to random vector to random\nvalue by taking distribution moments of $x$ observations in a bag as random\nvector. Then Radon--Nikodym or least squares theory can be applied, what give\n$y(x)$ estimator. The probability distribution of $y$ is also obtained, what\nrequires solving generalized eigenvalues problem, matrix spectrum (not\ndepending on $x$) give possible $y$ outcomes and depending on $x$ probabilities\nof outcomes can be obtained by projecting the distribution with fixed $x$ value\n(delta--function) to corresponding eigenvector. A library providing numerically\nstable polynomial basis for these calculations is available, what make the\nproposed approach practical.\n",
        "published": "2015-11-29T18:41:02Z",
        "pdf_link": "http://arxiv.org/pdf/1511.09058v2"
    },
    {
        "id": "http://arxiv.org/abs/1511.09263v4",
        "title": "Scalable and Accurate Online Feature Selection for Big Data",
        "summary": "  Feature selection is important in many big data applications. Two critical\nchallenges closely associate with big data. Firstly, in many big data\napplications, the dimensionality is extremely high, in millions, and keeps\ngrowing. Secondly, big data applications call for highly scalable feature\nselection algorithms in an online manner such that each feature can be\nprocessed in a sequential scan. We present SAOLA, a Scalable and Accurate\nOnLine Approach for feature selection in this paper. With a theoretical\nanalysis on bounds of the pairwise correlations between features, SAOLA employs\nnovel pairwise comparison techniques and maintain a parsimonious model over\ntime in an online manner. Furthermore, to deal with upcoming features that\narrive by groups, we extend the SAOLA algorithm, and then propose a new\ngroup-SAOLA algorithm for online group feature selection. The group-SAOLA\nalgorithm can online maintain a set of feature groups that is sparse at the\nlevels of both groups and individual features simultaneously. An empirical\nstudy using a series of benchmark real data sets shows that our two algorithms,\nSAOLA and group-SAOLA, are scalable on data sets of extremely high\ndimensionality, and have superior performance over the state-of-the-art feature\nselection methods.\n",
        "published": "2015-11-30T12:11:43Z",
        "pdf_link": "http://arxiv.org/pdf/1511.09263v4"
    },
    {
        "id": "http://arxiv.org/abs/1512.00408v1",
        "title": "Reinforcement Learning Applied to an Electric Water Heater: From Theory\n  to Practice",
        "summary": "  Electric water heaters have the ability to store energy in their water buffer\nwithout impacting the comfort of the end user. This feature makes them a prime\ncandidate for residential demand response. However, the stochastic and\nnonlinear dynamics of electric water heaters, makes it challenging to harness\ntheir flexibility. Driven by this challenge, this paper formulates the\nunderlying sequential decision-making problem as a Markov decision process and\nuses techniques from reinforcement learning. Specifically, we apply an\nauto-encoder network to find a compact feature representation of the sensor\nmeasurements, which helps to mitigate the curse of dimensionality. A wellknown\nbatch reinforcement learning technique, fitted Q-iteration, is used to find a\ncontrol policy, given this feature representation. In a simulation-based\nexperiment using an electric water heater with 50 temperature sensors, the\nproposed method was able to achieve good policies much faster than when using\nthe full state information. In a lab experiment, we apply fitted Q-iteration to\nan electric water heater with eight temperature sensors. Further reducing the\nstate vector did not improve the results of fitted Q-iteration. The results of\nthe lab experiment, spanning 40 days, indicate that compared to a thermostat\ncontroller, the presented approach was able to reduce the total cost of energy\nconsumption of the electric water heater by 15%.\n",
        "published": "2015-11-29T18:03:13Z",
        "pdf_link": "http://arxiv.org/pdf/1512.00408v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.00659v1",
        "title": "Centroid Based Binary Tree Structured SVM for Multi Classification",
        "summary": "  Support Vector Machines (SVMs) were primarily designed for 2-class\nclassification. But they have been extended for N-class classification also\nbased on the requirement of multiclasses in the practical applications.\nAlthough N-class classification using SVM has considerable research attention,\ngetting minimum number of classifiers at the time of training and testing is\nstill a continuing research. We propose a new algorithm CBTS-SVM (Centroid\nbased Binary Tree Structured SVM) which addresses this issue. In this we build\na binary tree of SVM models based on the similarity of the class labels by\nfinding their distance from the corresponding centroids at the root level. The\nexperimental results demonstrates the comparable accuracy for CBTS with OVO\nwith reasonable gamma and cost values. On the other hand when CBTS is compared\nwith OVA, it gives the better accuracy with reduced training time and testing\ntime. Furthermore CBTS is also scalable as it is able to handle the large data\nsets.\n",
        "published": "2015-12-02T11:48:38Z",
        "pdf_link": "http://arxiv.org/pdf/1512.00659v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.01563v2",
        "title": "State of the Art Control of Atari Games Using Shallow Reinforcement\n  Learning",
        "summary": "  The recently introduced Deep Q-Networks (DQN) algorithm has gained attention\nas one of the first successful combinations of deep neural networks and\nreinforcement learning. Its promise was demonstrated in the Arcade Learning\nEnvironment (ALE), a challenging framework composed of dozens of Atari 2600\ngames used to evaluate general competency in AI. It achieved dramatically\nbetter results than earlier approaches, showing that its ability to learn good\nrepresentations is quite robust and general. This paper attempts to understand\nthe principles that underlie DQN's impressive performance and to better\ncontextualize its success. We systematically evaluate the importance of key\nrepresentational biases encoded by DQN's network by proposing simple linear\nrepresentations that make use of these concepts. Incorporating these\ncharacteristics, we obtain a computationally practical feature set that\nachieves competitive performance to DQN in the ALE. Besides offering insight\ninto the strengths and weaknesses of DQN, we provide a generic representation\nfor the ALE, significantly reducing the burden of learning a representation for\neach game. Moreover, we also provide a simple, reproducible benchmark for the\nsake of comparison to future work in the ALE.\n",
        "published": "2015-12-04T21:06:04Z",
        "pdf_link": "http://arxiv.org/pdf/1512.01563v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.01693v1",
        "title": "Deep Attention Recurrent Q-Network",
        "summary": "  A deep learning approach to reinforcement learning led to a general learner\nable to train on visual input to play a variety of arcade games at the human\nand superhuman levels. Its creators at the Google DeepMind's team called the\napproach: Deep Q-Network (DQN). We present an extension of DQN by \"soft\" and\n\"hard\" attention mechanisms. Tests of the proposed Deep Attention Recurrent\nQ-Network (DARQN) algorithm on multiple Atari 2600 games show level of\nperformance superior to that of DQN. Moreover, built-in attention mechanisms\nallow a direct online monitoring of the training process by highlighting the\nregions of the game screen the agent is focusing on when making decisions.\n",
        "published": "2015-12-05T18:35:40Z",
        "pdf_link": "http://arxiv.org/pdf/1512.01693v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.01728v1",
        "title": "Similarity Learning via Adaptive Regression and Its Application to Image\n  Retrieval",
        "summary": "  We study the problem of similarity learning and its application to image\nretrieval with large-scale data. The similarity between pairs of images can be\nmeasured by the distances between their high dimensional representations, and\nthe problem of learning the appropriate similarity is often addressed by\ndistance metric learning. However, distance metric learning requires the\nlearned metric to be a PSD matrix, which is computational expensive and not\nnecessary for retrieval ranking problem. On the other hand, the bilinear model\nis shown to be more flexible for large-scale image retrieval task, hence, we\nadopt it to learn a matrix for estimating pairwise similarities under the\nregression framework. By adaptively updating the target matrix in regression,\nwe can mimic the hinge loss, which is more appropriate for similarity learning\nproblem. Although the regression problem can have the closed-form solution, the\ncomputational cost can be very expensive. The computational challenges come\nfrom two aspects: the number of images can be very large and image features\nhave high dimensionality. We address the first challenge by compressing the\ndata by a randomized algorithm with the theoretical guarantee. For the high\ndimensional issue, we address it by taking low rank assumption and applying\nalternating method to obtain the partial matrix, which has a global optimal\nsolution. Empirical studies on real world image datasets (i.e., Caltech and\nImageNet) demonstrate the effectiveness and efficiency of the proposed method.\n",
        "published": "2015-12-06T02:56:32Z",
        "pdf_link": "http://arxiv.org/pdf/1512.01728v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.01914v1",
        "title": "Rademacher Complexity of the Restricted Boltzmann Machine",
        "summary": "  Boltzmann machine, as a fundamental construction block of deep belief network\nand deep Boltzmann machines, is widely used in deep learning community and\ngreat success has been achieved. However, theoretical understanding of many\naspects of it is still far from clear. In this paper, we studied the Rademacher\ncomplexity of both the asymptotic restricted Boltzmann machine and the\npractical implementation with single-step contrastive divergence (CD-1)\nprocedure. Our results disclose the fact that practical implementation training\nprocedure indeed increased the Rademacher complexity of restricted Boltzmann\nmachines. A further research direction might be the investigation of the VC\ndimension of a compositional function used in the CD-1 procedure.\n",
        "published": "2015-12-07T05:20:30Z",
        "pdf_link": "http://arxiv.org/pdf/1512.01914v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.02033v2",
        "title": "Risk Minimization in Structured Prediction using Orbit Loss",
        "summary": "  We introduce a new surrogate loss function called orbit loss in the\nstructured prediction framework, which has good theoretical and practical\nadvantages. While the orbit loss is not convex, it has a simple analytical\ngradient and a simple perceptron-like learning rule. We analyze the new loss\ntheoretically and state a PAC-Bayesian generalization bound. We also prove that\nthe new loss is consistent in the strong sense; namely, the risk achieved by\nthe set of the trained parameters approaches the infimum risk achievable by any\nlinear decoder over the given features. Methods that are aimed at risk\nminimization, such as the structured ramp loss, the structured probit loss and\nthe direct loss minimization require at least two inference operations per\ntraining iteration. In this sense, the orbit loss is more efficient as it\nrequires only one inference operation per training iteration, while yields\nsimilar performance. We conclude the paper with an empirical comparison of the\nproposed loss function to the structured hinge loss, the structured ramp loss,\nthe structured probit loss and the direct loss minimization method on several\nbenchmark datasets and tasks.\n",
        "published": "2015-12-07T13:30:27Z",
        "pdf_link": "http://arxiv.org/pdf/1512.02033v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.02181v1",
        "title": "The Teaching Dimension of Linear Learners",
        "summary": "  Teaching dimension is a learning theoretic quantity that specifies the\nminimum training set size to teach a target model to a learner. Previous\nstudies on teaching dimension focused on version-space learners which maintain\nall hypotheses consistent with the training data, and cannot be applied to\nmodern machine learners which select a specific hypothesis via optimization.\nThis paper presents the first known teaching dimension for ridge regression,\nsupport vector machines, and logistic regression. We also exhibit optimal\ntraining sets that match these teaching dimensions. Our approach generalizes to\nother linear learners.\n",
        "published": "2015-12-07T19:24:55Z",
        "pdf_link": "http://arxiv.org/pdf/1512.02181v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.02393v2",
        "title": "Online Crowdsourcing",
        "summary": "  With the success of modern internet based platform, such as Amazon Mechanical\nTurk, it is now normal to collect a large number of hand labeled samples from\nnon-experts. The Dawid- Skene algorithm, which is based on Expectation-\nMaximization update, has been widely used for inferring the true labels from\nnoisy crowdsourced labels. However, Dawid-Skene scheme requires all the data to\nperform each EM iteration, and can be infeasible for streaming data or large\nscale data. In this paper, we provide an online version of Dawid- Skene\nalgorithm that only requires one data frame for each iteration. Further, we\nprove that under mild conditions, the online Dawid-Skene scheme with projection\nconverges to a stationary point of the marginal log-likelihood of the observed\ndata. Our experiments demonstrate that the online Dawid- Skene scheme achieves\nstate of the art performance comparing with other methods based on the Dawid-\nSkene scheme.\n",
        "published": "2015-12-08T10:35:29Z",
        "pdf_link": "http://arxiv.org/pdf/1512.02393v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.02394v2",
        "title": "Online Gradient Descent in Function Space",
        "summary": "  In many problems in machine learning and operations research, we need to\noptimize a function whose input is a random variable or a probability density\nfunction, i.e. to solve optimization problems in an infinite dimensional space.\nOn the other hand, online learning has the advantage of dealing with streaming\nexamples, and better model a changing environ- ment. In this paper, we extend\nthe celebrated online gradient descent algorithm to Hilbert spaces (function\nspaces), and analyze the convergence guarantee of the algorithm. Finally, we\ndemonstrate that our algorithms can be useful in several important problems.\n",
        "published": "2015-12-08T10:38:19Z",
        "pdf_link": "http://arxiv.org/pdf/1512.02394v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.03201v1",
        "title": "Gated networks: an inventory",
        "summary": "  Gated networks are networks that contain gating connections, in which the\noutputs of at least two neurons are multiplied. Initially, gated networks were\nused to learn relationships between two input sources, such as pixels from two\nimages. More recently, they have been applied to learning activity recognition\nor multi-modal representations. The aims of this paper are threefold: 1) to\nexplain the basic computations in gated networks to the non-expert, while\nadopting a standpoint that insists on their symmetric nature. 2) to serve as a\nquick reference guide to the recent literature, by providing an inventory of\napplications of these networks, as well as recent extensions to the basic\narchitecture. 3) to suggest future research directions and applications.\n",
        "published": "2015-12-10T10:31:13Z",
        "pdf_link": "http://arxiv.org/pdf/1512.03201v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.03953v1",
        "title": "Active Distance-Based Clustering using K-medoids",
        "summary": "  k-medoids algorithm is a partitional, centroid-based clustering algorithm\nwhich uses pairwise distances of data points and tries to directly decompose\nthe dataset with $n$ points into a set of $k$ disjoint clusters. However,\nk-medoids itself requires all distances between data points that are not so\neasy to get in many applications. In this paper, we introduce a new method\nwhich requires only a small proportion of the whole set of distances and makes\nan effort to estimate an upper-bound for unknown distances using the inquired\nones. This algorithm makes use of the triangle inequality to calculate an\nupper-bound estimation of the unknown distances. Our method is built upon a\nrecursive approach to cluster objects and to choose some points actively from\neach bunch of data and acquire the distances between these prominent points\nfrom oracle. Experimental results show that the proposed method using only a\nsmall subset of the distances can find proper clustering on many real-world and\nsynthetic datasets.\n",
        "published": "2015-12-12T19:33:52Z",
        "pdf_link": "http://arxiv.org/pdf/1512.03953v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.04011v2",
        "title": "L1-Regularized Distributed Optimization: A Communication-Efficient\n  Primal-Dual Framework",
        "summary": "  Despite the importance of sparsity in many large-scale applications, there\nare few methods for distributed optimization of sparsity-inducing objectives.\nIn this paper, we present a communication-efficient framework for\nL1-regularized optimization in the distributed environment. By viewing\nclassical objectives in a more general primal-dual setting, we develop a new\nclass of methods that can be efficiently distributed and applied to common\nsparsity-inducing models, such as Lasso, sparse logistic regression, and\nelastic net-regularized problems. We provide theoretical convergence guarantees\nfor our framework, and demonstrate its efficiency and flexibility with a\nthorough experimental comparison on Amazon EC2. Our proposed framework yields\nspeedups of up to 50x as compared to current state-of-the-art methods for\ndistributed L1-regularized optimization.\n",
        "published": "2015-12-13T06:49:00Z",
        "pdf_link": "http://arxiv.org/pdf/1512.04011v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.04392v2",
        "title": "Automatic Incident Classification for Big Traffic Data by Adaptive\n  Boosting SVM",
        "summary": "  Modern cities experience heavy traffic flows and congestions regularly across\nspace and time. Monitoring traffic situations becomes an important challenge\nfor the Traffic Control and Surveillance Systems (TCSS). In advanced TCSS, it\nis helpful to automatically detect and classify different traffic incidents\nsuch as severity of congestion, abnormal driving pattern, abrupt or illegal\nstop on road, etc. Although most TCSS are equipped with basic incident\ndetection algorithms, they are however crude to be really useful as an\nautomated tool for further classification. In literature, there is a lack of\nresearch for Automated Incident Classification (AIC). Therefore, a novel AIC\nmethod is proposed in this paper to tackle such challenges. In the proposed\nmethod, traffic signals are firstly extracted from captured videos and\nconverted as spatial-temporal (ST) signals. Based on the characteristics of the\nST signals, a set of realistic simulation data are generated to construct an\nextended big traffic database to cover a variety of traffic situations. Next, a\nMean-Shift filter is introduced to suppress the effect of noise and extract\nsignificant features from the ST signals. The extracted features are then\nassociated with various types of traffic data: one normal type (inliers) and\nmultiple abnormal types (outliers). For the classification, an adaptive\nboosting classifier is trained to detect outliers in traffic data\nautomatically. Further, a Support Vector Machine (SVM) based method is adopted\nto train the model for identifying the categories of outliers. In short, this\nhybrid approach is called an Adaptive Boosting Support Vector Machines (AB-SVM)\nmethod. Experimental results show that the proposed AB-SVM method achieves a\nsatisfied result with more than 92% classification accuracy on average.\n",
        "published": "2015-12-14T16:23:59Z",
        "pdf_link": "http://arxiv.org/pdf/1512.04392v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.04455v1",
        "title": "Memory-based control with recurrent neural networks",
        "summary": "  Partially observed control problems are a challenging aspect of reinforcement\nlearning. We extend two related, model-free algorithms for continuous control\n-- deterministic policy gradient and stochastic value gradient -- to solve\npartially observed domains using recurrent neural networks trained with\nbackpropagation through time.\n  We demonstrate that this approach, coupled with long-short term memory is\nable to solve a variety of physical control problems exhibiting an assortment\nof memory requirements. These include the short-term integration of information\nfrom noisy sensors and the identification of system parameters, as well as\nlong-term memory problems that require preserving information over many time\nsteps. We also demonstrate success on a combined exploration and memory problem\nin the form of a simplified version of the well-known Morris water maze task.\nFinally, we show that our approach can deal with high-dimensional observations\nby learning directly from pixels.\n  We find that recurrent deterministic and stochastic policies are able to\nlearn similarly good solutions to these tasks, including the water maze where\nthe agent must learn effective search strategies.\n",
        "published": "2015-12-14T18:44:48Z",
        "pdf_link": "http://arxiv.org/pdf/1512.04455v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.04466v1",
        "title": "Semisupervised Autoencoder for Sentiment Analysis",
        "summary": "  In this paper, we investigate the usage of autoencoders in modeling textual\ndata. Traditional autoencoders suffer from at least two aspects: scalability\nwith the high dimensionality of vocabulary size and dealing with\ntask-irrelevant words. We address this problem by introducing supervision via\nthe loss function of autoencoders. In particular, we first train a linear\nclassifier on the labeled data, then define a loss for the autoencoder with the\nweights learned from the linear classifier. To reduce the bias brought by one\nsingle classifier, we define a posterior probability distribution on the\nweights of the classifier, and derive the marginalized loss of the autoencoder\nwith Laplace approximation. We show that our choice of loss function can be\nrationalized from the perspective of Bregman Divergence, which justifies the\nsoundness of our model. We evaluate the effectiveness of our model on six\nsentiment analysis datasets, and show that our model significantly outperforms\nall the competing methods with respect to classification accuracy. We also show\nthat our model is able to take advantage of unlabeled dataset and get improved\nperformance. We further show that our model successfully learns highly\ndiscriminative feature maps, which explains its superior performance.\n",
        "published": "2015-12-14T19:09:53Z",
        "pdf_link": "http://arxiv.org/pdf/1512.04466v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.04469v1",
        "title": "Über die Klassifizierung von Knoten in dynamischen Netzwerken mit\n  Inhalt",
        "summary": "  This paper explains the DYCOS-Algorithm as it was introduced in by Aggarwal\nand Li in 2011. It operates on graphs whichs nodes are partially labeled and\nautomatically adds missing labels to nodes. To do so, the DYCOS algorithm makes\nuse of the structure of the graph as well as content which is assigned to the\nnode. Aggarwal and Li measured in an experimental analysis that DYCOS adds the\nmissing labels to a Graph with 19396 nodes of which 14814 are labeled and\nanother Graph with 806635 nodes of which 18999 are labeld on one core of an\nIntel Xeon 2.5 GHz CPU with 32 G RAM within less than a minute. Additionally,\nextensions of the DYCOS algorithm are proposed.\n  -----\n  In dieser Arbeit wird der DYCOS-Algorithmus, wie er 2011 von Aggarwal und Li\nvorgestellt wurde, erkl\\\"art. Er arbeitet auf Graphen, deren Knoten teilweise\nmit Beschriftungen versehen sind und erg\\\"anzt automatisch Beschriftungen f\\\"ur\nKnoten, die bisher noch keine Beschriftung haben. Dieser Vorgang wird\n\"Klassifizierung\" genannt. Dazu verwendet er die Struktur des Graphen sowie\ntextuelle Informationen, die den Knoten zugeordnet sind. Die von Aggarwal und\nLi beschriebene experimentelle Analyse ergab, dass er auch auf dynamischen\nGraphen mit 19396 bzw. 806635 Knoten, von denen nur 14814 bzw. 18999\nbeschriftet waren, innerhalb von weniger als einer Minute auf einem Kern einer\nIntel Xeon 2.5 GHz CPU mit 32 G RAM ausgef\\\"uhrt werden kann. Zus\\\"atzlich wird\ndie Ver\\\"offentlichung von Aggarwal und Li kritisch er\\\"ortert und und es\nwerden m\\\"ogliche Erweiterungen des DYCOS-Algorithmus vorgeschlagen.\n",
        "published": "2015-11-23T13:28:11Z",
        "pdf_link": "http://arxiv.org/pdf/1512.04469v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.04483v1",
        "title": "Dropout Training of Matrix Factorization and Autoencoder for Link\n  Prediction in Sparse Graphs",
        "summary": "  Matrix factorization (MF) and Autoencoder (AE) are among the most successful\napproaches of unsupervised learning. While MF based models have been\nextensively exploited in the graph modeling and link prediction literature, the\nAE family has not gained much attention. In this paper we investigate both MF\nand AE's application to the link prediction problem in sparse graphs. We show\nthe connection between AE and MF from the perspective of multiview learning,\nand further propose MF+AE: a model training MF and AE jointly with shared\nparameters. We apply dropout to training both the MF and AE parts, and show\nthat it can significantly prevent overfitting by acting as an adaptive\nregularization. We conduct experiments on six real world sparse graph datasets,\nand show that MF+AE consistently outperforms the competing methods, especially\non datasets that demonstrate strong non-cohesive structures.\n",
        "published": "2015-12-14T19:38:14Z",
        "pdf_link": "http://arxiv.org/pdf/1512.04483v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.04960v2",
        "title": "A Light Touch for Heavily Constrained SGD",
        "summary": "  Minimizing empirical risk subject to a set of constraints can be a useful\nstrategy for learning restricted classes of functions, such as monotonic\nfunctions, submodular functions, classifiers that guarantee a certain class\nlabel for some subset of examples, etc. However, these restrictions may result\nin a very large number of constraints. Projected stochastic gradient descent\n(SGD) is often the default choice for large-scale optimization in machine\nlearning, but requires a projection after each update. For heavily-constrained\nobjectives, we propose an efficient extension of SGD that stays close to the\nfeasible region while only applying constraints probabilistically at each\niteration. Theoretical analysis shows a compelling trade-off between\nper-iteration work and the number of iterations needed on problems with a large\nnumber of constraints.\n",
        "published": "2015-12-15T21:07:02Z",
        "pdf_link": "http://arxiv.org/pdf/1512.04960v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.05244v2",
        "title": "Learning Games and Rademacher Observations Losses",
        "summary": "  It has recently been shown that supervised learning with the popular logistic\nloss is equivalent to optimizing the exponential loss over sufficient\nstatistics about the class: Rademacher observations (rados). We first show that\nthis unexpected equivalence can actually be generalized to other example / rado\nlosses, with necessary and sufficient conditions for the equivalence,\nexemplified on four losses that bear popular names in various fields:\nexponential (boosting), mean-variance (finance), Linear Hinge (on-line\nlearning), ReLU (deep learning), and unhinged (statistics). Second, we show\nthat the generalization unveils a surprising new connection to regularized\nlearning, and in particular a sufficient condition under which regularizing the\nloss over examples is equivalent to regularizing the rados (with Minkowski\nsums) in the equivalent rado loss. This brings simple and powerful rado-based\nlearning algorithms for sparsity-controlling regularization, that we exemplify\non a boosting algorithm for the regularized exponential rado-loss, which\nformally boosts over four types of regularization, including the popular ridge\nand lasso, and the recently coined slope --- we obtain the first proven\nboosting algorithm for this last regularization. Through our first contribution\non the equivalence of rado and example-based losses, Omega-R.AdaBoost~appears\nto be an efficient proxy to boost the regularized logistic loss over examples\nusing whichever of the four regularizers. Experiments display that\nregularization consistently improves performances of rado-based learning, and\nmay challenge or beat the state of the art of example-based learning even when\nlearning over small sets of rados. Finally, we connect regularization to\ndifferential privacy, and display how tiny budgets can be afforded on big\ndomains while beating (protected) example-based learning.\n",
        "published": "2015-12-16T16:56:02Z",
        "pdf_link": "http://arxiv.org/pdf/1512.05244v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.05808v1",
        "title": "Successive Ray Refinement and Its Application to Coordinate Descent for\n  LASSO",
        "summary": "  Coordinate descent is one of the most popular approaches for solving Lasso\nand its extensions due to its simplicity and efficiency. When applying\ncoordinate descent to solving Lasso, we update one coordinate at a time while\nfixing the remaining coordinates. Such an update, which is usually easy to\ncompute, greedily decreases the objective function value. In this paper, we aim\nto improve its computational efficiency by reducing the number of coordinate\ndescent iterations. To this end, we propose a novel technique called Successive\nRay Refinement (SRR). SRR makes use of the following ray continuation property\non the successive iterations: for a particular coordinate, the value obtained\nin the next iteration almost always lies on a ray that starts at its previous\niteration and passes through the current iteration. Motivated by this\nray-continuation property, we propose that coordinate descent be performed not\ndirectly on the previous iteration but on a refined search point that has the\nfollowing properties: on one hand, it lies on a ray that starts at a history\nsolution and passes through the previous iteration, and on the other hand, it\nachieves the minimum objective function value among all the points on the ray.\nWe propose two schemes for defining the search point and show that the refined\nsearch point can be efficiently obtained. Empirical results for real and\nsynthetic data sets show that the proposed SRR can significantly reduce the\nnumber of coordinate descent iterations, especially for small Lasso\nregularization parameters.\n",
        "published": "2015-12-17T21:47:02Z",
        "pdf_link": "http://arxiv.org/pdf/1512.05808v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.06173v1",
        "title": "Discriminative Subnetworks with Regularized Spectral Learning for\n  Global-state Network Data",
        "summary": "  Data mining practitioners are facing challenges from data with network\nstructure. In this paper, we address a specific class of global-state networks\nwhich comprises of a set of network instances sharing a similar structure yet\nhaving different values at local nodes. Each instance is associated with a\nglobal state which indicates the occurrence of an event. The objective is to\nuncover a small set of discriminative subnetworks that can optimally classify\nglobal network values. Unlike most existing studies which explore an\nexponential subnetwork space, we address this difficult problem by adopting a\nspace transformation approach. Specifically, we present an algorithm that\noptimizes a constrained dual-objective function to learn a low-dimensional\nsubspace that is capable of discriminating networks labelled by different\nglobal states, while reconciling with common network topology sharing across\ninstances. Our algorithm takes an appealing approach from spectral graph\nlearning and we show that the globally optimum solution can be achieved via\nmatrix eigen-decomposition.\n",
        "published": "2015-12-19T01:20:02Z",
        "pdf_link": "http://arxiv.org/pdf/1512.06173v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.06430v1",
        "title": "Behavioral Modeling for Churn Prediction: Early Indicators and Accurate\n  Predictors of Custom Defection and Loyalty",
        "summary": "  Churn prediction, or the task of identifying customers who are likely to\ndiscontinue use of a service, is an important and lucrative concern of firms in\nmany different industries. As these firms collect an increasing amount of\nlarge-scale, heterogeneous data on the characteristics and behaviors of\ncustomers, new methods become possible for predicting churn. In this paper, we\npresent a unified analytic framework for detecting the early warning signs of\nchurn, and assigning a \"Churn Score\" to each customer that indicates the\nlikelihood that the particular individual will churn within a predefined amount\nof time. This framework employs a brute force approach to feature engineering,\nthen winnows the set of relevant attributes via feature selection, before\nfeeding the final feature-set into a suite of supervised learning algorithms.\nUsing several terabytes of data from a large mobile phone network, our method\nidentifies several intuitive - and a few surprising - early warning signs of\nchurn, and our best model predicts whether a subscriber will churn with 89.4%\naccuracy.\n",
        "published": "2015-12-20T20:45:55Z",
        "pdf_link": "http://arxiv.org/pdf/1512.06430v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.06900v1",
        "title": "Predicting the Co-Evolution of Event and Knowledge Graphs",
        "summary": "  Embedding learning, a.k.a. representation learning, has been shown to be able\nto model large-scale semantic knowledge graphs. A key concept is a mapping of\nthe knowledge graph to a tensor representation whose entries are predicted by\nmodels using latent representations of generalized entities. Knowledge graphs\nare typically treated as static: A knowledge graph grows more links when more\nfacts become available but the ground truth values associated with links is\nconsidered time invariant. In this paper we address the issue of knowledge\ngraphs where triple states depend on time. We assume that changes in the\nknowledge graph always arrive in form of events, in the sense that the events\nare the gateway to the knowledge graph. We train an event prediction model\nwhich uses both knowledge graph background information and information on\nrecent events. By predicting future events, we also predict likely changes in\nthe knowledge graph and thus obtain a model for the evolution of the knowledge\ngraph as well. Our experiments demonstrate that our approach performs well in a\nclinical application, a recommendation engine and a sensor network application.\n",
        "published": "2015-12-21T22:49:43Z",
        "pdf_link": "http://arxiv.org/pdf/1512.06900v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.06927v4",
        "title": "A C++ library for Multimodal Deep Learning",
        "summary": "  MDL, Multimodal Deep Learning Library, is a deep learning framework that\nsupports multiple models, and this document explains its philosophy and\nfunctionality. MDL runs on Linux, Mac, and Unix platforms. It depends on\nOpenCV.\n",
        "published": "2015-12-22T01:27:23Z",
        "pdf_link": "http://arxiv.org/pdf/1512.06927v4"
    },
    {
        "id": "http://arxiv.org/abs/1512.07074v1",
        "title": "Move from Perturbed scheme to exponential weighting average",
        "summary": "  In an online decision problem, one makes decisions often with a pool of\ndecision sequence called experts but without knowledge of the future. After\neach step, one pays a cost based on the decision and observed rate. One\nreasonal goal would be to perform as well as the best expert in the pool. The\nmodern and well-known way to attain this goal is the algorithm of exponential\nweighting. However, recently, another algorithm called follow the perturbed\nleader is developed and achieved about the same performance. In our work, we\nfirst show the properties shared in common by the two algorithms which explain\nthe similarities on the performance. Next we will show that for a specific\nperturbation, the two algorithms are identical. Finally, we show with some\nexamples that follow-the-leader style algorithms extend naturally to a large\nclass of structured online problems for which the exponential algorithms are\ninefficient.\n",
        "published": "2015-12-22T13:18:17Z",
        "pdf_link": "http://arxiv.org/pdf/1512.07074v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.07716v1",
        "title": "Fast Parallel SVM using Data Augmentation",
        "summary": "  As one of the most popular classifiers, linear SVMs still have challenges in\ndealing with very large-scale problems, even though linear or sub-linear\nalgorithms have been developed recently on single machines. Parallel computing\nmethods have been developed for learning large-scale SVMs. However, existing\nmethods rely on solving local sub-optimization problems. In this paper, we\ndevelop a novel parallel algorithm for learning large-scale linear SVM. Our\napproach is based on a data augmentation equivalent formulation, which casts\nthe problem of learning SVM as a Bayesian inference problem, for which we can\ndevelop very efficient parallel sampling methods. We provide empirical results\nfor this parallel sampling SVM, and provide extensions for SVR, non-linear\nkernels, and provide a parallel implementation of the Crammer and Singer model.\nThis approach is very promising in its own right, and further is a very useful\ntechnique to parallelize a broader family of general maximum-margin models.\n",
        "published": "2015-12-24T04:56:28Z",
        "pdf_link": "http://arxiv.org/pdf/1512.07716v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.07851v2",
        "title": "Context-Based Prediction of App Usage",
        "summary": "  There are around a hundred installed apps on an average smartphone. The high\nnumber of apps and the limited number of app icons that can be displayed on the\ndevice's screen requires a new paradigm to address their visibility to the\nuser. In this paper we propose a new online algorithm for dynamically\npredicting a set of apps that the user is likely to use. The algorithm runs on\nthe user's device and constantly learns the user's habits at a given time,\nlocation, and device state. It is designed to actively help the user to\nnavigate to the desired app as well as to provide a personalized feeling, and\nhence is aimed at maximizing the AUC. We show both theoretically and\nempirically that the algorithm maximizes the AUC, and yields good results on a\nset of 1,000 devices.\n",
        "published": "2015-12-24T16:27:40Z",
        "pdf_link": "http://arxiv.org/pdf/1512.07851v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.07876v2",
        "title": "An unsupervised spatiotemporal graphical modeling approach to anomaly\n  detection in distributed CPS",
        "summary": "  Modern distributed cyber-physical systems (CPSs) encounter a large variety of\nphysical faults and cyber anomalies and in many cases, they are vulnerable to\ncatastrophic fault propagation scenarios due to strong connectivity among the\nsub-systems. This paper presents a new data-driven framework for system-wide\nanomaly detection for addressing such issues. The framework is based on a\nspatiotemporal feature extraction scheme built on the concept of symbolic\ndynamics for discovering and representing causal interactions among the\nsubsystems of a CPS. The extracted spatiotemporal features are then used to\nlearn system-wide patterns via a Restricted Boltzmann Machine (RBM). The\nresults show that: (1) the RBM free energy in the off-nominal conditions is\ndifferent from that in the nominal conditions and can be used for anomaly\ndetection; (2) the framework can capture multiple nominal modes with one\ngraphical model; (3) the case studies with simulated data and an integrated\nbuilding system validate the proposed approach.\n",
        "published": "2015-12-24T18:15:42Z",
        "pdf_link": "http://arxiv.org/pdf/1512.07876v2"
    },
    {
        "id": "http://arxiv.org/abs/1512.08133v1",
        "title": "The Utility of Abstaining in Binary Classification",
        "summary": "  We explore the problem of binary classification in machine learning, with a\ntwist - the classifier is allowed to abstain on any datum, professing ignorance\nabout the true class label without committing to any prediction. This is\ndirectly motivated by applications like medical diagnosis and fraud risk\nassessment, in which incorrect predictions have potentially calamitous\nconsequences. We focus on a recent spate of theoretically driven work in this\narea that characterizes how allowing abstentions can lead to fewer errors in\nvery general settings. Two areas are highlighted: the surprising possibility of\nzero-error learning, and the fundamental tradeoff between predicting\nsufficiently often and avoiding incorrect predictions. We review efficient\nalgorithms with provable guarantees for each of these areas. We also discuss\nconnections to other scenarios, notably active learning, as they suggest\npromising directions of further inquiry in this emerging field.\n",
        "published": "2015-12-26T19:02:00Z",
        "pdf_link": "http://arxiv.org/pdf/1512.08133v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.08178v1",
        "title": "Electricity Demand Forecasting by Multi-Task Learning",
        "summary": "  We explore the application of kernel-based multi-task learning techniques to\nforecast the demand of electricity in multiple nodes of a distribution network.\nWe show that recently developed output kernel learning techniques are\nparticularly well suited to solve this problem, as they allow to flexibly model\nthe complex seasonal effects that characterize electricity demand data, while\nlearning and exploiting correlations between multiple demand profiles. We also\ndemonstrate that kernels with a multiplicative structure yield superior\npredictive performance with respect to the widely adopted (generalized)\nadditive models. Our study is based on residential and industrial smart meter\ndata provided by the Irish Commission for Energy Regulation (CER).\n",
        "published": "2015-12-27T07:18:03Z",
        "pdf_link": "http://arxiv.org/pdf/1512.08178v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.08279v1",
        "title": "Using Causal Discovery to Track Information Flow in Spatio-Temporal Data\n  - A Testbed and Experimental Results Using Advection-Diffusion Simulations",
        "summary": "  Causal discovery algorithms based on probabilistic graphical models have\nemerged in geoscience applications for the identification and visualization of\ndynamical processes. The key idea is to learn the structure of a graphical\nmodel from observed spatio-temporal data, which indicates information flow,\nthus pathways of interactions, in the observed physical system. Studying those\npathways allows geoscientists to learn subtle details about the underlying\ndynamical mechanisms governing our planet. Initial studies using this approach\non real-world atmospheric data have shown great potential for scientific\ndiscovery. However, in these initial studies no ground truth was available, so\nthat the resulting graphs have been evaluated only by whether a domain expert\nthinks they seemed physically plausible. This paper seeks to fill this gap. We\ndevelop a testbed that emulates two dynamical processes dominant in many\ngeoscience applications, namely advection and diffusion, in a 2D grid. Then we\napply the causal discovery based information tracking algorithms to the\nsimulation data to study how well the algorithms work for different scenarios\nand to gain a better understanding of the physical meaning of the graph\nresults, in particular of instantaneous connections. We make all data sets used\nin this study available to the community as a benchmark.\n  Keywords: Information flow, graphical model, structure learning, causal\ndiscovery, geoscience.\n",
        "published": "2015-12-27T21:42:06Z",
        "pdf_link": "http://arxiv.org/pdf/1512.08279v1"
    },
    {
        "id": "http://arxiv.org/abs/1512.08836v2",
        "title": "Learning to Filter with Predictive State Inference Machines",
        "summary": "  Latent state space models are a fundamental and widely used tool for modeling\ndynamical systems. However, they are difficult to learn from data and learned\nmodels often lack performance guarantees on inference tasks such as filtering\nand prediction. In this work, we present the PREDICTIVE STATE INFERENCE MACHINE\n(PSIM), a data-driven method that considers the inference procedure on a\ndynamical system as a composition of predictors. The key idea is that rather\nthan first learning a latent state space model, and then using the learned\nmodel for inference, PSIM directly learns predictors for inference in\npredictive state space. We provide theoretical guarantees for inference, in\nboth realizable and agnostic settings, and showcase practical performance on a\nvariety of simulated and real world robotics benchmarks.\n",
        "published": "2015-12-30T03:17:00Z",
        "pdf_link": "http://arxiv.org/pdf/1512.08836v2"
    },
    {
        "id": "http://arxiv.org/abs/1601.00574v1",
        "title": "NFL Play Prediction",
        "summary": "  Based on NFL game data we try to predict the outcome of a play in multiple\ndifferent ways. An application of this is the following: by plugging in various\nplay options one could determine the best play for a given situation in real\ntime. While the outcome of a play can be described in many ways we had the most\npromising results with a newly defined measure that we call \"progress\". We see\nthis work as a first step to include predictive analysis into NFL playcalling.\n",
        "published": "2016-01-04T17:30:07Z",
        "pdf_link": "http://arxiv.org/pdf/1601.00574v1"
    },
    {
        "id": "http://arxiv.org/abs/1601.00925v1",
        "title": "Complex Decomposition of the Negative Distance kernel",
        "summary": "  A Support Vector Machine (SVM) has become a very popular machine learning\nmethod for text classification. One reason for this relates to the range of\nexisting kernels which allow for classifying data that is not linearly\nseparable. The linear, polynomial and RBF (Gaussian Radial Basis Function)\nkernel are commonly used and serve as a basis of comparison in our study. We\nshow how to derive the primal form of the quadratic Power Kernel (PK) -- also\ncalled the Negative Euclidean Distance Kernel (NDK) -- by means of complex\nnumbers. We exemplify the NDK in the framework of text categorization using the\nDewey Document Classification (DDC) as the target scheme. Our evaluation shows\nthat the power kernel produces F-scores that are comparable to the reference\nkernels, but is -- except for the linear kernel -- faster to compute. Finally,\nwe show how to extend the NDK-approach by including the Mahalanobis distance.\n",
        "published": "2016-01-05T18:16:07Z",
        "pdf_link": "http://arxiv.org/pdf/1601.00925v1"
    },
    {
        "id": "http://arxiv.org/abs/1601.01121v1",
        "title": "A pragmatic approach to multi-class classification",
        "summary": "  We present a novel hierarchical approach to multi-class classification which\nis generic in that it can be applied to different classification models (e.g.,\nsupport vector machines, perceptrons), and makes no explicit assumptions about\nthe probabilistic structure of the problem as it is usually done in multi-class\nclassification. By adding a cascade of additional classifiers, each of which\nreceives the previous classifier's output in addition to regular input data,\nthe approach harnesses unused information that manifests itself in the form of,\ne.g., correlations between predicted classes. Using multilayer perceptrons as a\nclassification model, we demonstrate the validity of this approach by testing\nit on a complex ten-class 3D gesture recognition task.\n",
        "published": "2016-01-06T09:55:17Z",
        "pdf_link": "http://arxiv.org/pdf/1601.01121v1"
    },
    {
        "id": "http://arxiv.org/abs/1601.01157v1",
        "title": "A simple technique for improving multi-class classification with neural\n  networks",
        "summary": "  We present a novel method to perform multi-class pattern classification with\nneural networks and test it on a challenging 3D hand gesture recognition\nproblem. Our method consists of a standard one-against-all (OAA)\nclassification, followed by another network layer classifying the resulting\nclass scores, possibly augmented by the original raw input vector. This allows\nthe network to disambiguate hard-to-separate classes as the distribution of\nclass scores carries considerable information as well, and is in fact often\nused for assessing the confidence of a decision. We show that by this approach\nwe are able to significantly boost our results, overall as well as for\nparticular difficult cases, on the hard 10-class gesture classification task.\n",
        "published": "2016-01-06T12:33:35Z",
        "pdf_link": "http://arxiv.org/pdf/1601.01157v1"
    },
    {
        "id": "http://arxiv.org/abs/1601.01799v2",
        "title": "Dense Bag-of-Temporal-SIFT-Words for Time Series Classification",
        "summary": "  Time series classification is an application of particular interest with the\nincrease of data to monitor. Classical techniques for time series\nclassification rely on point-to-point distances. Recently, Bag-of-Words\napproaches have been used in this context. Words are quantized versions of\nsimple features extracted from sliding windows. The SIFT framework has proved\nefficient for image classification. In this paper, we design a time series\nclassification scheme that builds on the SIFT framework adapted to time series\nto feed a Bag-of-Words. We then refine our method by studying the impact of\nnormalized Bag-of-Words, as well as densely extract point descriptors. Proposed\nadjustements achieve better performance. The evaluation shows that our method\noutperforms classical techniques in terms of classification.\n",
        "published": "2016-01-08T09:06:44Z",
        "pdf_link": "http://arxiv.org/pdf/1601.01799v2"
    },
    {
        "id": "http://arxiv.org/abs/1601.01974v2",
        "title": "Scale-Free Online Learning",
        "summary": "  We design and analyze algorithms for online linear optimization that have\noptimal regret and at the same time do not need to know any upper or lower\nbounds on the norm of the loss vectors. Our algorithms are instances of the\nFollow the Regularized Leader (FTRL) and Mirror Descent (MD) meta-algorithms.\nWe achieve adaptiveness to the norms of the loss vectors by scale invariance,\ni.e., our algorithms make exactly the same decisions if the sequence of loss\nvectors is multiplied by any positive constant. The algorithm based on FTRL\nworks for any decision set, bounded or unbounded. For unbounded decisions sets,\nthis is the first adaptive algorithm for online linear optimization with a\nnon-vacuous regret bound. In contrast, we show lower bounds on scale-free\nalgorithms based on MD on unbounded domains.\n",
        "published": "2016-01-08T18:47:18Z",
        "pdf_link": "http://arxiv.org/pdf/1601.01974v2"
    },
    {
        "id": "http://arxiv.org/abs/1601.02680v1",
        "title": "Using SVM to pre-classify government purchases",
        "summary": "  The Brazilian government often misclassifies the goods it buys. That makes it\nhard to audit government expenditures. We cannot know whether the price paid\nfor a ballpoint pen (code #7510) was reasonable if the pen was misclassified as\na technical drawing pen (code #6675) or as any other good. This paper shows how\nwe can use machine learning to reduce misclassification. I trained a support\nvector machine (SVM) classifier that takes a product description as input and\nreturns the most likely category codes as output. I trained the classifier\nusing 20 million goods purchased by the Brazilian government between 1999-04-01\nand 2015-04-02. In 83.3% of the cases the correct category code was one of the\nthree most likely category codes identified by the classifier. I used the\ntrained classifier to develop a web app that might help the government reduce\nmisclassification. I open sourced the code on GitHub; anyone can use and modify\nit.\n",
        "published": "2015-12-07T02:34:43Z",
        "pdf_link": "http://arxiv.org/pdf/1601.02680v1"
    },
    {
        "id": "http://arxiv.org/abs/1601.03466v3",
        "title": "Dynamic Privacy For Distributed Machine Learning Over Network",
        "summary": "  Privacy-preserving distributed machine learning becomes increasingly\nimportant due to the recent rapid growth of data. This paper focuses on a class\nof regularized empirical risk minimization (ERM) machine learning problems, and\ndevelops two methods to provide differential privacy to distributed learning\nalgorithms over a network. We first decentralize the learning algorithm using\nthe alternating direction method of multipliers (ADMM), and propose the methods\nof dual variable perturbation and primal variable perturbation to provide\ndynamic differential privacy. The two mechanisms lead to algorithms that can\nprovide privacy guarantees under mild conditions of the convexity and\ndifferentiability of the loss function and the regularizer. We study the\nperformance of the algorithms, and show that the dual variable perturbation\noutperforms its primal counterpart. To design an optimal privacy mechanisms, we\nanalyze the fundamental tradeoff between privacy and accuracy, and provide\nguidelines to choose privacy parameters. Numerical experiments using customer\ninformation database are performed to corroborate the results on privacy and\nutility tradeoffs and design.\n",
        "published": "2016-01-14T02:20:46Z",
        "pdf_link": "http://arxiv.org/pdf/1601.03466v3"
    },
    {
        "id": "http://arxiv.org/abs/1601.03483v1",
        "title": "A survey on feature weighting based K-Means algorithms",
        "summary": "  In a real-world data set there is always the possibility, rather high in our\nopinion, that different features may have different degrees of relevance. Most\nmachine learning algorithms deal with this fact by either selecting or\ndeselecting features in the data preprocessing phase. However, we maintain that\neven among relevant features there may be different degrees of relevance, and\nthis should be taken into account during the clustering process. With over 50\nyears of history, K-Means is arguably the most popular partitional clustering\nalgorithm there is. The first K-Means based clustering algorithm to compute\nfeature weights was designed just over 30 years ago. Various such algorithms\nhave been designed since but there has not been, to our knowledge, a survey\nintegrating empirical evidence of cluster recovery ability, common flaws, and\npossible directions for future research. This paper elaborates on the concept\nof feature weighting and addresses these issues by critically analysing some of\nthe most popular, or innovative, feature weighting mechanisms based in K-Means.\n",
        "published": "2015-09-22T08:46:39Z",
        "pdf_link": "http://arxiv.org/pdf/1601.03483v1"
    },
    {
        "id": "http://arxiv.org/abs/1601.03805v2",
        "title": "Matrix Neural Networks",
        "summary": "  Traditional neural networks assume vectorial inputs as the network is\narranged as layers of single line of computing units called neurons. This\nspecial structure requires the non-vectorial inputs such as matrices to be\nconverted into vectors. This process can be problematic. Firstly, the spatial\ninformation among elements of the data may be lost during vectorisation.\nSecondly, the solution space becomes very large which demands very special\ntreatments to the network parameters and high computational cost. To address\nthese issues, we propose matrix neural networks (MatNet), which takes matrices\ndirectly as inputs. Each neuron senses summarised information through bilinear\nmapping from lower layer units in exactly the same way as the classic feed\nforward neural networks. Under this structure, back prorogation and gradient\ndescent combination can be utilised to obtain network parameters efficiently.\nFurthermore, it can be conveniently extended for multimodal inputs. We apply\nMatNet to MNIST handwritten digits classification and image super resolution\ntasks to show its effectiveness. Without too much tweaking MatNet achieves\ncomparable performance as the state-of-the-art methods in both tasks with\nconsiderably reduced complexity.\n",
        "published": "2016-01-15T03:33:35Z",
        "pdf_link": "http://arxiv.org/pdf/1601.03805v2"
    },
    {
        "id": "http://arxiv.org/abs/1601.03855v1",
        "title": "A Relative Exponential Weighing Algorithm for Adversarial Utility-based\n  Dueling Bandits",
        "summary": "  We study the K-armed dueling bandit problem which is a variation of the\nclassical Multi-Armed Bandit (MAB) problem in which the learner receives only\nrelative feedback about the selected pairs of arms. We propose a new algorithm\ncalled Relative Exponential-weight algorithm for Exploration and Exploitation\n(REX3) to handle the adversarial utility-based formulation of this problem.\nThis algorithm is a non-trivial extension of the Exponential-weight algorithm\nfor Exploration and Exploitation (EXP3) algorithm. We prove a finite time\nexpected regret upper bound of order O(sqrt(K ln(K)T)) for this algorithm and a\ngeneral lower bound of order omega(sqrt(KT)). At the end, we provide\nexperimental results using real data from information retrieval applications.\n",
        "published": "2016-01-15T09:50:07Z",
        "pdf_link": "http://arxiv.org/pdf/1601.03855v1"
    },
    {
        "id": "http://arxiv.org/abs/1601.04011v4",
        "title": "Average Stability is Invariant to Data Preconditioning. Implications to\n  Exp-concave Empirical Risk Minimization",
        "summary": "  We show that the average stability notion introduced by\n\\cite{kearns1999algorithmic, bousquet2002stability} is invariant to data\npreconditioning, for a wide class of generalized linear models that includes\nmost of the known exp-concave losses. In other words, when analyzing the\nstability rate of a given algorithm, we may assume the optimal preconditioning\nof the data. This implies that, at least from a statistical perspective,\nexplicit regularization is not required in order to compensate for\nill-conditioned data, which stands in contrast to a widely common approach that\nincludes a regularization for analyzing the sample complexity of generalized\nlinear models. Several important implications of our findings include: a) We\ndemonstrate that the excess risk of empirical risk minimization (ERM) is\ncontrolled by the preconditioned stability rate. This immediately yields a\nrelatively short and elegant proof for the fast rates attained by ERM in our\ncontext. b) We strengthen the recent bounds of \\cite{hardt2015train} on the\nstability rate of the Stochastic Gradient Descent algorithm.\n",
        "published": "2016-01-15T17:32:44Z",
        "pdf_link": "http://arxiv.org/pdf/1601.04011v4"
    },
    {
        "id": "http://arxiv.org/abs/1601.04114v2",
        "title": "Training Recurrent Neural Networks by Diffusion",
        "summary": "  This work presents a new algorithm for training recurrent neural networks\n(although ideas are applicable to feedforward networks as well). The algorithm\nis derived from a theory in nonconvex optimization related to the diffusion\nequation. The contributions made in this work are two fold. First, we show how\nsome seemingly disconnected mechanisms used in deep learning such as smart\ninitialization, annealed learning rate, layerwise pretraining, and noise\ninjection (as done in dropout and SGD) arise naturally and automatically from\nthis framework, without manually crafting them into the algorithms. Second, we\npresent some preliminary results on comparing the proposed method against SGD.\nIt turns out that the new algorithm can achieve similar level of generalization\naccuracy of SGD in much fewer number of epochs.\n",
        "published": "2016-01-16T02:24:17Z",
        "pdf_link": "http://arxiv.org/pdf/1601.04114v2"
    },
    {
        "id": "http://arxiv.org/abs/1601.04756v1",
        "title": "Improved Sampling Techniques for Learning an Imbalanced Data Set",
        "summary": "  This paper presents the performance of a classifier built using the stackingC\nalgorithm in nine different data sets. Each data set is generated using a\nsampling technique applied on the original imbalanced data set. Five new\nsampling techniques are proposed in this paper (i.e., SMOTERandRep, Lax Random\nOversampling, Lax Random Undersampling, Combined-Lax Random Oversampling\nUndersampling, and Combined-Lax Random Undersampling Oversampling) that were\nbased on the three sampling techniques (i.e., Random Undersampling, Random\nOversampling, and Synthetic Minority Oversampling Technique) usually used as\nsolutions in imbalance learning. The metrics used to evaluate the classifier's\nperformance were F-measure and G-mean. F-measure determines the performance of\nthe classifier for every class, while G-mean measures the overall performance\nof the classifier. The results using F-measure showed that for the data without\na sampling technique, the classifier's performance is good only for the\nmajority class. It also showed that among the eight sampling techniques, RU and\nLRU have the worst performance while other techniques (i.e., RO, C-LRUO and\nC-LROU) performed well only on some classes. The best performing techniques in\nall data sets were SMOTE, SMOTERandRep, and LRO having the lowest F-measure\nvalues between 0.5 and 0.65. The results using G-mean showed that the\noversampling technique that attained the highest G-mean value is LRO (0.86),\nnext is C-LROU (0.85), then SMOTE (0.84) and finally is SMOTERandRep (0.83).\nCombining the result of the two metrics (F-measure and G-mean), only the three\nsampling techniques are considered as good performing (i.e., LRO, SMOTE, and\nSMOTERandRep).\n",
        "published": "2016-01-18T23:31:12Z",
        "pdf_link": "http://arxiv.org/pdf/1601.04756v1"
    },
    {
        "id": "http://arxiv.org/abs/1601.06933v1",
        "title": "A Novel Memetic Feature Selection Algorithm",
        "summary": "  Feature selection is a problem of finding efficient features among all\nfeatures in which the final feature set can improve accuracy and reduce\ncomplexity. In feature selection algorithms search strategies are key aspects.\nSince feature selection is an NP-Hard problem; therefore heuristic algorithms\nhave been studied to solve this problem. In this paper, we have proposed a\nmethod based on memetic algorithm to find an efficient feature subset for a\nclassification problem. It incorporates a filter method in the genetic\nalgorithm to improve classification performance and accelerates the search in\nidentifying core feature subsets. Particularly, the method adds or deletes a\nfeature from a candidate feature subset based on the multivariate feature\ninformation. Empirical study on commonly data sets of the university of\nCalifornia, Irvine shows that the proposed method outperforms existing methods.\n",
        "published": "2016-01-26T09:07:08Z",
        "pdf_link": "http://arxiv.org/pdf/1601.06933v1"
    },
    {
        "id": "http://arxiv.org/abs/1601.07996v5",
        "title": "Feature Selection: A Data Perspective",
        "summary": "  Feature selection, as a data preprocessing strategy, has been proven to be\neffective and efficient in preparing data (especially high-dimensional data)\nfor various data mining and machine learning problems. The objectives of\nfeature selection include: building simpler and more comprehensible models,\nimproving data mining performance, and preparing clean, understandable data.\nThe recent proliferation of big data has presented some substantial challenges\nand opportunities to feature selection. In this survey, we provide a\ncomprehensive and structured overview of recent advances in feature selection\nresearch. Motivated by current challenges and opportunities in the era of big\ndata, we revisit feature selection research from a data perspective and review\nrepresentative feature selection algorithms for conventional data, structured\ndata, heterogeneous data and streaming data. Methodologically, to emphasize the\ndifferences and similarities of most existing feature selection algorithms for\nconventional data, we categorize them into four main groups: similarity based,\ninformation theoretical based, sparse learning based and statistical based\nmethods. To facilitate and promote the research in this community, we also\npresent an open-source feature selection repository that consists of most of\nthe popular feature selection algorithms\n(\\url{http://featureselection.asu.edu/}). Also, we use it as an example to show\nhow to evaluate feature selection algorithms. At the end of the survey, we\npresent a discussion about some open problems and challenges that require more\nattention in future research.\n",
        "published": "2016-01-29T08:32:10Z",
        "pdf_link": "http://arxiv.org/pdf/1601.07996v5"
    },
    {
        "id": "http://arxiv.org/abs/1602.00163v2",
        "title": "Multiple instance learning for sequence data with across bag\n  dependencies",
        "summary": "  In Multiple Instance Learning (MIL) problem for sequence data, the instances\ninside the bags are sequences. In some real world applications such as\nbioinformatics, comparing a random couple of sequences makes no sense. In fact,\neach instance may have structural and/or functional relations with instances of\nother bags. Thus, the classification task should take into account this across\nbag relation. In this work, we present two novel MIL approaches for sequence\ndata classification named ABClass and ABSim. ABClass extracts motifs from\nrelated instances and use them to encode sequences. A discriminative classifier\nis then applied to compute a partial classification result for each set of\nrelated sequences. ABSim uses a similarity measure to discriminate the related\ninstances and to compute a scores matrix. For both approaches, an aggregation\nmethod is applied in order to generate the final classification result. We\napplied both approaches to solve the problem of bacterial Ionizing Radiation\nResistance prediction. The experimental results of the presented approaches are\nsatisfactory.\n",
        "published": "2016-01-30T21:15:10Z",
        "pdf_link": "http://arxiv.org/pdf/1602.00163v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.00309v1",
        "title": "Bandits meet Computer Architecture: Designing a Smartly-allocated Cache",
        "summary": "  In many embedded systems, such as imaging sys- tems, the system has a single\ndesignated purpose, and same threads are executed repeatedly. Profiling thread\nbehavior, allows the system to allocate each thread its resources in a way that\nimproves overall system performance. We study an online resource al-\nlocationproblem,wherearesourcemanagersimulta- neously allocates resources\n(exploration), learns the impact on the different consumers (learning) and im-\nproves allocation towards optimal performance (ex- ploitation). We build on the\nrich framework of multi- armed bandits and present online and offline algo-\nrithms. Through extensive experiments with both synthetic data and real-world\ncache allocation to threads we show the merits and properties of our al-\ngorithms\n",
        "published": "2016-01-31T19:53:49Z",
        "pdf_link": "http://arxiv.org/pdf/1602.00309v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.00351v1",
        "title": "Adaptive Subgradient Methods for Online AUC Maximization",
        "summary": "  Learning for maximizing AUC performance is an important research problem in\nMachine Learning and Artificial Intelligence. Unlike traditional batch learning\nmethods for maximizing AUC which often suffer from poor scalability, recent\nyears have witnessed some emerging studies that attempt to maximize AUC by\nsingle-pass online learning approaches. Despite their encouraging results\nreported, the existing online AUC maximization algorithms often adopt simple\nonline gradient descent approaches that fail to exploit the geometrical\nknowledge of the data observed during the online learning process, and thus\ncould suffer from relatively larger regret. To address the above limitation, in\nthis work, we explore a novel algorithm of Adaptive Online AUC Maximization\n(AdaOAM) which employs an adaptive gradient method that exploits the knowledge\nof historical gradients to perform more informative online learning. The new\nadaptive updating strategy of the AdaOAM is less sensitive to the parameter\nsettings and maintains the same time complexity as previous non-adaptive\ncounterparts. Additionally, we extend the algorithm to handle high-dimensional\nsparse data (SAdaOAM) and address sparsity in the solution by performing lazy\ngradient updating. We analyze the theoretical bounds and evaluate their\nempirical performance on various types of data sets. The encouraging empirical\nresults obtained clearly highlighted the effectiveness and efficiency of the\nproposed algorithms.\n",
        "published": "2016-02-01T00:25:18Z",
        "pdf_link": "http://arxiv.org/pdf/1602.00351v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.00374v1",
        "title": "ConfidentCare: A Clinical Decision Support System for Personalized\n  Breast Cancer Screening",
        "summary": "  Breast cancer screening policies attempt to achieve timely diagnosis by the\nregular screening of apparently healthy women. Various clinical decisions are\nneeded to manage the screening process; those include: selecting the screening\ntests for a woman to take, interpreting the test outcomes, and deciding whether\nor not a woman should be referred to a diagnostic test. Such decisions are\ncurrently guided by clinical practice guidelines (CPGs), which represent a\none-size-fits-all approach that are designed to work well on average for a\npopulation, without guaranteeing that it will work well uniformly over that\npopulation. Since the risks and benefits of screening are functions of each\npatients features, personalized screening policies that are tailored to the\nfeatures of individuals are needed in order to ensure that the right tests are\nrecommended to the right woman. In order to address this issue, we present\nConfidentCare: a computer-aided clinical decision support system that learns a\npersonalized screening policy from the electronic health record (EHR) data.\nConfidentCare operates by recognizing clusters of similar patients, and\nlearning the best screening policy to adopt for each cluster. A cluster of\npatients is a set of patients with similar features (e.g. age, breast density,\nfamily history, etc.), and the screening policy is a set of guidelines on what\nactions to recommend for a woman given her features and screening test scores.\nConfidentCare algorithm ensures that the policy adopted for every cluster of\npatients satisfies a predefined accuracy requirement with a high level of\nconfidence. We show that our algorithm outperforms the current CPGs in terms of\ncost-efficiency and false positive rates.\n",
        "published": "2016-02-01T03:21:46Z",
        "pdf_link": "http://arxiv.org/pdf/1602.00374v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.00554v2",
        "title": "Graph-based Predictable Feature Analysis",
        "summary": "  We propose graph-based predictable feature analysis (GPFA), a new method for\nunsupervised learning of predictable features from high-dimensional time\nseries, where high predictability is understood very generically as low\nvariance in the distribution of the next data point given the previous ones. We\nshow how this measure of predictability can be understood in terms of graph\nembedding as well as how it relates to the information-theoretic measure of\npredictive information in special cases. We confirm the effectiveness of GPFA\non different datasets, comparing it to three existing algorithms with similar\nobjectives---namely slow feature analysis, forecastable component analysis, and\npredictable feature analysis---to which GPFA shows very competitive results.\n",
        "published": "2016-02-01T15:11:48Z",
        "pdf_link": "http://arxiv.org/pdf/1602.00554v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.00575v2",
        "title": "Multi-object Classification via Crowdsourcing with a Reject Option",
        "summary": "  Consider designing an effective crowdsourcing system for an $M$-ary\nclassification task. Crowd workers complete simple binary microtasks whose\nresults are aggregated to give the final result. We consider the novel scenario\nwhere workers have a reject option so they may skip microtasks when they are\nunable or choose not to respond. For example, in mismatched speech\ntranscription, workers who do not know the language may not be able to respond\nto microtasks focused on phonological dimensions outside their categorical\nperception. We present an aggregation approach using a weighted majority voting\nrule, where each worker's response is assigned an optimized weight to maximize\nthe crowd's classification performance. We evaluate system performance in both\nexact and asymptotic forms. Further, we consider the setting where there may be\na set of greedy workers that complete microtasks even when they are unable to\nperform it reliably. We consider an oblivious and an expurgation strategy to\ndeal with greedy workers, developing an algorithm to adaptively switch between\nthe two based on the estimated fraction of greedy workers in the anonymous\ncrowd. Simulation results show improved performance compared with conventional\nmajority voting.\n",
        "published": "2016-02-01T16:00:47Z",
        "pdf_link": "http://arxiv.org/pdf/1602.00575v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.01024v1",
        "title": "On Deep Multi-View Representation Learning: Objectives and Optimization",
        "summary": "  We consider learning representations (features) in the setting in which we\nhave access to multiple unlabeled views of the data for learning while only one\nview is available for downstream tasks. Previous work on this problem has\nproposed several techniques based on deep neural networks, typically involving\neither autoencoder-like networks with a reconstruction objective or paired\nfeedforward networks with a batch-style correlation-based objective. We analyze\nseveral techniques based on prior work, as well as new variants, and compare\nthem empirically on image, speech, and text tasks. We find an advantage for\ncorrelation-based representation learning, while the best results on most tasks\nare obtained with our new variant, deep canonically correlated autoencoders\n(DCCAE). We also explore a stochastic optimization procedure for minibatch\ncorrelation-based objectives and discuss the time/performance trade-offs for\nkernel-based and neural network-based implementations.\n",
        "published": "2016-02-02T17:51:43Z",
        "pdf_link": "http://arxiv.org/pdf/1602.01024v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.01198v2",
        "title": "k-variates++: more pluses in the k-means++",
        "summary": "  k-means++ seeding has become a de facto standard for hard clustering\nalgorithms. In this paper, our first contribution is a two-way generalisation\nof this seeding, k-variates++, that includes the sampling of general densities\nrather than just a discrete set of Dirac densities anchored at the point\nlocations, and a generalisation of the well known Arthur-Vassilvitskii (AV)\napproximation guarantee, in the form of a bias+variance approximation bound of\nthe global optimum. This approximation exhibits a reduced dependency on the\n\"noise\" component with respect to the optimal potential --- actually\napproaching the statistical lower bound. We show that k-variates++ reduces to\nefficient (biased seeding) clustering algorithms tailored to specific\nframeworks; these include distributed, streaming and on-line clustering, with\ndirect approximation results for these algorithms. Finally, we present a novel\napplication of k-variates++ to differential privacy. For either the specific\nframeworks considered here, or for the differential privacy setting, there is\nlittle to no prior results on the direct application of k-means++ and its\napproximation bounds --- state of the art contenders appear to be significantly\nmore complex and / or display less favorable (approximation) properties. We\nstress that our algorithms can still be run in cases where there is \\textit{no}\nclosed form solution for the population minimizer. We demonstrate the\napplicability of our analysis via experimental evaluation on several domains\nand settings, displaying competitive performances vs state of the art.\n",
        "published": "2016-02-03T06:31:09Z",
        "pdf_link": "http://arxiv.org/pdf/1602.01198v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.01323v1",
        "title": "Biclustering Readings and Manuscripts via Non-negative Matrix\n  Factorization, with Application to the Text of Jude",
        "summary": "  The text-critical practice of grouping witnesses into families or texttypes\noften faces two obstacles: Contamination in the manuscript tradition, and\nco-dependence in identifying characteristic readings and manuscripts. We\nintroduce non-negative matrix factorization (NMF) as a simple, unsupervised,\nand efficient way to cluster large numbers of manuscripts and readings\nsimultaneously while summarizing contamination using an easy-to-interpret\nmixture model. We apply this method to an extensive collation of the New\nTestament epistle of Jude and show that the resulting clusters correspond to\nhuman-identified textual families from existing research.\n",
        "published": "2016-02-03T14:54:05Z",
        "pdf_link": "http://arxiv.org/pdf/1602.01323v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.01580v1",
        "title": "Long-term Planning by Short-term Prediction",
        "summary": "  We consider planning problems, that often arise in autonomous driving\napplications, in which an agent should decide on immediate actions so as to\noptimize a long term objective. For example, when a car tries to merge in a\nroundabout it should decide on an immediate acceleration/braking command, while\nthe long term effect of the command is the success/failure of the merge. Such\nproblems are characterized by continuous state and action spaces, and by\ninteraction with multiple agents, whose behavior can be adversarial. We argue\nthat dual versions of the MDP framework (that depend on the value function and\nthe $Q$ function) are problematic for autonomous driving applications due to\nthe non Markovian of the natural state space representation, and due to the\ncontinuous state and action spaces. We propose to tackle the planning task by\ndecomposing the problem into two phases: First, we apply supervised learning\nfor predicting the near future based on the present. We require that the\npredictor will be differentiable with respect to the representation of the\npresent. Second, we model a full trajectory of the agent using a recurrent\nneural network, where unexplained factors are modeled as (additive) input\nnodes. This allows us to solve the long-term planning problem using supervised\nlearning techniques and direct optimization over the recurrent neural network.\nOur approach enables us to learn robust policies by incorporating adversarial\nelements to the environment.\n",
        "published": "2016-02-04T08:06:59Z",
        "pdf_link": "http://arxiv.org/pdf/1602.01580v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.01582v2",
        "title": "SDCA without Duality, Regularization, and Individual Convexity",
        "summary": "  Stochastic Dual Coordinate Ascent is a popular method for solving regularized\nloss minimization for the case of convex losses. We describe variants of SDCA\nthat do not require explicit regularization and do not rely on duality. We\nprove linear convergence rates even if individual loss functions are\nnon-convex, as long as the expected loss is strongly convex.\n",
        "published": "2016-02-04T08:14:06Z",
        "pdf_link": "http://arxiv.org/pdf/1602.01582v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.01690v2",
        "title": "Minimizing the Maximal Loss: How and Why?",
        "summary": "  A commonly used learning rule is to approximately minimize the \\emph{average}\nloss over the training set. Other learning algorithms, such as AdaBoost and\nhard-SVM, aim at minimizing the \\emph{maximal} loss over the training set. The\naverage loss is more popular, particularly in deep learning, due to three main\nreasons. First, it can be conveniently minimized using online algorithms, that\nprocess few examples at each iteration. Second, it is often argued that there\nis no sense to minimize the loss on the training set too much, as it will not\nbe reflected in the generalization loss. Last, the maximal loss is not robust\nto outliers. In this paper we describe and analyze an algorithm that can\nconvert any online algorithm to a minimizer of the maximal loss. We prove that\nin some situations better accuracy on the training set is crucial to obtain\ngood performance on unseen examples. Last, we propose robust versions of the\napproach that can handle outliers.\n",
        "published": "2016-02-04T14:32:23Z",
        "pdf_link": "http://arxiv.org/pdf/1602.01690v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.01711v1",
        "title": "The Great Time Series Classification Bake Off: An Experimental\n  Evaluation of Recently Proposed Algorithms. Extended Version",
        "summary": "  In the last five years there have been a large number of new time series\nclassification algorithms proposed in the literature. These algorithms have\nbeen evaluated on subsets of the 47 data sets in the University of California,\nRiverside time series classification archive. The archive has recently been\nexpanded to 85 data sets, over half of which have been donated by researchers\nat the University of East Anglia. Aspects of previous evaluations have made\ncomparisons between algorithms difficult. For example, several different\nprogramming languages have been used, experiments involved a single train/test\nsplit and some used normalised data whilst others did not. The relaunch of the\narchive provides a timely opportunity to thoroughly evaluate algorithms on a\nlarger number of datasets. We have implemented 18 recently proposed algorithms\nin a common Java framework and compared them against two standard benchmark\nclassifiers (and each other) by performing 100 resampling experiments on each\nof the 85 datasets. We use these results to test several hypotheses relating to\nwhether the algorithms are significantly more accurate than the benchmarks and\neach other. Our results indicate that only 9 of these algorithms are\nsignificantly more accurate than both benchmarks and that one classifier, the\nCollective of Transformation Ensembles, is significantly more accurate than all\nof the others. All of our experiments and results are reproducible: we release\nall of our code, results and experimental details and we hope these experiments\nform the basis for more rigorous testing of new algorithms in the future.\n",
        "published": "2016-02-04T15:24:22Z",
        "pdf_link": "http://arxiv.org/pdf/1602.01711v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.01783v2",
        "title": "Asynchronous Methods for Deep Reinforcement Learning",
        "summary": "  We propose a conceptually simple and lightweight framework for deep\nreinforcement learning that uses asynchronous gradient descent for optimization\nof deep neural network controllers. We present asynchronous variants of four\nstandard reinforcement learning algorithms and show that parallel\nactor-learners have a stabilizing effect on training allowing all four methods\nto successfully train neural network controllers. The best performing method,\nan asynchronous variant of actor-critic, surpasses the current state-of-the-art\non the Atari domain while training for half the time on a single multi-core CPU\ninstead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds\non a wide variety of continuous motor control problems as well as on a new task\nof navigating random 3D mazes using a visual input.\n",
        "published": "2016-02-04T18:38:41Z",
        "pdf_link": "http://arxiv.org/pdf/1602.01783v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.01910v1",
        "title": "Fast Multiplier Methods to Optimize Non-exhaustive, Overlapping\n  Clustering",
        "summary": "  Clustering is one of the most fundamental and important tasks in data mining.\nTraditional clustering algorithms, such as K-means, assign every data point to\nexactly one cluster. However, in real-world datasets, the clusters may overlap\nwith each other. Furthermore, often, there are outliers that should not belong\nto any cluster. We recently proposed the NEO-K-Means (Non-Exhaustive,\nOverlapping K-Means) objective as a way to address both issues in an integrated\nfashion. Optimizing this discrete objective is NP-hard, and even though there\nis a convex relaxation of the objective, straightforward convex optimization\napproaches are too expensive for large datasets. A practical alternative is to\nuse a low-rank factorization of the solution matrix in the convex formulation.\nThe resulting optimization problem is non-convex, and we can locally optimize\nthe objective function using an augmented Lagrangian method. In this paper, we\nconsider two fast multiplier methods to accelerate the convergence of an\naugmented Lagrangian scheme: a proximal method of multipliers and an\nalternating direction method of multipliers (ADMM). For the proximal augmented\nLagrangian or proximal method of multipliers, we show a convergence result for\nthe non-convex case with bound-constrained subproblems. These methods are up to\n13 times faster---with no change in quality---compared with a standard\naugmented Lagrangian method on problems with over 10,000 variables and bring\nruntimes down from over an hour to around 5 minutes.\n",
        "published": "2016-02-05T02:08:57Z",
        "pdf_link": "http://arxiv.org/pdf/1602.01910v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.02070v4",
        "title": "Compressive PCA for Low-Rank Matrices on Graphs",
        "summary": "  We introduce a novel framework for an approxi- mate recovery of data matrices\nwhich are low-rank on graphs, from sampled measurements. The rows and columns\nof such matrices belong to the span of the first few eigenvectors of the graphs\nconstructed between their rows and columns. We leverage this property to\nrecover the non-linear low-rank structures efficiently from sampled data\nmeasurements, with a low cost (linear in n). First, a Resrtricted Isometry\nProperty (RIP) condition is introduced for efficient uniform sampling of the\nrows and columns of such matrices based on the cumulative coherence of graph\neigenvectors. Secondly, a state-of-the-art fast low-rank recovery method is\nsuggested for the sampled data. Finally, several efficient, parallel and\nparameter-free decoders are presented along with their theoretical analysis for\ndecoding the low-rank and cluster indicators for the full data matrix. Thus, we\novercome the computational limitations of the standard linear low-rank recovery\nmethods for big datasets. Our method can also be seen as a major step towards\nefficient recovery of non- linear low-rank structures. For a matrix of size n X\np, on a single core machine, our method gains a speed up of $p^2/k$ over Robust\nPrincipal Component Analysis (RPCA), where k << p is the subspace dimension.\nNumerically, we can recover a low-rank matrix of size 10304 X 1000, 100 times\nfaster than Robust PCA.\n",
        "published": "2016-02-05T15:51:34Z",
        "pdf_link": "http://arxiv.org/pdf/1602.02070v4"
    },
    {
        "id": "http://arxiv.org/abs/1602.02101v2",
        "title": "Variance-Reduced and Projection-Free Stochastic Optimization",
        "summary": "  The Frank-Wolfe optimization algorithm has recently regained popularity for\nmachine learning applications due to its projection-free property and its\nability to handle structured constraints. However, in the stochastic learning\nsetting, it is still relatively understudied compared to the gradient descent\ncounterpart. In this work, leveraging a recent variance reduction technique, we\npropose two stochastic Frank-Wolfe variants which substantially improve\nprevious results in terms of the number of stochastic gradient evaluations\nneeded to achieve $1-\\epsilon$ accuracy. For example, we improve from\n$O(\\frac{1}{\\epsilon})$ to $O(\\ln\\frac{1}{\\epsilon})$ if the objective function\nis smooth and strongly convex, and from $O(\\frac{1}{\\epsilon^2})$ to\n$O(\\frac{1}{\\epsilon^{1.5}})$ if the objective function is smooth and\nLipschitz. The theoretical improvement is also observed in experiments on\nreal-world datasets for a multiclass classification application.\n",
        "published": "2016-02-05T17:14:59Z",
        "pdf_link": "http://arxiv.org/pdf/1602.02101v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.02123v1",
        "title": "Sequence Classification with Neural Conditional Random Fields",
        "summary": "  The proliferation of sensor devices monitoring human activity generates\nvoluminous amount of temporal sequences needing to be interpreted and\ncategorized. Moreover, complex behavior detection requires the personalization\nof multi-sensor fusion algorithms. Conditional random fields (CRFs) are\ncommonly used in structured prediction tasks such as part-of-speech tagging in\nnatural language processing. Conditional probabilities guide the choice of each\ntag/label in the sequence conflating the structured prediction task with the\nsequence classification task where different models provide different\ncategorization of the same sequence. The claim of this paper is that CRF models\nalso provide discriminative models to distinguish between types of sequence\nregardless of the accuracy of the labels obtained if we calibrate the class\nmembership estimate of the sequence. We introduce and compare different neural\nnetwork based linear-chain CRFs and we present experiments on two complex\nsequence classification and structured prediction tasks to support this claim.\n",
        "published": "2016-02-05T19:19:46Z",
        "pdf_link": "http://arxiv.org/pdf/1602.02123v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.02202v4",
        "title": "Efficient Second Order Online Learning by Sketching",
        "summary": "  We propose Sketched Online Newton (SON), an online second order learning\nalgorithm that enjoys substantially improved regret guarantees for\nill-conditioned data. SON is an enhanced version of the Online Newton Step,\nwhich, via sketching techniques enjoys a running time linear in the dimension\nand sketch size. We further develop sparse forms of the sketching methods (such\nas Oja's rule), making the computation linear in the sparsity of features.\nTogether, the algorithm eliminates all computational obstacles in previous\nsecond order online learning approaches.\n",
        "published": "2016-02-06T02:33:53Z",
        "pdf_link": "http://arxiv.org/pdf/1602.02202v4"
    },
    {
        "id": "http://arxiv.org/abs/1602.02350v2",
        "title": "Solving Ridge Regression using Sketched Preconditioned SVRG",
        "summary": "  We develop a novel preconditioning method for ridge regression, based on\nrecent linear sketching methods. By equipping Stochastic Variance Reduced\nGradient (SVRG) with this preconditioning process, we obtain a significant\nspeed-up relative to fast stochastic methods such as SVRG, SDCA and SAG.\n",
        "published": "2016-02-07T08:37:18Z",
        "pdf_link": "http://arxiv.org/pdf/1602.02350v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.02454v1",
        "title": "Efficient Algorithms for Adversarial Contextual Learning",
        "summary": "  We provide the first oracle efficient sublinear regret algorithms for\nadversarial versions of the contextual bandit problem. In this problem, the\nlearner repeatedly makes an action on the basis of a context and receives\nreward for the chosen action, with the goal of achieving reward competitive\nwith a large class of policies. We analyze two settings: i) in the transductive\nsetting the learner knows the set of contexts a priori, ii) in the small\nseparator setting, there exists a small set of contexts such that any two\npolicies behave differently in one of the contexts in the set. Our algorithms\nfall into the follow the perturbed leader family \\cite{Kalai2005} and achieve\nregret $O(T^{3/4}\\sqrt{K\\log(N)})$ in the transductive setting and $O(T^{2/3}\nd^{3/4} K\\sqrt{\\log(N)})$ in the separator setting, where $K$ is the number of\nactions, $N$ is the number of baseline policies, and $d$ is the size of the\nseparator. We actually solve the more general adversarial contextual\nsemi-bandit linear optimization problem, whilst in the full information setting\nwe address the even more general contextual combinatorial optimization. We\nprovide several extensions and implications of our algorithms, such as\nswitching regret and efficient learning with predictable sequences.\n",
        "published": "2016-02-08T03:11:39Z",
        "pdf_link": "http://arxiv.org/pdf/1602.02454v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.02830v3",
        "title": "Binarized Neural Networks: Training Deep Neural Networks with Weights\n  and Activations Constrained to +1 or -1",
        "summary": "  We introduce a method to train Binarized Neural Networks (BNNs) - neural\nnetworks with binary weights and activations at run-time. At training-time the\nbinary weights and activations are used for computing the parameters gradients.\nDuring the forward pass, BNNs drastically reduce memory size and accesses, and\nreplace most arithmetic operations with bit-wise operations, which is expected\nto substantially improve power-efficiency. To validate the effectiveness of\nBNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On\nboth, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10\nand SVHN datasets. Last but not least, we wrote a binary matrix multiplication\nGPU kernel with which it is possible to run our MNIST BNN 7 times faster than\nwith an unoptimized GPU kernel, without suffering any loss in classification\naccuracy. The code for training and running our BNNs is available on-line.\n",
        "published": "2016-02-09T01:01:59Z",
        "pdf_link": "http://arxiv.org/pdf/1602.02830v3"
    },
    {
        "id": "http://arxiv.org/abs/1602.02887v1",
        "title": "Classification with Boosting of Extreme Learning Machine Over\n  Arbitrarily Partitioned Data",
        "summary": "  Machine learning based computational intelligence methods are widely used to\nanalyze large scale data sets in this age of big data. Extracting useful\npredictive modeling from these types of data sets is a challenging problem due\nto their high complexity. Analyzing large amount of streaming data that can be\nleveraged to derive business value is another complex problem to solve. With\nhigh levels of data availability (\\textit{i.e. Big Data}) automatic\nclassification of them has become an important and complex task. Hence, we\nexplore the power of applying MapReduce based Distributed AdaBoosting of\nExtreme Learning Machine (ELM) to build a predictive bag of classification\nmodels. Accordingly, (i) data set ensembles are created; (ii) ELM algorithm is\nused to build weak learners (classifier functions); and (iii) builds a strong\nlearner from a set of weak learners. We applied this training model to the\nbenchmark knowledge discovery and data mining data sets.\n",
        "published": "2016-02-09T08:09:26Z",
        "pdf_link": "http://arxiv.org/pdf/1602.02887v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.02888v1",
        "title": "Robust Ensemble Classifier Combination Based on Noise Removal with\n  One-Class SVM",
        "summary": "  In machine learning area, as the number of labeled input samples becomes very\nlarge, it is very difficult to build a classification model because of input\ndata set is not fit in a memory in training phase of the algorithm, therefore,\nit is necessary to utilize data partitioning to handle overall data set.\nBagging and boosting based data partitioning methods have been broadly used in\ndata mining and pattern recognition area. Both of these methods have shown a\ngreat possibility for improving classification model performance. This study is\nconcerned with the analysis of data set partitioning with noise removal and its\nimpact on the performance of multiple classifier models. In this study, we\npropose noise filtering preprocessing at each data set partition to increment\nclassifier model performance. We applied Gini impurity approach to find the\nbest split percentage of noise filter ratio. The filtered sub data set is then\nused to train individual ensemble models.\n",
        "published": "2016-02-09T08:14:29Z",
        "pdf_link": "http://arxiv.org/pdf/1602.02888v1"
    },
    {
        "id": "http://arxiv.org/abs/1602.03040v3",
        "title": "The Structured Weighted Violations Perceptron Algorithm",
        "summary": "  We present the Structured Weighted Violations Perceptron (SWVP) algorithm, a\nnew structured prediction algorithm that generalizes the Collins Structured\nPerceptron (CSP). Unlike CSP, the update rule of SWVP explicitly exploits the\ninternal structure of the predicted labels. We prove the convergence of SWVP\nfor linearly separable training sets, provide mistake and generalization\nbounds, and show that in the general case these bounds are tighter than those\nof the CSP special case. In synthetic data experiments with data drawn from an\nHMM, various variants of SWVP substantially outperform its CSP special case.\nSWVP also provides encouraging initial dependency parsing results.\n",
        "published": "2016-02-09T15:51:19Z",
        "pdf_link": "http://arxiv.org/pdf/1602.03040v3"
    },
    {
        "id": "http://arxiv.org/abs/1602.03218v2",
        "title": "Learning Efficient Algorithms with Hierarchical Attentive Memory",
        "summary": "  In this paper, we propose and investigate a novel memory architecture for\nneural networks called Hierarchical Attentive Memory (HAM). It is based on a\nbinary tree with leaves corresponding to memory cells. This allows HAM to\nperform memory access in O(log n) complexity, which is a significant\nimprovement over the standard attention mechanism that requires O(n)\noperations, where n is the size of the memory.\n  We show that an LSTM network augmented with HAM can learn algorithms for\nproblems like merging, sorting or binary searching from pure input-output\nexamples. In particular, it learns to sort n numbers in time O(n log n) and\ngeneralizes well to input sequences much longer than the ones seen during the\ntraining. We also show that HAM can be trained to act like classic data\nstructures: a stack, a FIFO queue and a priority queue.\n",
        "published": "2016-02-09T23:24:33Z",
        "pdf_link": "http://arxiv.org/pdf/1602.03218v2"
    },
    {
        "id": "http://arxiv.org/abs/1602.03258v3",
        "title": "Interactive Bayesian Hierarchical Clustering",
        "summary": "  Clustering is a powerful tool in data analysis, but it is often difficult to\nfind a grouping that aligns with a user's needs. To address this, several\nmethods incorporate constraints obtained from users into clustering algorithms,\nbut unfortunately do not apply to hierarchical clustering. We design an\ninteractive Bayesian algorithm that incorporates user interaction into\nhierarchical clustering while still utilizing the geometry of the data by\nsampling a constrained posterior distribution over hierarchies. We also suggest\nseveral ways to intelligently query a user. The algorithm, along with the\nquerying schemes, shows promising results on real data.\n",
        "published": "2016-02-10T03:59:57Z",
        "pdf_link": "http://arxiv.org/pdf/1602.03258v3"
    },
    {
        "id": "http://arxiv.org/abs/1602.03822v8",
        "title": "A Critical Connectivity Radius for Segmenting Randomly-Generated, High\n  Dimensional Data Points",
        "summary": "  Motivated by a $2$-dimensional (unsupervised) image segmentation task whereby\nlocal regions of pixels are clustered via edge detection methods, a more\ngeneral probabilistic mathematical framework is devised. Critical thresholds\nare calculated that indicate strong correlation between randomly-generated,\nhigh dimensional data points that have been projected into structures in a\npartition of a bounded, $2$-dimensional area, of which, an image is a special\ncase. A neighbor concept for structures in the partition is defined and a\ncritical radius is uncovered. Measured from a central structure in localized\nregions of the partition, the radius indicates strong, long and short range\ncorrelation in the count of occupied structures. The size of a short interval\nof radii is estimated upon which the transition from short-to-long range\ncorrelation is virtually assured, which defines a demarcation of when an image\nceases to be \"interesting\".\n",
        "published": "2016-02-11T18:37:53Z",
        "pdf_link": "http://arxiv.org/pdf/1602.03822v8"
    },
    {
        "id": "http://arxiv.org/abs/1602.04128v4",
        "title": "Coin Betting and Parameter-Free Online Learning",
        "summary": "  In the recent years, a number of parameter-free algorithms have been\ndeveloped for online linear optimization over Hilbert spaces and for learning\nwith expert advice. These algorithms achieve optimal regret bounds that depend\non the unknown competitors, without having to tune the learning rates with\noracle choices.\n  We present a new intuitive framework to design parameter-free algorithms for\n\\emph{both} online linear optimization over Hilbert spaces and for learning\nwith expert advice, based on reductions to betting on outcomes of adversarial\ncoins. We instantiate it using a betting algorithm based on the\nKrichevsky-Trofimov estimator. The resulting algorithms are simple, with no\nparameters to be tuned, and they improve or match previous results in terms of\nregret guarantee and per-round complexity.\n",
        "published": "2016-02-12T17:11:42Z",
        "pdf_link": "http://arxiv.org/pdf/1602.04128v4"
    },
    {
        "id": "http://arxiv.org/abs/1602.04364v1",
        "title": "Look, Listen and Learn - A Multimodal LSTM for Speaker Identification",
        "summary": "  Speaker identification refers to the task of localizing the face of a person\nwho has the same identity as the ongoing voice in a video. This task not only\nrequires collective perception over both visual and auditory signals, the\nrobustness to handle severe quality degradations and unconstrained content\nvariations are also indispensable. In this paper, we describe a novel\nmultimodal Long Short-Term Memory (LSTM) architecture which seamlessly unifies\nboth visual and auditory modalities from the beginning of each sequence input.\nThe key idea is to extend the conventional LSTM by not only sharing weights\nacross time steps, but also sharing weights across modalities. We show that\nmodeling the temporal dependency across face and voice can significantly\nimprove the robustness to content quality degradations and variations. We also\nfound that our multimodal LSTM is robustness to distractors, namely the\nnon-speaking identities. We applied our multimodal LSTM to The Big Bang Theory\ndataset and showed that our system outperforms the state-of-the-art systems in\nspeaker identification with lower false alarm rate and higher recognition\naccuracy.\n",
        "published": "2016-02-13T18:49:50Z",
        "pdf_link": "http://arxiv.org/pdf/1602.04364v1"
    }
]