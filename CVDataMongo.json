[
    {
        "id": "http://arxiv.org/abs/cs/9810003v1",
        "title": "A Linear Shift Invariant Multiscale Transform",
        "summary": "  This paper presents a multiscale decomposition algorithm. Unlike standard\nwavelet transforms, the proposed operator is both linear and shift invariant.\nThe central idea is to obtain shift invariance by averaging the aligned wavelet\ntransform projections over all circular shifts of the signal. It is shown how\nthe same transform can be obtained by a linear filter bank.\n",
        "published": "1998-10-02T03:34:38Z",
        "pdf_link": "http://arxiv.org/pdf/cs/9810003v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/9810017v1",
        "title": "General Theory of Image Normalization",
        "summary": "  We give a systematic, abstract formulation of the image normalization method\nas applied to a general group of image transformations, and then illustrate the\nabstract analysis by applying it to the hierarchy of viewing transformations of\na planar object.\n",
        "published": "1998-10-19T20:46:16Z",
        "pdf_link": "http://arxiv.org/pdf/cs/9810017v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/9908017v1",
        "title": "A Differential Invariant for Zooming",
        "summary": "  This paper presents an invariant under scaling and linear brightness change.\nThe invariant is based on differentials and therefore is a local feature.\nRotationally invariant 2-d differential Gaussian operators up to third order\nare proposed for the implementation of the invariant. The performance is\nanalyzed by simulating a camera zoom-out.\n",
        "published": "1999-08-26T17:18:49Z",
        "pdf_link": "http://arxiv.org/pdf/cs/9908017v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0001024v1",
        "title": "A Parallel Algorithm for Dilated Contour Extraction from Bilevel Images",
        "summary": "  We describe a simple, but efficient algorithm for the generation of dilated\ncontours from bilevel images. The initial part of the contour extraction is\nexplained to be a good candidate for parallel computer code generation. The\nremainder of the algorithm is of linear nature.\n",
        "published": "2000-01-25T16:09:37Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0001024v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0003065v1",
        "title": "Image Compression with Iterated Function Systems, Finite Automata and\n  Zerotrees: Grand Unification",
        "summary": "  Fractal image compression, Culik's image compression and zerotree prediction\ncoding of wavelet image decomposition coefficients succeed only because typical\nimages being compressed possess a significant degree of self-similarity.\nBesides the common concept, these methods turn out to be even more tightly\nrelated, to the point of algorithmical reducibility of one technique to\nanother. The goal of the present paper is to demonstrate these relations.\n  The paper offers a plain-term interpretation of Culik's image compression, in\nregular image processing terms, without resorting to finite state machines and\nsimilar lofty language. The interpretation is shown to be algorithmically\nrelated to an IFS fractal image compression method: an IFS can be exactly\ntransformed into Culik's image code. Using this transformation, we will prove\nthat in a self-similar (part of an) image any zero wavelet coefficient is the\nroot of a zerotree, or its branch.\n  The paper discusses the zerotree coding of (wavelet/projection) coefficients\nas a common predictor/corrector, applied vertically through different layers of\na multiresolutional decomposition, rather than within the same view. This\ninterpretation leads to an insight into the evolution of image compression\ntechniques: from a causal single-layer prediction, to non-causal same-view\npredictions (wavelet decomposition among others) and to a causal cross-layer\nprediction (zero-trees, Culik's method).\n",
        "published": "2000-03-15T19:31:51Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0003065v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0003079v1",
        "title": "Differential Invariants under Gamma Correction",
        "summary": "  This paper presents invariants under gamma correction and similarity\ntransformations. The invariants are local features based on differentials which\nare implemented using derivatives of the Gaussian. The use of the proposed\ninvariant representation is shown to yield improved correlation results in a\ntemplate matching scenario.\n",
        "published": "2000-03-26T23:18:43Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0003079v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0004012v1",
        "title": "Assisted Video Sequences Indexing : Motion Analysis Based on Interest\n  Points",
        "summary": "  This work deals with content-based video indexing. Our viewpoint is\nsemi-automatic analysis of compressed video. We consider the possible\napplications of motion analysis and moving object detection : assisting moving\nobject indexing, summarising videos, and allowing image and motion queries. We\npropose an approach based on interest points. As first results, we test and\ncompare the stability of different types of interest point detectors in\ncompressed sequences.\n",
        "published": "2000-04-21T17:32:29Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0004012v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0005001v1",
        "title": "Robustness of Regional Matching Scheme over Global Matching Scheme",
        "summary": "  The paper has established and verified the theory prevailing widely among\nimage and pattern recognition specialists that the bottom-up indirect regional\nmatching process is the more stable and the more robust than the global\nmatching process against concentrated types of noise represented by clutter,\noutlier or occlusion in the imagery. We have demonstrated this by analyzing the\neffect of concentrated noise on a typical decision making process of a\nsimplified two candidate voting model where our theorem establishes the lower\nbounds to a critical breakdown point of election (or decision) result by the\nbottom-up matching process are greater than the exact bound of the global\nmatching process implying that the former regional process is capable of\naccommodating a higher level of noise than the latter global process before the\nresult of decision overturns. We present a convincing experimental verification\nsupporting not only the theory by a white-black flag recognition problem in the\npresence of localized noise but also the validity of the conjecture by a facial\nrecognition problem that the theorem remains valid for other decision making\nprocesses involving an important dimension-reducing transform such as principal\ncomponent analysis or a Gabor transform.\n",
        "published": "2000-05-03T08:49:28Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0005001v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0006001v1",
        "title": "Boosting the Differences: A fast Bayesian classifier neural network",
        "summary": "  A Bayesian classifier that up-weights the differences in the attribute values\nis discussed. Using four popular datasets from the UCI repository, some\ninteresting features of the network are illustrated. The network is suitable\nfor classification problems.\n",
        "published": "2000-05-31T23:37:48Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0006001v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0006002v1",
        "title": "Distorted English Alphabet Identification : An application of Difference\n  Boosting Algorithm",
        "summary": "  The difference-boosting algorithm is used on letters dataset from the UCI\nrepository to classify distorted raster images of English alphabets. In\ncontrast to rather complex networks, the difference-boosting is found to\nproduce comparable or better classification efficiency on this complex problem.\n",
        "published": "2000-05-31T23:52:31Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0006002v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0006047v1",
        "title": "Geometric Morphology of Granular Materials",
        "summary": "  We present a new method to transform the spectral pixel information of a\nmicrograph into an affine geometric description, which allows us to analyze the\nmorphology of granular materials. We use spectral and pulse-coupled neural\nnetwork based segmentation techniques to generate blobs, and a newly developed\nalgorithm to extract dilated contours. A constrained Delaunay tesselation of\nthe contour points results in a triangular mesh. This mesh is the basic\ningredient of the Chodal Axis Transform, which provides a morphological\ndecomposition of shapes. Such decomposition allows for grain separation and the\nefficient computation of the statistical features of granular materials.\n",
        "published": "2000-06-30T22:17:42Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0006047v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0208005v1",
        "title": "Probabilistic Search for Object Segmentation and Recognition",
        "summary": "  The problem of searching for a model-based scene interpretation is analyzed\nwithin a probabilistic framework. Object models are formulated as generative\nmodels for range data of the scene. A new statistical criterion, the truncated\nobject probability, is introduced to infer an optimal sequence of object\nhypotheses to be evaluated for their match to the data. The truncated\nprobability is partly determined by prior knowledge of the objects and partly\nlearned from data. Some experiments on sequence quality and object segmentation\nand recognition from stereo data are presented. The article recovers classic\nconcepts from object recognition (grouping, geometric hashing, alignment) from\nthe probabilistic perspective and adds insight into the optimal ordering of\nobject hypotheses for evaluation. Moreover, it introduces point-relation\ndensities, a key component of the truncated probability, as statistical models\nof local surface shape.\n",
        "published": "2002-08-05T10:57:09Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0208005v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0301001v1",
        "title": "Least squares fitting of circles and lines",
        "summary": "  We study theoretical and computational aspects of the least squares fit (LSF)\nof circles and circular arcs. First we discuss the existence and uniqueness of\nLSF and various parametrization schemes. Then we evaluate several popular\ncircle fitting algorithms and propose a new one that surpasses the existing\nmethods in reliability. We also discuss and compare direct (algebraic) circle\nfits.\n",
        "published": "2003-01-01T19:58:03Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0301001v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0303015v1",
        "title": "Statistical efficiency of curve fitting algorithms",
        "summary": "  We study the problem of fitting parametrized curves to noisy data. Under\ncertain assumptions (known as Cartesian and radial functional models), we\nderive asymptotic expressions for the bias and the covariance matrix of the\nparameter estimates. We also extend Kanatani's version of the Cramer-Rao lower\nbound, which he proved for unbiased estimates only, to more general estimates\nthat include many popular algorithms (most notably, the orthogonal least\nsquares and algebraic fits). We then show that the gradient-weighted algebraic\nfit is statistically efficient and describe all other statistically efficient\nalgebraic fits.\n",
        "published": "2003-03-18T21:30:36Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0303015v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0307045v1",
        "title": "Flexible Camera Calibration Using a New Analytical Radial Undistortion\n  Formula with Application to Mobile Robot Localization",
        "summary": "  Most algorithms in 3D computer vision rely on the pinhole camera model\nbecause of its simplicity, whereas virtually all imaging devices introduce\ncertain amount of nonlinear distortion, where the radial distortion is the most\nsevere part. Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved. An application of the new radial distortion model is non-iterative\nyellow line alignment with a calibrated camera on ODIS, a robot built in our\nCSOIS.\n",
        "published": "2003-07-20T02:35:38Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0307045v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0307046v1",
        "title": "A New Analytical Radial Distortion Model for Camera Calibration",
        "summary": "  Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved.\n",
        "published": "2003-07-20T05:18:59Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0307046v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0307047v1",
        "title": "Rational Radial Distortion Models with Analytical Undistortion Formulae",
        "summary": "  The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nclass of rational radial distortion models with easy analytical undistortion\nformulae. Experimental results are presented to show that with this class of\nrational radial distortion models, satisfactory and comparable accuracy is\nachieved.\n",
        "published": "2003-07-20T05:54:42Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0307047v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0307051v1",
        "title": "An Analytical Piecewise Radial Distortion Model for Precision Camera\n  Calibration",
        "summary": "  The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\npiecewise radial distortion model with easy analytical undistortion formula.\nThe motivation for seeking a piecewise radial distortion model is that, when a\ncamera is resulted in a low quality during manufacturing, the nonlinear radial\ndistortion can be complex. Using low order polynomials to approximate the\nradial distortion might not be precise enough. On the other hand, higher order\npolynomials suffer from the inverse problem. With the new piecewise radial\ndistortion function, more flexibility is obtained and the radial undistortion\ncan be performed analytically. Experimental results are presented to show that\nwith this new piecewise radial distortion model, better performance is achieved\nthan that using the single function. Furthermore, a comparable performance with\nthe conventional polynomial model using 2 coefficients can also be\naccomplished.\n",
        "published": "2003-07-21T16:30:11Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0307051v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0307072v1",
        "title": "Camera Calibration: a USU Implementation",
        "summary": "  The task of camera calibration is to estimate the intrinsic and extrinsic\nparameters of a camera model. Though there are some restricted techniques to\ninfer the 3-D information about the scene from uncalibrated cameras, effective\ncamera calibration procedures will open up the possibility of using a wide\nrange of existing algorithms for 3-D reconstruction and recognition.\n  The applications of camera calibration include vision-based metrology, robust\nvisual platooning and visual docking of mobile robots where the depth\ninformation is important.\n",
        "published": "2003-07-31T19:33:48Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0307072v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0308003v1",
        "title": "A Family of Simplified Geometric Distortion Models for Camera\n  Calibration",
        "summary": "  The commonly used radial distortion model for camera calibration is in fact\nan assumption or a restriction. In practice, camera distortion could happen in\na general geometrical manner that is not limited to the radial sense. This\npaper proposes a simplified geometrical distortion modeling method by using two\ndifferent radial distortion functions in the two image axes. A family of\nsimplified geometric distortion models is proposed, which are either simple\npolynomials or the rational functions of polynomials. Analytical geometric\nundistortion is possible using two of the distortion functions discussed in\nthis paper and their performance can be improved by applying a piecewise\nfitting idea. Our experimental results show that the geometrical distortion\nmodels always perform better than their radial distortion counterparts.\nFurthermore, the proposed geometric modeling method is more appropriate for\ncameras whose distortion is not perfectly radially symmetric around the center\nof distortion.\n",
        "published": "2003-08-02T01:39:38Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0308003v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0308034v1",
        "title": "Fingerprint based bio-starter and bio-access",
        "summary": "  In the paper will be presented a safety and security system based on\nfingerprint technology. The results suggest a new scenario where the new cars\ncan use a fingerprint sensor integrated in car handle to allow access and in\nthe dashboard as starter button.\n",
        "published": "2003-08-21T10:47:27Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0308034v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0308035v1",
        "title": "IS (Iris Security)",
        "summary": "  In the paper will be presented a safety system based on iridology. The\nresults suggest a new scenario where the security problem in supervised and\nunsupervised areas can be treat with the present system and the iris image\nrecognition.\n",
        "published": "2003-08-21T10:52:53Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0308035v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0401017v2",
        "title": "Better Foreground Segmentation Through Graph Cuts",
        "summary": "  For many tracking and surveillance applications, background subtraction\nprovides an effective means of segmenting objects moving in front of a static\nbackground. Researchers have traditionally used combinations of morphological\noperations to remove the noise inherent in the background-subtracted result.\nSuch techniques can effectively isolate foreground objects, but tend to lose\nfidelity around the borders of the segmentation, especially for noisy input.\nThis paper explores the use of a minimum graph cut algorithm to segment the\nforeground, resulting in qualitatively and quantitiatively cleaner\nsegmentations. Experiments on both artificial and real data show that the\ngraph-based method reduces the error around segmented foreground objects. A\nMATLAB code implementation is available at\nhttp://www.cs.smith.edu/~nhowe/research/code/#fgseg\n",
        "published": "2004-01-21T20:06:51Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0401017v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0401018v1",
        "title": "Factor Temporal Prognosis of Tick-Borne Encephalitis Foci Functioning on\n  the South of Russian Far East",
        "summary": "  A method of temporal factor prognosis of TE (tick-borne encephalitis)\ninfection has been developed. The high precision of the prognosis results for a\nnumber of geographical regions of Primorsky Krai has been achieved. The method\ncan be applied not only to epidemiological research but also to others.\n",
        "published": "2004-01-22T05:53:30Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0401018v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0402020v1",
        "title": "Geometrical Complexity of Classification Problems",
        "summary": "  Despite encouraging recent progresses in ensemble approaches, classification\nmethods seem to have reached a plateau in development. Further advances depend\non a better understanding of geometrical and topological characteristics of\npoint sets in high-dimensional spaces, the preservation of such characteristics\nunder feature transformations and sampling processes, and their interaction\nwith geometrical models used in classifiers. We discuss an attempt to measure\nsuch properties from data sets and relate them to classifier accuracies.\n",
        "published": "2004-02-11T16:34:16Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0402020v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0405093v2",
        "title": "Computerized Face Detection and Recognition",
        "summary": "  This publication presents methods for face detection, analysis and\nrecognition: fast normalized cross-correlation (fast correlation coefficient)\nbetween multiple templates based face pre-detection method, method for\ndetection of exact face contour based on snakes and Generalized Gradient Vector\nFlow field, method for combining recognition algorithms based on Cumulative\nMatch Characteristics in order to increase recognition speed and accuracy, and\nface recognition method based on Principal Component Analysis of the Wavelet\nPacket Decomposition allowing to use PCA - based recognition method with large\nnumber of training images. For all the methods are presented experimental\nresults and comparisons of speed and accuracy with large face databases.\n",
        "published": "2004-05-25T11:36:34Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0405093v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0405095v1",
        "title": "Blind Detection and Compensation of Camera Lens Geometric Distortions",
        "summary": "  This paper presents a blind detection and compensation technique for camera\nlens geometric distortions. The lens distortion introduces higher-order\ncorrelations in the frequency domain and in turn it can be detected using\nhigher-order spectral analysis tools without assuming any specific calibration\ntarget. The existing blind lens distortion removal method only considered a\nsingle-coefficient radial distortion model. In this paper, two coefficients are\nconsidered to model approximately the geometric distortion. All the models\nconsidered have analytical closed-form inverse formulae.\n",
        "published": "2004-05-25T22:40:42Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0405095v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0406008v1",
        "title": "Image compression by rectangular wavelet transform",
        "summary": "  We study image compression by a separable wavelet basis\n$\\big\\{\\psi(2^{k_1}x-i)\\psi(2^{k_2}y-j),$ $\\phi(x-i)\\psi(2^{k_2}y-j),$\n$\\psi(2^{k_1}(x-i)\\phi(y-j),$ $\\phi(x-i)\\phi(y-i)\\big\\},$ where $k_1, k_2 \\in\n\\mathbb{Z}_+$; $i,j\\in\\mathbb{Z}$; and $\\phi,\\psi$ are elements of a standard\nbiorthogonal wavelet basis in $L_2(\\mathbb{R})$. Because $k_1\\ne k_2$, the\nsupports of the basis elements are rectangles, and the corresponding transform\nis known as the {\\em rectangular wavelet transform}. We prove that if\none-dimensional wavelet basis has $M$ dual vanishing moments then the rate of\napproximation by $N$ coefficients of rectangular wavelet transform is\n$\\mathcal{O}(N^{-M}\\log^C N)$ for functions with mixed derivative of order $M$\nin each direction.\n  The square wavelet transform yields the approximation rate is\n$\\mathcal{O}(N^{-M/2})$ for functions with all derivatives of the total order\n$M$. Thus, the rectangular wavelet transform can outperform the square one if\nan image has a mixed derivative. We provide experimental comparison of image\ncompression which shows that rectangular wavelet transform outperform the\nsquare one.\n",
        "published": "2004-06-04T12:28:06Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0406008v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0502095v2",
        "title": "Gradient Vector Flow Models for Boundary Extraction in 2D Images",
        "summary": "  The Gradient Vector Flow (GVF) is a vector diffusion approach based on\nPartial Differential Equations (PDEs). This method has been applied together\nwith snake models for boundary extraction medical images segmentation. The key\nidea is to use a diffusion-reaction PDE to generate a new external force field\nthat makes snake models less sensitivity to initialization as well as improves\nthe snake's ability to move into boundary concavities. In this paper, we\nfirstly review basic results about convergence and numerical analysis of usual\nGVF schemes. We point out that GVF presents numerical problems due to\ndiscontinuities image intensity. This point is considered from a practical\nviewpoint from which the GVF parameters must follow a relationship in order to\nimprove numerical convergence. Besides, we present an analytical analysis of\nthe GVF dependency from the parameters values. Also, we observe that the method\ncan be used for multiply connected domains by just imposing the suitable\nboundary condition. In the experimental results we verify these theoretical\npoints and demonstrate the utility of GVF on a segmentation approach that we\nhave developed based on snakes.\n",
        "published": "2005-02-28T15:09:08Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0502095v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0505006v1",
        "title": "Searching for image information content, its discovery, extraction, and\n  representation",
        "summary": "  Image information content is known to be a complicated and controvercial\nproblem. This paper posits a new image information content definition.\nFollowing the theory of Solomonoff-Kolmogorov-Chaitin's complexity, we define\nimage information content as a set of descriptions of imafe data structures.\nThree levels of such description can be generally distinguished: 1)the global\nlevel, where the coarse structure of the entire scene is initially outlined; 2)\nthe intermediate level, where structures of separate, non-overlapping image\nregions usually associated with individual scene objects are deliniated; and 3)\nthe low-level description, where local image structures observed in a limited\nand restricted field of view are resolved. A technique for creating such image\ninformation content descriptors is developed. Its algorithm is presented and\nelucidated with some examples, which demonstrate the effectiveness of the\nproposed approach.\n",
        "published": "2005-05-02T03:17:02Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0505006v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0507058v1",
        "title": "Paving the Way for Image Understanding: A New Kind of Image\n  Decomposition is Desired",
        "summary": "  In this paper we present an unconventional image segmentation approach which\nis devised to meet the requirements of image understanding and pattern\nrecognition tasks. Generally image understanding assumes interplay of two\nsub-processes: image information content discovery and image information\ncontent interpretation. Despite of its widespread use, the notion of \"image\ninformation content\" is still ill defined, intuitive, and ambiguous. Most\noften, it is used in the Shannon's sense, which means information content\nassessment averaged over the whole signal ensemble. Humans, however,rarely\nresort to such estimates. They are very effective in decomposing images into\ntheir meaningful constituents and focusing attention to the perceptually\nrelevant image parts. We posit that following the latest findings in human\nattention vision studies and the concepts of Kolmogorov's complexity theory an\nunorthodox segmentation approach can be proposed that provides effective image\ndecomposition to information preserving image fragments well suited for\nsubsequent image interpretation. We provide some illustrative examples,\ndemonstrating effectiveness of this approach.\n",
        "published": "2005-07-22T12:18:44Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0507058v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0509081v1",
        "title": "Automatic Face Recognition System Based on Local Fourier-Bessel Features",
        "summary": "  We present an automatic face verification system inspired by known properties\nof biological systems. In the proposed algorithm the whole image is converted\nfrom the spatial to polar frequency domain by a Fourier-Bessel Transform (FBT).\nUsing the whole image is compared to the case where only face image regions\n(local analysis) are considered. The resulting representations are embedded in\na dissimilarity space, where each image is represented by its distance to all\nthe other images, and a Pseudo-Fisher discriminator is built. Verification test\nresults on the FERET database showed that the local-based algorithm outperforms\nthe global-FBT version. The local-FBT algorithm performed as state-of-the-art\nmethods under different testing conditions, indicating that the proposed system\nis highly robust for expression, age, and illumination variations. We also\nevaluated the performance of the proposed system under strong occlusion\nconditions and found that it is highly robust for up to 50% of face occlusion.\nFinally, we automated completely the verification system by implementing face\nand eye detection algorithms. Under this condition, the local approach was only\nslightly superior to the global approach.\n",
        "published": "2005-09-27T15:25:36Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0509081v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0509082v1",
        "title": "Face Recognition Based on Polar Frequency Features",
        "summary": "  A novel biologically motivated face recognition algorithm based on polar\nfrequency is presented. Polar frequency descriptors are extracted from face\nimages by Fourier-Bessel transform (FBT). Next, the Euclidean distance between\nall images is computed and each image is now represented by its dissimilarity\nto the other images. A Pseudo-Fisher Linear Discriminant was built on this\ndissimilarity space. The performance of Discrete Fourier transform (DFT)\ndescriptors, and a combination of both feature types was also evaluated. The\nalgorithms were tested on a 40- and 1196-subjects face database (ORL and FERET,\nrespectively). With 5 images per subject in the training and test datasets,\nerror rate on the ORL database was 3.8, 1.25 and 0.2% for the FBT, DFT, and the\ncombined classifier, respectively, as compared to 2.6% achieved by the best\nprevious algorithm. The most informative polar frequency features were\nconcentrated at low-to-medium angular frequencies coupled to low radial\nfrequencies. On the FERET database, where an affine normalization\npre-processing was applied, the FBT algorithm outperformed only the PCA in a\nrank recognition test. However, it achieved performance comparable to\nstate-of-the-art methods when evaluated by verification tests. These results\nindicate the high informative value of the polar frequency content of face\nimages in relation to recognition and verification tasks, and that the\nCartesian frequency content can complement information about the subjects'\nidentity, but possibly only when the images are not pre-normalized. Possible\nimplications for human face recognition are discussed.\n",
        "published": "2005-09-27T15:50:27Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0509082v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0509083v1",
        "title": "Face Verification in Polar Frequency Domain: a Biologically Motivated\n  Approach",
        "summary": "  We present a novel local-based face verification system whose components are\nanalogous to those of biological systems. In the proposed system, after global\nregistration and normalization, three eye regions are converted from the\nspatial to polar frequency domain by a Fourier-Bessel Transform. The resulting\nrepresentations are embedded in a dissimilarity space, where each image is\nrepresented by its distance to all the other images. In this dissimilarity\nspace a Pseudo-Fisher discriminator is built. ROC and equal error rate\nverification test results on the FERET database showed that the system\nperformed at least as state-of-the-art methods and better than a system based\non polar Fourier features. The local-based system is especially robust to\nfacial expression and age variations, but sensitive to registration errors.\n",
        "published": "2005-09-27T16:06:22Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0509083v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0510001v2",
        "title": "Retinal Vessel Segmentation Using the 2-D Morlet Wavelet and Supervised\n  Classification",
        "summary": "  We present a method for automated segmentation of the vasculature in retinal\nimages. The method produces segmentations by classifying each image pixel as\nvessel or non-vessel, based on the pixel's feature vector. Feature vectors are\ncomposed of the pixel's intensity and continuous two-dimensional Morlet wavelet\ntransform responses taken at multiple scales. The Morlet wavelet is capable of\ntuning to specific frequencies, thus allowing noise filtering and vessel\nenhancement in a single step. We use a Bayesian classifier with\nclass-conditional probability density functions (likelihoods) described as\nGaussian mixtures, yielding a fast classification, while being able to model\ncomplex decision surfaces and compare its performance with the linear minimum\nsquared error classifier. The probability distributions are estimated based on\na training set of labeled pixels obtained from manual segmentations. The\nmethod's performance is evaluated on publicly available DRIVE and STARE\ndatabases of manually labeled non-mydriatic images. On the DRIVE database, it\nachieves an area under the receiver operating characteristic (ROC) curve of\n0.9598, being slightly superior than that presented by the method of Staal et\nal.\n",
        "published": "2005-09-30T22:27:45Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0510001v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0510026v1",
        "title": "A decision support system for ship identification based on the curvature\n  scale space representation",
        "summary": "  In this paper, a decision support system for ship identification is\npresented. The system receives as input a silhouette of the vessel to be\nidentified, previously extracted from a side view of the object. This view\ncould have been acquired with imaging sensors operating at different spectral\nranges (CCD, FLIR, image intensifier). The input silhouette is preprocessed and\ncompared to those stored in a database, retrieving a small number of potential\nmatches ranked by their similarity to the target silhouette. This set of\npotential matches is presented to the system operator, who makes the final ship\nidentification. This system makes use of an evolved version of the Curvature\nScale Space (CSS) representation. In the proposed approach, it is curvature\nextrema, instead of zero crossings, that are tracked during silhouette\nevolution, hence improving robustness and enabling to cope successfully with\ncases where the standard CCS representation is found to be unstable. Also, the\nuse of local curvature was replaced with the more robust concept of lobe\nconcavity, with significant additional gains in performance. Experimental\nresults on actual operational imagery prove the excellent performance and\nrobustness of the developed method.\n",
        "published": "2005-10-11T08:43:04Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0510026v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0512084v1",
        "title": "Understanding physics from interconnected data",
        "summary": "  Metal melting on release after explosion is a physical system far from\nquilibrium. A complete physical model of this system does not exist, because\nmany interrelated effects have to be considered. General methodology needs to\nbe developed so as to describe and understand physical phenomena involved.\n  The high noise of the data, moving blur of images, the high degree of\nuncertainty due to the different types of sensors, and the information\nentangled and hidden inside the noisy images makes reasoning about the physical\nprocesses very difficult. Major problems include proper information extraction\nand the problem of reconstruction, as well as prediction of the missing data.\nIn this paper, several techniques addressing the first problem are given,\nbuilding the basis for tackling the second problem.\n",
        "published": "2005-12-21T20:23:38Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0512084v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0601105v3",
        "title": "The Perceptron Algorithm: Image and Signal Decomposition, Compression,\n  and Analysis by Iterative Gaussian Blurring",
        "summary": "  A novel algorithm for tunable compression to within the precision of\nreproduction targets, or storage, is proposed. The new algorithm is termed the\n`Perceptron Algorithm', which utilises simple existing concepts in a novel way,\nhas multiple immediate commercial application aspects as well as it opens up a\nmultitude of fronts in computational science and technology. The aims of this\npaper are to present the concepts underlying the algorithm, observations by its\napplication to some example cases, and the identification of a multitude of\npotential areas of applications such as: image compression by orders of\nmagnitude, signal compression including sound as well, image analysis in a\nmultilayered detailed analysis, pattern recognition and matching and rapid\ndatabase searching (e.g. face recognition), motion analysis, biomedical\napplications e.g. in MRI and CAT scan image analysis and compression, as well\nas hints on the link of these ideas to the way how biological memory might work\nleading to new points of view in neural computation. Commercial applications of\nimmediate interest are the compression of images at the source (e.g.\nphotographic equipment, scanners, satellite imaging systems), DVD film\ncompression, pay-per-view downloads acceleration and many others identified in\nthe present paper at its conclusion and future work section.\n",
        "published": "2006-01-24T17:23:17Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0601105v3"
    },
    {
        "id": "http://arxiv.org/abs/cs/0601106v1",
        "title": "The `Face on Mars': a photographic approach for the search of signs of\n  past civilizations from a macroscopic point of view, factoring long-term\n  erosion in image reconstruction",
        "summary": "  This short article presents an alternative view of high resolution imaging\nfrom various sources with the aim of the discovery of potential sites of\narchaeological importance, or sites that exhibit `anomalies' such that they may\nmerit closer inspection and analysis. It is conjectured, and to a certain\nextent demonstrated here, that it is possible for advanced civilizations to\nfactor in erosion by natural processes into a large scale design so that main\nfeatures be preserved even with the passage of millions of years. Alternatively\nviewed, even without such intent embedded in a design left for posterity, it is\npossible that a gigantic construction may naturally decay in such a way that\neven cataclysmic (massive) events may leave sufficient information intact with\nthe passage of time, provided one changes the point of view from high\nresolution images to enhanced blurred renderings of the sites in question.\n",
        "published": "2006-01-24T18:12:00Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0601106v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0602044v1",
        "title": "Multilevel Thresholding for Image Segmentation through a Fast\n  Statistical Recursive Algorithm",
        "summary": "  A novel algorithm is proposed for segmenting an image into multiple levels\nusing its mean and variance. Starting from the extreme pixel values at both\nends of the histogram plot, the algorithm is applied recursively on sub-ranges\ncomputed from the previous step, so as to find a threshold level and a new\nsub-range for the next step, until no significant improvement in image quality\ncan be achieved. The method makes use of the fact that a number of\ndistributions tend towards Dirac delta function, peaking at the mean, in the\nlimiting condition of vanishing variance. The procedure naturally provides for\nvariable size segmentation with bigger blocks near the extreme pixel values and\nfiner divisions around the mean or other chosen value for better visualization.\nExperiments on a variety of images show that the new algorithm effectively\nsegments the image in computationally very less time.\n",
        "published": "2006-02-12T18:22:41Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0602044v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0603041v1",
        "title": "Locally Adaptive Block Thresholding Method with Continuity Constraint",
        "summary": "  We present an algorithm that enables one to perform locally adaptive block\nthresholding, while maintaining image continuity. Images are divided into\nsub-images based some standard image attributes and thresholding technique is\nemployed over the sub-images. The present algorithm makes use of the thresholds\nof neighboring sub-images to calculate a range of values. The image continuity\nis taken care by choosing the threshold of the sub-image under consideration to\nlie within the above range. After examining the average range values for\nvarious sub-image sizes of a variety of images, it was found that the range of\nacceptable threshold values is substantially high, justifying our assumption of\nexploiting the freedom of range for bringing out local details.\n",
        "published": "2006-03-09T17:14:00Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0603041v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0603086v1",
        "title": "Matching Edges in Images ; Application to Face Recognition",
        "summary": "  This communication describes a representation of images as a set of edges\ncharacterized by their position and orientation. This representation allows the\ncomparison of two images and the computation of their similarity. The first\nstep in this computation of similarity is the seach of a geometrical basis of\nthe two dimensional space where the two images are represented simultaneously\nafter transformation of one of them. Presently, this simultaneous\nrepresentation takes into account a shift and a scaling ; it may be extended to\nrotations or other global geometrical transformations. An elementary\nprobabilistic computation shows that a sufficient but not excessive number of\ntrials (a few tens) ensures that the exhibition of this common basis is\nguaranteed in spite of possible errors in the detection of edges. When this\nfirst step is performed, the search of similarity between the two images\nreduces to counting the coincidence of edges in the two images. The approach\nmay be applied to many problems of pattern matching ; it was checked on face\nrecognition.\n",
        "published": "2006-03-22T14:51:53Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0603086v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0603116v2",
        "title": "Fourier Analysis and Holographic Representations of 1D and 2D Signals",
        "summary": "  In this paper, we focus on Fourier analysis and holographic transforms for\nsignal representation. For instance, in the case of image processing, the\nholographic representation has the property that an arbitrary portion of the\ntransformed image enables reconstruction of the whole image with details\nmissing. We focus on holographic representation defined through the Fourier\nTransforms. Thus, We firstly review some results in Fourier transform and\nFourier series. Next, we review the Discrete Holographic Fourier Transform\n(DHFT) for image representation. Then, we describe the contributions of our\nwork. We show a simple scheme for progressive transmission based on the DHFT.\nNext, we propose the Continuous Holographic Fourier Transform (CHFT) and\ndiscuss some theoretical aspects of it for 1D signals. Finally, some testes are\npresented in the experimental results\n",
        "published": "2006-03-29T19:07:52Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0603116v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0604062v1",
        "title": "Biologically Inspired Hierarchical Model for Feature Extraction and\n  Localization",
        "summary": "  Feature extraction and matching are among central problems of computer\nvision. It is inefficent to search features over all locations and scales.\nNeurophysiological evidence shows that to locate objects in a digital image the\nhuman visual system employs visual attention to a specific object while\nignoring others. The brain also has a mechanism to search from coarse to fine.\nIn this paper, we present a feature extractor and an associated hierarchical\nsearching model to simulate such processes. With the hierarchical\nrepresentation of the object, coarse scanning is done through the matching of\nthe larger scale and precise localization is conducted through the matching of\nthe smaller scale. Experimental results justify the proposed model in its\neffectiveness and efficiency to localize features.\n",
        "published": "2006-04-14T04:40:29Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0604062v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0605025v1",
        "title": "Face Recognition using Principal Component Analysis and Log-Gabor\n  Filters",
        "summary": "  In this article we propose a novel face recognition method based on Principal\nComponent Analysis (PCA) and Log-Gabor filters. The main advantages of the\nproposed method are its simple implementation, training, and very high\nrecognition accuracy. For recognition experiments we used 5151 face images of\n1311 persons from different sets of the FERET and AR databases that allow to\nanalyze how recognition accuracy is affected by the change of facial\nexpressions, illumination, and aging. Recognition experiments with the FERET\ndatabase (containing photographs of 1196 persons) showed that our method can\nachieve maximal 97-98% first one recognition rate and 0.3-0.4% Equal Error\nRate. The experiments also showed that the accuracy of our method is less\naffected by eye location errors and used image normalization method than of\ntraditional PCA -based recognition method.\n",
        "published": "2006-05-07T13:30:09Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0605025v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0605027v1",
        "title": "Recognition of expression variant faces using masked log-Gabor features\n  and Principal Component Analysis",
        "summary": "  In this article we propose a method for the recognition of faces with\ndifferent facial expressions. For recognition we extract feature vectors by\nusing log-Gabor filters of multiple orientations and scales. Using sliding\nwindow algorithm and variances -based masking these features are extracted at\nimage regions that are less affected by the changes of facial expressions.\nExtracted features are passed to the Principal Component Analysis (PCA) -based\nrecognition method. The results of face recognition experiments using\nexpression variant faces showed that the proposed method could achieve higher\nrecognition accuracy than many other methods. For development and testing we\nused facial images from the AR and FERET databases. Using facial photographs of\nmore than one thousand persons from the FERET database the proposed method\nachieved 96.6-98.9% first one recognition rate and 0.2-0.6% Equal Error Rate\n(EER).\n",
        "published": "2006-05-07T15:02:53Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0605027v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0605131v2",
        "title": "Notes on Geometric Measure Theory Applications to Image Processing;\n  De-noising, Segmentation, Pattern, Texture, Lines, Gestalt and Occlusion",
        "summary": "  Regularization functionals that lower level set boundary length when used\nwith L^1 fidelity functionals on signal de-noising on images create artifacts.\nThese are (i) rounding of corners, (ii) shrinking of radii, (iii) shrinking of\ncusps, and (iv) non-smoothing of staircasing. Regularity functionals based upon\ntotal curvature of level set boundaries do not create artifacts (i) and (ii).\nAn adjusted fidelity term based on the flat norm on the current (a\ndistributional graph) representing the density of curvature of level sets\nboundaries can minimize (iii) by weighting the position of a cusp. A regularity\nterm to eliminate staircasing can be based upon the mass of the current\nrepresenting the graph of an image function or its second derivatives.\nDensities on the Grassmann bundle of the Grassmann bundle of the ambient space\nof the graph can be used to identify patterns, textures, occlusion and lines.\n",
        "published": "2006-05-29T13:27:38Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0605131v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0609010v1",
        "title": "An effective edge--directed frequency filter for removal of aliasing in\n  upsampled images",
        "summary": "  Raster images can have a range of various distortions connected to their\nraster structure. Upsampling them might in effect substantially yield the\nraster structure of the original image, known as aliasing. The upsampling\nitself may introduce aliasing into the upsampled image as well. The presented\nmethod attempts to remove the aliasing using frequency filters based on the\ndiscrete fast Fourier transform, and applied directionally in certain regions\nplaced along the edges in the image.\n  As opposed to some anisotropic smoothing methods, the presented algorithm\naims to selectively reduce only the aliasing, preserving the sharpness of image\ndetails.\n  The method can be used as a post--processing filter along with various\nupsampling algorithms. It was experimentally shown that the method can improve\nthe visual quality of the upsampled images.\n",
        "published": "2006-09-04T13:04:57Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0609010v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0609100v1",
        "title": "Total Variation Minimization and Graph Cuts for Moving Objects\n  Segmentation",
        "summary": "  In this paper, we are interested in the application to video segmentation of\nthe discrete shape optimization problem involving the shape weighted perimeter\nand an additional term depending on a parameter. Based on recent works and in\nparticular the one of Darbon and Sigelle, we justify the equivalence of the\nshape optimization problem and a weighted total variation regularization. For\nsolving this problem, we adapt the projection algorithm proposed recently for\nsolving the basic TV regularization problem. Another solution to the shape\noptimization investigated here is the graph cut technique. Both methods have\nthe advantage to lead to a global minimum. Since we can distinguish moving\nobjects from static elements of a scene by analyzing norm of the optical flow\nvectors, we choose the optical flow norm as initial data. In order to have the\ncontour as close as possible to an edge in the image, we use a classical edge\ndetector function as the weight of the weighted total variation. This model has\nbeen used in one of our former works. We also apply the same methods to a video\nsegmentation model used by Jehan-Besson, Barlaud and Aubert. In this case, only\nstandard perimeter is incorporated in the shape functional. We also propose\nanother way for finding moving objects by using an a contrario detection of\nobjects on the image obtained by solving the Rudin-Osher-Fatemi Total Variation\nregularization problem.We can notice the segmentation can be associated to a\nlevel set in the former methods.\n",
        "published": "2006-09-18T06:40:44Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0609100v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0609164v1",
        "title": "Conditional Expressions for Blind Deconvolution: Multi-point form",
        "summary": "  We present conditional expression (CE) for finding blurs convolved in given\nimages. The CE is given in terms of the zero-values of the blurs evaluated at\nmulti-point. The CE can detect multiple blur all at once. We illustrate the\nmultiple blur-detection by using a test image.\n",
        "published": "2006-09-29T13:48:35Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0609164v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0609165v1",
        "title": "Simple method to eliminate blur based on Lane and Bates algorithm",
        "summary": "  A simple search method for finding a blur convolved in a given image is\npresented. The method can be easily extended to a large blur. The method has\nbeen experimentally tested with a model blurred image.\n",
        "published": "2006-09-29T13:50:12Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0609165v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0610002v1",
        "title": "Conditional Expressions for Blind Deconvolution: Derivative form",
        "summary": "  We developed novel conditional expressions (CEs) for Lane and Bates' blind\ndeconvolution. The CEs are given in term of the derivatives of the zero-values\nof the z-transform of given images. The CEs make it possible to automatically\ndetect multiple blur convolved in the given images all at once without\nperforming any analysis of the zero-sheets of the given images. We illustrate\nthe multiple blur-detection by the CEs for a model image\n",
        "published": "2006-09-30T08:05:02Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0610002v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0610059v2",
        "title": "Camera motion estimation through planar deformation determination",
        "summary": "  In this paper, we propose a global method for estimating the motion of a\ncamera which films a static scene. Our approach is direct, fast and robust, and\ndeals with adjacent frames of a sequence. It is based on a quadratic\napproximation of the deformation between two images, in the case of a scene\nwith constant depth in the camera coordinate system. This condition is very\nrestrictive but we show that provided translation and depth inverse variations\nare small enough, the error on optical flow involved by the approximation of\ndepths by a constant is small. In this context, we propose a new model of\ncamera motion, that allows to separate the image deformation in a similarity\nand a ``purely'' projective application, due to change of optical axis\ndirection. This model leads to a quadratic approximation of image deformation\nthat we estimate with an M-estimator; we can immediatly deduce camera motion\nparameters.\n",
        "published": "2006-10-11T09:31:52Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0610059v2"
    },
    {
        "id": "http://arxiv.org/abs/cs/0611115v1",
        "title": "A higher-order active contour model of a `gas of circles' and its\n  application to tree crown extraction",
        "summary": "  Many image processing problems involve identifying the region in the image\ndomain occupied by a given entity in the scene. Automatic solution of these\nproblems requires models that incorporate significant prior knowledge about the\nshape of the region. Many methods for including such knowledge run into\ndifficulties when the topology of the region is unknown a priori, for example\nwhen the entity is composed of an unknown number of similar objects.\nHigher-order active contours (HOACs) represent one method for the modelling of\nnon-trivial prior knowledge about shape without necessarily constraining region\ntopology, via the inclusion of non-local interactions between region boundary\npoints in the energy defining the model. The case of an unknown number of\ncircular objects arises in a number of domains, e.g. medical, biological,\nnanotechnological, and remote sensing imagery. Regions composed of an a priori\nunknown number of circles may be referred to as a `gas of circles'. In this\nreport, we present a HOAC model of a `gas of circles'. In order to guarantee\nstable circles, we conduct a stability analysis via a functional Taylor\nexpansion of the HOAC energy around a circular shape. This analysis fixes one\nof the model parameters in terms of the others and constrains the rest. In\nconjunction with a suitable likelihood energy, we apply the model to the\nextraction of tree crowns from aerial imagery, and show that the new model\noutperforms other techniques.\n",
        "published": "2006-11-22T13:44:11Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0611115v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0701150v1",
        "title": "Contains and Inside relationships within combinatorial Pyramids",
        "summary": "  Irregular pyramids are made of a stack of successively reduced graphs\nembedded in the plane. Such pyramids are used within the segmentation framework\nto encode a hierarchy of partitions. The different graph models used within the\nirregular pyramid framework encode different types of relationships between\nregions. This paper compares different graph models used within the irregular\npyramid framework according to a set of relationships between regions. We also\ndefine a new algorithm based on a pyramid of combinatorial maps which allows to\ndetermine if one region contains the other using only local calculus.\n",
        "published": "2007-01-24T15:13:06Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0701150v1"
    },
    {
        "id": "http://arxiv.org/abs/cs/0703053v1",
        "title": "Extraction of cartographic objects in high resolution satellite images\n  for object model generation",
        "summary": "  The aim of this study is to detect man-made cartographic objects in\nhigh-resolution satellite images. New generation satellites offer a sub-metric\nspatial resolution, in which it is possible (and necessary) to develop methods\nat object level rather than at pixel level, and to exploit structural features\nof objects. With this aim, a method to generate structural object models from\nmanually segmented images has been developed. To generate the model from\nnon-segmented images, extraction of the objects from the sample images is\nrequired. A hybrid method of extraction (both in terms of input sources and\nsegmentation algorithms) is proposed: A region based segmentation is applied on\na 10 meter resolution multi-spectral image. The result is used as marker in a\n\"marker-controlled watershed method using edges\" on a 2.5 meter resolution\npanchromatic image. Very promising results have been obtained even on images\nwhere the limits of the target objects are not apparent.\n",
        "published": "2007-03-12T15:57:23Z",
        "pdf_link": "http://arxiv.org/pdf/cs/0703053v1"
    },
    {
        "id": "http://arxiv.org/abs/0704.1267v1",
        "title": "Text Line Segmentation of Historical Documents: a Survey",
        "summary": "  There is a huge amount of historical documents in libraries and in various\nNational Archives that have not been exploited electronically. Although\nautomatic reading of complete pages remains, in most cases, a long-term\nobjective, tasks such as word spotting, text/image alignment, authentication\nand extraction of specific fields are in use today. For all these tasks, a\nmajor step is document segmentation into text lines. Because of the low quality\nand the complexity of these documents (background noise, artifacts due to\naging, interfering lines),automatic text line segmentation remains an open\nresearch field. The objective of this paper is to present a survey of existing\nmethods, developed during the last decade, and dedicated to documents of\nhistorical interest.\n",
        "published": "2007-04-10T16:26:42Z",
        "pdf_link": "http://arxiv.org/pdf/0704.1267v1"
    },
    {
        "id": "http://arxiv.org/abs/0705.0214v1",
        "title": "Riemannian level-set methods for tensor-valued data",
        "summary": "  We present a novel approach for the derivation of PDE modeling\ncurvature-driven flows for matrix-valued data. This approach is based on the\nRiemannian geometry of the manifold of Symmetric Positive Definite Matrices\nPos(n).\n",
        "published": "2007-05-02T07:32:58Z",
        "pdf_link": "http://arxiv.org/pdf/0705.0214v1"
    },
    {
        "id": "http://arxiv.org/abs/0705.0449v1",
        "title": "Multiresolution Approximation of Polygonal Curves in Linear Complexity",
        "summary": "  We propose a new algorithm to the problem of polygonal curve approximation\nbased on a multiresolution approach. This algorithm is suboptimal but still\nmaintains some optimality between successive levels of resolution using dynamic\nprogramming. We show theoretically and experimentally that this algorithm has a\nlinear complexity in time and space. We experimentally compare the outcomes of\nour algorithm to the optimal \"full search\" dynamic programming solution and\nfinally to classical merge and split approaches. The experimental evaluations\nconfirm the theoretical derivations and show that the proposed approach\nevaluated on 2D coastal maps either show a lower time complexity or provide\npolygonal approximations closer to the input discrete curves.\n",
        "published": "2007-05-03T12:47:31Z",
        "pdf_link": "http://arxiv.org/pdf/0705.0449v1"
    },
    {
        "id": "http://arxiv.org/abs/0705.0781v1",
        "title": "Medical Image Segmentation and Localization using Deformable Templates",
        "summary": "  This paper presents deformable templates as a tool for segmentation and\nlocalization of biological structures in medical images. Structures are\nrepresented by a prototype template, combined with a parametric warp mapping\nused to deform the original shape. The localization procedure is achieved using\na multi-stage, multi-resolution algorithm de-signed to reduce computational\ncomplexity and time. The algorithm initially identifies regions in the image\nmost likely to contain the desired objects and then examines these regions at\nprogressively increasing resolutions. The final stage of the algorithm involves\nwarping the prototype template to match the localized objects. The algorithm is\npresented along with the results of four example applications using MRI, x-ray\nand ultrasound images.\n",
        "published": "2007-05-06T06:02:46Z",
        "pdf_link": "http://arxiv.org/pdf/0705.0781v1"
    },
    {
        "id": "http://arxiv.org/abs/0705.0828v1",
        "title": "Enhancement of Noisy Planar Nuclear Medicine Images using Mean Field\n  Annealing",
        "summary": "  Nuclear medicine (NM) images inherently suffer from large amounts of noise\nand blur. The purpose of this research is to reduce the noise and blur while\nmaintaining image integrity for improved diagnosis. The proposed solution is to\nincrease image quality after the standard pre- and post-processing undertaken\nby a gamma camera system. Mean Field Annealing (MFA) is the image processing\ntechnique used in this research. It is a computational iterative technique that\nmakes use of the Point Spread Function (PSF) and the noise associated with the\nNM image. MFA is applied to NM images with the objective of reducing noise\nwhile not compromising edge integrity. Using a sharpening filter as a\npost-processing technique (after MFA) yields image enhancement of planar NM\nimages.\n",
        "published": "2007-05-06T23:08:04Z",
        "pdf_link": "http://arxiv.org/pdf/0705.0828v1"
    },
    {
        "id": "http://arxiv.org/abs/0705.0952v1",
        "title": "An Independent Evaluation of Subspace Face Recognition Algorithms",
        "summary": "  This paper explores a comparative study of both the linear and kernel\nimplementations of three of the most popular Appearance-based Face Recognition\nprojection classes, these being the methodologies of Principal Component\nAnalysis, Linear Discriminant Analysis and Independent Component Analysis. The\nexperimental procedure provides a platform of equal working conditions and\nexamines the ten algorithms in the categories of expression, illumination,\nocclusion and temporal delay. The results are then evaluated based on a\nsequential combination of assessment tools that facilitate both intuitive and\nstatistical decisiveness among the intra and interclass comparisons. The best\ncategorical algorithms are then incorporated into a hybrid methodology, where\nthe advantageous effects of fusion strategies are considered.\n",
        "published": "2007-05-07T19:19:55Z",
        "pdf_link": "http://arxiv.org/pdf/0705.0952v1"
    },
    {
        "id": "http://arxiv.org/abs/0705.3593v2",
        "title": "MI image registration using prior knowledge",
        "summary": "  Subtraction of aligned images is a means to assess changes in a wide variety\nof clinical applications. In this paper we explore the information theoretical\norigin of Mutual Information (MI), which is based on Shannon's entropy.However,\nthe interpretation of standard MI registration as a communication channel\nsuggests that MI is too restrictive a criterion. In this paper the concept of\nMutual Information (MI) is extended to (Normalized) Focussed Mutual Information\n(FMI) to incorporate prior knowledge to overcome some shortcomings of MI. We\nuse this to develop new methodologies to successfully address specific\nregistration problems, the follow-up of dental restorations, cephalometry, and\nthe monitoring of implants.\n",
        "published": "2007-05-24T14:41:11Z",
        "pdf_link": "http://arxiv.org/pdf/0705.3593v2"
    },
    {
        "id": "http://arxiv.org/abs/0706.0300v1",
        "title": "Automatic Detection of Pulmonary Embolism using Computational\n  Intelligence",
        "summary": "  This article describes the implementation of a system designed to\nautomatically detect the presence of pulmonary embolism in lung scans. These\nimages are firstly segmented, before alignment and feature extraction using\nPCA. The neural network was trained using the Hybrid Monte Carlo method,\nresulting in a committee of 250 neural networks and good results are obtained.\n",
        "published": "2007-06-03T05:17:38Z",
        "pdf_link": "http://arxiv.org/pdf/0706.0300v1"
    },
    {
        "id": "http://arxiv.org/abs/0709.1771v1",
        "title": "Variational local structure estimation for image super-resolution",
        "summary": "  Super-resolution is an important but difficult problem in image/video\nprocessing. If a video sequence or some training set other than the given\nlow-resolution image is available, this kind of extra information can greatly\naid in the reconstruction of the high-resolution image. The problem is\nsubstantially more difficult with only a single low-resolution image on hand.\nThe image reconstruction methods designed primarily for denoising is\ninsufficient for super-resolution problem in the sense that it tends to\noversmooth images with essentially no noise. We propose a new adaptive linear\ninterpolation method based on variational method and inspired by local linear\nembedding (LLE). The experimental result shows that our method avoids the\nproblem of oversmoothing and preserves image structures well.\n",
        "published": "2007-09-12T08:41:36Z",
        "pdf_link": "http://arxiv.org/pdf/0709.1771v1"
    },
    {
        "id": "http://arxiv.org/abs/0709.1920v2",
        "title": "Bandwidth selection for kernel estimation in mixed multi-dimensional\n  spaces",
        "summary": "  Kernel estimation techniques, such as mean shift, suffer from one major\ndrawback: the kernel bandwidth selection. The bandwidth can be fixed for all\nthe data set or can vary at each points. Automatic bandwidth selection becomes\na real challenge in case of multidimensional heterogeneous features. This paper\npresents a solution to this problem. It is an extension of \\cite{Comaniciu03a}\nwhich was based on the fundamental property of normal distributions regarding\nthe bias of the normalized density gradient. The selection is done iteratively\nfor each type of features, by looking for the stability of local bandwidth\nestimates across a predefined range of bandwidths. A pseudo balloon mean shift\nfiltering and partitioning are introduced. The validity of the method is\ndemonstrated in the context of color image segmentation based on a\n5-dimensional space.\n",
        "published": "2007-09-12T16:02:25Z",
        "pdf_link": "http://arxiv.org/pdf/0709.1920v2"
    },
    {
        "id": "http://arxiv.org/abs/0709.3013v2",
        "title": "Supervised learning on graphs of spatio-temporal similarity in satellite\n  image sequences",
        "summary": "  High resolution satellite image sequences are multidimensional signals\ncomposed of spatio-temporal patterns associated to numerous and various\nphenomena. Bayesian methods have been previously proposed in (Heas and Datcu,\n2005) to code the information contained in satellite image sequences in a graph\nrepresentation using Bayesian methods. Based on such a representation, this\npaper further presents a supervised learning methodology of semantics\nassociated to spatio-temporal patterns occurring in satellite image sequences.\nIt enables the recognition and the probabilistic retrieval of similar events.\nIndeed, graphs are attached to statistical models for spatio-temporal\nprocesses, which at their turn describe physical changes in the observed scene.\nTherefore, we adjust a parametric model evaluating similarity types between\ngraph patterns in order to represent user-specific semantics attached to\nspatio-temporal phenomena. The learning step is performed by the incremental\ndefinition of similarity types via user-provided spatio-temporal pattern\nexamples attached to positive or/and negative semantics. From these examples,\nprobabilities are inferred using a Bayesian network and a Dirichlet model. This\nenables to links user interest to a specific similarity model between graph\npatterns. According to the current state of learning, semantic posterior\nprobabilities are updated for all possible graph patterns so that similar\nspatio-temporal phenomena can be recognized and retrieved from the image\nsequence. Few experiments performed on a multi-spectral SPOT image sequence\nillustrate the proposed spatio-temporal recognition method.\n",
        "published": "2007-09-19T13:18:18Z",
        "pdf_link": "http://arxiv.org/pdf/0709.3013v2"
    },
    {
        "id": "http://arxiv.org/abs/0710.0043v2",
        "title": "Graph rigidity, Cyclic Belief Propagation and Point Pattern Matching",
        "summary": "  A recent paper \\cite{CaeCaeSchBar06} proposed a provably optimal, polynomial\ntime method for performing near-isometric point pattern matching by means of\nexact probabilistic inference in a chordal graphical model. Their fundamental\nresult is that the chordal graph in question is shown to be globally rigid,\nimplying that exact inference provides the same matching solution as exact\ninference in a complete graphical model. This implies that the algorithm is\noptimal when there is no noise in the point patterns. In this paper, we present\na new graph which is also globally rigid but has an advantage over the graph\nproposed in \\cite{CaeCaeSchBar06}: its maximal clique size is smaller,\nrendering inference significantly more efficient. However, our graph is not\nchordal and thus standard Junction Tree algorithms cannot be directly applied.\nNevertheless, we show that loopy belief propagation in such a graph converges\nto the optimal solution. This allows us to retain the optimality guarantee in\nthe noiseless case, while substantially reducing both memory requirements and\nprocessing time. Our experimental results show that the accuracy of the\nproposed solution is indistinguishable from that of \\cite{CaeCaeSchBar06} when\nthere is noise in the point patterns.\n",
        "published": "2007-09-29T06:19:09Z",
        "pdf_link": "http://arxiv.org/pdf/0710.0043v2"
    },
    {
        "id": "http://arxiv.org/abs/0710.0243v1",
        "title": "High-Order Nonparametric Belief-Propagation for Fast Image Inpainting",
        "summary": "  In this paper, we use belief-propagation techniques to develop fast\nalgorithms for image inpainting. Unlike traditional gradient-based approaches,\nwhich may require many iterations to converge, our techniques achieve\ncompetitive results after only a few iterations. On the other hand, while\nbelief-propagation techniques are often unable to deal with high-order models\ndue to the explosion in the size of messages, we avoid this problem by\napproximating our high-order prior model using a Gaussian mixture. By using\nsuch an approximation, we are able to inpaint images quickly while at the same\ntime retaining good visual results.\n",
        "published": "2007-10-01T09:18:36Z",
        "pdf_link": "http://arxiv.org/pdf/0710.0243v1"
    },
    {
        "id": "http://arxiv.org/abs/0710.2037v2",
        "title": "An Affinity Propagation Based method for Vector Quantization Codebook\n  Design",
        "summary": "  In this paper, we firstly modify a parameter in affinity propagation (AP) to\nimprove its convergence ability, and then, we apply it to vector quantization\n(VQ) codebook design problem. In order to improve the quality of the resulted\ncodebook, we combine the improved AP (IAP) with the conventional LBG algorithm\nto generate an effective algorithm call IAP-LBG. According to the experimental\nresults, the proposed method not only enhances the convergence abilities but\nalso is capable of providing higher-quality codebooks than conventional LBG\nmethod.\n",
        "published": "2007-10-10T15:12:20Z",
        "pdf_link": "http://arxiv.org/pdf/0710.2037v2"
    },
    {
        "id": "http://arxiv.org/abs/0710.2231v1",
        "title": "Comparison and Combination of State-of-the-art Techniques for\n  Handwritten Character Recognition: Topping the MNIST Benchmark",
        "summary": "  Although the recognition of isolated handwritten digits has been a research\ntopic for many years, it continues to be of interest for the research community\nand for commercial applications. We show that despite the maturity of the\nfield, different approaches still deliver results that vary enough to allow\nimprovements by using their combination. We do so by choosing four\nwell-motivated state-of-the-art recognition systems for which results on the\nstandard MNIST benchmark are available. When comparing the errors made, we\nobserve that the errors made differ between all four systems, suggesting the\nuse of classifier combination. We then determine the error rate of a\nhypothetical system that combines the output of the four systems. The result\nobtained in this manner is an error rate of 0.35% on the MNIST data, the best\nresult published so far. We furthermore discuss the statistical significance of\nthe combined result and of the results of the individual classifiers.\n",
        "published": "2007-10-11T12:22:27Z",
        "pdf_link": "http://arxiv.org/pdf/0710.2231v1"
    },
    {
        "id": "http://arxiv.org/abs/0712.0131v1",
        "title": "Learning Similarity for Character Recognition and 3D Object Recognition",
        "summary": "  I describe an approach to similarity motivated by Bayesian methods. This\nyields a similarity function that is learnable using a standard Bayesian\nmethods. The relationship of the approach to variable kernel and variable\nmetric methods is discussed. The approach is related to variable kernel\nExperimental results on character recognition and 3D object recognition are\npresented..\n",
        "published": "2007-12-02T10:02:01Z",
        "pdf_link": "http://arxiv.org/pdf/0712.0131v1"
    },
    {
        "id": "http://arxiv.org/abs/0712.0136v1",
        "title": "Learning View Generalization Functions",
        "summary": "  Learning object models from views in 3D visual object recognition is usually\nformulated either as a function approximation problem of a function describing\nthe view-manifold of an object, or as that of learning a class-conditional\ndensity. This paper describes an alternative framework for learning in visual\nobject recognition, that of learning the view-generalization function. Using\nthe view-generalization function, an observer can perform Bayes-optimal 3D\nobject recognition given one or more 2D training views directly, without the\nneed for a separate model acquisition step. The paper shows that view\ngeneralization functions can be computationally practical by restating two\nwidely-used methods, the eigenspace and linear combination of views approaches,\nin a view generalization framework. The paper relates the approach to recent\nmethods for object recognition based on non-uniform blurring. The paper\npresents results both on simulated 3D ``paperclip'' objects and real-world\nimages from the COIL-100 database showing that useful view-generalization\nfunctions can be realistically be learned from a comparatively small number of\ntraining examples.\n",
        "published": "2007-12-02T10:54:40Z",
        "pdf_link": "http://arxiv.org/pdf/0712.0136v1"
    },
    {
        "id": "http://arxiv.org/abs/0712.0137v1",
        "title": "View Based Methods can achieve Bayes-Optimal 3D Recognition",
        "summary": "  This paper proves that visual object recognition systems using only 2D\nEuclidean similarity measurements to compare object views against previously\nseen views can achieve the same recognition performance as observers having\naccess to all coordinate information and able of using arbitrary 3D models\ninternally. Furthermore, it demonstrates that such systems do not require more\ntraining views than Bayes-optimal 3D model-based systems. For building computer\nvision systems, these results imply that using view-based or appearance-based\ntechniques with carefully constructed combination of evidence mechanisms may\nnot be at a disadvantage relative to 3D model-based systems. For computational\napproaches to human vision, they show that it is impossible to distinguish\nview-based and 3D model-based techniques for 3D object recognition solely by\ncomparing the performance achievable by human and 3D model-based systems.}\n",
        "published": "2007-12-02T11:02:37Z",
        "pdf_link": "http://arxiv.org/pdf/0712.0137v1"
    },
    {
        "id": "http://arxiv.org/abs/0712.1878v1",
        "title": "Hierarchy construction schemes within the Scale set framework",
        "summary": "  Segmentation algorithms based on an energy minimisation framework often\ndepend on a scale parameter which balances a fit to data and a regularising\nterm. Irregular pyramids are defined as a stack of graphs successively reduced.\nWithin this framework, the scale is often defined implicitly as the height in\nthe pyramid. However, each level of an irregular pyramid can not usually be\nreadily associated to the global optimum of an energy or a global criterion on\nthe base level graph. This last drawback is addressed by the scale set\nframework designed by Guigues. The methods designed by this author allow to\nbuild a hierarchy and to design cuts within this hierarchy which globally\nminimise an energy. This paper studies the influence of the construction scheme\nof the initial hierarchy on the resulting optimal cuts. We propose one\nsequential and one parallel method with two variations within both. Our\nsequential methods provide partitions near the global optima while parallel\nmethods require less execution times than the sequential method of Guigues even\non sequential machines.\n",
        "published": "2007-12-12T07:45:08Z",
        "pdf_link": "http://arxiv.org/pdf/0712.1878v1"
    },
    {
        "id": "http://arxiv.org/abs/0712.2923v1",
        "title": "A Class of LULU Operators on Multi-Dimensional Arrays",
        "summary": "  The LULU operators for sequences are extended to multi-dimensional arrays via\nthe morphological concept of connection in a way which preserves their\nessential properties, e.g. they are separators and form a four element fully\nordered semi-group. The power of the operators is demonstrated by deriving a\ntotal variation preserving discrete pulse decomposition of images.\n",
        "published": "2007-12-18T10:43:23Z",
        "pdf_link": "http://arxiv.org/pdf/0712.2923v1"
    },
    {
        "id": "http://arxiv.org/abs/0712.4015v1",
        "title": "A Fast Hierarchical Multilevel Image Segmentation Method using Unbiased\n  Estimators",
        "summary": "  This paper proposes a novel method for segmentation of images by hierarchical\nmultilevel thresholding. The method is global, agglomerative in nature and\ndisregards pixel locations. It involves the optimization of the ratio of the\nunbiased estimators of within class to between class variances. We obtain a\nrecursive relation at each step for the variances which expedites the process.\nThe efficacy of the method is shown in a comparison with some well-known\nmethods.\n",
        "published": "2007-12-24T17:11:56Z",
        "pdf_link": "http://arxiv.org/pdf/0712.4015v1"
    },
    {
        "id": "http://arxiv.org/abs/0801.4807v1",
        "title": "Automatic Text Area Segmentation in Natural Images",
        "summary": "  We present a hierarchical method for segmenting text areas in natural images.\nThe method assumes that the text is written with a contrasting color on a more\nor less uniform background. But no assumption is made regarding the language or\ncharacter set used to write the text. In particular, the text can contain\nsimple graphics or symbols. The key feature of our approach is that we first\nconcentrate on finding the background of the text, before testing whether there\nis actually text on the background. Since uniform areas are easy to find in\nnatural images, and since text backgrounds define areas which contain \"holes\"\n(where the text is written) we thus look for uniform areas containing \"holes\"\nand label them as text backgrounds candidates. Each candidate area is then\nfurther tested for the presence of text within its convex hull. We tested our\nmethod on a database of 65 images including English and Urdu text. The method\ncorrectly segmented all the text areas in 63 of these images, and in only 4 of\nthese were areas that do not contain text also segmented.\n",
        "published": "2008-01-31T01:46:32Z",
        "pdf_link": "http://arxiv.org/pdf/0801.4807v1"
    },
    {
        "id": "http://arxiv.org/abs/0802.3528v1",
        "title": "Wavelet and Curvelet Moments for Image Classification: Application to\n  Aggregate Mixture Grading",
        "summary": "  We show the potential for classifying images of mixtures of aggregate, based\nthemselves on varying, albeit well-defined, sizes and shapes, in order to\nprovide a far more effective approach compared to the classification of\nindividual sizes and shapes. While a dominant (additive, stationary) Gaussian\nnoise component in image data will ensure that wavelet coefficients are of\nGaussian distribution, long tailed distributions (symptomatic, for example, of\nextreme values) may well hold in practice for wavelet coefficients. Energy (2nd\norder moment) has often been used for image characterization for image\ncontent-based retrieval, and higher order moments may be important also, not\nleast for capturing long tailed distributional behavior. In this work, we\nassess 2nd, 3rd and 4th order moments of multiresolution transform -- wavelet\nand curvelet transform -- coefficients as features. As analysis methodology,\ntaking account of image types, multiresolution transforms, and moments of\ncoefficients in the scales or bands, we use correspondence analysis as well as\nk-nearest neighbors supervised classification.\n",
        "published": "2008-02-24T18:25:51Z",
        "pdf_link": "http://arxiv.org/pdf/0802.3528v1"
    },
    {
        "id": "http://arxiv.org/abs/0803.1586v1",
        "title": "Spatio-activity based object detection",
        "summary": "  We present the SAMMI lightweight object detection method which has a high\nlevel of accuracy and robustness, and which is able to operate in an\nenvironment with a large number of cameras. Background modeling is based on DCT\ncoefficients provided by cameras. Foreground detection uses similarity in\ntemporal characteristics of adjacent blocks of pixels, which is a\ncomputationally inexpensive way to make use of object coherence. Scene model\nupdating uses the approximated median method for improved performance.\nEvaluation at pixel level and application level shows that SAMMI object\ndetection performs better and faster than the conventional Mixture of Gaussians\nmethod.\n",
        "published": "2008-03-11T13:40:42Z",
        "pdf_link": "http://arxiv.org/pdf/0803.1586v1"
    },
    {
        "id": "http://arxiv.org/abs/0803.2812v2",
        "title": "Using Spatially Varying Pixels Exposures and Bayer-covered Photosensors\n  for High Dynamic Range Imaging",
        "summary": "  The method of a linear high dynamic range imaging using solid-state\nphotosensors with Bayer colour filters array is provided in this paper. Using\ninformation from neighbour pixels, it is possible to reconstruct linear images\nwith wide dynamic range from the oversaturated images. Bayer colour filters\narray is considered as an array of neutral filters in a quasimonochromatic\nlight. If the camera's response function to the desirable light source is known\nthen one can calculate correction coefficients to reconstruct oversaturated\nimages. Reconstructed images are linearized in order to provide a linear high\ndynamic range images for optical-digital imaging systems. The calibration\nprocedure for obtaining the camera's response function to the desired light\nsource is described. Experimental results of the reconstruction of the images\nfrom the oversaturated images are presented for red, green, and blue\nquasimonochromatic light sources. Quantitative analysis of the accuracy of the\nreconstructed images is provided.\n",
        "published": "2008-03-19T14:55:15Z",
        "pdf_link": "http://arxiv.org/pdf/0803.2812v2"
    },
    {
        "id": "http://arxiv.org/abs/0804.1982v2",
        "title": "Linear Time Recognition Algorithms for Topological Invariants in 3D",
        "summary": "  In this paper, we design linear time algorithms to recognize and determine\ntopological invariants such as the genus and homology groups in 3D. These\nproperties can be used to identify patterns in 3D image recognition. This has\ntremendous amount of applications in 3D medical image analysis. Our method is\nbased on cubical images with direct adjacency, also called (6,26)-connectivity\nimages in discrete geometry. According to the fact that there are only six\ntypes of local surface points in 3D and a discrete version of the well-known\nGauss-Bonnett Theorem in differential geometry, we first determine the genus of\na closed 2D-connected component (a closed digital surface). Then, we use\nAlexander duality to obtain the homology groups of a 3D object in 3D space.\n",
        "published": "2008-04-12T03:13:33Z",
        "pdf_link": "http://arxiv.org/pdf/0804.1982v2"
    },
    {
        "id": "http://arxiv.org/abs/0806.0689v1",
        "title": "Directional Cross Diamond Search Algorithm for Fast Block Motion\n  Estimation",
        "summary": "  In block-matching motion estimation (BMME), the search patterns have a\nsignificant impact on the algorithm's performance, both the search speed and\nthe search quality. The search pattern should be designed to fit the motion\nvector probability (MVP) distribution characteristics of the real-world\nsequences. In this paper, we build a directional model of MVP distribution to\ndescribe the directional-center-biased characteristic of the MVP distribution\nand the directional characteristics of the conditional MVP distribution more\nexactly based on the detailed statistical data of motion vectors of eighteen\npopular sequences. Three directional search patterns are firstly designed by\nutilizing the directional characteristics and they are the smallest search\npatterns among the popular ones. A new algorithm is proposed using the\nhorizontal cross search pattern as the initial step and the horizontal/vertical\ndiamond search pattern as the subsequent step for the fast BMME, which is\ncalled the directional cross diamond search (DCDS) algorithm. The DCDS\nalgorithm can obtain the motion vector with fewer search points than CDS, DS or\nHEXBS while maintaining the similar or even better search quality. The gain on\nspeedup of DCDS over CDS or DS can be up to 54.9%. The simulation results show\nthat DCDS is efficient, effective and robust, and it can always give the faster\nsearch speed on different sequences than other fast block-matching algorithm in\ncommon use.\n",
        "published": "2008-06-04T05:05:19Z",
        "pdf_link": "http://arxiv.org/pdf/0806.0689v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.1446v1",
        "title": "Fast Wavelet-Based Visual Classification",
        "summary": "  We investigate a biologically motivated approach to fast visual\nclassification, directly inspired by the recent work of Serre et al.\nSpecifically, trading-off biological accuracy for computational efficiency, we\nexplore using wavelet and grouplet-like transforms to parallel the tuning of\nvisual cortex V1 and V2 cells, alternated with max operations to achieve scale\nand translation invariance. A feature selection procedure is applied during\nlearning to accelerate recognition. We introduce a simple attention-like\nfeedback mechanism, significantly improving recognition and robustness in\nmultiple-object scenes. In experiments, the proposed algorithm achieves or\nexceeds state-of-the-art success rate on object recognition, texture and\nsatellite image classification, language identification and sound\nclassification.\n",
        "published": "2008-06-08T10:15:04Z",
        "pdf_link": "http://arxiv.org/pdf/0806.1446v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.1984v1",
        "title": "Classification of curves in 2D and 3D via affine integral signatures",
        "summary": "  We propose a robust classification algorithm for curves in 2D and 3D, under\nthe special and full groups of affine transformations. To each plane or spatial\ncurve we assign a plane signature curve. Curves, equivalent under an affine\ntransformation, have the same signature. The signatures introduced in this\npaper are based on integral invariants, which behave much better on noisy\nimages than classically known differential invariants. The comparison with\nother types of invariants is given in the introduction. Though the integral\ninvariants for planar curves were known before, the affine integral invariants\nfor spatial curves are proposed here for the first time. Using the inductive\nvariation of the moving frame method we compute affine invariants in terms of\nEuclidean invariants. We present two types of signatures, the global signature\nand the local signature. Both signatures are independent of parameterization\n(curve sampling). The global signature depends on the choice of the initial\npoint and does not allow us to compare fragments of curves, and is therefore\nsensitive to occlusions. The local signature, although is slightly more\nsensitive to noise, is independent of the choice of the initial point and is\nnot sensitive to occlusions in an image. It helps establish local equivalence\nof curves. The robustness of these invariants and signatures in their\napplication to the problem of classification of noisy spatial curves extracted\nfrom a 3D object is analyzed.\n",
        "published": "2008-06-12T01:12:25Z",
        "pdf_link": "http://arxiv.org/pdf/0806.1984v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.3885v1",
        "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  1: the framework",
        "summary": "  Adams and Bishop have proposed in 1994 a novel region growing algorithm\ncalled seeded region growing by pixels aggregation (SRGPA). This paper\nintroduces a framework to implement an algorithm using SRGPA. This framework is\nbuilt around two concepts: localization and organization of applied action.\nThis conceptualization gives a quick implementation of algorithms, a direct\ntranslation between the mathematical idea and the numerical implementation, and\nan improvement of algorithms efficiency.\n",
        "published": "2008-06-24T13:43:06Z",
        "pdf_link": "http://arxiv.org/pdf/0806.3885v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.3887v1",
        "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  2: how to localize a final partition invariant about the seeded region\n  initialisation order",
        "summary": "  In the previous paper, we have conceptualized the localization and the\norganization of seeded region growing by pixels aggregation (SRGPA) but we do\nnot give the issue when there is a collision between two distinct regions\nduring the growing process. In this paper, we propose two implementations to\nmanage two classical growing processes: one without a boundary region region to\ndivide the other regions and another with. Unfortunately, as noticed by Mehnert\nand Jakway (1997), this partition depends on the seeded region initialisation\norder (SRIO). We propose a growing process, invariant about SRIO such as the\nboundary region is the set of ambiguous pixels.\n",
        "published": "2008-06-24T13:34:15Z",
        "pdf_link": "http://arxiv.org/pdf/0806.3887v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.3928v1",
        "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  3: a wide range of algorithms",
        "summary": "  In the two previous papers of this serie, we have created a library, called\nPopulation, dedicated to seeded region growing by pixels aggregation and we\nhave proposed different growing processes to get a partition with or without a\nboundary region to divide the other regions or to get a partition invariant\nabout the seeded region initialisation order. Using this work, we implement\nsome algorithms belonging to the field of SRGPA using this library and these\ngrowing processes.\n",
        "published": "2008-06-24T17:02:47Z",
        "pdf_link": "http://arxiv.org/pdf/0806.3928v1"
    },
    {
        "id": "http://arxiv.org/abs/0806.3939v2",
        "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  4: Simple, generic and robust extraction of grains in granular materials\n  obtained by X-ray tomography",
        "summary": "  This paper proposes a simple, generic and robust method to extract the grains\nfrom experimental tridimensionnal images of granular materials obtained by\nX-ray tomography. This extraction has two steps: segmentation and splitting.\nFor the segmentation step, if there is a sufficient contrast between the\ndifferent components, a classical threshold procedure followed by a succession\nof morphological filters can be applied. If not, and if the boundary needs to\nbe localized precisely, a watershed transformation controlled by labels is\napplied. The basement of this transformation is to localize a label included in\nthe component and another label in the component complementary. A \"soft\"\nthreshold following by an opening is applied on the initial image to localize a\nlabel in a component. For any segmentation procedure, the visualisation shows a\nproblem: some groups of two grains, close one to each other, become connected.\nSo if a classical cluster procedure is applied on the segmented binary image,\nthese numerical connected grains are considered as a single grain. To overcome\nthis problem, we applied a procedure introduced by L. Vincent in 1993. This\ngrains extraction is tested for various complexes porous media and granular\nmaterial, to predict various properties (diffusion, electrical conductivity,\ndeformation field) in a good agreement with experiment data.\n",
        "published": "2008-06-24T17:40:25Z",
        "pdf_link": "http://arxiv.org/pdf/0806.3939v2"
    },
    {
        "id": "http://arxiv.org/abs/0807.2047v3",
        "title": "The Five Points Pose Problem : A New and Accurate Solution Adapted to\n  any Geometric Configuration",
        "summary": "  The goal of this paper is to estimate directly the rotation and translation\nbetween two stereoscopic images with the help of five homologous points. The\nmethodology presented does not mix the rotation and translation parameters,\nwhich is comparably an important advantage over the methods using the\nwell-known essential matrix. This results in correct behavior and accuracy for\nsituations otherwise known as quite unfavorable, such as planar scenes, or\npanoramic sets of images (with a null base length), while providing quite\ncomparable results for more \"standard\" cases. The resolution of the algebraic\npolynomials resulting from the modeling of the coplanarity constraint is made\nwith the help of powerful algebraic solver tools (the Groebner bases and the\nRational Univariate Representation).\n",
        "published": "2008-07-13T18:37:06Z",
        "pdf_link": "http://arxiv.org/pdf/0807.2047v3"
    },
    {
        "id": "http://arxiv.org/abs/0807.4701v1",
        "title": "An image processing analysis of skin textures",
        "summary": "  Colour and coarseness of skin are visually different. When image processing\nis involved in the skin analysis, it is important to quantitatively evaluate\nsuch differences using texture features. In this paper, we discuss a texture\nanalysis and measurements based on a statistical approach to the pattern\nrecognition. Grain size and anisotropy are evaluated with proper diagrams. The\npossibility to determine the presence of pattern defects is also discussed.\n",
        "published": "2008-07-29T16:28:44Z",
        "pdf_link": "http://arxiv.org/pdf/0807.4701v1"
    },
    {
        "id": "http://arxiv.org/abs/0808.2227v1",
        "title": "Higher Order Moments Generation by Mellin Transform for Compound Models\n  of Clutter",
        "summary": "  The compound models of clutter statistics are found suitable to describe the\nnonstationary nature of radar backscattering from high-resolution observations.\nIn this letter, we show that the properties of Mellin transform can be utilized\nto generate higher order moments of simple and compound models of clutter\nstatistics in a compact manner.\n",
        "published": "2008-08-16T01:34:48Z",
        "pdf_link": "http://arxiv.org/pdf/0808.2227v1"
    },
    {
        "id": "http://arxiv.org/abs/0809.1802v1",
        "title": "Automatic Identification and Data Extraction from 2-Dimensional Plots in\n  Digital Documents",
        "summary": "  Most search engines index the textual content of documents in digital\nlibraries. However, scholarly articles frequently report important findings in\nfigures for visual impact and the contents of these figures are not indexed.\nThese contents are often invaluable to the researcher in various fields, for\nthe purposes of direct comparison with their own work. Therefore, searching for\nfigures and extracting figure data are important problems. To the best of our\nknowledge, there exists no tool to automatically extract data from figures in\ndigital documents. If we can extract data from these images automatically and\nstore them in a database, an end-user can query and combine data from multiple\ndigital documents simultaneously and efficiently. We propose a framework based\non image analysis and machine learning to extract information from 2-D plot\nimages and store them in a database. The proposed algorithm identifies a 2-D\nplot and extracts the axis labels, legend and the data points from the 2-D\nplot. We also segregate overlapping shapes that correspond to different data\npoints. We demonstrate performance of individual algorithms, using a\ncombination of generated and real-life images.\n",
        "published": "2008-09-10T14:43:37Z",
        "pdf_link": "http://arxiv.org/pdf/0809.1802v1"
    },
    {
        "id": "http://arxiv.org/abs/0809.3083v1",
        "title": "Supervised Dictionary Learning",
        "summary": "  It is now well established that sparse signal models are well suited to\nrestoration tasks and can effectively be learned from audio, image, and video\ndata. Recent research has been aimed at learning discriminative sparse models\ninstead of purely reconstructive ones. This paper proposes a new step in that\ndirection, with a novel sparse representation for signals belonging to\ndifferent classes in terms of a shared dictionary and multiple class-decision\nfunctions. The linear variant of the proposed model admits a simple\nprobabilistic interpretation, while its most general variant admits an\ninterpretation in terms of kernels. An optimization framework for learning all\nthe components of the proposed model is presented, along with experimental\nresults on standard handwritten digit and texture classification tasks.\n",
        "published": "2008-09-18T07:16:34Z",
        "pdf_link": "http://arxiv.org/pdf/0809.3083v1"
    },
    {
        "id": "http://arxiv.org/abs/0809.3690v1",
        "title": "Modeling and Control with Local Linearizing Nadaraya Watson Regression",
        "summary": "  Black box models of technical systems are purely descriptive. They do not\nexplain why a system works the way it does. Thus, black box models are\ninsufficient for some problems. But there are numerous applications, for\nexample, in control engineering, for which a black box model is absolutely\nsufficient. In this article, we describe a general stochastic framework with\nwhich such models can be built easily and fully automated by observation.\nFurthermore, we give a practical example and show how this framework can be\nused to model and control a motorcar powertrain.\n",
        "published": "2008-09-22T12:08:24Z",
        "pdf_link": "http://arxiv.org/pdf/0809.3690v1"
    },
    {
        "id": "http://arxiv.org/abs/0810.3579v1",
        "title": "Hierarchical Bag of Paths for Kernel Based Shape Classification",
        "summary": "  Graph kernels methods are based on an implicit embedding of graphs within a\nvector space of large dimension. This implicit embedding allows to apply to\ngraphs methods which where until recently solely reserved to numerical data.\nWithin the shape classification framework, graphs are often produced by a\nskeletonization step which is sensitive to noise. We propose in this paper to\nintegrate the robustness to structural noise by using a kernel based on a bag\nof path where each path is associated to a hierarchy encoding successive\nsimplifications of the path. Several experiments prove the robustness and the\nflexibility of our approach compared to alternative shape classification\nmethods.\n",
        "published": "2008-10-20T15:13:18Z",
        "pdf_link": "http://arxiv.org/pdf/0810.3579v1"
    },
    {
        "id": "http://arxiv.org/abs/0810.4426v2",
        "title": "Camera distortion self-calibration using the plumb-line constraint and\n  minimal Hough entropy",
        "summary": "  In this paper we present a simple and robust method for self-correction of\ncamera distortion using single images of scenes which contain straight lines.\nSince the most common distortion can be modelled as radial distortion, we\nillustrate the method using the Harris radial distortion model, but the method\nis applicable to any distortion model. The method is based on transforming the\nedgels of the distorted image to a 1-D angular Hough space, and optimizing the\ndistortion correction parameters which minimize the entropy of the\ncorresponding normalized histogram. Properly corrected imagery will have fewer\ncurved lines, and therefore less spread in Hough space. Since the method does\nnot rely on any image structure beyond the existence of edgels sharing some\ncommon orientations and does not use edge fitting, it is applicable to a wide\nvariety of image types. For instance, it can be applied equally well to images\nof texture with weak but dominant orientations, or images with strong vanishing\npoints. Finally, the method is performed on both synthetic and real data\nrevealing that it is particularly robust to noise.\n",
        "published": "2008-10-24T10:50:59Z",
        "pdf_link": "http://arxiv.org/pdf/0810.4426v2"
    },
    {
        "id": "http://arxiv.org/abs/0810.4617v2",
        "title": "Graph-based classification of multiple observation sets",
        "summary": "  We consider the problem of classification of an object given multiple\nobservations that possibly include different transformations. The possible\ntransformations of the object generally span a low-dimensional manifold in the\noriginal signal space. We propose to take advantage of this manifold structure\nfor the effective classification of the object represented by the observation\nset. In particular, we design a low complexity solution that is able to exploit\nthe properties of the data manifolds with a graph-based algorithm. Hence, we\nformulate the computation of the unknown label matrix as a smoothing process on\nthe manifold under the constraint that all observations represent an object of\none single class. It results into a discrete optimization problem, which can be\nsolved by an efficient and low complexity algorithm. We demonstrate the\nperformance of the proposed graph-based algorithm in the classification of sets\nof multiple images. Moreover, we show its high potential in video-based face\nrecognition, where it outperforms state-of-the-art solutions that fall short of\nexploiting the manifold structure of the face image data sets.\n",
        "published": "2008-10-25T16:02:32Z",
        "pdf_link": "http://arxiv.org/pdf/0810.4617v2"
    },
    {
        "id": "http://arxiv.org/abs/0810.5325v1",
        "title": "3D Face Recognition with Sparse Spherical Representations",
        "summary": "  This paper addresses the problem of 3D face recognition using simultaneous\nsparse approximations on the sphere. The 3D face point clouds are first aligned\nwith a novel and fully automated registration process. They are then\nrepresented as signals on the 2D sphere in order to preserve depth and geometry\ninformation. Next, we implement a dimensionality reduction process with\nsimultaneous sparse approximations and subspace projection. It permits to\nrepresent each 3D face by only a few spherical functions that are able to\ncapture the salient facial characteristics, and hence to preserve the\ndiscriminant facial information. We eventually perform recognition by effective\nmatching in the reduced space, where Linear Discriminant Analysis can be\nfurther activated for improved recognition performance. The 3D face recognition\nalgorithm is evaluated on the FRGC v.1.0 data set, where it is shown to\noutperform classical state-of-the-art solutions that work with depth images.\n",
        "published": "2008-10-29T17:43:54Z",
        "pdf_link": "http://arxiv.org/pdf/0810.5325v1"
    },
    {
        "id": "http://arxiv.org/abs/0812.1340v2",
        "title": "Obtaining Depth Maps From Color Images By Region Based Stereo Matching\n  Algorithms",
        "summary": "  In the paper, region based stereo matching algorithms are developed for\nextraction depth information from two color stereo image pair. A filter\neliminating unreliable disparity estimation was used for increasing reliability\nof the disparity map. Obtained results by algorithms were represented and\ncompared.\n",
        "published": "2008-12-07T11:42:41Z",
        "pdf_link": "http://arxiv.org/pdf/0812.1340v2"
    },
    {
        "id": "http://arxiv.org/abs/0812.2892v1",
        "title": "Sparse Component Analysis (SCA) in Random-valued and Salt and Pepper\n  Noise Removal",
        "summary": "  In this paper, we propose a new method for impulse noise removal from images.\nIt uses the sparsity of images in the Discrete Cosine Transform (DCT) domain.\nThe zeros in this domain give us the exact mathematical equation to reconstruct\nthe pixels that are corrupted by random-value impulse noises. The proposed\nmethod can also detect and correct the corrupted pixels. Moreover, in a simpler\ncase that salt and pepper noise is the brightest and darkest pixels in the\nimage, we propose a simpler version of our method. In addition to the proposed\nmethod, we suggest a combination of the traditional median filter method with\nour method to yield better results when the percentage of the corrupted samples\nis high.\n",
        "published": "2008-12-15T19:24:45Z",
        "pdf_link": "http://arxiv.org/pdf/0812.2892v1"
    },
    {
        "id": "http://arxiv.org/abs/0901.4953v1",
        "title": "A Keygraph Classification Framework for Real-Time Object Detection",
        "summary": "  In this paper, we propose a new approach for keypoint-based object detection.\nTraditional keypoint-based methods consist in classifying individual points and\nusing pose estimation to discard misclassifications. Since a single point\ncarries no relational features, such methods inherently restrict the usage of\nstructural information to the pose estimation phase. Therefore, the classifier\nconsiders purely appearance-based feature vectors, thus requiring\ncomputationally expensive feature extraction or complex probabilistic modelling\nto achieve satisfactory robustness. In contrast, our approach consists in\nclassifying graphs of keypoints, which incorporates structural information\nduring the classification phase and allows the extraction of simpler feature\nvectors that are naturally robust. In the present work, 3-vertices graphs have\nbeen considered, though the methodology is general and larger order graphs may\nbe adopted. Successful experimental results obtained for real-time object\ndetection in video sequences are reported.\n",
        "published": "2009-01-30T19:38:44Z",
        "pdf_link": "http://arxiv.org/pdf/0901.4953v1"
    },
    {
        "id": "http://arxiv.org/abs/0902.2788v2",
        "title": "Using SLP Neural Network to Persian Handwritten Digits Recognition",
        "summary": "  This paper has been withdrawn by the author ali pourmohammad.\n",
        "published": "2009-02-16T21:13:35Z",
        "pdf_link": "http://arxiv.org/pdf/0902.2788v2"
    },
    {
        "id": "http://arxiv.org/abs/0902.4073v1",
        "title": "Dipole and Quadrupole Moments in Image Processing",
        "summary": "  This paper proposes an algorithm for image processing, obtained by adapting\nto image maps the definitions of two well-known physical quantities. These\nquantities are the dipole and quadrupole moments of a charge distribution. We\nwill see how it is possible to define dipole and quadrupole moments for the\ngray-tone maps and apply them in the development of algorithms for edge\ndetection.\n",
        "published": "2009-02-24T20:34:43Z",
        "pdf_link": "http://arxiv.org/pdf/0902.4073v1"
    },
    {
        "id": "http://arxiv.org/abs/0902.4663v1",
        "title": "Dipole Vectors in Images Processing",
        "summary": "  Instead of evaluating the gradient field of the brightness map of an image,\nwe propose the use of dipole vectors. This approach is obtained by adapting to\nthe image gray-tone distribution the definition of the dipole moment of charge\ndistributions. We will show how to evaluate the dipoles and obtain a vector\nfield, which can be a good alternative to the gradient field in pattern\nrecognition.\n",
        "published": "2009-02-26T18:42:30Z",
        "pdf_link": "http://arxiv.org/pdf/0902.4663v1"
    },
    {
        "id": "http://arxiv.org/abs/0903.0134v2",
        "title": "Recognition of Regular Shapes in Satelite Images",
        "summary": "  This paper has been withdrawn by the author ali pourmohammad.\n",
        "published": "2009-03-01T11:10:27Z",
        "pdf_link": "http://arxiv.org/pdf/0903.0134v2"
    },
    {
        "id": "http://arxiv.org/abs/0903.0538v1",
        "title": "Real-time Texture Error Detection",
        "summary": "  This paper advocates an improved solution for real-time error detection of\ntexture errors that occurs in the production process in textile industry. The\nresearch is focused on the mono-color products with 3D texture model (Jaquard\nfabrics). This is a more difficult task than, for example, 2D multicolor\ntextures.\n",
        "published": "2009-03-03T14:08:24Z",
        "pdf_link": "http://arxiv.org/pdf/0903.0538v1"
    },
    {
        "id": "http://arxiv.org/abs/0903.5045v1",
        "title": "Digital Restoration of Ancient Papyri",
        "summary": "  Image processing can be used for digital restoration of ancient papyri, that\nis, for a restoration performed on their digital images. The digital\nmanipulation allows reducing the background signals and enhancing the\nreadability of texts. In the case of very old and damaged documents, this is\nfundamental for identification of the patterns of letters. Some examples of\nrestoration, obtained with an image processing which uses edges detection and\nFourier filtering, are shown. One of them concerns 7Q5 fragment of the Dead Sea\nScrolls.\n",
        "published": "2009-03-30T06:00:15Z",
        "pdf_link": "http://arxiv.org/pdf/0903.5045v1"
    },
    {
        "id": "http://arxiv.org/abs/0904.0962v1",
        "title": "Color Dipole Moments for Edge Detection",
        "summary": "  Dipole and higher moments are physical quantities used to describe a charge\ndistribution. In analogy with electromagnetism, it is possible to define the\ndipole moments for a gray-scale image, according to the single aspect of a\ngray-tone map. In this paper we define the color dipole moments for color\nimages. For color maps in fact, we have three aspects, the three primary\ncolors, to consider. Associating three color charges to each pixel, color\ndipole moments can be easily defined and used for edge detection.\n",
        "published": "2009-04-06T16:25:08Z",
        "pdf_link": "http://arxiv.org/pdf/0904.0962v1"
    },
    {
        "id": "http://arxiv.org/abs/0904.1613v1",
        "title": "On the closed-form solution of the rotation matrix arising in computer\n  vision problems",
        "summary": "  We show the closed-form solution to the maximization of trace(A'R), where A\nis given and R is unknown rotation matrix. This problem occurs in many computer\nvision tasks involving optimal rotation matrix estimation. The solution has\nbeen continuously reinvented in different fields as part of specific problems.\nWe summarize the historical evolution of the problem and present the general\nproof of the solution. We contribute to the proof by considering the degenerate\ncases of A and discuss the uniqueness of R.\n",
        "published": "2009-04-09T22:15:25Z",
        "pdf_link": "http://arxiv.org/pdf/0904.1613v1"
    },
    {
        "id": "http://arxiv.org/abs/0905.2635v1",
        "title": "Point-Set Registration: Coherent Point Drift",
        "summary": "  Point set registration is a key component in many computer vision tasks. The\ngoal of point set registration is to assign correspondences between two sets of\npoints and to recover the transformation that maps one point set to the other.\nMultiple factors, including an unknown non-rigid spatial transformation, large\ndimensionality of point set, noise and outliers, make the point set\nregistration a challenging problem. We introduce a probabilistic method, called\nthe Coherent Point Drift (CPD) algorithm, for both rigid and non-rigid point\nset registration. We consider the alignment of two point sets as a probability\ndensity estimation problem. We fit the GMM centroids (representing the first\npoint set) to the data (the second point set) by maximizing the likelihood. We\nforce the GMM centroids to move coherently as a group to preserve the\ntopological structure of the point sets. In the rigid case, we impose the\ncoherence constraint by re-parametrization of GMM centroid locations with rigid\nparameters and derive a closed form solution of the maximization step of the EM\nalgorithm in arbitrary dimensions. In the non-rigid case, we impose the\ncoherence constraint by regularizing the displacement field and using the\nvariational calculus to derive the optimal transformation. We also introduce a\nfast algorithm that reduces the method computation complexity to linear. We\ntest the CPD algorithm for both rigid and non-rigid transformations in the\npresence of noise, outliers and missing points, where CPD shows accurate\nresults and outperforms current state-of-the-art methods.\n",
        "published": "2009-05-15T22:28:00Z",
        "pdf_link": "http://arxiv.org/pdf/0905.2635v1"
    },
    {
        "id": "http://arxiv.org/abs/0905.2924v1",
        "title": "Colorization of Natural Images via L1 Optimization",
        "summary": "  Natural images in the colour space YUV have been observed to have a\nnon-Gaussian, heavy tailed distribution (called 'sparse') when the filter\nG(U)(r) = U(r) - sum_{s \\in N(r)} w{(Y)_{rs}} U(s), is applied to the\nchromacity channel U (and equivalently to V), where w is a weighting function\nconstructed from the intensity component Y [1]. In this paper we develop\nBayesian analysis of the colorization problem using the filter response as a\nregularization term to arrive at a non-convex optimization problem. This\nproblem is convexified using L1 optimization which often gives the same results\nfor sparse signals [2]. It is observed that L1 optimization, in many cases,\nover-performs the famous colorization algorithm by Levin et al [3].\n",
        "published": "2009-05-18T16:07:52Z",
        "pdf_link": "http://arxiv.org/pdf/0905.2924v1"
    },
    {
        "id": "http://arxiv.org/abs/0905.2958v3",
        "title": "A statistical learning approach to color demosaicing",
        "summary": "  A statistical learning/inference framework for color demosaicing is\npresented. We start with simplistic assumptions about color constancy, and\nrecast color demosaicing as a blind linear inverse problem: color parameterizes\nthe unknown kernel, while brightness takes on the role of a latent variable. An\nexpectation-maximization algorithm naturally suggests itself for the estimation\nof them both. Then, as we gradually broaden the family of hypothesis where\ncolor is learned, we let our demosaicing behave adaptively, in a manner that\nreflects our prior knowledge about the statistics of color images. We show that\nwe can incorporate realistic, learned priors without essentially changing the\ncomplexity of the simple expectation-maximization algorithm we started with.\n",
        "published": "2009-05-18T19:44:58Z",
        "pdf_link": "http://arxiv.org/pdf/0905.2958v3"
    },
    {
        "id": "http://arxiv.org/abs/0905.3964v1",
        "title": "A New Solution to the Relative Orientation Problem using only 3 Points\n  and the Vertical Direction",
        "summary": "  This paper presents a new method to recover the relative pose between two\nimages, using three points and the vertical direction information. The vertical\ndirection can be determined in two ways: 1- using direct physical measurement\nlike IMU (inertial measurement unit), 2- using vertical vanishing point. This\nknowledge of the vertical direction solves 2 unknowns among the 3 parameters of\nthe relative rotation, so that only 3 homologous points are requested to\nposition a couple of images. Rewriting the coplanarity equations leads to a\nsimpler solution. The remaining unknowns resolution is performed by an\nalgebraic method using Grobner bases. The elements necessary to build a\nspecific algebraic solver are given in this paper, allowing for a real-time\nimplementation. The results on real and synthetic data show the efficiency of\nthis method.\n",
        "published": "2009-05-25T08:29:01Z",
        "pdf_link": "http://arxiv.org/pdf/0905.3964v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.1763v2",
        "title": "Segmentation of Facial Expressions Using Semi-Definite Programming and\n  Generalized Principal Component Analysis",
        "summary": "  In this paper, we use semi-definite programming and generalized principal\ncomponent analysis (GPCA) to distinguish between two or more different facial\nexpressions. In the first step, semi-definite programming is used to reduce the\ndimension of the image data and \"unfold\" the manifold which the data points\n(corresponding to facial expressions) reside on. Next, GPCA is used to fit a\nseries of subspaces to the data points and associate each data point with a\nsubspace. Data points that belong to the same subspace are claimed to belong to\nthe same facial expression category. An example is provided.\n",
        "published": "2009-06-09T19:50:10Z",
        "pdf_link": "http://arxiv.org/pdf/0906.1763v2"
    },
    {
        "id": "http://arxiv.org/abs/0906.2770v1",
        "title": "Combinatorial pyramids and discrete geometry for energy-minimizing\n  segmentation",
        "summary": "  This paper defines the basis of a new hierarchical framework for segmentation\nalgorithms based on energy minimization schemes. This new framework is based on\ntwo formal tools. First, a combinatorial pyramid encode efficiently a hierarchy\nof partitions. Secondly, discrete geometric estimators measure precisely some\nimportant geometric parameters of the regions. These measures combined with\nphotometrical and topological features of the partition allows to design energy\nterms based on discrete measures. Our segmentation framework exploits these\nenergies to build a pyramid of image partitions with a minimization scheme.\nSome experiments illustrating our framework are shown and discussed.\n",
        "published": "2009-06-15T19:33:21Z",
        "pdf_link": "http://arxiv.org/pdf/0906.2770v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.3068v1",
        "title": "Deformable Model with a Complexity Independent from Image Resolution",
        "summary": "  We present a parametric deformable model which recovers image components with\na complexity independent from the resolution of input images. The proposed\nmodel also automatically changes its topology and remains fully compatible with\nthe general framework of deformable models. More precisely, the image space is\nequipped with a metric that expands salient image details according to their\nstrength and their curvature. During the whole evolution of the model, the\nsampling of the contour is kept regular with respect to this metric. By this\nway, the vertex density is reduced along most parts of the curve while a high\nquality of shape representation is preserved. The complexity of the deformable\nmodel is thus improved and is no longer influenced by feature-preserving\nchanges in the resolution of input images. Building the metric requires a prior\nestimation of contour curvature. It is obtained using a robust estimator which\ninvestigates the local variations in the orientation of image gradient.\nExperimental results on both computer generated and biomedical images are\npresented to illustrate the advantages of our approach.\n",
        "published": "2009-06-17T04:42:39Z",
        "pdf_link": "http://arxiv.org/pdf/0906.3068v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.3323v1",
        "title": "Adaptive Regularization of Ill-Posed Problems: Application to Non-rigid\n  Image Registration",
        "summary": "  We introduce an adaptive regularization approach. In contrast to conventional\nTikhonov regularization, which specifies a fixed regularization operator, we\nestimate it simultaneously with parameters. From a Bayesian perspective we\nestimate the prior distribution on parameters assuming that it is close to some\ngiven model distribution. We constrain the prior distribution to be a\nGauss-Markov random field (GMRF), which allows us to solve for the prior\ndistribution analytically and provides a fast optimization algorithm. We apply\nour approach to non-rigid image registration to estimate the spatial\ntransformation between two images. Our evaluation shows that the adaptive\nregularization approach significantly outperforms standard variational methods.\n",
        "published": "2009-06-17T23:24:38Z",
        "pdf_link": "http://arxiv.org/pdf/0906.3323v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.3770v1",
        "title": "Automatic Defect Detection and Classification Technique from Image: A\n  Special Case Using Ceramic Tiles",
        "summary": "  Quality control is an important issue in the ceramic tile industry. On the\nother hand maintaining the rate of production with respect to time is also a\nmajor issue in ceramic tile manufacturing. Again, price of ceramic tiles also\ndepends on purity of texture, accuracy of color, shape etc. Considering this\ncriteria, an automated defect detection and classification technique has been\nproposed in this report that can have ensured the better quality of tiles in\nmanufacturing process as well as production rate. Our proposed method plays an\nimportant role in ceramic tiles industries to detect the defects and to control\nthe quality of ceramic tiles. This automated classification method helps us to\nacquire knowledge about the pattern of defect within a very short period of\ntime and also to decide about the recovery process so that the defected tiles\nmay not be mixed with the fresh tiles.\n",
        "published": "2009-06-20T03:00:37Z",
        "pdf_link": "http://arxiv.org/pdf/0906.3770v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.4131v2",
        "title": "Automatic Spatially-Adaptive Balancing of Energy Terms for Image\n  Segmentation",
        "summary": "  Image segmentation techniques are predominately based on parameter-laden\noptimization. The objective function typically involves weights for balancing\ncompeting image fidelity and segmentation regularization cost terms. Setting\nthese weights suitably has been a painstaking, empirical process. Even if such\nideal weights are found for a novel image, most current approaches fix the\nweight across the whole image domain, ignoring the spatially-varying properties\nof object shape and image appearance. We propose a novel technique that\nautonomously balances these terms in a spatially-adaptive manner through the\nincorporation of image reliability in a graph-based segmentation framework. We\nvalidate on synthetic data achieving a reduction in mean error of 47% (p-value\n<< 0.05) when compared to the best fixed parameter segmentation. We also\npresent results on medical images (including segmentations of the corpus\ncallosum and brain tissue in MRI data) and on natural images.\n",
        "published": "2009-06-22T21:10:46Z",
        "pdf_link": "http://arxiv.org/pdf/0906.4131v2"
    },
    {
        "id": "http://arxiv.org/abs/0906.4789v1",
        "title": "Efficient IRIS Recognition through Improvement of Feature Extraction and\n  subset Selection",
        "summary": "  The selection of the optimal feature subset and the classification has become\nan important issue in the field of iris recognition. In this paper we propose\nseveral methods for iris feature subset selection and vector creation. The\ndeterministic feature sequence is extracted from the iris image by using the\ncontourlet transform technique. Contourlet transform captures the intrinsic\ngeometrical structures of iris image. It decomposes the iris image into a set\nof directional sub-bands with texture details captured in different\norientations at various scales so for reducing the feature vector dimensions we\nuse the method for extract only significant bit and information from normalized\niris images. In this method we ignore fragile bits. And finally we use SVM\n(Support Vector Machine) classifier for approximating the amount of people\nidentification in our proposed system. Experimental result show that most\nproposed method reduces processing time and increase the classification\naccuracy and also the iris feature vector length is much smaller versus the\nother methods.\n",
        "published": "2009-06-25T20:14:42Z",
        "pdf_link": "http://arxiv.org/pdf/0906.4789v1"
    },
    {
        "id": "http://arxiv.org/abs/0906.5039v1",
        "title": "A new approach for digit recognition based on hand gesture analysis",
        "summary": "  We present in this paper a new approach for hand gesture analysis that allows\ndigit recognition. The analysis is based on extracting a set of features from a\nhand image and then combining them by using an induction graph. The most\nimportant features we extract from each image are the fingers locations, their\nheights and the distance between each pair of fingers. Our approach consists of\nthree steps: (i) Hand detection and localization, (ii) fingers extraction and\n(iii) features identification and combination to digit recognition. Each input\nimage is assumed to contain only one person, thus we apply a fuzzy classifier\nto identify the skin pixels. In the finger extraction step, we attempt to\nremove all the hand components except the fingers, this process is based on the\nhand anatomy properties. The final step consists on representing histogram of\nthe detected fingers in order to extract features that will be used for digit\nrecognition. The approach is invariant to scale, rotation and translation of\nthe hand. Some experiments have been undertaken to show the effectiveness of\nthe proposed approach.\n",
        "published": "2009-06-27T04:46:23Z",
        "pdf_link": "http://arxiv.org/pdf/0906.5039v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.0204v1",
        "title": "Multi-Label MRF Optimization via Least Squares s-t Cuts",
        "summary": "  There are many applications of graph cuts in computer vision, e.g.\nsegmentation. We present a novel method to reformulate the NP-hard, k-way graph\npartitioning problem as an approximate minimal s-t graph cut problem, for which\na globally optimal solution is found in polynomial time. Each non-terminal\nvertex in the original graph is replaced by a set of ceil(log_2(k)) new\nvertices. The original graph edges are replaced by new edges connecting the new\nvertices to each other and to only two, source s and sink t, terminal nodes.\nThe weights of the new edges are obtained using a novel least squares solution\napproximating the constraints of the initial k-way setup. The minimal s-t cut\nlabels each new vertex with a binary (s vs t) \"Gray\" encoding, which is then\ndecoded into a decimal label number that assigns each of the original vertices\nto one of k classes. We analyze the properties of the approximation and present\nquantitative as well as qualitative segmentation results.\n",
        "published": "2009-07-01T17:18:46Z",
        "pdf_link": "http://arxiv.org/pdf/0907.0204v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.0288v1",
        "title": "An Iterative Fingerprint Enhancement Algorithm Based on Accurate\n  Determination of Orientation Flow",
        "summary": "  We describe an algorithm to enhance and binarize a fingerprint image. The\nalgorithm is based on accurate determination of orientation flow of the ridges\nof the fingerprint image by computing variance of the neighborhood pixels\naround a pixel in different directions. We show that an iterative algorithm\nwhich captures the mutual interdependence of orientation flow computation,\nenhancement and binarization gives very good results on poor quality images.\n",
        "published": "2009-07-02T04:57:32Z",
        "pdf_link": "http://arxiv.org/pdf/0907.0288v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.0418v1",
        "title": "Bounding the Probability of Error for High Precision Recognition",
        "summary": "  We consider models for which it is important, early in processing, to\nestimate some variables with high precision, but perhaps at relatively low\nrates of recall. If some variables can be identified with near certainty, then\nthey can be conditioned upon, allowing further inference to be done\nefficiently. Specifically, we consider optical character recognition (OCR)\nsystems that can be bootstrapped by identifying a subset of correctly\ntranslated document words with very high precision. This \"clean set\" is\nsubsequently used as document-specific training data. While many current OCR\nsystems produce measures of confidence for the identity of each letter or word,\nthresholding these confidence values, even at very high values, still produces\nsome errors.\n  We introduce a novel technique for identifying a set of correct words with\nvery high precision. Rather than estimating posterior probabilities, we bound\nthe probability that any given word is incorrect under very general\nassumptions, using an approximate worst case analysis. As a result, the\nparameters of the model are nearly irrelevant, and we are able to identify a\nsubset of words, even in noisy documents, of which we are highly confident. On\nour set of 10 documents, we are able to identify about 6% of the words on\naverage without making a single error. This ability to produce word lists with\nvery high precision allows us to use a family of models which depends upon such\nclean word lists.\n",
        "published": "2009-07-02T16:09:47Z",
        "pdf_link": "http://arxiv.org/pdf/0907.0418v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.1545v1",
        "title": "Augmenting Light Field to model Wave Optics effects",
        "summary": "  The ray-based 4D light field representation cannot be directly used to\nanalyze diffractive or phase--sensitive optical elements. In this paper, we\nexploit tools from wave optics and extend the light field representation via a\nnovel \"light field transform\". We introduce a key modification to the\nray--based model to support the transform. We insert a \"virtual light source\",\nwith potentially negative valued radiance for certain emitted rays. We create a\nlook-up table of light field transformers of canonical optical elements. The\ntwo key conclusions are that (i) in free space, the 4D light field completely\nrepresents wavefront propagation via rays with real (positive as well as\nnegative) valued radiance and (ii) at occluders, a light field composed of\nlight field transformers plus insertion of (ray--based) virtual light sources\nrepresents resultant phase and amplitude of wavefronts. For free--space\npropagation, we analyze different wavefronts and coherence possibilities. For\noccluders, we show that the light field transform is simply based on a\nconvolution followed by a multiplication operation. This formulation brings\npowerful concepts from wave optics to computer vision and graphics. We show\napplications in cubic-phase plate imaging and holographic displays.\n",
        "published": "2009-07-09T13:43:12Z",
        "pdf_link": "http://arxiv.org/pdf/0907.1545v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.2075v1",
        "title": "Multiresolution Elastic Medical Image Registration in Standard Intensity\n  Scale",
        "summary": "  Medical image registration is a difficult problem. Not only a registration\nalgorithm needs to capture both large and small scale image deformations, it\nalso has to deal with global and local image intensity variations. In this\npaper we describe a new multiresolution elastic image registration method that\nchallenges these difficulties in image registration. To capture large and small\nscale image deformations, we use both global and local affine transformation\nalgorithms. To address global and local image intensity variations, we apply an\nimage intensity standardization algorithm to correct image intensity\nvariations. This transforms image intensities into a standard intensity scale,\nwhich allows highly accurate registration of medical images.\n",
        "published": "2009-07-12T22:39:34Z",
        "pdf_link": "http://arxiv.org/pdf/0907.2075v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.3209v1",
        "title": "Registration of Standardized Histological Images in Feature Space",
        "summary": "  In this paper, we propose three novel and important methods for the\nregistration of histological images for 3D reconstruction. First, possible\nintensity variations and nonstandardness in images are corrected by an\nintensity standardization process which maps the image scale into a standard\nscale where the similar intensities correspond to similar tissues meaning.\nSecond, 2D histological images are mapped into a feature space where continuous\nvariables are used as high confidence image features for accurate registration.\nThird, we propose an automatic best reference slice selection algorithm that\nimproves reconstruction quality based on both image entropy and mean square\nerror of the registration process. We demonstrate that the choice of reference\nslice has a significant impact on registration error, standardization, feature\nspace and entropy information. After 2D histological slices are registered\nthrough an affine transformation with respect to an automatically chosen\nreference, the 3D volume is reconstructed by co-registering 2D slices\nelastically.\n",
        "published": "2009-07-18T11:28:41Z",
        "pdf_link": "http://arxiv.org/pdf/0907.3209v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.3215v1",
        "title": "Fully Automatic 3D Reconstruction of Histological Images",
        "summary": "  In this paper, we propose a computational framework for 3D volume\nreconstruction from 2D histological slices using registration algorithms in\nfeature space. To improve the quality of reconstructed 3D volume, first,\nintensity variations in images are corrected by an intensity standardization\nprocess which maps image intensity scale to a standard scale where similar\nintensities correspond to similar tissues. Second, a subvolume approach is\nproposed for 3D reconstruction by dividing standardized slices into groups.\nThird, in order to improve the quality of the reconstruction process, an\nautomatic best reference slice selection algorithm is developed based on an\niterative assessment of image entropy and mean square error of the registration\nprocess. Finally, we demonstrate that the choice of the reference slice has a\nsignificant impact on registration quality and subsequent 3D reconstruction.\n",
        "published": "2009-07-18T12:32:27Z",
        "pdf_link": "http://arxiv.org/pdf/0907.3215v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.3218v1",
        "title": "Parallel AdaBoost Algorithm for Gabor Wavelet Selection in Face\n  Recognition",
        "summary": "  In this paper, the problem of automatic Gabor wavelet selection for face\nrecognition is tackled by introducing an automatic algorithm based on Parallel\nAdaBoosting method. Incorporating mutual information into the algorithm leads\nto the selection procedure not only based on classification accuracy but also\non efficiency. Effective image features are selected by using properly chosen\nGabor wavelets optimised with Parallel AdaBoost method and mutual information\nto get high recognition rates with low computational cost. Experiments are\nconducted using the well-known FERET face database. In proposed framework,\nmemory and computation costs are reduced significantly and high classification\naccuracy is obtained.\n",
        "published": "2009-07-18T13:03:19Z",
        "pdf_link": "http://arxiv.org/pdf/0907.3218v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.4354v1",
        "title": "Learning Object Location Predictors with Boosting and Grammar-Guided\n  Feature Extraction",
        "summary": "  We present BEAMER: a new spatially exploitative approach to learning object\ndetectors which shows excellent results when applied to the task of detecting\nobjects in greyscale aerial imagery in the presence of ambiguous and noisy\ndata. There are four main contributions used to produce these results. First,\nwe introduce a grammar-guided feature extraction system, enabling the\nexploration of a richer feature space while constraining the features to a\nuseful subset. This is specified with a rule-based generative grammar crafted\nby a human expert. Second, we learn a classifier on this data using a newly\nproposed variant of AdaBoost which takes into account the spatially correlated\nnature of the data. Third, we perform another round of training to optimize the\nmethod of converting the pixel classifications generated by boosting into a\nhigh quality set of (x, y) locations. Lastly, we carefully define three common\nproblems in object detection and define two evaluation criteria that are\ntightly matched to these problems. Major strengths of this approach are: (1) a\nway of randomly searching a broad feature space, (2) its performance when\nevaluated on well-matched evaluation criteria, and (3) its use of the location\nprediction domain to learn object detectors as well as to generate detections\nthat perform well on several tasks: object counting, tracking, and target\ndetection. We demonstrate the efficacy of BEAMER with a comprehensive\nexperimental evaluation on a challenging data set.\n",
        "published": "2009-07-24T18:01:08Z",
        "pdf_link": "http://arxiv.org/pdf/0907.4354v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.4984v1",
        "title": "Automatic local Gabor Features extraction for face recognition",
        "summary": "  We present in this paper a biometric system of face detection and recognition\nin color images. The face detection technique is based on skin color\ninformation and fuzzy classification. A new algorithm is proposed in order to\ndetect automatically face features (eyes, mouth and nose) and extract their\ncorrespondent geometrical points. These fiducial points are described by sets\nof wavelet components which are used for recognition. To achieve the face\nrecognition, we use neural networks and we study its performances for different\ninputs. We compare the two types of features used for recognition: geometric\ndistances and Gabor coefficients which can be used either independently or\njointly. This comparison shows that Gabor coefficients are more powerful than\ngeometric distances. We show with experimental results how the importance\nrecognition ratio makes our system an effective tool for automatic face\ndetection and recognition.\n",
        "published": "2009-07-28T20:02:15Z",
        "pdf_link": "http://arxiv.org/pdf/0907.4984v1"
    },
    {
        "id": "http://arxiv.org/abs/0907.5321v2",
        "title": "Multiple pattern classification by sparse subspace decomposition",
        "summary": "  A robust classification method is developed on the basis of sparse subspace\ndecomposition. This method tries to decompose a mixture of subspaces of\nunlabeled data (queries) into class subspaces as few as possible. Each query is\nclassified into the class whose subspace significantly contributes to the\ndecomposed subspace. Multiple queries from different classes can be\nsimultaneously classified into their respective classes. A practical greedy\nalgorithm of the sparse subspace decomposition is designed for the\nclassification. The present method achieves high recognition rate and robust\nperformance exploiting joint sparsity.\n",
        "published": "2009-07-30T12:23:25Z",
        "pdf_link": "http://arxiv.org/pdf/0907.5321v2"
    },
    {
        "id": "http://arxiv.org/abs/0908.1369v1",
        "title": "Segmentation for radar images based on active contour",
        "summary": "  We exam various geometric active contour methods for radar image\nsegmentation. Due to special properties of radar images, we propose our new\nmodel based on modified Chan-Vese functional. Our method is efficient in\nseparating non-meteorological noises from meteorological images.\n",
        "published": "2009-08-10T18:33:51Z",
        "pdf_link": "http://arxiv.org/pdf/0908.1369v1"
    },
    {
        "id": "http://arxiv.org/abs/0908.1919v3",
        "title": "A dyadic solution of relative pose problems",
        "summary": "  A hierarchical interval subdivision is shown to lead to a $p$-adic encoding\nof image data. This allows in the case of the relative pose problem in computer\nvision and photogrammetry to derive equations having 2-adic numbers as\ncoefficients, and to use Hensel's lifting method to their solution. This method\nis applied to the linear and non-linear equations coming from eight, seven or\nfive point correspondences. An inherent property of the method is its\nrobustness.\n",
        "published": "2009-08-13T15:41:44Z",
        "pdf_link": "http://arxiv.org/pdf/0908.1919v3"
    },
    {
        "id": "http://arxiv.org/abs/0908.4386v1",
        "title": "Handwritten Farsi Character Recognition using Artificial Neural Network",
        "summary": "  Neural Networks are being used for character recognition from last many years\nbut most of the work was confined to English character recognition. Till date,\na very little work has been reported for Handwritten Farsi Character\nrecognition. In this paper, we have made an attempt to recognize handwritten\nFarsi characters by using a multilayer perceptron with one hidden layer. The\nerror backpropagation algorithm has been used to train the MLP network. In\naddition, an analysis has been carried out to determine the number of hidden\nnodes to achieve high performance of backpropagation network in the recognition\nof handwritten Farsi characters. The system has been trained using several\ndifferent forms of handwriting provided by both male and female participants of\ndifferent age groups. Finally, this rigorous training results an automatic HCR\nsystem using MLP network. In this work, the experiments were carried out on two\nhundred fifty samples of five writers. The results showed that the MLP networks\ntrained by the error backpropagation algorithm are superior in recognition\naccuracy and memory usage. The result indicates that the backpropagation\nnetwork provides good recognition accuracy of more than 80% of handwritten\nFarsi characters.\n",
        "published": "2009-08-30T11:55:48Z",
        "pdf_link": "http://arxiv.org/pdf/0908.4386v1"
    },
    {
        "id": "http://arxiv.org/abs/0909.0481v1",
        "title": "Scale-Based Gaussian Coverings: Combining Intra and Inter Mixture Models\n  in Image Segmentation",
        "summary": "  By a \"covering\" we mean a Gaussian mixture model fit to observed data.\nApproximations of the Bayes factor can be availed of to judge model fit to the\ndata within a given Gaussian mixture model. Between families of Gaussian\nmixture models, we propose the R\\'enyi quadratic entropy as an excellent and\ntractable model comparison framework. We exemplify this using the segmentation\nof an MRI image volume, based (1) on a direct Gaussian mixture model applied to\nthe marginal distribution function, and (2) Gaussian model fit through k-means\napplied to the 4D multivalued image volume furnished by the wavelet transform.\nVisual preference for one model over another is not immediate. The R\\'enyi\nquadratic entropy allows us to show clearly that one of these modelings is\nsuperior to the other.\n",
        "published": "2009-09-02T17:46:08Z",
        "pdf_link": "http://arxiv.org/pdf/0909.0481v1"
    },
    {
        "id": "http://arxiv.org/abs/0909.1605v1",
        "title": "Kernel Spectral Curvature Clustering (KSCC)",
        "summary": "  Multi-manifold modeling is increasingly used in segmentation and data\nrepresentation tasks in computer vision and related fields. While the general\nproblem, modeling data by mixtures of manifolds, is very challenging, several\napproaches exist for modeling data by mixtures of affine subspaces (which is\noften referred to as hybrid linear modeling). We translate some important\ninstances of multi-manifold modeling to hybrid linear modeling in embedded\nspaces, without explicitly performing the embedding but applying the kernel\ntrick. The resulting algorithm, Kernel Spectral Curvature Clustering, uses\nkernels at two levels - both as an implicit embedding method to linearize\nnonflat manifolds and as a principled method to convert a multiway affinity\nproblem into a spectral clustering one. We demonstrate the effectiveness of the\nmethod by comparing it with other state-of-the-art methods on both synthetic\ndata and a real-world problem of segmenting multiple motions from two\nperspective camera views.\n",
        "published": "2009-09-09T01:58:23Z",
        "pdf_link": "http://arxiv.org/pdf/0909.1605v1"
    },
    {
        "id": "http://arxiv.org/abs/0909.1608v1",
        "title": "Motion Segmentation by SCC on the Hopkins 155 Database",
        "summary": "  We apply the Spectral Curvature Clustering (SCC) algorithm to a benchmark\ndatabase of 155 motion sequences, and show that it outperforms all other\nstate-of-the-art methods. The average misclassification rate by SCC is 1.41%\nfor sequences having two motions and 4.85% for three motions.\n",
        "published": "2009-09-09T02:12:22Z",
        "pdf_link": "http://arxiv.org/pdf/0909.1608v1"
    },
    {
        "id": "http://arxiv.org/abs/0909.3911v1",
        "title": "A Method for Extraction and Recognition of Isolated License Plate\n  Characters",
        "summary": "  A method to extract and recognize isolated characters in license plates is\nproposed. In extraction stage, the proposed method detects isolated characters\nby using Difference-of-Gaussian (DOG) function, The DOG function, similar to\nLaplacian of Gaussian function, was proven to produce the most stable image\nfeatures compared to a range of other possible image functions. The candidate\ncharacters are extracted by doing connected component analysis on different\nscale DOG images. In recognition stage, a novel feature vector named\naccumulated gradient projection vector (AGPV) is used to compare the candidate\ncharacter with the standard ones. The AGPV is calculated by first projecting\npixels of similar gradient orientations onto specific axes, and then\naccumulates the projected gradient magnitudes by each axis. In the experiments,\nthe AGPVs are proven to be invariant from image scaling and rotation, and\nrobust to noise and illumination change.\n",
        "published": "2009-09-22T05:38:32Z",
        "pdf_link": "http://arxiv.org/pdf/0909.3911v1"
    },
    {
        "id": "http://arxiv.org/abs/0909.5458v1",
        "title": "Information tracking approach to segmentation of ultrasound imagery of\n  prostate",
        "summary": "  The size and geometry of the prostate are known to be pivotal quantities used\nby clinicians to assess the condition of the gland during prostate cancer\nscreening. As an alternative to palpation, an increasing number of methods for\nestimation of the above-mentioned quantities are based on using imagery data of\nprostate. The necessity to process large volumes of such data creates a need\nfor automatic segmentation tools which would allow the estimation to be carried\nout with maximum accuracy and efficiency. In particular, the use of transrectal\nultrasound (TRUS) imaging in prostate cancer screening seems to be becoming a\nstandard clinical practice due to the high benefit-to-cost ratio of this\nimaging modality. Unfortunately, the segmentation of TRUS images is still\nhampered by relatively low contrast and reduced SNR of the images, thereby\nrequiring the segmentation algorithms to incorporate prior knowledge about the\ngeometry of the gland. In this paper, a novel approach to the problem of\nsegmenting the TRUS images is described. The proposed approach is based on the\nconcept of distribution tracking, which provides a unified framework for\nmodeling and fusing image-related and morphological features of the prostate.\nMoreover, the same framework allows the segmentation to be regularized via\nusing a new type of \"weak\" shape priors, which minimally bias the estimation\nprocedure, while rendering the latter stable and robust.\n",
        "published": "2009-09-29T22:39:19Z",
        "pdf_link": "http://arxiv.org/pdf/0909.5458v1"
    },
    {
        "id": "http://arxiv.org/abs/0909.5460v2",
        "title": "Iterative Shrinkage Approach to Restoration of Optical Imagery",
        "summary": "  The problem of reconstruction of digital images from their degraded\nmeasurements is regarded as a problem of central importance in various fields\nof engineering and imaging sciences. In such cases, the degradation is\ntypically caused by the resolution limitations of an imaging device in use\nand/or by the destructive influence of measurement noise. Specifically, when\nthe noise obeys a Poisson probability law, standard approaches to the problem\nof image reconstruction are based on using fixed-point algorithms which follow\nthe methodology first proposed by Richardson and Lucy. The practice of using\nthese methods, however, shows that their convergence properties tend to\ndeteriorate at relatively high noise levels. Accordingly, in the present paper,\na novel method for de-noising and/or de-blurring of digital images corrupted by\nPoisson noise is introduced. The proposed method is derived under the\nassumption that the image of interest can be sparsely represented in the domain\nof a linear transform. Consequently, a shrinkage-based iterative procedure is\nproposed, which guarantees the solution to converge to the global maximizer of\nan associated maximum-a-posteriori criterion. It is shown in a series of both\ncomputer-simulated and real-life experiments that the proposed method\noutperforms a number of existing alternatives in terms of stability, precision,\nand computational efficiency.\n",
        "published": "2009-09-29T22:33:10Z",
        "pdf_link": "http://arxiv.org/pdf/0909.5460v2"
    },
    {
        "id": "http://arxiv.org/abs/0910.1295v1",
        "title": "Modular Traffic Sign Recognition applied to on-vehicle real-time visual\n  detection of American and European speed limit signs",
        "summary": "  We present a new modular traffic signs recognition system, successfully\napplied to both American and European speed limit signs. Our sign detection\nstep is based only on shape-detection (rectangles or circles). This enables it\nto work on grayscale images, contrary to most European competitors, which eases\nrobustness to illumination conditions (notably night operation). Speed sign\ncandidates are classified (or rejected) by segmenting potential digits inside\nthem (which is rather original and has several advantages), and then applying a\nneural digit recognition. The global detection rate is ~90% for both (standard)\nU.S. and E.U. speed signs, with a misclassification rate <1%, and no validated\nfalse alarm in >150 minutes of video. The system processes in real-time ~20\nframes/s on a standard high-end laptop.\n",
        "published": "2009-10-07T15:43:01Z",
        "pdf_link": "http://arxiv.org/pdf/0910.1295v1"
    },
    {
        "id": "http://arxiv.org/abs/0910.1844v1",
        "title": "3D/2D Registration of Mapping Catheter Images for Arrhythmia\n  Interventional Assistance",
        "summary": "  Radiofrequency (RF) catheter ablation has transformed treatment for\ntachyarrhythmias and has become first-line therapy for some tachycardias. The\nprecise localization of the arrhythmogenic site and the positioning of the RF\ncatheter over that site are problematic: they can impair the efficiency of the\nprocedure and are time consuming (several hours). Electroanatomic mapping\ntechnologies are available that enable the display of the cardiac chambers and\nthe relative position of ablation lesions. However, these are expensive and use\ncustom-made catheters. The proposed methodology makes use of standard catheters\nand inexpensive technology in order to create a 3D volume of the heart chamber\naffected by the arrhythmia. Further, we propose a novel method that uses a\npriori 3D information of the mapping catheter in order to estimate the 3D\nlocations of multiple electrodes across single view C-arm images. The monoplane\nalgorithm is tested for feasibility on computer simulations and initial canine\ndata.\n",
        "published": "2009-10-09T20:07:11Z",
        "pdf_link": "http://arxiv.org/pdf/0910.1844v1"
    },
    {
        "id": "http://arxiv.org/abs/0910.1849v1",
        "title": "Color Image Clustering using Block Truncation Algorithm",
        "summary": "  With the advancement in image capturing device, the image data been generated\nat high volume. If images are analyzed properly, they can reveal useful\ninformation to the human users. Content based image retrieval address the\nproblem of retrieving images relevant to the user needs from image databases on\nthe basis of low-level visual features that can be derived from the images.\nGrouping images into meaningful categories to reveal useful information is a\nchallenging and important problem. Clustering is a data mining technique to\ngroup a set of unsupervised data based on the conceptual clustering principal:\nmaximizing the intraclass similarity and minimizing the interclass similarity.\nProposed framework focuses on color as feature. Color Moment and Block\nTruncation Coding (BTC) are used to extract features for image dataset.\nExperimental study using K-Means clustering algorithm is conducted to group the\nimage dataset into various clusters.\n",
        "published": "2009-10-09T20:21:23Z",
        "pdf_link": "http://arxiv.org/pdf/0910.1849v1"
    },
    {
        "id": "http://arxiv.org/abs/0910.2381v4",
        "title": "Fractional differentiation based image processing",
        "summary": "  There are many resources useful for processing images, most of them freely\navailable and quite friendly to use. In spite of this abundance of tools, a\nstudy of the processing methods is still worthy of efforts. Here, we want to\ndiscuss the possibilities arising from the use of fractional differential\ncalculus. This calculus evolved in the research field of pure mathematics until\n1920, when applied science started to use it. Only recently, fractional\ncalculus was involved in image processing methods. As we shall see, the\nfractional calculation is able to enhance the quality of images, with\ninteresting possibilities in edge detection and image restoration. We suggest\nalso the fractional differentiation as a tool to reveal faint objects in\nastronomical images.\n",
        "published": "2009-10-13T12:37:32Z",
        "pdf_link": "http://arxiv.org/pdf/0910.2381v4"
    },
    {
        "id": "http://arxiv.org/abs/0910.2917v1",
        "title": "Behavior Subtraction",
        "summary": "  Background subtraction has been a driving engine for many computer vision and\nvideo analytics tasks. Although its many variants exist, they all share the\nunderlying assumption that photometric scene properties are either static or\nexhibit temporal stationarity. While this works in some applications, the model\nfails when one is interested in discovering {\\it changes in scene dynamics}\nrather than those in a static background; detection of unusual pedestrian and\nmotor traffic patterns is but one example. We propose a new model and\ncomputational framework that address this failure by considering stationary\nscene dynamics as a ``background'' with which observed scene dynamics are\ncompared. Central to our approach is the concept of an {\\it event}, that we\ndefine as short-term scene dynamics captured over a time window at a specific\nspatial location in the camera field of view. We compute events by\ntime-aggregating motion labels, obtained by background subtraction, as well as\nobject descriptors (e.g., object size). Subsequently, we characterize events\nprobabilistically, but use a low-memory, low-complexity surrogates in practical\nimplementation. Using these surrogates amounts to {\\it behavior subtraction}, a\nnew algorithm with some surprising properties. As demonstrated here, behavior\nsubtraction is an effective tool in anomaly detection and localization. It is\nresilient to spurious background motion, such as one due to camera jitter, and\nis content-blind, i.e., it works equally well on humans, cars, animals, and\nother objects in both uncluttered and highly-cluttered scenes. Clearly,\ntreating video as a collection of events rather than colored pixels opens new\npossibilities for video analytics.\n",
        "published": "2009-10-15T16:09:18Z",
        "pdf_link": "http://arxiv.org/pdf/0910.2917v1"
    },
    {
        "id": "http://arxiv.org/abs/0910.4839v2",
        "title": "A $p$-adic RanSaC algorithm for stereo vision using Hensel lifting",
        "summary": "  A $p$-adic variation of the Ran(dom) Sa(mple) C(onsensus) method for solving\nthe relative pose problem in stereo vision is developped. From two 2-adically\nencoded images a random sample of five pairs of corresponding points is taken,\nand the equations for the essential matrix are solved by lifting solutions\nmodulo 2 to the 2-adic integers. A recently devised $p$-adic hierarchical\nclassification algorithm imitating the known LBG quantisation method classifies\nthe solutions for all the samples after having determined the number of\nclusters using the known intra-inter validity of clusterings. In the successful\ncase, a cluster ranking will determine the cluster containing a 2-adic\napproximation to the \"true\" solution of the problem.\n",
        "published": "2009-10-26T09:34:29Z",
        "pdf_link": "http://arxiv.org/pdf/0910.4839v2"
    },
    {
        "id": "http://arxiv.org/abs/0910.5002v1",
        "title": "An Iterative Shrinkage Approach to Total-Variation Image Restoration",
        "summary": "  The problem of restoration of digital images from their degraded measurements\nplays a central role in a multitude of practically important applications. A\nparticularly challenging instance of this problem occurs in the case when the\ndegradation phenomenon is modeled by an ill-conditioned operator. In such a\ncase, the presence of noise makes it impossible to recover a valuable\napproximation of the image of interest without using some a priori information\nabout its properties. Such a priori information is essential for image\nrestoration, rendering it stable and robust to noise. Particularly, if the\noriginal image is known to be a piecewise smooth function, one of the standard\npriors used in this case is defined by the Rudin-Osher-Fatemi model, which\nresults in total variation (TV) based image restoration. The current arsenal of\nalgorithms for TV-based image restoration is vast. In the present paper, a\ndifferent approach to the solution of the problem is proposed based on the\nmethod of iterative shrinkage (aka iterated thresholding). In the proposed\nmethod, the TV-based image restoration is performed through a recursive\napplication of two simple procedures, viz. linear filtering and soft\nthresholding. Therefore, the method can be identified as belonging to the group\nof first-order algorithms which are efficient in dealing with images of\nrelatively large sizes. Another valuable feature of the proposed method\nconsists in its working directly with the TV functional, rather then with its\nsmoothed versions. Moreover, the method provides a single solution for both\nisotropic and anisotropic definitions of the TV functional, thereby\nestablishing a useful connection between the two formulae.\n",
        "published": "2009-10-26T22:50:18Z",
        "pdf_link": "http://arxiv.org/pdf/0910.5002v1"
    },
    {
        "id": "http://arxiv.org/abs/0911.0481v1",
        "title": "An Optimal Method For Wake Detection In SAR Images Using Radon\n  Transformation Combined With Wavelet Filters",
        "summary": "  A new fangled method for ship wake detection in synthetic aperture radar\n(SAR) images is explored here. Most of the detection procedure applies the\nRadon transform as its properties outfit more than any other transformation for\nthe detection purpose. But still it holds problems when the transform is\napplied to an image with a high level of noise. Here this paper articulates the\ncombination between the radon transformation and the shrinkage methods which\nincrease the mode of wake detection process. The latter shrinkage method with\nRT maximize the signal to noise ratio hence it leads to most optimal detection\nof lines in the SAR images. The originality mainly works on the denoising\nsegment of the proposed algorithm. Experimental work outs are carried over both\nin simulated and real SAR images. The detection process is more adequate with\nthe proposed method and improves better than the conventional methods.\n",
        "published": "2009-11-03T03:37:03Z",
        "pdf_link": "http://arxiv.org/pdf/0911.0481v1"
    },
    {
        "id": "http://arxiv.org/abs/0911.0490v1",
        "title": "Breast Cancer Detection Using Multilevel Thresholding",
        "summary": "  This paper presents an algorithm which aims to assist the radiologist in\nidentifying breast cancer at its earlier stages. It combines several image\nprocessing techniques like image negative, thresholding and segmentation\ntechniques for detection of tumor in mammograms. The algorithm is verified by\nusing mammograms from Mammographic Image Analysis Society. The results obtained\nby applying these techniques are described.\n",
        "published": "2009-11-03T04:33:55Z",
        "pdf_link": "http://arxiv.org/pdf/0911.0490v1"
    },
    {
        "id": "http://arxiv.org/abs/0911.4874v2",
        "title": "Non-photorealistic image processing: an Impressionist rendering",
        "summary": "  The paper describes an image processing for a non-photorealistic rendering.\nThe algorithm is based on a random choice of a set of pixels from those ot the\noriginal image and substitution of them with colour spots. An iterative\nprocedure is applied to cover, at a desired level, the canvas. The resulting\neffect mimics the impressionist painting and Pointillism.\n",
        "published": "2009-11-25T15:16:53Z",
        "pdf_link": "http://arxiv.org/pdf/0911.4874v2"
    },
    {
        "id": "http://arxiv.org/abs/0911.5462v1",
        "title": "Pigment Melanin: Pattern for Iris Recognition",
        "summary": "  Recognition of iris based on Visible Light (VL) imaging is a difficult\nproblem because of the light reflection from the cornea. Nonetheless, pigment\nmelanin provides a rich feature source in VL, unavailable in Near-Infrared\n(NIR) imaging. This is due to biological spectroscopy of eumelanin, a chemical\nnot stimulated in NIR. In this case, a plausible solution to observe such\npatterns may be provided by an adaptive procedure using a variational technique\non the image histogram. To describe the patterns, a shape analysis method is\nused to derive feature-code for each subject. An important question is how much\nthe melanin patterns, extracted from VL, are independent of iris texture in\nNIR. With this question in mind, the present investigation proposes fusion of\nfeatures extracted from NIR and VL to boost the recognition performance. We\nhave collected our own database (UTIRIS) consisting of both NIR and VL images\nof 158 eyes of 79 individuals. This investigation demonstrates that the\nproposed algorithm is highly sensitive to the patterns of cromophores and\nimproves the iris recognition rate.\n",
        "published": "2009-11-29T07:07:54Z",
        "pdf_link": "http://arxiv.org/pdf/0911.5462v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.0927v1",
        "title": "Accelerating Competitive Learning Graph Quantization",
        "summary": "  Vector quantization(VQ) is a lossy data compression technique from signal\nprocessing for which simple competitive learning is one standard method to\nquantize patterns from the input space. Extending competitive learning VQ to\nthe domain of graphs results in competitive learning for quantizing input\ngraphs. In this contribution, we propose an accelerated version of competitive\nlearning graph quantization (GQ) without trading computational time against\nsolution quality. For this, we lift graphs locally to vectors in order to avoid\nunnecessary calculations of intractable graph distances. In doing so, the\naccelerated version of competitive learning GQ gradually turns locally into a\ncompetitive learning VQ with increasing number of iterations. Empirical results\nshow a significant speedup by maintaining a comparable solution quality.\n",
        "published": "2010-01-06T16:05:25Z",
        "pdf_link": "http://arxiv.org/pdf/1001.0927v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.1221v1",
        "title": "Boosting k-NN for categorization of natural scenes",
        "summary": "  The k-nearest neighbors (k-NN) classification rule has proven extremely\nsuccessful in countless many computer vision applications. For example, image\ncategorization often relies on uniform voting among the nearest prototypes in\nthe space of descriptors. In spite of its good properties, the classic k-NN\nrule suffers from high variance when dealing with sparse prototype datasets in\nhigh dimensions. A few techniques have been proposed to improve k-NN\nclassification, which rely on either deforming the nearest neighborhood\nrelationship or modifying the input space. In this paper, we propose a novel\nboosting algorithm, called UNN (Universal Nearest Neighbors), which induces\nleveraged k-NN, thus generalizing the classic k-NN rule. We redefine the voting\nrule as a strong classifier that linearly combines predictions from the k\nclosest prototypes. Weak classifiers are learned by UNN so as to minimize a\nsurrogate risk. A major feature of UNN is the ability to learn which prototypes\nare the most relevant for a given class, thus allowing one for effective data\nreduction. Experimental results on the synthetic two-class dataset of Ripley\nshow that such a filtering strategy is able to reject \"noisy\" prototypes. We\ncarried out image categorization experiments on a database containing eight\nclasses of natural scenes. We show that our method outperforms significantly\nthe classic k-NN classification, while enabling significant reduction of the\ncomputational cost by means of data filtering.\n",
        "published": "2010-01-08T08:30:51Z",
        "pdf_link": "http://arxiv.org/pdf/1001.1221v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.1968v1",
        "title": "A Topological derivative based image segmentation for sign language\n  recognition system using isotropic filter",
        "summary": "  The need of sign language is increasing radically especially to hearing\nimpaired community. Only few research groups try to automatically recognize\nsign language from video, colored gloves and etc. Their approach requires a\nvalid segmentation of the data that is used for training and of the data that\nis used to be recognized. Recognition of a sign language image sequence is\nchallenging because of the variety of hand shapes and hand motions. Here, this\npaper proposes to apply a combination of image segmentation with restoration\nusing topological derivatives for achieving high recognition accuracy. Image\nquality measures are conceded here to differentiate the methods both\nsubjectively as well as objectively. Experiments show that the additional use\nof the restoration before segmenting the postures significantly improves the\ncorrect rate of hand detection, and that the discrete derivatives yields a high\nrate of discrimination between different static hand postures as well as\nbetween hand postures and the scene background. Eventually, the research is to\ncontribute to the implementation of automated sign language recognition system\nmainly established for the welfare purpose.\n",
        "published": "2010-01-12T18:18:10Z",
        "pdf_link": "http://arxiv.org/pdf/1001.1968v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.3487v1",
        "title": "Features Based Text Similarity Detection",
        "summary": "  As the Internet help us cross cultural border by providing different\ninformation, plagiarism issue is bound to arise. As a result, plagiarism\ndetection becomes more demanding in overcoming this issue. Different plagiarism\ndetection tools have been developed based on various detection techniques.\nNowadays, fingerprint matching technique plays an important role in those\ndetection tools. However, in handling some large content articles, there are\nsome weaknesses in fingerprint matching technique especially in space and time\nconsumption issue. In this paper, we propose a new approach to detect\nplagiarism which integrates the use of fingerprint matching technique with four\nkey features to assist in the detection process. These proposed features are\ncapable to choose the main point or key sentence in the articles to be\ncompared. Those selected sentence will be undergo the fingerprint matching\nprocess in order to detect the similarity between the sentences. Hence, time\nand space usage for the comparison process is reduced without affecting the\neffectiveness of the plagiarism detection.\n",
        "published": "2010-01-20T07:46:23Z",
        "pdf_link": "http://arxiv.org/pdf/1001.3487v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.3502v1",
        "title": "3D Skull Recognition Using 3D Matching Technique",
        "summary": "  Biometrics has become a \"hot\" area. Governments are funding research programs\nfocused on biometrics. In this paper the problem of person recognition and\nverification based on a different biometric application has been addressed. The\nsystem is based on the 3DSkull recognition using 3D matching technique, in fact\nthis paper present several bio-metric approaches in order of assign the weak\npoint in term of used the biometric from the authorize person and insure the\nperson who access the data is the real person. The feature of the simulate\nsystem shows the capability of using 3D matching system as an efficient way to\nidentify the person through his or her skull by match it with database, this\ntechnique grantee fast processing with optimizing the false positive and\nnegative as well .\n",
        "published": "2010-01-20T08:17:26Z",
        "pdf_link": "http://arxiv.org/pdf/1001.3502v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.3503v1",
        "title": "Hybrid Medical Image Classification Using Association Rule Mining with\n  Decision Tree Algorithm",
        "summary": "  The main focus of image mining in the proposed method is concerned with the\nclassification of brain tumor in the CT scan brain images. The major steps\ninvolved in the system are: pre-processing, feature extraction, association\nrule mining and hybrid classifier. The pre-processing step has been done using\nthe median filtering process and edge features have been extracted using canny\nedge detection technique. The two image mining approaches with a hybrid manner\nhave been proposed in this paper. The frequent patterns from the CT scan images\nare generated by frequent pattern tree (FP-Tree) algorithm that mines the\nassociation rules. The decision tree method has been used to classify the\nmedical images for diagnosis. This system enhances the classification process\nto be more accurate. The hybrid method improves the efficiency of the proposed\nmethod than the traditional image mining methods. The experimental result on\nprediagnosed database of brain images showed 97% sensitivity and 95% accuracy\nrespectively. The physicians can make use of this accurate decision tree\nclassification phase for classifying the brain images into normal, benign and\nmalignant for effective medical diagnosis.\n",
        "published": "2010-01-20T08:19:48Z",
        "pdf_link": "http://arxiv.org/pdf/1001.3503v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.3735v1",
        "title": "Gradient Based Seeded Region Grow method for CT Angiographic Image\n  Segmentation",
        "summary": "  Segmentation of medical images using seeded region growing technique is\nincreasingly becoming a popular method because of its ability to involve\nhigh-level knowledge of anatomical structures in seed selection process. Region\nbased segmentation of medical images are widely used in varied clinical\napplications like visualization, bone detection, tumor detection and\nunsupervised image retrieval in clinical databases. As medical images are\nmostly fuzzy in nature, segmenting regions based intensity is the most\nchallenging task. In this paper, we discuss about popular seeded region grow\nmethodology used for segmenting anatomical structures in CT Angiography images.\nWe have proposed a gradient based homogeneity criteria to control the region\ngrow process while segmenting CTA images.\n",
        "published": "2010-01-21T07:15:29Z",
        "pdf_link": "http://arxiv.org/pdf/1001.3735v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.4189v1",
        "title": "Detection and Demarcation of Tumor using Vector Quantization in MRI\n  images",
        "summary": "  Segmenting a MRI images into homogeneous texture regions representing\ndisparate tissue types is often a useful preprocessing step in the\ncomputer-assisted detection of breast cancer. That is why we proposed new\nalgorithm to detect cancer in mammogram breast cancer images. In this paper we\nproposed segmentation using vector quantization technique. Here we used Linde\nBuzo-Gray algorithm (LBG) for segmentation of MRI images. Initially a codebook\nof size 128 was generated for MRI images. These code vectors were further\nclustered in 8 clusters using same LBG algorithm. These 8 images were displayed\nas a result. This approach does not leads to over segmentation or under\nsegmentation. For the comparison purpose we displayed results of watershed\nsegmentation and Entropy using Gray Level Co-occurrence Matrix along with this\nmethod.\n",
        "published": "2010-01-23T19:00:44Z",
        "pdf_link": "http://arxiv.org/pdf/1001.4189v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.4297v1",
        "title": "Multi-camera Realtime 3D Tracking of Multiple Flying Animals",
        "summary": "  Automated tracking of animal movement allows analyses that would not\notherwise be possible by providing great quantities of data. The additional\ncapability of tracking in realtime - with minimal latency - opens up the\nexperimental possibility of manipulating sensory feedback, thus allowing\ndetailed explorations of the neural basis for control of behavior. Here we\ndescribe a new system capable of tracking the position and body orientation of\nanimals such as flies and birds. The system operates with less than 40 msec\nlatency and can track multiple animals simultaneously. To achieve these\nresults, a multi target tracking algorithm was developed based on the Extended\nKalman Filter and the Nearest Neighbor Standard Filter data association\nalgorithm. In one implementation, an eleven camera system is capable of\ntracking three flies simultaneously at 60 frames per second using a gigabit\nnetwork of nine standard Intel Pentium 4 and Core 2 Duo computers. This\nmanuscript presents the rationale and details of the algorithms employed and\nshows three implementations of the system. An experiment was performed using\nthe tracking system to measure the effect of visual contrast on the flight\nspeed of Drosophila melanogaster. At low contrasts, speed is more variable and\nfaster on average than at high contrasts. Thus, the system is already a useful\ntool to study the neurobiology and behavior of freely flying animals. If\ncombined with other techniques, such as `virtual reality'-type computer\ngraphics or genetic manipulation, the tracking system would offer a powerful\nnew way to investigate the biology of flying animals.\n",
        "published": "2010-01-25T01:40:40Z",
        "pdf_link": "http://arxiv.org/pdf/1001.4297v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.5352v1",
        "title": "Kannada Character Recognition System A Review",
        "summary": "  Intensive research has been done on optical character recognition ocr and a\nlarge number of articles have been published on this topic during the last few\ndecades. Many commercial OCR systems are now available in the market, but most\nof these systems work for Roman, Chinese, Japanese and Arabic characters. There\nare no sufficient number of works on Indian language character recognition\nespecially Kannada script among 12 major scripts in India. This paper presents\na review of existing work on printed Kannada script and their results. The\ncharacteristics of Kannada script and Kannada Character Recognition System kcr\nare discussed in detail. Finally fusion at the classifier level is proposed to\nincrease the recognition accuracy.\n",
        "published": "2010-01-29T08:29:57Z",
        "pdf_link": "http://arxiv.org/pdf/1001.5352v1"
    },
    {
        "id": "http://arxiv.org/abs/1001.5359v1",
        "title": "Threshold Based Indexing of Commercial Shoe Print to Create Reference\n  and Recovery Images",
        "summary": "  One of the important evidence in a crime scene that is normally overlooked\nbut very important evidence is shoe print as the criminal is normally unaware\nof the mask for this. In this paper we use image processing technique to\nprocess reference shoe images to make it index-able for a search from the\ndatabase the shoe print impressions available in the commercial market. This is\nachieved first by converting the commercially available image through the\nprocess of converting them to gray scale then apply image enhancement and\nrestoration techniques and finally do image segmentation to store the segmented\nparameter as index in the database storage. We use histogram method for image\nenhancement, inverse filtering for image restoration and threshold method for\nindexing. We use global threshold as index of the shoe print. The paper\ndescribes this method and simulation results are included to validate the\nmethod.\n",
        "published": "2010-01-29T09:03:48Z",
        "pdf_link": "http://arxiv.org/pdf/1001.5359v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.1148v1",
        "title": "A Comparative Study of Removal Noise from Remote Sensing Image",
        "summary": "  This paper attempts to undertake the study of three types of noise such as\nSalt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN).\nDifferent noise densities have been removed between 10% to 60% by using five\ntypes of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian\nFilter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The\nsame is applied to the Saturn remote sensing image and they are compared with\none another. The comparative study is conducted with the help of Mean Square\nErrors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base\nmethod for removal of noise from remote sensing image.\n",
        "published": "2010-02-05T08:34:39Z",
        "pdf_link": "http://arxiv.org/pdf/1002.1148v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.1285v1",
        "title": "The Influence of Intensity Standardization on Medical Image Registration",
        "summary": "  Acquisition-to-acquisition signal intensity variations (non-standardness) are\ninherent in MR images. Standardization is a post processing method for\ncorrecting inter-subject intensity variations through transforming all images\nfrom the given image gray scale into a standard gray scale wherein similar\nintensities achieve similar tissue meanings. The lack of a standard image\nintensity scale in MRI leads to many difficulties in tissue characterizability,\nimage display, and analysis, including image segmentation. This phenomenon has\nbeen documented well; however, effects of standardization on medical image\nregistration have not been studied yet. In this paper, we investigate the\ninfluence of intensity standardization in registration tasks with systematic\nand analytic evaluations involving clinical MR images. We conducted nearly\n20,000 clinical MR image registration experiments and evaluated the quality of\nregistrations both quantitatively and qualitatively. The evaluations show that\nintensity variations between images degrades the accuracy of registration\nperformance. The results imply that the accuracy of image registration not only\ndepends on spatial and geometric similarity but also on the similarity of the\nintensity values for the same tissues in different images.\n",
        "published": "2010-02-05T17:35:49Z",
        "pdf_link": "http://arxiv.org/pdf/1002.1285v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.1288v1",
        "title": "Ball-Scale Based Hierarchical Multi-Object Recognition in 3D Medical\n  Images",
        "summary": "  This paper investigates, using prior shape models and the concept of ball\nscale (b-scale), ways of automatically recognizing objects in 3D images without\nperforming elaborate searches or optimization. That is, the goal is to place\nthe model in a single shot close to the right pose (position, orientation, and\nscale) in a given image so that the model boundaries fall in the close vicinity\nof object boundaries in the image. This is achieved via the following set of\nkey ideas: (a) A semi-automatic way of constructing a multi-object shape model\nassembly. (b) A novel strategy of encoding, via b-scale, the pose relationship\nbetween objects in the training images and their intensity patterns captured in\nb-scale images. (c) A hierarchical mechanism of positioning the model, in a\none-shot way, in a given image from a knowledge of the learnt pose relationship\nand the b-scale image of the given image to be segmented. The evaluation\nresults on a set of 20 routine clinical abdominal female and male CT data sets\nindicate the following: (1) Incorporating a large number of objects improves\nthe recognition accuracy dramatically. (2) The recognition algorithm can be\nthought as a hierarchical framework such that quick replacement of the model\nassembly is defined as coarse recognition and delineation itself is known as\nfinest recognition. (3) Scale yields useful information about the relationship\nbetween the model assembly and any given image such that the recognition\nresults in a placement of the model close to the actual pose without doing any\nelaborate searches or optimization. (4) Effective object recognition can make\ndelineation most accurate.\n",
        "published": "2010-02-05T17:54:36Z",
        "pdf_link": "http://arxiv.org/pdf/1002.1288v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.2182v1",
        "title": "Detection of Microcalcification in Mammograms Using Wavelet Transform\n  and Fuzzy Shell Clustering",
        "summary": "  Microcalcifications in mammogram have been mainly targeted as a reliable\nearliest sign of breast cancer and their early detection is vital to improve\nits prognosis. Since their size is very small and may be easily overlooked by\nthe examining radiologist, computer-based detection output can assist the\nradiologist to improve the diagnostic accuracy. In this paper, we have proposed\nan algorithm for detecting microcalcification in mammogram. The proposed\nmicrocalcification detection algorithm involves mammogram quality enhancement\nusing multirresolution analysis based on the dyadic wavelet transform and\nmicrocalcification detection by fuzzy shell clustering. It may be possible to\ndetect nodular components such as microcalcification accurately by introducing\nshape information. The effectiveness of the proposed algorithm for\nmicrocalcification detection is confirmed by experimental results.\n",
        "published": "2010-02-10T19:22:25Z",
        "pdf_link": "http://arxiv.org/pdf/1002.2182v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.2408v1",
        "title": "Automatic diagnosis of retinal diseases from color retinal images",
        "summary": "  Teleophthalmology holds a great potential to improve the quality, access, and\naffordability in health care. For patients, it can reduce the need for travel\nand provide the access to a superspecialist. Ophthalmology lends itself easily\nto telemedicine as it is a largely image based diagnosis. The main goal of the\nproposed system is to diagnose the type of disease in the retina and to\nautomatically detect and segment retinal diseases without human supervision or\ninteraction. The proposed system will diagnose the disease present in the\nretina using a neural network based classifier.The extent of the disease spread\nin the retina can be identified by extracting the textural features of the\nretina. This system will diagnose the following type of diseases: Diabetic\nRetinopathy and Drusen.\n",
        "published": "2010-02-11T19:54:08Z",
        "pdf_link": "http://arxiv.org/pdf/1002.2408v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.2418v1",
        "title": "Medical Image Compression using Wavelet Decomposition for Prediction\n  Method",
        "summary": "  In this paper offers a simple and lossless compression method for compression\nof medical images. Method is based on wavelet decomposition of the medical\nimages followed by the correlation analysis of coefficients. The correlation\nanalyses are the basis of prediction equation for each sub band. Predictor\nvariable selection is performed through coefficient graphic method to avoid\nmulticollinearity problem and to achieve high prediction accuracy and\ncompression rate. The method is applied on MRI and CT images. Results show that\nthe proposed approach gives a high compression rate for MRI and CT images\ncomparing with state of the art methods.\n",
        "published": "2010-02-11T20:16:33Z",
        "pdf_link": "http://arxiv.org/pdf/1002.2418v1"
    },
    {
        "id": "http://arxiv.org/abs/1002.3985v1",
        "title": "Supervised Learning of Digital image restoration based on Quantization\n  Nearest Neighbor algorithm",
        "summary": "  In this paper, an algorithm is proposed for Image Restoration. Such algorithm\nis different from the traditional approaches in this area, by utilizing priors\nthat are learned from similar images. Original images and their degraded\nversions by the known degradation operators are utilized for designing the\nQuantization. The code vectors are designed using the blurred images. For each\nsuch vector, the high frequency information obtained from the original images\nis also available. During restoration, the high frequency information of a\ngiven degraded image is estimated from its low frequency information based on\nthe artificial noise. For the restoration problem, a number of techniques are\ndesigned corresponding to various versions of the blurring function. Given a\nnoisy and blurred image, one of the techniques is chosen based on a similarity\nmeasure, therefore providing the identification of the blur. To make the\nrestoration process computationally efficient, the Quantization Nearest\nNeighborhood approaches are utilized.\n",
        "published": "2010-02-21T18:34:10Z",
        "pdf_link": "http://arxiv.org/pdf/1002.3985v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.0487v1",
        "title": "Scalable Large-Margin Mahalanobis Distance Metric Learning",
        "summary": "  For many machine learning algorithms such as $k$-Nearest Neighbor ($k$-NN)\nclassifiers and $ k $-means clustering, often their success heavily depends on\nthe metric used to calculate distances between different data points.\n  An effective solution for defining such a metric is to learn it from a set of\nlabeled training samples. In this work, we propose a fast and scalable\nalgorithm to learn a Mahalanobis distance metric. By employing the principle of\nmargin maximization to achieve better generalization performances, this\nalgorithm formulates the metric learning as a convex optimization problem and a\npositive semidefinite (psd) matrix is the unknown variable. a specialized\ngradient descent method is proposed. our algorithm is much more efficient and\nhas a better performance in scalability compared with existing methods.\nExperiments on benchmark data sets suggest that, compared with state-of-the-art\nmetric learning algorithms, our algorithm can achieve a comparable\nclassification accuracy with reduced computational complexity.\n",
        "published": "2010-03-02T01:12:34Z",
        "pdf_link": "http://arxiv.org/pdf/1003.0487v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.0642v2",
        "title": "Text Region Extraction from Business Card Images for Mobile Devices",
        "summary": "  Designing a Business Card Reader (BCR) for mobile devices is a challenge to\nthe researchers because of huge deformation in acquired images, multiplicity in\nnature of the business cards and most importantly the computational constraints\nof the mobile devices. This paper presents a text extraction method designed in\nour work towards developing a BCR for mobile devices. At first, the background\nof a camera captured image is eliminated at a coarse level. Then, various rule\nbased techniques are applied on the Connected Components (CC) to filter out the\nnoises and picture regions. The CCs identified as text are then binarized using\nan adaptive but light-weight binarization technique. Experiments show that the\ntext extraction accuracy is around 98% for a wide range of resolutions with\nvarying computation time and memory requirements. The optimum performance is\nachieved for the images of resolution 1024x768 pixels with text extraction\naccuracy of 98.54% and, space and time requirements as 1.1 MB and 0.16 seconds\nrespectively.\n",
        "published": "2010-03-02T17:45:26Z",
        "pdf_link": "http://arxiv.org/pdf/1003.0642v2"
    },
    {
        "id": "http://arxiv.org/abs/1003.0645v2",
        "title": "Binarizing Business Card Images for Mobile Devices",
        "summary": "  Business card images are of multiple natures as these often contain graphics,\npictures and texts of various fonts and sizes both in background and\nforeground. So, the conventional binarization techniques designed for document\nimages can not be directly applied on mobile devices. In this paper, we have\npresented a fast binarization technique for camera captured business card\nimages. A card image is split into small blocks. Some of these blocks are\nclassified as part of the background based on intensity variance. Then the\nnon-text regions are eliminated and the text ones are skew corrected and\nbinarized using a simple yet adaptive technique. Experiment shows that the\ntechnique is fast, efficient and applicable for the mobile devices.\n",
        "published": "2010-03-02T18:02:40Z",
        "pdf_link": "http://arxiv.org/pdf/1003.0645v2"
    },
    {
        "id": "http://arxiv.org/abs/1003.0776v1",
        "title": "Properties of the Discrete Pulse Transform for Multi-Dimensional Arrays",
        "summary": "  This report presents properties of the Discrete Pulse Transform on\nmulti-dimensional arrays introduced by the authors two or so years ago. The\nmain result given here in Lemma 2.1 is also formulated in a paper to appear in\nIEEE Transactions on Image Processing. However, the proof, being too technical,\nwas omitted there and hence it appears in full in this publication.\n",
        "published": "2010-03-03T10:58:20Z",
        "pdf_link": "http://arxiv.org/pdf/1003.0776v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.1072v2",
        "title": "An Offline Technique for Localization of License Plates for Indian\n  Commercial Vehicles",
        "summary": "  Automatic License Plate Recognition (ALPR) is a challenging area of research\ndue to its importance to variety of commercial applications. The overall\nproblem may be subdivided into two key modules, firstly, localization of\nlicense plates from vehicle images, and secondly, optical character recognition\nof extracted license plates. In the current work, we have concentrated on the\nfirst part of the problem, i.e., localization of license plate regions from\nIndian commercial vehicles as a significant step towards development of a\ncomplete ALPR system for Indian vehicles. The technique is based on color based\nsegmentation of vehicle images and identification of potential license plate\nregions. True license plates are finally localized based on four spatial and\nhorizontal contrast features. The technique successfully localizes the actual\nlicense plates in 73.4% images.\n",
        "published": "2010-03-04T15:57:41Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1072v2"
    },
    {
        "id": "http://arxiv.org/abs/1003.1511v1",
        "title": "Clinical gait data analysis based on Spatio-Temporal features",
        "summary": "  Analysing human gait has found considerable interest in recent computer\nvision research. So far, however, contributions to this topic exclusively dealt\nwith the tasks of person identification or activity recognition. In this paper,\nwe consider a different application for gait analysis and examine its use as a\nmeans of deducing the physical well-being of people. The proposed method is\nbased on transforming the joint motion trajectories using wavelets to extract\nspatio-temporal features which are then fed as input to a vector quantiser; a\nself-organising map for classification of walking patterns of individuals with\nand without pathology. We show that our proposed algorithm is successful in\nextracting features that successfully discriminate between individuals with and\nwithout locomotion impairment.\n",
        "published": "2010-03-07T18:46:12Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1511v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.1803v1",
        "title": "Nonlinear Filter Based Image Denoising Using AMF Approach",
        "summary": "  This paper proposes a new technique based on nonlinear Adaptive Median filter\n(AMF) for image restoration. Image denoising is a common procedure in digital\nimage processing aiming at the removal of noise, which may corrupt an image\nduring its acquisition or transmission, while retaining its quality. This\nprocedure is traditionally performed in the spatial or frequency domain by\nfiltering. The aim of image enhancement is to reconstruct the true image from\nthe corrupted image. The process of image acquisition frequently leads to\ndegradation and the quality of the digitized image becomes inferior to the\noriginal image. Filtering is a technique for enhancing the image. Linear filter\nis the filtering in which the value of an output pixel is a linear combination\nof neighborhood values, which can produce blur in the image. Thus a variety of\nsmoothing techniques have been developed that are non linear. Median filter is\nthe one of the most popular non-linear filter. When considering a small\nneighborhood it is highly efficient but for large window and in case of high\nnoise it gives rise to more blurring to image. The Centre Weighted Median (CWM)\nfilter has got a better average performance over the median filter [8]. However\nthe original pixel corrupted and noise reduction is substantial under high\nnoise condition. Hence this technique has also blurring affect on the image. To\nillustrate the superiority of the proposed approach by overcoming the existing\nproblem, the proposed new scheme (AMF) Adaptive Median Filter has been\nsimulated along with the standard ones and various performance measures have\nbeen compared.\n",
        "published": "2010-03-09T07:05:47Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1803v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.1819v1",
        "title": "Facial Gesture Recognition Using Correlation And Mahalanobis Distance",
        "summary": "  Augmenting human computer interaction with automated analysis and synthesis\nof facial expressions is a goal towards which much research effort has been\ndevoted recently. Facial gesture recognition is one of the important component\nof natural human-machine interfaces; it may also be used in behavioural\nscience, security systems and in clinical practice. Although humans recognise\nfacial expressions virtually without effort or delay, reliable expression\nrecognition by machine is still a challenge. The face expression recognition\nproblem is challenging because different individuals display the same\nexpression differently. This paper presents an overview of gesture recognition\nin real time using the concepts of correlation and Mahalanobis distance.We\nconsider the six universal emotional categories namely joy, anger, fear,\ndisgust, sadness and surprise.\n",
        "published": "2010-03-09T07:39:03Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1819v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.1826v1",
        "title": "A GA based Window Selection Methodology to Enhance Window based Multi\n  wavelet transformation and thresholding aided CT image denoising technique",
        "summary": "  Image denoising is getting more significance, especially in Computed\nTomography (CT), which is an important and most common modality in medical\nimaging. This is mainly due to that the effectiveness of clinical diagnosis\nusing CT image lies on the image quality. The denoising technique for CT images\nusing window-based Multi-wavelet transformation and thresholding shows the\neffectiveness in denoising, however, a drawback exists in selecting the closer\nwindows in the process of window-based multi-wavelet transformation and\nthresholding. Generally, the windows of the duplicate noisy image that are\ncloser to each window of original noisy image are obtained by the checking them\nsequentially. This leads to the possibility of missing out very closer windows\nand so enhancement is required in the aforesaid process of the denoising\ntechnique. In this paper, we propose a GA-based window selection methodology to\ninclude the denoising technique. With the aid of the GA-based window selection\nmethodology, the windows of the duplicate noisy image that are very closer to\nevery window of the original noisy image are extracted in an effective manner.\nBy incorporating the proposed GA-based window selection methodology, the\ndenoising the CT image is performed effectively. Eventually, a comparison is\nmade between the denoising technique with and without the proposed GA-based\nwindow selection methodology.\n",
        "published": "2010-03-09T08:09:02Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1826v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.1827v1",
        "title": "Investigation and Assessment of Disorder of Ultrasound B-mode Images",
        "summary": "  Digital image plays a vital role in the early detection of cancers, such as\nprostate cancer, breast cancer, lungs cancer, cervical cancer. Ultrasound\nimaging method is also suitable for early detection of the abnormality of\nfetus. The accurate detection of region of interest in ultrasound image is\ncrucial. Since the result of reflection, refraction and deflection of\nultrasound waves from different types of tissues with different acoustic\nimpedance. Usually, the contrast in ultrasound image is very low and weak edges\nmake the image difficult to identify the fetus region in the ultrasound image.\nSo the analysis of ultrasound image is more challenging one. We try to develop\na new algorithmic approach to solve the problem of non clarity and find\ndisorder of it. Generally there is no common enhancement approach for noise\nreduction. This paper proposes different filtering techniques based on\nstatistical methods for the removal of various noise. The quality of the\nenhanced images is measured by the statistical quantity measures:\nSignal-to-Noise Ratio (SNR), Peak Signal-to-Noise Ratio (PSNR), and Root Mean\nSquare Error (RMSE).\n",
        "published": "2010-03-09T08:13:37Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1827v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.1891v1",
        "title": "Handwritten Arabic Numeral Recognition using a Multi Layer Perceptron",
        "summary": "  Handwritten numeral recognition is in general a benchmark problem of Pattern\nRecognition and Artificial Intelligence. Compared to the problem of printed\nnumeral recognition, the problem of handwritten numeral recognition is\ncompounded due to variations in shapes and sizes of handwritten characters.\nConsidering all these, the problem of handwritten numeral recognition is\naddressed under the present work in respect to handwritten Arabic numerals.\nArabic is spoken throughout the Arab World and the fifth most popular language\nin the world slightly before Portuguese and Bengali. For the present work, we\nhave developed a feature set of 88 features is designed to represent samples of\nhandwritten Arabic numerals for this work. It includes 72 shadow and 16 octant\nfeatures. A Multi Layer Perceptron (MLP) based classifier is used here for\nrecognition handwritten Arabic digits represented with the said feature set. On\nexperimentation with a database of 3000 samples, the technique yields an\naverage recognition rate of 94.93% evaluated after three-fold cross validation\nof results. It is useful for applications related to OCR of handwritten Arabic\nDigit and can also be extended to include OCR of handwritten characters of\nArabic alphabet.\n",
        "published": "2010-03-09T14:56:00Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1891v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.1894v1",
        "title": "A comparative study of different feature sets for recognition of\n  handwritten Arabic numerals using a Multi Layer Perceptron",
        "summary": "  The work presents a comparative assessment of seven different feature sets\nfor recognition of handwritten Arabic numerals using a Multi Layer Perceptron\n(MLP) based classifier. The seven feature sets employed here consist of shadow\nfeatures, octant centroids, longest runs, angular distances, effective spans,\ndynamic centers of gravity, and some of their combinations. On experimentation\nwith a database of 3000 samples, the maximum recognition rate of 95.80% is\nobserved with both of two separate combinations of features. One of these\ncombinations consists of shadow and centriod features, i. e. 88 features in\nall, and the other shadow, centroid and longest run features, i. e. 124\nfeatures in all. Out of these two, the former combination having a smaller\nnumber of features is finally considered effective for applications related to\nOptical Character Recognition (OCR) of handwritten Arabic numerals. The work\ncan also be extended to include OCR of handwritten characters of Arabic\nalphabet.\n",
        "published": "2010-03-09T15:05:37Z",
        "pdf_link": "http://arxiv.org/pdf/1003.1894v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.3266v1",
        "title": "Pattern recognition using inverse resonance filtration",
        "summary": "  An approach to textures pattern recognition based on inverse resonance\nfiltration (IRF) is considered. A set of principal resonance harmonics of\ntextured image signal fluctuations eigen harmonic decomposition (EHD) is used\nfor the IRF design. It was shown that EHD is invariant to textured image linear\nshift. The recognition of texture is made by transfer of its signal into\nunstructured signal which simple statistical parameters can be used for texture\npattern recognition. Anomalous variations of this signal point on foreign\nobjects. Two methods of 2D EHD parameters estimation are considered with the\naccount of texture signal breaks presence. The first method is based on the\nlinear symmetry model that is not sensitive to signal phase jumps. The\ncondition of characteristic polynomial symmetry provides the model stationarity\nand periodicity. Second method is based on the eigenvalues problem of matrices\npencil projection into principal vectors space of singular values decomposition\n(SVD) of 2D correlation matrix. Two methods of classification of retrieval from\ntextured image foreign objects are offered.\n",
        "published": "2010-03-16T22:30:12Z",
        "pdf_link": "http://arxiv.org/pdf/1003.3266v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.3654v1",
        "title": "Sliding window approach based Text Binarisation from Complex Textual\n  images",
        "summary": "  Text binarisation process classifies individual pixels as text or background\nin the textual images. Binarization is necessary to bridge the gap between\nlocalization and recognition by OCR. This paper presents Sliding window method\nto binarise text from textual images with textured background. Suitable\npreprocessing techniques are applied first to increase the contrast of the\nimage and blur the background noises due to textured background. Then Edges are\ndetected by iterative thresholding. Subsequently formed edge boxes are analyzed\nto remove unwanted edges due to complex background and binarised by sliding\nwindow approach based character size uniformity check algorithm. The proposed\nmethod has been applied on localized region from heterogeneous textual images\nand compared with Otsu, Niblack methods and shown encouraging performance of\nthe proposed method.\n",
        "published": "2010-03-18T19:01:56Z",
        "pdf_link": "http://arxiv.org/pdf/1003.3654v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.4021v1",
        "title": "System-theoretic approach to image interest point detection",
        "summary": "  Interest point detection is a common task in various computer vision\napplications. Although a big variety of detector are developed so far\ncomputational efficiency of interest point based image analysis remains to be\nthe problem. Current paper proposes a system-theoretic approach to interest\npoint detection. Starting from the analysis of interdependency between detector\nand descriptor it is shown that given a descriptor it is possible to introduce\nto notion of detector redundancy. Furthermore for each detector it is possible\nto construct its irredundant and equivalent modification. Modified detector\npossesses lower computational complexity and is preferable. It is also shown\nthat several known approaches to reduce computational complexity of image\nregistration can be generalized in terms of proposed theory.\n",
        "published": "2010-03-21T20:21:09Z",
        "pdf_link": "http://arxiv.org/pdf/1003.4021v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.4053v1",
        "title": "A Comprehensive Review of Image Enhancement Techniques",
        "summary": "  Principle objective of Image enhancement is to process an image so that\nresult is more suitable than original image for specific application. Digital\nimage enhancement techniques provide a multitude of choices for improving the\nvisual quality of images. Appropriate choice of such techniques is greatly\ninfluenced by the imaging modality, task at hand and viewing conditions. This\npaper will provide an overview of underlying concepts, along with algorithms\ncommonly used for image enhancement. The paper focuses on spatial domain\ntechniques for image enhancement, with particular reference to point processing\nmethods and histogram processing.\n",
        "published": "2010-03-22T03:39:46Z",
        "pdf_link": "http://arxiv.org/pdf/1003.4053v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.4087v1",
        "title": "Land-cover Classification and Mapping for Eastern Himalayan State Sikkim",
        "summary": "  Area of classifying satellite imagery has become a challenging task in\ncurrent era where there is tremendous growth in settlement i.e. construction of\nbuildings, roads, bridges, dam etc. This paper suggests an improvised k-means\nand Artificial Neural Network (ANN) classifier for land-cover mapping of\nEastern Himalayan state Sikkim. The improvised k-means algorithm shows\nsatisfactory results compared to existing methods that includes k-Nearest\nNeighbor and maximum likelihood classifier. The strength of the Artificial\nNeural Network (ANN) classifier lies in the fact that they are fast and have\ngood recognition rate and it's capability of self-learning compared to other\nclassification algorithms has made it widely accepted. Classifier based on ANN\nshows satisfactory and accurate result in comparison with the classical method.\n",
        "published": "2010-03-22T06:49:30Z",
        "pdf_link": "http://arxiv.org/pdf/1003.4087v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.5249v1",
        "title": "Active Testing for Face Detection and Localization",
        "summary": "  We provide a novel search technique, which uses a hierarchical model and a\nmutual information gain heuristic to efficiently prune the search space when\nlocalizing faces in images. We show exponential gains in computation over\ntraditional sliding window approaches, while keeping similar performance\nlevels.\n",
        "published": "2010-03-27T00:17:19Z",
        "pdf_link": "http://arxiv.org/pdf/1003.5249v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.5320v1",
        "title": "The Video Genome",
        "summary": "  Fast evolution of Internet technologies has led to an explosive growth of\nvideo data available in the public domain and created unprecedented challenges\nin the analysis, organization, management, and control of such content. The\nproblems encountered in video analysis such as identifying a video in a large\ndatabase (e.g. detecting pirated content in YouTube), putting together video\nfragments, finding similarities and common ancestry between different versions\nof a video, have analogous counterpart problems in genetic research and\nanalysis of DNA and protein sequences. In this paper, we exploit the analogy\nbetween genetic sequences and videos and propose an approach to video analysis\nmotivated by genomic research. Representing video information as video DNA\nsequences and applying bioinformatic algorithms allows to search, match, and\ncompare videos in large-scale databases. We show an application for\ncontent-based metadata mapping between versions of annotated video.\n",
        "published": "2010-03-27T20:57:47Z",
        "pdf_link": "http://arxiv.org/pdf/1003.5320v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.5821v1",
        "title": "Tuning CLD Maps",
        "summary": "  The Coherence Length Diagram and the related maps have been shown to\nrepresent a useful tool for image analysis. Setting threshold parameters is one\nof the most important issues when dealing with such applications, as they\naffect both the computability, which is outlined by the support map, and the\nappearance of the coherence length diagram itself and of defect maps. A coupled\noptimization analysis, returning a range for the basic (saturation) threshold,\nand a histogram based method, yielding suitable values for a desired map\nappearance, are proposed for an effective control of the analysis process.\n",
        "published": "2010-03-30T13:58:08Z",
        "pdf_link": "http://arxiv.org/pdf/1003.5821v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.5861v1",
        "title": "Robust multi-camera view face recognition",
        "summary": "  This paper presents multi-appearance fusion of Principal Component Analysis\n(PCA) and generalization of Linear Discriminant Analysis (LDA) for multi-camera\nview offline face recognition (verification) system. The generalization of LDA\nhas been extended to establish correlations between the face classes in the\ntransformed representation and this is called canonical covariate. The proposed\nsystem uses Gabor filter banks for characterization of facial features by\nspatial frequency, spatial locality and orientation to make compensate to the\nvariations of face instances occurred due to illumination, pose and facial\nexpression changes. Convolution of Gabor filter bank to face images produces\nGabor face representations with high dimensional feature vectors. PCA and\ncanonical covariate are then applied on the Gabor face representations to\nreduce the high dimensional feature spaces into low dimensional Gabor\neigenfaces and Gabor canonical faces. Reduced eigenface vector and canonical\nface vector are fused together using weighted mean fusion rule. Finally,\nsupport vector machines (SVM) have trained with augmented fused set of features\nand perform the recognition task. The system has been evaluated with UMIST face\ndatabase consisting of multiview faces. The experimental results demonstrate\nthe efficiency and robustness of the proposed system for multi-view face images\nwith high recognition rates. Complexity analysis of the proposed system is also\npresented at the end of the experimental results.\n",
        "published": "2010-03-30T16:26:39Z",
        "pdf_link": "http://arxiv.org/pdf/1003.5861v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.5886v1",
        "title": "Development of a multi-user handwriting recognition system using\n  Tesseract open source OCR engine",
        "summary": "  The objective of the paper is to recognize handwritten samples of lower case\nRoman script using Tesseract open source Optical Character Recognition (OCR)\nengine under Apache License 2.0. Handwritten data samples containing isolated\nand free-flow text were collected from different users. Tesseract is trained\nwith user-specific data samples of both the categories of document pages to\ngenerate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated and free-flow handwritten test samples\ncollected from the designated user. On a three user model, the system is\ntrained with 1844, 1535 and 1113 isolated handwritten character samples\ncollected from three different users and the performance is tested on 1133,\n1186 and 1204 character samples, collected form the test sets of the three\nusers respectively. The user specific character level accuracies were obtained\nas 87.92%, 81.53% and 65.71% respectively. The overall character-level accuracy\nof the system is observed as 78.39%. The system fails to segment 10.96%\ncharacters and erroneously classifies 10.65% characters on the overall dataset.\n",
        "published": "2010-03-30T18:22:44Z",
        "pdf_link": "http://arxiv.org/pdf/1003.5886v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.5891v1",
        "title": "Recognition of Handwritten Roman Script Using Tesseract Open source OCR\n  Engine",
        "summary": "  In the present work, we have used Tesseract 2.01 open source Optical\nCharacter Recognition (OCR) Engine under Apache License 2.0 for recognition of\nhandwriting samples of lower case Roman script. Handwritten isolated and\nfree-flow text samples were collected from multiple users. Tesseract is trained\nto recognize user-specific handwriting samples of both the categories of\ndocument pages. On a single user model, the system is trained with 1844\nisolated handwritten characters and the performance is tested on 1133\ncharacters, taken form the test set. The overall character-level accuracy of\nthe system is observed as 83.5%. The system fails to segment 5.56% characters\nand erroneously classifies 10.94% characters.\n",
        "published": "2010-03-30T18:35:37Z",
        "pdf_link": "http://arxiv.org/pdf/1003.5891v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.5893v1",
        "title": "Recognition of Handwritten Textual Annotations using Tesseract Open\n  Source OCR Engine for information Just In Time (iJIT)",
        "summary": "  Objective of the current work is to develop an Optical Character Recognition\n(OCR) engine for information Just In Time (iJIT) system that can be used for\nrecognition of handwritten textual annotations of lower case Roman script.\nTesseract open source OCR engine under Apache License 2.0 is used to develop\nuser-specific handwriting recognition models, viz., the language sets, for the\nsaid system, where each user is identified by a unique identification tag\nassociated with the digital pen. To generate the language set for any user,\nTesseract is trained with labeled handwritten data samples of isolated and\nfree-flow texts of Roman script, collected exclusively from that user. The\ndesigned system is tested on five different language sets with free- flow\nhandwritten annotations as test samples. The system could successfully segment\nand subsequently recognize 87.92%, 81.53%, 92.88%, 86.75% and 90.80%\nhandwritten characters in the test samples of five different users.\n",
        "published": "2010-03-30T18:48:47Z",
        "pdf_link": "http://arxiv.org/pdf/1003.5893v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.5897v1",
        "title": "Development of a Multi-User Recognition Engine for Handwritten Bangla\n  Basic Characters and Digits",
        "summary": "  The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset.\n",
        "published": "2010-03-30T18:54:57Z",
        "pdf_link": "http://arxiv.org/pdf/1003.5897v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.5898v1",
        "title": "Recognition of handwritten Roman Numerals using Tesseract open source\n  OCR engine",
        "summary": "  The objective of the paper is to recognize handwritten samples of Roman\nnumerals using Tesseract open source Optical Character Recognition (OCR)\nengine. Tesseract is trained with data samples of different persons to generate\none user-independent language model, representing the handwritten Roman\ndigit-set. The system is trained with 1226 digit samples collected form the\ndifferent users. The performance is tested on two different datasets, one\nconsisting of samples collected from the known users (those who prepared the\ntraining data samples) and the other consisting of handwritten data samples of\nunknown users. The overall recognition accuracy is obtained as 92.1% and 86.59%\non these test datasets respectively.\n",
        "published": "2010-03-30T18:59:49Z",
        "pdf_link": "http://arxiv.org/pdf/1003.5898v1"
    },
    {
        "id": "http://arxiv.org/abs/1003.6052v2",
        "title": "Development of an automated Red Light Violation Detection System (RLVDS)\n  for Indian vehicles",
        "summary": "  Integrated Traffic Management Systems (ITMS) are now implemented in different\ncities in India to primarily address the concerns of road-safety and security.\nAn automated Red Light Violation Detection System (RLVDS) is an integral part\nof the ITMS. In our present work we have designed and developed a complete\nsystem for generating the list of all stop-line violating vehicle images\nautomatically from video snapshots of road-side surveillance cameras. The\nsystem first generates adaptive background images for each camera view,\nsubtracts captured images from the corresponding background images and analyses\npotential occlusions over the stop-line in a traffic signal. Considering\nround-the-clock operations in a real-life test environment, the developed\nsystem could successfully track 92% images of vehicles with violations on the\nstop-line in a \"Red\" traffic signal.\n",
        "published": "2010-03-31T13:44:29Z",
        "pdf_link": "http://arxiv.org/pdf/1003.6052v2"
    },
    {
        "id": "http://arxiv.org/abs/1003.6059v2",
        "title": "A novel scheme for binarization of vehicle images using hierarchical\n  histogram equalization technique",
        "summary": "  Automatic License Plate Recognition system is a challenging area of research\nnow-a-days and binarization is an integral and most important part of it. In\ncase of a real life scenario, most of existing methods fail to properly\nbinarize the image of a vehicle in a congested road, captured through a CCD\ncamera. In the current work we have applied histogram equalization technique\nover the complete image and also over different hierarchy of image\npartitioning. A novel scheme is formulated for giving the membership value to\neach pixel for each hierarchy of histogram equalization. Then the image is\nbinarized depending on the net membership value of each pixel. The technique is\nexhaustively evaluated on the vehicle image dataset as well as the license\nplate dataset, giving satisfactory performances.\n",
        "published": "2010-03-31T14:00:16Z",
        "pdf_link": "http://arxiv.org/pdf/1003.6059v2"
    },
    {
        "id": "http://arxiv.org/abs/1005.0858v1",
        "title": "Randomized hybrid linear modeling by local best-fit flats",
        "summary": "  The hybrid linear modeling problem is to identify a set of d-dimensional\naffine sets in a D-dimensional Euclidean space. It arises, for example, in\nobject tracking and structure from motion. The hybrid linear model can be\nconsidered as the second simplest (behind linear) manifold model of data. In\nthis paper we will present a very simple geometric method for hybrid linear\nmodeling based on selecting a set of local best fit flats that minimize a\nglobal l1 error measure. The size of the local neighborhoods is determined\nautomatically by the Jones' l2 beta numbers; it is proven under certain\ngeometric conditions that good local neighborhoods exist and are found by our\nmethod. We also demonstrate how to use this algorithm for fast determination of\nthe number of affine subspaces. We give extensive experimental evidence\ndemonstrating the state of the art accuracy and speed of the algorithm on\nsynthetic and real hybrid linear data.\n",
        "published": "2010-05-05T21:46:13Z",
        "pdf_link": "http://arxiv.org/pdf/1005.0858v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.0907v1",
        "title": "Multistage Hybrid Arabic/Indian Numeral OCR System",
        "summary": "  The use of OCR in postal services is not yet universal and there are still\nmany countries that process mail sorting manually. Automated Arabic/Indian\nnumeral Optical Character Recognition (OCR) systems for Postal services are\nbeing used in some countries, but still there are errors during the mail\nsorting process, thus causing a reduction in efficiency. The need to\ninvestigate fast and efficient recognition algorithms/systems is important so\nas to correctly read the postal codes from mail addresses and to eliminate any\nerrors during the mail sorting stage. The objective of this study is to\nrecognize printed numerical postal codes from mail addresses. The proposed\nsystem is a multistage hybrid system which consists of three different feature\nextraction methods, i.e., binary, zoning, and fuzzy features, and three\ndifferent classifiers, i.e., Hamming Nets, Euclidean Distance, and Fuzzy Neural\nNetwork Classifiers. The proposed system, systematically compares the\nperformance of each of these methods, and ensures that the numerals are\nrecognized correctly. Comprehensive results provide a very high recognition\nrate, outperforming the other known developed methods in literature.\n",
        "published": "2010-05-06T07:25:23Z",
        "pdf_link": "http://arxiv.org/pdf/1005.0907v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.0945v1",
        "title": "An Efficient Vein Pattern-based Recognition System",
        "summary": "  This paper presents an efficient human recognition system based on vein\npattern from the palma dorsa. A new absorption based technique has been\nproposed to collect good quality images with the help of a low cost camera and\nlight source. The system automatically detects the region of interest from the\nimage and does the necessary preprocessing to extract features. A Euclidean\nDistance based matching technique has been used for making the decision. It has\nbeen tested on a data set of 1750 image samples collected from 341 individuals.\nThe accuracy of the verification system is found to be 99.26% with false\nrejection rate (FRR) of 0.03%.\n",
        "published": "2010-05-06T09:34:21Z",
        "pdf_link": "http://arxiv.org/pdf/1005.0945v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.1471v1",
        "title": "Classification via Incoherent Subspaces",
        "summary": "  This article presents a new classification framework that can extract\nindividual features per class. The scheme is based on a model of incoherent\nsubspaces, each one associated to one class, and a model on how the elements in\na class are represented in this subspace. After the theoretical analysis an\nalternate projection algorithm to find such a collection is developed. The\nclassification performance and speed of the proposed method is tested on the AR\nand YaleB databases and compared to that of Fisher's LDA and a recent approach\nbased on on $\\ell_1$ minimisation. Finally connections of the presented scheme\nto already existing work are discussed and possible ways of extensions are\npointed out.\n",
        "published": "2010-05-10T08:49:56Z",
        "pdf_link": "http://arxiv.org/pdf/1005.1471v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.2715v1",
        "title": "On the Subspace of Image Gradient Orientations",
        "summary": "  We introduce the notion of Principal Component Analysis (PCA) of image\ngradient orientations. As image data is typically noisy, but noise is\nsubstantially different from Gaussian, traditional PCA of pixel intensities\nvery often fails to estimate reliably the low-dimensional subspace of a given\ndata population. We show that replacing intensities with gradient orientations\nand the $\\ell_2$ norm with a cosine-based distance measure offers, to some\nextend, a remedy to this problem. Our scheme requires the eigen-decomposition\nof a covariance matrix and is as computationally efficient as standard $\\ell_2$\nPCA. We demonstrate some of its favorable properties on robust subspace\nestimation.\n",
        "published": "2010-05-16T00:31:19Z",
        "pdf_link": "http://arxiv.org/pdf/1005.2715v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.4020v1",
        "title": "Image Segmentation by Using Threshold Techniques",
        "summary": "  This paper attempts to undertake the study of segmentation image techniques\nby using five threshold methods as Mean method, P-tile method, Histogram\nDependent Technique (HDT), Edge Maximization Technique (EMT) and visual\nTechnique and they are compared with one another so as to choose the best\ntechnique for threshold segmentation techniques image. These techniques applied\non three satellite images to choose base guesses for threshold segmentation\nimage.\n",
        "published": "2010-05-21T17:30:08Z",
        "pdf_link": "http://arxiv.org/pdf/1005.4020v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.4034v1",
        "title": "Face Synthesis (FASY) System for Generation of a Face Image from Human\n  Description",
        "summary": "  This paper aims at generating a new face based on the human like description\nusing a new concept. The FASY (FAce SYnthesis) System is a Face Database\nRetrieval and new Face generation System that is under development. One of its\nmain features is the generation of the requested face when it is not found in\nthe existing database, which allows a continuous growing of the database also.\n",
        "published": "2010-05-21T18:03:44Z",
        "pdf_link": "http://arxiv.org/pdf/1005.4034v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.4035v1",
        "title": "Classification of Polar-Thermal Eigenfaces using Multilayer Perceptron\n  for Human Face Recognition",
        "summary": "  This paper presents a novel approach to handle the challenges of face\nrecognition. In this work thermal face images are considered, which minimizes\nthe affect of illumination changes and occlusion due to moustache, beards,\nadornments etc. The proposed approach registers the training and testing\nthermal face images in polar coordinate, which is capable to handle\ncomplicacies introduced by scaling and rotation. Polar images are projected\ninto eigenspace and finally classified using a multi-layer perceptron. In the\nexperiments we have used Object Tracking and Classification Beyond Visible\nSpectrum (OTCBVS) database benchmark thermal face images. Experimental results\nshow that the proposed approach significantly improves the verification and\nidentification performance and the success rate is 97.05%.\n",
        "published": "2010-05-21T18:07:42Z",
        "pdf_link": "http://arxiv.org/pdf/1005.4035v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.4044v1",
        "title": "Reduction of Feature Vectors Using Rough Set Theory for Human Face\n  Recognition",
        "summary": "  In this paper we describe a procedure to reduce the size of the input feature\nvector. A complex pattern recognition problem like face recognition involves\nhuge dimension of input feature vector. To reduce that dimension here we have\nused eigenspace projection (also called as Principal Component Analysis), which\nis basically transformation of space. To reduce further we have applied feature\nselection method to select indispensable features, which will remain in the\nfinal feature vectors. Features those are not selected are removed from the\nfinal feature vector considering them as redundant or superfluous. For\nselection of features we have used the concept of reduct and core from rough\nset theory. This method has shown very good performance. It is worth to mention\nthat in some cases the recognition rate increases with the decrease in the\nfeature vector dimension.\n",
        "published": "2010-05-21T19:13:39Z",
        "pdf_link": "http://arxiv.org/pdf/1005.4044v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.4103v1",
        "title": "LACBoost and FisherBoost: Optimally Building Cascade Classifiers",
        "summary": "  Object detection is one of the key tasks in computer vision. The cascade\nframework of Viola and Jones has become the de facto standard. A classifier in\neach node of the cascade is required to achieve extremely high detection rates,\ninstead of low overall classification error. Although there are a few reported\nmethods addressing this requirement in the context of object detection, there\nis no a principled feature selection method that explicitly takes into account\nthis asymmetric node learning objective. We provide such a boosting algorithm\nin this work. It is inspired by the linear asymmetric classifier (LAC) of Wu et\nal. in that our boosting algorithm optimizes a similar cost function. The new\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on face detection\nsuggest that our proposed boosting algorithms can improve the state-of-the-art\nmethods in detection performance.\n",
        "published": "2010-05-22T04:22:57Z",
        "pdf_link": "http://arxiv.org/pdf/1005.4103v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.4118v1",
        "title": "Incremental Training of a Detector Using Online Sparse\n  Eigen-decomposition",
        "summary": "  The ability to efficiently and accurately detect objects plays a very crucial\nrole for many computer vision tasks. Recently, offline object detectors have\nshown a tremendous success. However, one major drawback of offline techniques\nis that a complete set of training data has to be collected beforehand. In\naddition, once learned, an offline detector can not make use of newly arriving\ndata. To alleviate these drawbacks, online learning has been adopted with the\nfollowing objectives: (1) the technique should be computationally and storage\nefficient; (2) the updated classifier must maintain its high classification\naccuracy. In this paper, we propose an effective and efficient framework for\nlearning an adaptive online greedy sparse linear discriminant analysis (GSLDA)\nmodel. Unlike many existing online boosting detectors, which usually apply\nexponential or logistic loss, our online algorithm makes use of LDA's learning\ncriterion that not only aims to maximize the class-separation criterion but\nalso incorporates the asymmetrical property of training data distributions. We\nprovide a better alternative for online boosting algorithms in the context of\ntraining a visual object detector. We demonstrate the robustness and efficiency\nof our methods on handwriting digit and face data sets. Our results confirm\nthat object detection tasks benefit significantly when trained in an online\nmanner.\n",
        "published": "2010-05-22T11:05:58Z",
        "pdf_link": "http://arxiv.org/pdf/1005.4118v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.4216v1",
        "title": "Classification of LULC Change Detection using Remotely Sensed Data for\n  Coimbatore City, Tamilnadu, India",
        "summary": "  Maps are used to describe far-off places . It is an aid for navigation and\nmilitary strategies. Mapping of the lands are important and the mapping work is\nbased on (i). Natural resource management & development (ii). Information\ntechnology ,(iii). Environmental development ,(iv). Facility management and\n(v). e-governance. The Landuse / Landcover system espoused by almost all\nOrganisations and scientists, engineers and remote sensing community who are\ninvolved in mapping of earth surface features, is a system which is derived\nfrom the united States Geological Survey (USGS) LULC classification system. The\napplication of RS and GIS involves influential of homogeneous zones, drift\nanalysis of land use integration of new area changes or change detection\netc.,National Remote Sensing Agency(NRSA) Govt. of India has devised a\ngeneralized LULC classification system respect to the Indian conditions based\non the various categories of Earth surface features , resolution of available\nsatellite data, capabilities of sensors and present and future applications.\nThe profusion information of the earth surface offered by the high resolution\nsatellite images for remote sensing applications. Using change detection\nmethodologies to extract the target changes in the areas from high resolution\nimages and rapidly updates geodatabase information processing.Traditionally,\nclassification approaches have focused on per-pixel technologies. Pixels within\nareas assumed to be automatically homogeneous are analyzed independently.\n",
        "published": "2010-05-23T18:16:49Z",
        "pdf_link": "http://arxiv.org/pdf/1005.4216v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.4292v1",
        "title": "Application Of Fuzzy System In Segmentation Of MRI Brain Tumor",
        "summary": "  Segmentation of images holds an important position in the area of image\nprocessing. It becomes more important whi le typically dealing with medical\nimages where presurgery and post surgery decisions are required for the purpose\nof initiating and speeding up the recovery process. Segmentation of 3-D tumor\nstructures from magnetic resonance images (MRI) is a very challenging problem\ndue to the variability of tumor geometry and intensity patterns. Level set\nevolution combining global smoothness with the flexibility of topology changes\noffers significant advantages over the conventional statistical classification\nfollowed by mathematical morphology. Level set evolution with constant\npropagation needs to be initialized either completely inside or outside the\ntumor and can leak through weak or missing boundary parts. Replacing the\nconstant propagation term by a statistical force overcomes these limitations\nand results in a convergence to a stable solution. Using MR images presenting\ntumors, probabilities for background and tumor regions are calculated from a\npre- and post-contrast difference image and mixture modeling fit of the\nhistogram. The whole image is used for initialization of the level set\nevolution to segment the tumor boundaries.\n",
        "published": "2010-05-24T09:59:08Z",
        "pdf_link": "http://arxiv.org/pdf/1005.4292v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.5181v1",
        "title": "Compression Rate Method for Empirical Science and Application to\n  Computer Vision",
        "summary": "  This philosophical paper proposes a modified version of the scientific\nmethod, in which large databases are used instead of experimental observations\nas the necessary empirical ingredient. This change in the source of the\nempirical data allows the scientific method to be applied to several aspects of\nphysical reality that previously resisted systematic interrogation. Under the\nnew method, scientific theories are compared by instantiating them as\ncompression programs, and examining the codelengths they achieve on a database\nof measurements related to a phenomenon of interest. Because of the\nimpossibility of compressing random data, \"real world\" data can only be\ncompressed by discovering and exploiting the empirical structure it exhibits.\nThe method also provides a new way of thinking about two longstanding issues in\nthe philosophy of science: the problem of induction and the problem of\ndemarcation.\n  The second part of the paper proposes to reformulate computer vision as an\nempirical science of visual reality, by applying the new method to large\ndatabases of natural images. The immediate goal of the proposed reformulation\nis to repair the chronic difficulties in evaluation experienced by the field of\ncomputer vision. The reformulation should bring a wide range of benefits,\nincluding a substantially increased degree of methodological rigor, the ability\nto justify complex theories without overfitting, a scalable evaluation\nparadigm, and the potential to make systematic progress. A crucial argument is\nthat the change is not especially drastic, because most computer vision tasks\ncan be reformulated as specialized image compression techniques. Finally, a\nconcrete proposal is discussed in which a database is produced by recording\nfrom a roadside video camera, and compression is achieved by developing a\ncomputational understanding of the appearance of moving cars.\n",
        "published": "2010-05-27T21:27:43Z",
        "pdf_link": "http://arxiv.org/pdf/1005.5181v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.5437v1",
        "title": "Content Based Image Retrieval Using Exact Legendre Moments and Support\n  Vector Machine",
        "summary": "  Content Based Image Retrieval (CBIR) systems based on shape using invariant\nimage moments, viz., Moment Invariants (MI) and Zernike Moments (ZM) are\navailable in the literature. MI and ZM are good at representing the shape\nfeatures of an image. However, non-orthogonality of MI and poor reconstruction\nof ZM restrict their application in CBIR. Therefore, an efficient and\northogonal moment based CBIR system is needed. Legendre Moments (LM) are\northogonal, computationally faster, and can represent image shape features\ncompactly. CBIR system using Exact Legendre Moments (ELM) for gray scale images\nis proposed in this work. Superiority of the proposed CBIR system is observed\nover other moment based methods, viz., MI and ZM in terms of retrieval\nefficiency and retrieval time. Further, the classification efficiency is\nimproved by employing Support Vector Machine (SVM) classifier. Improved\nretrieval results are obtained over existing CBIR algorithm based on Stacked\nEuler Vector (SERVE) combined with Modified Moment Invariants (MMI).\n",
        "published": "2010-05-29T08:12:16Z",
        "pdf_link": "http://arxiv.org/pdf/1005.5437v1"
    },
    {
        "id": "http://arxiv.org/abs/1005.5439v1",
        "title": "Detection of Bleeding in Wireless Capsule Endoscopy Images Using Range\n  Ratio Color",
        "summary": "  Wireless Capsule Endoscopy (WCE) is device to detect abnormalities in\ncolon,esophagus,small intestinal and stomach, to distinguish bleeding in WCE\nimages from non bleeding is a hard job by human reviewing and very time\nconsuming. Consequently, automation for classifying bleeding frames not only\nwill expedite the process but will reduce the burden on the doctors. Using the\npurity of the red color we can detect the Bleeding areas in WCE images. But, we\ncould find various intensity of red color values in different parts of the\nsmall intestinal,so it is not enough to depend on the red color feature alone.\nWe select RGB(Red,Green,Blue) because it takes raw level values and it is easy\nto use. In this paper we will put range ratio color for each of R,G,and B.\nTherefore, we divide each image into multiple pixels and apply the range ratio\ncolor condition for each pixel. Then we count the number of the pixels that\nachieved our condition. If the number of pixels grater than zero, then the\nframe is classified as a bleeding type. Otherwise, it is a non-bleeding. Our\nexperimental results show that this method could achieve a very high accuracy\nin detecting bleeding images for the different parts of the small intestinal\n",
        "published": "2010-05-29T08:25:50Z",
        "pdf_link": "http://arxiv.org/pdf/1005.5439v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.1187v1",
        "title": "Biometric Authentication using Nonparametric Methods",
        "summary": "  The physiological and behavioral trait is employed to develop biometric\nauthentication systems. The proposed work deals with the authentication of iris\nand signature based on minimum variance criteria. The iris patterns are\npreprocessed based on area of the connected components. The segmented image\nused for authentication consists of the region with large variations in the\ngray level values. The image region is split into quadtree components. The\ncomponents with minimum variance are determined from the training samples. Hu\nmoments are applied on the components. The summation of moment values\ncorresponding to minimum variance components are provided as input vector to\nk-means and fuzzy kmeans classifiers. The best performance was obtained for MMU\ndatabase consisting of 45 subjects. The number of subjects with zero False\nRejection Rate [FRR] was 44 and number of subjects with zero False Acceptance\nRate [FAR] was 45. This paper addresses the computational load reduction in\noff-line signature verification based on minimal features using k-means, fuzzy\nk-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and\nFAR of 10% was achieved using k-nn classifier. The signature is a biometric,\nwhere variations in a genuine case, is a natural expectation. In the genuine\nsignature, certain parts of signature vary from one instance to another. The\nsystem aims to provide simple, fast and robust system using less number of\nfeatures when compared to state of art works.\n",
        "published": "2010-06-07T07:15:37Z",
        "pdf_link": "http://arxiv.org/pdf/1006.1187v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.2700v1",
        "title": "Image Segmentation Using Weak Shape Priors",
        "summary": "  The problem of image segmentation is known to become particularly challenging\nin the case of partial occlusion of the object(s) of interest, background\nclutter, and the presence of strong noise. To overcome this problem, the\npresent paper introduces a novel approach segmentation through the use of\n\"weak\" shape priors. Specifically, in the proposed method, an segmenting active\ncontour is constrained to converge to a configuration at which its geometric\nparameters attain their empirical probability densities closely matching the\ncorresponding model densities that are learned based on training samples. It is\nshown through numerical experiments that the proposed shape modeling can be\nregarded as \"weak\" in the sense that it minimally influences the segmentation,\nwhich is allowed to be dominated by data-related forces. On the other hand, the\npriors provide sufficient constraints to regularize the convergence of\nsegmentation, while requiring substantially smaller training sets to yield less\nbiased results as compared to the case of PCA-based regularization methods. The\nmain advantages of the proposed technique over some existing alternatives is\ndemonstrated in a series of experiments.\n",
        "published": "2010-06-14T12:43:37Z",
        "pdf_link": "http://arxiv.org/pdf/1006.2700v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.2734v1",
        "title": "Penalized K-Nearest-Neighbor-Graph Based Metrics for Clustering",
        "summary": "  A difficult problem in clustering is how to handle data with a manifold\nstructure, i.e. data that is not shaped in the form of compact clouds of\npoints, forming arbitrary shapes or paths embedded in a high-dimensional space.\nIn this work we introduce the Penalized k-Nearest-Neighbor-Graph (PKNNG) based\nmetric, a new tool for evaluating distances in such cases. The new metric can\nbe used in combination with most clustering algorithms. The PKNNG metric is\nbased on a two-step procedure: first it constructs the k-Nearest-Neighbor-Graph\nof the dataset of interest using a low k-value and then it adds edges with an\nexponentially penalized weight for connecting the sub-graphs produced by the\nfirst step. We discuss several possible schemes for connecting the different\nsub-graphs. We use three artificial datasets in four different embedding\nsituations to evaluate the behavior of the new metric, including a comparison\namong different clustering methods. We also evaluate the new metric in a real\nworld application, clustering the MNIST digits dataset. In all cases the PKNNG\nmetric shows promising clustering results.\n",
        "published": "2010-06-14T15:07:45Z",
        "pdf_link": "http://arxiv.org/pdf/1006.2734v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.2804v1",
        "title": "An Effective Fingerprint Verification Technique",
        "summary": "  This paper presents an effective method for fingerprint verification based on\na data mining technique called minutiae clustering and a graph-theoretic\napproach to analyze the process of fingerprint comparison to give a feature\nspace representation of minutiae and to produce a lower bound on the number of\ndetectably distinct fingerprints. The method also proving the invariance of\neach individual fingerprint by using both the topological behavior of the\nminutiae graph and also using a distance measure called Hausdorff distance.The\nmethod provides a graph based index generation mechanism of fingerprint\nbiometric data. The self-organizing map neural network is also used for\nclassifying the fingerprints.\n",
        "published": "2010-06-14T18:57:35Z",
        "pdf_link": "http://arxiv.org/pdf/1006.2804v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.3056v1",
        "title": "Solving Inverse Problems with Piecewise Linear Estimators: From Gaussian\n  Mixture Models to Structured Sparsity",
        "summary": "  A general framework for solving image inverse problems is introduced in this\npaper. The approach is based on Gaussian mixture models, estimated via a\ncomputationally efficient MAP-EM algorithm. A dual mathematical interpretation\nof the proposed framework with structured sparse estimation is described, which\nshows that the resulting piecewise linear estimate stabilizes the estimation\nwhen compared to traditional sparse inverse problem techniques. This\ninterpretation also suggests an effective dictionary motivated initialization\nfor the MAP-EM algorithm. We demonstrate that in a number of image inverse\nproblems, including inpainting, zooming, and deblurring, the same algorithm\nproduces either equal, often significantly better, or very small margin worse\nresults than the best published ones, at a lower computational cost.\n",
        "published": "2010-06-15T19:29:08Z",
        "pdf_link": "http://arxiv.org/pdf/1006.3056v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.3506v1",
        "title": "Action Recognition in Videos: from Motion Capture Labs to the Web",
        "summary": "  This paper presents a survey of human action recognition approaches based on\nvisual data recorded from a single video camera. We propose an organizing\nframework which puts in evidence the evolution of the area, with techniques\nmoving from heavily constrained motion capture scenarios towards more\nchallenging, realistic, \"in the wild\" videos. The proposed organization is\nbased on the representation used as input for the recognition task, emphasizing\nthe hypothesis assumed and thus, the constraints imposed on the type of video\nthat each technique is able to address. Expliciting the hypothesis and\nconstraints makes the framework particularly useful to select a method, given\nan application. Another advantage of the proposed organization is that it\nallows categorizing newest approaches seamlessly with traditional ones, while\nproviding an insightful perspective of the evolution of the action recognition\ntask up to now. That perspective is the basis for the discussion in the end of\nthe paper, where we also present the main open issues in the area.\n",
        "published": "2010-06-17T16:27:35Z",
        "pdf_link": "http://arxiv.org/pdf/1006.3506v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.4175v1",
        "title": "Optimization of Weighted Curvature for Image Segmentation",
        "summary": "  Minimization of boundary curvature is a classic regularization technique for\nimage segmentation in the presence of noisy image data. Techniques for\nminimizing curvature have historically been derived from descent methods which\ncould be trapped in a local minimum and therefore required a good\ninitialization. Recently, combinatorial optimization techniques have been\napplied to the optimization of curvature which provide a solution that achieves\nnearly a global optimum. However, when applied to image segmentation these\nmethods required a meaningful data term. Unfortunately, for many images,\nparticularly medical images, it is difficult to find a meaningful data term.\nTherefore, we propose to remove the data term completely and instead weight the\ncurvature locally, while still achieving a global optimum.\n",
        "published": "2010-06-21T20:59:43Z",
        "pdf_link": "http://arxiv.org/pdf/1006.4175v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.4588v1",
        "title": "Efficient Region-Based Image Querying",
        "summary": "  Retrieving images from large and varied repositories using visual contents\nhas been one of major research items, but a challenging task in the image\nmanagement community. In this paper we present an efficient approach for\nregion-based image classification and retrieval using a fast multi-level neural\nnetwork model. The advantages of this neural model in image classification and\nretrieval domain will be highlighted. The proposed approach accomplishes its\ngoal in three main steps. First, with the help of a mean-shift based\nsegmentation algorithm, significant regions of the image are isolated.\nSecondly, color and texture features of each region are extracted by using\ncolor moments and 2D wavelets decomposition technique. Thirdly the multi-level\nneural classifier is trained in order to classify each region in a given image\ninto one of five predefined categories, i.e., \"Sky\", \"Building\", \"SandnRock\",\n\"Grass\" and \"Water\". Simulation results show that the proposed method is\npromising in terms of classification and retrieval accuracy results. These\nresults compare favorably with the best published results obtained by other\nstate-of-the-art image retrieval techniques.\n",
        "published": "2010-06-23T16:52:26Z",
        "pdf_link": "http://arxiv.org/pdf/1006.4588v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.4910v5",
        "title": "Kalman Filters and Homography: Utilizing the Matrix $A$",
        "summary": "  Many problems in Computer Vision can be reduced to either working around a\nknown transform, or given a model for the transform computing the inverse\nproblem of the transform itself. We will look at two ways of working with the\nmatrix $A$ and see how transforms are at the root of image processing and\nvision problems.\n",
        "published": "2010-06-25T04:51:32Z",
        "pdf_link": "http://arxiv.org/pdf/1006.4910v5"
    },
    {
        "id": "http://arxiv.org/abs/1006.5902v1",
        "title": "Performance Comparison of SVM and ANN for Handwritten Devnagari\n  Character Recognition",
        "summary": "  Classification methods based on learning from examples have been widely\napplied to character recognition from the 1990s and have brought forth\nsignificant improvements of recognition accuracies. This class of methods\nincludes statistical methods, artificial neural networks, support vector\nmachines (SVM), multiple classifier combination, etc. In this paper, we discuss\nthe characteristics of the some classification methods that have been\nsuccessfully applied to handwritten Devnagari character recognition and results\nof SVM and ANNs classification method, applied on Handwritten Devnagari\ncharacters. After preprocessing the character image, we extracted shadow\nfeatures, chain code histogram features, view based features and longest run\nfeatures. These features are then fed to Neural classifier and in support\nvector machine for classification. In neural classifier, we explored three ways\nof combining decisions of four MLP's designed for four different features.\n",
        "published": "2010-06-30T16:16:43Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5902v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.5908v1",
        "title": "Recognition of Non-Compound Handwritten Devnagari Characters using a\n  Combination of MLP and Minimum Edit Distance",
        "summary": "  This paper deals with a new method for recognition of offline Handwritten\nnon-compound Devnagari Characters in two stages. It uses two well known and\nestablished pattern recognition techniques: one using neural networks and the\nother one using minimum edit distance. Each of these techniques is applied on\ndifferent sets of characters for recognition. In the first stage, two sets of\nfeatures are computed and two classifiers are applied to get higher recognition\naccuracy. Two MLP's are used separately to recognize the characters. For one of\nthe MLP's the characters are represented with their shadow features and for the\nother chain code histogram feature is used. The decision of both MLP's is\ncombined using weighted majority scheme. Top three results produced by combined\nMLP's in the first stage are used to calculate the relative difference values.\nIn the second stage, based on these relative differences character set is\ndivided into two. First set consists of the characters with distinct shapes and\nsecond set consists of confused characters, which appear very similar in\nshapes. Characters of distinct shapes of first set are classified using MLP.\nConfused characters in second set are classified using minimum edit distance\nmethod. Method of minimum edit distance makes use of corner detected in a\ncharacter image using modified Harris corner detection technique. Experiment on\nthis method is carried out on a database of 7154 samples. The overall\nrecognition is found to be 90.74%.\n",
        "published": "2010-06-30T16:25:21Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5908v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.5911v1",
        "title": "Application of Statistical Features in Handwritten Devnagari Character\n  Recognition",
        "summary": "  In this paper a scheme for offline Handwritten Devnagari Character\nRecognition is proposed, which uses different feature extraction methodologies\nand recognition algorithms. The proposed system assumes no constraints in\nwriting style or size. First the character is preprocessed and features namely\n: Chain code histogram and moment invariant features are extracted and fed to\nMultilayer Perceptrons as a preliminary recognition step. Finally the results\nof both MLP's are combined using weighted majority scheme. The proposed system\nis tested on 1500 handwritten devnagari character database collected from\ndifferent people. It is observed that the proposed system achieves recognition\nrates 98.03% for top 5 results and 89.46% for top 1 result.\n",
        "published": "2010-06-30T16:33:01Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5911v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.5913v1",
        "title": "Multiple Classifier Combination for Off-line Handwritten Devnagari\n  Character Recognition",
        "summary": "  This work presents the application of weighted majority voting technique for\ncombination of classification decision obtained from three Multi_Layer\nPerceptron(MLP) based classifiers for Recognition of Handwritten Devnagari\ncharacters using three different feature sets. The features used are\nintersection, shadow feature and chain code histogram features. Shadow features\nare computed globally for character image while intersection features and chain\ncode histogram features are computed by dividing the character image into\ndifferent segments. On experimentation with a dataset of 4900 samples the\noverall recognition rate observed is 92.16% as we considered top five choices\nresults. This method is compared with other recent methods for Handwritten\nDevnagari Character Recognition and it has been observed that this approach has\nbetter success rate than other methods.\n",
        "published": "2010-06-30T16:38:02Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5913v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.5920v1",
        "title": "A Two Stage Classification Approach for Handwritten Devanagari\n  Characters",
        "summary": "  The paper presents a two stage classification approach for handwritten\ndevanagari characters The first stage is using structural properties like\nshirorekha, spine in character and second stage exploits some intersection\nfeatures of characters which are fed to a feedforward neural network. Simple\nhistogram based method does not work for finding shirorekha, vertical bar\n(Spine) in handwritten devnagari characters. So we designed a differential\ndistance based technique to find a near straight line for shirorekha and spine.\nThis approach has been tested for 50000 samples and we got 89.12% success\n",
        "published": "2010-06-30T16:54:43Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5920v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.5924v1",
        "title": "A novel approach for handwritten Devnagari character recognition",
        "summary": "  In this paper a method for recognition of handwritten devanagari characters\nis described. Here, feature vector is constituted by accumulated directional\ngradient changes in different segments, number of intersections points for the\ncharacter, type of spine present and type of shirorekha present in the\ncharacter. One Multi-layer Perceptron with conjugate-gradient training is used\nto classify these feature vectors. This method is applied to a database with\n1000 sample characters and the recognition rate obtained is 88.12%\n",
        "published": "2010-06-30T17:09:39Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5924v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.5927v1",
        "title": "Classification Of Gradient Change Features Using MLP For Handwritten\n  Character Recognition",
        "summary": "  A novel, generic scheme for off-line handwritten English alphabets character\nimages is proposed. The advantage of the technique is that it can be applied in\na generic manner to different applications and is expected to perform better in\nuncertain and noisy environments. The recognition scheme is using a multilayer\nperceptron(MLP) neural networks. The system was trained and tested on a\ndatabase of 300 samples of handwritten characters. For improved generalization\nand to avoid overtraining, the whole available dataset has been divided into\ntwo subsets: training set and test set. We achieved 99.10% and 94.15% correct\nrecognition rates on training and test sets respectively. The purposed scheme\nis robust with respect to various writing styles and size as well as presence\nof considerable noise.\n",
        "published": "2010-06-30T17:14:40Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5927v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.5942v1",
        "title": "FPGA Based Assembling of Facial Components for Human Face Construction",
        "summary": "  This paper aims at VLSI realization for generation of a new face from textual\ndescription. The FASY (FAce SYnthesis) System is a Face Database Retrieval and\nnew Face generation System that is under development. One of its main features\nis the generation of the requested face when it is not found in the existing\ndatabase. The new face generation system works in three steps - searching\nphase, assembling phase and tuning phase. In this paper the tuning phase using\nhardware description language and its implementation in a Field Programmable\nGate Array (FPGA) device is presented.\n",
        "published": "2010-06-30T18:01:47Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5942v1"
    },
    {
        "id": "http://arxiv.org/abs/1006.5945v2",
        "title": "Fuzzy Classification of Facial Component Parameters",
        "summary": "  This paper presents a novel type-2 Fuzzy logic System to define the Shape of\na facial component with the crisp output. This work is the part of our main\nresearch effort to design a system (called FASY) which offers a novel face\nconstruction approach based on the textual description and also extracts and\nanalyzes the facial components from a face image by an efficient technique. The\nFuzzy model, designed in this paper, takes crisp value of width and height of a\nfacial component and produces the crisp value of Shape for different facial\ncomponents. This method is designed using Matlab 6.5 and Visual Basic 6.0 and\ntested with the facial components extracted from 200 male and female face\nimages of different ages from different face databases.\n",
        "published": "2010-06-30T18:07:35Z",
        "pdf_link": "http://arxiv.org/pdf/1006.5945v2"
    },
    {
        "id": "http://arxiv.org/abs/1007.0085v1",
        "title": "Survey of Nearest Neighbor Techniques",
        "summary": "  The nearest neighbor (NN) technique is very simple, highly efficient and\neffective in the field of pattern recognition, text categorization, object\nrecognition etc. Its simplicity is its main advantage, but the disadvantages\ncan't be ignored even. The memory requirement and computation complexity also\nmatter. Many techniques are developed to overcome these limitations. NN\ntechniques are broadly classified into structure less and structure based\ntechniques. In this paper, we present the survey of such techniques. Weighted\nkNN, Model based kNN, Condensed NN, Reduced NN, Generalized NN are structure\nless techniques whereas k-d tree, ball tree, Principal Axis Tree, Nearest\nFeature Line, Tunable NN, Orthogonal Search Tree are structure based algorithms\ndeveloped on the basis of kNN. The structure less method overcome memory\nlimitation and structure based techniques reduce the computational complexity.\n",
        "published": "2010-07-01T06:53:50Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0085v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0313v1",
        "title": "Repairing People Trajectories Based on Point Clustering",
        "summary": "  This paper presents a method for improving any object tracking algorithm\nbased on machine learning. During the training phase, important trajectory\nfeatures are extracted which are then used to calculate a confidence value of\ntrajectory. The positions at which objects are usually lost and found are\nclustered in order to construct the set of 'lost zones' and 'found zones' in\nthe scene. Using these zones, we construct a triplet set of zones i.e. three\nzones: In/Out zone (zone where an object can enter or exit the scene), 'lost\nzone' and 'found zone'. Thanks to these triplets, during the testing phase, we\ncan repair the erroneous trajectories according to which triplet they are most\nlikely to belong to. The advantage of our approach over the existing state of\nthe art approaches is that (i) this method does not depend on a predefined\ncontextual scene, (ii) we exploit the semantic of the scene and (iii) we have\nproposed a method to filter out noisy trajectories based on their confidence\nvalue.\n",
        "published": "2010-07-02T07:50:03Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0313v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0547v1",
        "title": "A Fast Decision Technique for Hierarchical Hough Transform for Line\n  Detection",
        "summary": "  Many techniques have been proposed to speedup the performance of classic\nHough Transform. These techniques are primarily based on converting the voting\nprocedure to a hierarchy based voting method. These methods use approximate\ndecision-making process. In this paper, we propose a fast decision making\nprocess that enhances the speed and reduces the space requirements.\nExperimental results demonstrate that the proposed algorithm is much faster\nthan a similar Fast Hough Transform.\n",
        "published": "2010-07-04T12:19:16Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0547v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0618v1",
        "title": "Face Synthesis (FASY) System for Determining the Characteristics of a\n  Face Image",
        "summary": "  This paper aims at determining the characteristics of a face image by\nextracting its components. The FASY (FAce SYnthesis) System is a Face Database\nRetrieval and new Face generation System that is under development. One of its\nmain features is the generation of the requested face when it is not found in\nthe existing database, which allows a continuous growing of the database also.\nTo generate the new face image, we need to store the face components in the\ndatabase. So we have designed a new technique to extract the face components by\na sophisticated method. After extraction of the facial feature points we have\nanalyzed the components to determine their characteristics. After extraction\nand analysis we have stored the components along with their characteristics\ninto the face database for later use during the face construction.\n",
        "published": "2010-07-05T05:24:30Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0618v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0620v1",
        "title": "Quotient Based Multiresolution Image Fusion of Thermal and Visual Images\n  Using Daubechies Wavelet Transform for Human Face Recognition",
        "summary": "  This paper investigates the multiresolution level-1 and level-2 Quotient\nbased Fusion of thermal and visual images. In the proposed system, the method-1\nnamely \"Decompose then Quotient Fuse Level-1\" and the method-2 namely\n\"Decompose-Reconstruct then Quotient Fuse Level-2\" both work on wavelet\ntransformations of the visual and thermal face images. The wavelet transform is\nwell-suited to manage different image resolution and allows the image\ndecomposition in different kinds of coefficients, while preserving the image\ninformation without any loss. This approach is based on a definition of an\nillumination invariant signature image which enables an analytic generation of\nthe image space with varying illumination. The quotient fused images are passed\nthrough Principal Component Analysis (PCA) for dimension reduction and then\nthose images are classified using a multi-layer perceptron (MLP). The\nperformances of both the methods have been evaluated using OTCBVS and IRIS\ndatabases. All the different classes have been tested separately, among them\nthe maximum recognition result is 100%.\n",
        "published": "2010-07-05T05:56:44Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0620v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0621v1",
        "title": "Fusion of Daubechies Wavelet Coefficients for Human Face Recognition",
        "summary": "  In this paper fusion of visual and thermal images in wavelet transformed\ndomain has been presented. Here, Daubechies wavelet transform, called as D2,\ncoefficients from visual and corresponding coefficients computed in the same\nmanner from thermal images are combined to get fused coefficients. After\ndecomposition up to fifth level (Level 5) fusion of coefficients is done.\nInverse Daubechies wavelet transform of those coefficients gives us fused face\nimages. The main advantage of using wavelet transform is that it is well-suited\nto manage different image resolution and allows the image decomposition in\ndifferent kinds of coefficients, while preserving the image information. Fused\nimages thus found are passed through Principal Component Analysis (PCA) for\nreduction of dimensions and then those reduced fused images are classified\nusing a multi-layer perceptron. For experiments IRIS Thermal/Visual Face\nDatabase was used. Experimental results show that the performance of the\napproach presented here achieves maximum success rate of 100% in many cases.\n",
        "published": "2010-07-05T06:04:43Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0621v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0626v1",
        "title": "Fusion of Wavelet Coefficients from Visual and Thermal Face Images for\n  Human Face Recognition - A Comparative Study",
        "summary": "  In this paper we present a comparative study on fusion of visual and thermal\nimages using different wavelet transformations. Here, coefficients of discrete\nwavelet transforms from both visual and thermal images are computed separately\nand combined. Next, inverse discrete wavelet transformation is taken in order\nto obtain fused face image. Both Haar and Daubechies (db2) wavelet transforms\nhave been used to compare recognition results. For experiments IRIS\nThermal/Visual Face Database was used. Experimental results using Haar and\nDaubechies wavelets show that the performance of the approach presented here\nachieves maximum success rate of 100% in many cases.\n",
        "published": "2010-07-05T07:33:45Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0626v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0627v1",
        "title": "A Parallel Framework for Multilayer Perceptron for Human Face\n  Recognition",
        "summary": "  Artificial neural networks have already shown their success in face\nrecognition and similar complex pattern recognition tasks. However, a major\ndisadvantage of the technique is that it is extremely slow during training for\nlarger classes and hence not suitable for real-time complex problems such as\npattern recognition. This is an attempt to develop a parallel framework for the\ntraining algorithm of a perceptron. In this paper, two general architectures\nfor a Multilayer Perceptron (MLP) have been demonstrated. The first\narchitecture is All-Class-in-One-Network (ACON) where all the classes are\nplaced in a single network and the second one is One-Class-in-One-Network\n(OCON) where an individual single network is responsible for each and every\nclass. Capabilities of these two architectures were compared and verified in\nsolving human face recognition, which is a complex pattern recognition task\nwhere several factors affect the recognition performance like pose variations,\nfacial expression changes, occlusions, and most importantly illumination\nchanges. Both the structures were implemented and tested for face recognition\npurpose and experimental results show that the OCON structure performs better\nthan the generally used ACON ones in term of training convergence speed of the\nnetwork. Unlike the conventional sequential approach of training the neural\nnetworks, the OCON technique may be implemented by training all the classes of\nthe face images simultaneously.\n",
        "published": "2010-07-05T07:40:56Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0627v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0628v1",
        "title": "Image Pixel Fusion for Human Face Recognition",
        "summary": "  In this paper we present a technique for fusion of optical and thermal face\nimages based on image pixel fusion approach. Out of several factors, which\naffect face recognition performance in case of visual images, illumination\nchanges are a significant factor that needs to be addressed. Thermal images are\nbetter in handling illumination conditions but not very consistent in capturing\ntexture details of the faces. Other factors like sunglasses, beard, moustache\netc also play active role in adding complicacies to the recognition process.\nFusion of thermal and visual images is a solution to overcome the drawbacks\npresent in the individual thermal and visual face images. Here fused images are\nprojected into an eigenspace and the projected images are classified using a\nradial basis function (RBF) neural network and also by a multi-layer perceptron\n(MLP). In the experiments Object Tracking and Classification Beyond Visible\nSpectrum (OTCBVS) database benchmark for thermal and visual face images have\nbeen used. Comparison of experimental results show that the proposed approach\nperforms significantly well in recognizing face images with a success rate of\n96% and 95.07% for RBF Neural Network and MLP respectively.\n",
        "published": "2010-07-05T07:45:48Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0628v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0631v1",
        "title": "Classification of Fused Images using Radial Basis Function Neural\n  Network for Human Face Recognition",
        "summary": "  Here an efficient fusion technique for automatic face recognition has been\npresented. Fusion of visual and thermal images has been done to take the\nadvantages of thermal images as well as visual images. By employing fusion a\nnew image can be obtained, which provides the most detailed, reliable, and\ndiscriminating information. In this method fused images are generated using\nvisual and thermal face images in the first step. In the second step, fused\nimages are projected into eigenspace and finally classified using a radial\nbasis function neural network. In the experiments Object Tracking and\nClassification Beyond Visible Spectrum (OTCBVS) database benchmark for thermal\nand visual face images have been used. Experimental results show that the\nproposed approach performs well in recognizing unknown individuals with a\nmaximum success rate of 96%.\n",
        "published": "2010-07-05T07:57:42Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0631v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0633v1",
        "title": "Classification of fused face images using multilayer perceptron neural\n  network",
        "summary": "  This paper presents a concept of image pixel fusion of visual and thermal\nfaces, which can significantly improve the overall performance of a face\nrecognition system. Several factors affect face recognition performance\nincluding pose variations, facial expression changes, occlusions, and most\nimportantly illumination changes. So, image pixel fusion of thermal and visual\nimages is a solution to overcome the drawbacks present in the individual\nthermal and visual face images. Fused images are projected into eigenspace and\nfinally classified using a multi-layer perceptron. In the experiments we have\nused Object Tracking and Classification Beyond Visible Spectrum (OTCBVS)\ndatabase benchmark thermal and visual face images. Experimental results show\nthat the proposed approach significantly improves the verification and\nidentification performance and the success rate is 95.07%. The main objective\nof employing fusion is to produce a fused image that provides the most detailed\nand reliable information. Fusion of multiple images together produces a more\nefficient representation of the image.\n",
        "published": "2010-07-05T08:01:11Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0633v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0636v1",
        "title": "Classification of Log-Polar-Visual Eigenfaces using Multilayer\n  Perceptron",
        "summary": "  In this paper we present a simple novel approach to tackle the challenges of\nscaling and rotation of face images in face recognition. The proposed approach\nregisters the training and testing visual face images by log-polar\ntransformation, which is capable to handle complicacies introduced by scaling\nand rotation. Log-polar images are projected into eigenspace and finally\nclassified using an improved multi-layer perceptron. In the experiments we have\nused ORL face database and Object Tracking and Classification Beyond Visible\nSpectrum (OTCBVS) database for visual face images. Experimental results show\nthat the proposed approach significantly improves the recognition performances\nfrom visual to log-polar-visual face images. In case of ORL face database,\nrecognition rate for visual face images is 89.5% and that is increased to 97.5%\nfor log-polar-visual face images whereas for OTCBVS face database recognition\nrate for visual images is 87.84% and 96.36% for log-polar-visual face images.\n",
        "published": "2010-07-05T08:05:14Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0636v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.0638v1",
        "title": "Human Face Recognition using Line Features",
        "summary": "  In this work we investigate a novel approach to handle the challenges of face\nrecognition, which includes rotation, scale, occlusion, illumination etc. Here,\nwe have used thermal face images as those are capable to minimize the affect of\nillumination changes and occlusion due to moustache, beards, adornments etc.\nThe proposed approach registers the training and testing thermal face images in\npolar coordinate, which is capable to handle complicacies introduced by scaling\nand rotation. Line features are extracted from thermal polar images and feature\nvectors are constructed using these line. Feature vectors thus obtained passes\nthrough principal component analysis (PCA) for the dimensionality reduction of\nfeature vectors. Finally, the images projected into eigenspace are classified\nusing a multi-layer perceptron. In the experiments we have used Object Tracking\nand Classification Beyond Visible Spectrum (OTCBVS) database. Experimental\nresults show that the proposed approach significantly improves the verification\nand identification performance and the success rate is 99.25%.\n",
        "published": "2010-07-05T08:10:30Z",
        "pdf_link": "http://arxiv.org/pdf/1007.0638v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.1016v1",
        "title": "Bilateral filters: what they can and cannot do",
        "summary": "  Nonlinear bilateral filters (BF) deliver a fine blend of computational\nsimplicity and blur-free denoising. However, little is known about their\nnature, noise-suppressing properties, and optimal choices of filter parameters.\nOur study is meant to fill this gap-explaining the underlying mechanism of\nbilateral filtering and providing the methodology for optimal filter selection.\nPractical application to CT image denoising is discussed to illustrate our\nresults.\n",
        "published": "2010-07-06T23:25:39Z",
        "pdf_link": "http://arxiv.org/pdf/1007.1016v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.1048v1",
        "title": "Registration of Brain Images using Fast Walsh Hadamard Transform",
        "summary": "  A lot of image registration techniques have been developed with great\nsignificance for data analysis in medicine, astrophotography, satellite imaging\nand few other areas. This work proposes a method for medical image registration\nusing Fast Walsh Hadamard transform. This algorithm registers images of the\nsame or different modalities. Each image bit is lengthened in terms of Fast\nWalsh Hadamard basis functions. Each basis function is a notion of determining\nvarious aspects of local structure, e.g., horizontal edge, corner, etc. These\ncoefficients are normalized and used as numerals in a chosen number system\nwhich allows one to form a unique number for each type of local structure. The\nexperimental results show that Fast Walsh Hadamard transform accomplished\nbetter results than the conventional Walsh transform in the time domain. Also\nFast Walsh Hadamard transform is more reliable in medical image registration\nconsuming less time.\n",
        "published": "2010-07-07T04:49:16Z",
        "pdf_link": "http://arxiv.org/pdf/1007.1048v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.1398v1",
        "title": "Multi-environment model estimation for motility analysis of\n  Caenorhabditis Elegans",
        "summary": "  The nematode Caenorhabditis elegans is a well-known model organism used to\ninvestigate fundamental questions in biology. Motility assays of this small\nroundworm are designed to study the relationships between genes and behavior.\nCommonly, motility analysis is used to classify nematode movements and\ncharacterize them quantitatively. Over the past years, C. elegans' motility has\nbeen studied across a wide range of environments, including crawling on\nsubstrates, swimming in fluids, and locomoting through microfluidic substrates.\nHowever, each environment often requires customized image processing tools\nrelying on heuristic parameter tuning. In the present study, we propose a novel\nMulti-Environment Model Estimation (MEME) framework for automated image\nsegmentation that is versatile across various environments. The MEME platform\nis constructed around the concept of Mixture of Gaussian (MOG) models, where\nstatistical models for both the background environment and the nematode\nappearance are explicitly learned and used to accurately segment a target\nnematode. Our method is designed to simplify the burden often imposed on users;\nhere, only a single image which includes a nematode in its environment must be\nprovided for model learning. In addition, our platform enables the extraction\nof nematode `skeletons' for straightforward motility quantification. We test\nour algorithm on various locomotive environments and compare performances with\nan intensity-based thresholding method. Overall, MEME outperforms the\nthreshold-based approach for the overwhelming majority of cases examined.\nUltimately, MEME provides researchers with an attractive platform for C.\nelegans' segmentation and `skeletonizing' across a wide range of motility\nassays.\n",
        "published": "2010-07-08T15:10:05Z",
        "pdf_link": "http://arxiv.org/pdf/1007.1398v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.1432v1",
        "title": "Improved RANSAC performance using simple, iterative minimal-set solvers",
        "summary": "  RANSAC is a popular technique for estimating model parameters in the presence\nof outliers. The best speed is achieved when the minimum possible number of\npoints is used to estimate hypotheses for the model. Many useful problems can\nbe represented using polynomial constraints (for instance, the determinant of a\nfundamental matrix must be zero) and so have a number of solutions which are\nconsistent with a minimal set. A considerable amount of effort has been\nexpended on finding the constraints of such problems, and these often require\nthe solution of systems of polynomial equations. We show that better\nperformance can be achieved by using a simple optimization based approach on\nminimal sets. For a given minimal set, the optimization approach is not\nguaranteed to converge to the correct solution. However, when used within\nRANSAC the greater speed and numerical stability results in better performance\noverall, and much simpler algorithms. We also show that by selecting more than\nthe minimal number of points and using robust optimization can yield better\nresults for very noisy by reducing the number of trials required. The increased\nspeed of our method demonstrated with experiments on essential matrix\nestimation.\n",
        "published": "2010-07-08T18:12:49Z",
        "pdf_link": "http://arxiv.org/pdf/1007.1432v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.1708v1",
        "title": "A Study on the Effectiveness of Different Patch Size and Shape for Eyes\n  and Mouth Detection",
        "summary": "  Template matching is one of the simplest methods used for eyes and mouth\ndetection. However, it can be modified and extended to become a powerful tool.\nSince the patch itself plays a significant role in optimizing detection\nperformance, a study on the influence of patch size and shape is carried out.\nThe optimum patch size and shape is determined using the proposed method.\nUsually, template matching is also combined with other methods in order to\nimprove detection accuracy. Thus, in this paper, the effectiveness of two image\nprocessing methods i.e. grayscale and Haar wavelet transform, when used with\ntemplate matching are analyzed.\n",
        "published": "2010-07-10T09:01:48Z",
        "pdf_link": "http://arxiv.org/pdf/1007.1708v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.2442v1",
        "title": "Neural Network Based Reconstruction of a 3D Object from a 2D Wireframe",
        "summary": "  We propose a new approach for constructing a 3D representation from a 2D\nwireframe drawing. A drawing is simply a parallel projection of a 3D object\nonto a 2D surface; humans are able to recreate mental 3D models from 2D\nrepresentations very easily, yet the process is very difficult to emulate\ncomputationally. We hypothesize that our ability to perform this construction\nrelies on the angles in the 2D scene, among other geometric properties. Being\nable to reproduce this reconstruction process automatically would allow for\nefficient and robust 3D sketch interfaces. Our research focuses on the\nrelationship between 2D geometry observable in the sketch and 3D geometry\nderived from a potential 3D construction. We present a fully automated system\nthat constructs 3D representations from 2D wireframes using a neural network in\nconjunction with a genetic search algorithm.\n",
        "published": "2010-07-14T22:01:26Z",
        "pdf_link": "http://arxiv.org/pdf/1007.2442v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.3772v1",
        "title": "Video Event Recognition for Surveillance Applications (VERSA)",
        "summary": "  VERSA provides a general-purpose framework for defining and recognizing\nevents in live or recorded surveillance video streams. The approach for event\nrecognition in VERSA is using a declarative logic language to define the\nspatial and temporal relationships that characterize a given event or activity.\nDoing so requires the definition of certain fundamental spatial and temporal\nrelationships and a high-level syntax for specifying frame templates and query\nparameters. Although the handling of uncertainty in the current VERSA\nimplementation is simplistic, the language and architecture is amenable to\nextending using Fuzzy Logic or similar approaches. VERSA's high-level\narchitecture is designed to work in XML-based, services- oriented environments.\nVERSA can be thought of as subscribing to the XML annotations streamed by a\nlower-level video analytics service that provides basic entity detection,\nlabeling, and tracking. One or many VERSA Event Monitors could thus analyze\nvideo streams and provide alerts when certain events are detected.\n",
        "published": "2010-07-21T22:47:00Z",
        "pdf_link": "http://arxiv.org/pdf/1007.3772v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.3926v1",
        "title": "Ear Identification by Fusion of Segmented Slice Regions using Invariant\n  Features: An Experimental Manifold with Dual Fusion Approach",
        "summary": "  This paper proposes a robust ear identification system which is developed by\nfusing SIFT features of color segmented slice regions of an ear. The proposed\near identification method makes use of Gaussian mixture model (GMM) to build\near model with mixture of Gaussian using vector quantization algorithm and K-L\ndivergence is applied to the GMM framework for recording the color similarity\nin the specified ranges by comparing color similarity between a pair of\nreference ear and probe ear. SIFT features are then detected and extracted from\neach color slice region as a part of invariant feature extraction. The\nextracted keypoints are then fused separately by the two fusion approaches,\nnamely concatenation and the Dempster-Shafer theory. Finally, the fusion\napproaches generate two independent augmented feature vectors which are used\nfor identification of individuals separately. The proposed identification\ntechnique is tested on IIT Kanpur ear database of 400 individuals and is found\nto achieve 98.25% accuracy for identification while top 5 matched criteria is\nset for each subject.\n",
        "published": "2010-07-21T14:09:33Z",
        "pdf_link": "http://arxiv.org/pdf/1007.3926v1"
    },
    {
        "id": "http://arxiv.org/abs/1007.5129v1",
        "title": "An Efficient Automatic Mass Classification Method In Digitized\n  Mammograms Using Artificial Neural Network",
        "summary": "  In this paper we present an efficient computer aided mass classification\nmethod in digitized mammograms using Artificial Neural Network (ANN), which\nperforms benign-malignant classification on region of interest (ROI) that\ncontains mass. One of the major mammographic characteristics for mass\nclassification is texture. ANN exploits this important factor to classify the\nmass into benign or malignant. The statistical textural features used in\ncharacterizing the masses are mean, standard deviation, entropy, skewness,\nkurtosis and uniformity. The main aim of the method is to increase the\neffectiveness and efficiency of the classification process in an objective\nmanner to reduce the numbers of false-positive of malignancies. Three layers\nartificial neural network (ANN) with seven features was proposed for\nclassifying the marked regions into benign and malignant and 90.91% sensitivity\nand 83.87% specificity is achieved that is very much promising compare to the\nradiologist's sensitivity 75%.\n",
        "published": "2010-07-29T07:19:58Z",
        "pdf_link": "http://arxiv.org/pdf/1007.5129v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.1695v1",
        "title": "Biometric Authentication using Nonparametric Methods",
        "summary": "  The physiological and behavioral trait is employed to develop biometric\nauthentication systems. The proposed work deals with the authentication of iris\nand signature based on minimum variance criteria. The iris patterns are\npreprocessed based on area of the connected components. The segmented image\nused for authentication consists of the region with large variations in the\ngray level values. The image region is split into quadtree components. The\ncomponents with minimum variance are determined from the training samples. Hu\nmoments are applied on the components. The summation of moment values\ncorresponding to minimum variance components are provided as input vector to\nk-means and fuzzy k-means classifiers. The best performance was obtained for\nMMU database consisting of 45 subjects. The number of subjects with zero False\nRejection Rate [FRR] was 44 and number of subjects with zero False Acceptance\nRate [FAR] was 45. This paper addresses the computational load reduction in\noff-line signature verification based on minimal features using k-means, fuzzy\nk-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and\nFAR of 10% was achieved using k-nn classifier. The signature is a biometric,\nwhere variations in a genuine case, is a natural expectation. In the genuine\nsignature, certain parts of signature vary from one instance to another. The\nsystem aims to provide simple, fast and robust system using less number of\nfeatures when compared to state of art works.\n",
        "published": "2010-08-10T11:38:29Z",
        "pdf_link": "http://arxiv.org/pdf/1008.1695v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.3346v1",
        "title": "A Miniature-Based Image Retrieval System",
        "summary": "  Due to the rapid development of World Wide Web (WWW) and imaging technology,\nmore and more images are available in the Internet and stored in databases.\nSearching the related images by the querying image is becoming tedious and\ndifficult. Most of the images on the web are compressed by methods based on\ndiscrete cosine transform (DCT) including Joint Photographic Experts\nGroup(JPEG) and H.261. This paper presents an efficient content-based image\nindexing technique for searching similar images using discrete cosine transform\nfeatures. Experimental results demonstrate its superiority with the existing\ntechniques.\n",
        "published": "2010-08-19T16:38:35Z",
        "pdf_link": "http://arxiv.org/pdf/1008.3346v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.3742v1",
        "title": "Optimally Training a Cascade Classifier",
        "summary": "  Cascade classifiers are widely used in real-time object detection. Different\nfrom conventional classifiers that are designed for a low overall\nclassification error rate, a classifier in each node of the cascade is required\nto achieve an extremely high detection rate and moderate false positive rate.\nAlthough there are a few reported methods addressing this requirement in the\ncontext of object detection, there is no a principled feature selection method\nthat explicitly takes into account this asymmetric node learning objective. We\nprovide such an algorithm here. We show a special case of the biased minimax\nprobability machine has the same formulation as the linear asymmetric\nclassifier (LAC) of \\cite{wu2005linear}. We then design a new boosting\nalgorithm that directly optimizes the cost function of LAC. The resulting\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on object detection\nverify the effectiveness of the proposed boosting algorithm as a node\nclassifier in cascade object detection, and show performance better than that\nof the current state-of-the-art.\n",
        "published": "2010-08-23T03:06:34Z",
        "pdf_link": "http://arxiv.org/pdf/1008.3742v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.3798v1",
        "title": "Proliferating cell nuclear antigen (PCNA) allows the automatic\n  identification of follicles in microscopic images of human ovarian tissue",
        "summary": "  Human ovarian reserve is defined by the population of nongrowing follicles\n(NGFs) in the ovary. Direct estimation of ovarian reserve involves the\nidentification of NGFs in prepared ovarian tissue. Previous studies involving\nhuman tissue have used hematoxylin and eosin (HE) stain, with NGF populations\nestimated by human examination either of tissue under a microscope, or of\nimages taken of this tissue. In this study we replaced HE with proliferating\ncell nuclear antigen (PCNA), and automated the identification and enumeration\nof NGFs that appear in the resulting microscopic images. We compared the\nautomated estimates to those obtained by human experts, with the \"gold\nstandard\" taken to be the average of the conservative and liberal estimates by\nthree human experts. The automated estimates were within 10% of the \"gold\nstandard\", for images at both 100x and 200x magnifications. Automated analysis\ntook longer than human analysis for several hundred images, not allowing for\nbreaks from analysis needed by humans. Our results both replicate and improve\non those of previous studies involving rodent ovaries, and demonstrate the\nviability of large-scale studies of human ovarian reserve using a combination\nof immunohistochemistry and computational image analysis techniques.\n",
        "published": "2010-08-23T11:37:43Z",
        "pdf_link": "http://arxiv.org/pdf/1008.3798v1"
    },
    {
        "id": "http://arxiv.org/abs/1008.4206v1",
        "title": "Comparative Study of Statistical Skin Detection Algorithms for\n  Sub-Continental Human Images",
        "summary": "  Object detection has been a focus of research in human-computer interaction.\nSkin area detection has been a key to different recognitions like face\nrecognition, human motion detection, pornographic and nude image prediction,\netc. Most of the research done in the fields of skin detection has been trained\nand tested on human images of African, Mongolian and Anglo-Saxon ethnic\norigins. Although there are several intensity invariant approaches to skin\ndetection, the skin color of Indian sub-continentals have not been focused\nseparately. The approach of this research is to make a comparative study\nbetween three image segmentation approaches using Indian sub-continental human\nimages, to optimize the detection criteria, and to find some efficient\nparameters to detect the skin area from these images. The experiments observed\nthat HSV color model based approach to Indian sub-continental skin detection is\nmore suitable with considerable success rate of 91.1% true positives and 88.1%\ntrue negatives.\n",
        "published": "2010-08-25T05:33:04Z",
        "pdf_link": "http://arxiv.org/pdf/1008.4206v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.0623v2",
        "title": "Weighted Attribute Fusion Model for Face Recognition",
        "summary": "  Recognizing a face based on its attributes is an easy task for a human to\nperform as it is a cognitive process. In recent years, Face Recognition is\nachieved with different kinds of facial features which were used separately or\nin a combined manner. Currently, Feature fusion methods and parallel methods\nare the facial features used and performed by integrating multiple feature sets\nat different levels. However, this integration and the combinational methods do\nnot guarantee better result. Hence to achieve better results, the feature\nfusion model with multiple weighted facial attribute set is selected. For this\nfeature model, face images from predefined data set has been taken from\nOlivetti Research Laboratory (ORL) and applied on different methods like\nPrincipal Component Analysis (PCA) based Eigen feature extraction technique,\nDiscrete Cosine Transformation (DCT) based feature extraction technique,\nHistogram Based Feature Extraction technique and Simple Intensity based\nfeatures. The extracted feature set obtained from these methods were compared\nand tested for accuracy. In this work we have developed a model which will use\nthe above set of feature extraction techniques with different levels of weights\nto attain better accuracy. The results show that the selection of optimum\nweight for a particular feature will lead to improvement in recognition rate.\n",
        "published": "2010-09-03T10:05:20Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0623v2"
    },
    {
        "id": "http://arxiv.org/abs/1009.0854v1",
        "title": "Fast Color Space Transformations Using Minimax Approximations",
        "summary": "  Color space transformations are frequently used in image processing,\ngraphics, and visualization applications. In many cases, these transformations\nare complex nonlinear functions, which prohibits their use in time-critical\napplications. In this paper, we present a new approach called Minimax\nApproximations for Color-space Transformations (MACT).We demonstrate MACT on\nthree commonly used color space transformations. Extensive experiments on a\nlarge and diverse image set and comparisons with well-known multidimensional\nlookup table interpolation methods show that MACT achieves an excellent balance\namong four criteria: ease of implementation, memory usage, accuracy, and\ncomputational speed.\n",
        "published": "2010-09-04T17:44:06Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0854v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.0892v2",
        "title": "Effective Pedestrian Detection Using Center-symmetric Local\n  Binary/Trinary Patterns",
        "summary": "  Accurately detecting pedestrians in images plays a critically important role\nin many computer vision applications. Extraction of effective features is the\nkey to this task. Promising features should be discriminative, robust to\nvarious variations and easy to compute. In this work, we present novel\nfeatures, termed dense center-symmetric local binary patterns (CS-LBP) and\npyramid center-symmetric local binary/ternary patterns (CS-LBP/LTP), for\npedestrian detection. The standard LBP proposed by Ojala et al. \\cite{c4}\nmainly captures the texture information. The proposed CS-LBP feature, in\ncontrast, captures the gradient information and some texture information.\nMoreover, the proposed dense CS-LBP and the pyramid CS-LBP/LTP are easy to\nimplement and computationally efficient, which is desirable for real-time\napplications. Experiments on the INRIA pedestrian dataset show that the dense\nCS-LBP feature with linear supporct vector machines (SVMs) is comparable with\nthe histograms of oriented gradients (HOG) feature with linear SVMs, and the\npyramid CS-LBP/LTP features outperform both HOG features with linear SVMs and\nthe start-of-the-art pyramid HOG (PHOG) feature with the histogram intersection\nkernel SVMs. We also demonstrate that the combination of our pyramid CS-LBP\nfeature and the PHOG feature could significantly improve the detection\nperformance-producing state-of-the-art accuracy on the INRIA pedestrian\ndataset.\n",
        "published": "2010-09-05T05:16:11Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0892v2"
    },
    {
        "id": "http://arxiv.org/abs/1009.0957v1",
        "title": "Distance Measures for Reduced Ordering Based Vector Filters",
        "summary": "  Reduced ordering based vector filters have proved successful in removing\nlong-tailed noise from color images while preserving edges and fine image\ndetails. These filters commonly utilize variants of the Minkowski distance to\norder the color vectors with the aim of distinguishing between noisy and\nnoise-free vectors. In this paper, we review various alternative distance\nmeasures and evaluate their performance on a large and diverse set of images\nusing several effectiveness and efficiency criteria. The results demonstrate\nthat there are in fact strong alternatives to the popular Minkowski metrics.\n",
        "published": "2010-09-05T23:49:38Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0957v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.0958v1",
        "title": "Real-Time Implementation of Order-Statistics Based Directional Filters",
        "summary": "  Vector filters based on order-statistics have proved successful in removing\nimpulsive noise from color images while preserving edges and fine image\ndetails. Among these filters, the ones that involve the cosine distance\nfunction (directional filters) have particularly high computational\nrequirements, which limits their use in time critical applications. In this\npaper, we introduce two methods to speed up these filters. Experiments on a\ndiverse set of color images show that the proposed methods provide substantial\ncomputational gains without significant loss of accuracy.\n",
        "published": "2010-09-05T23:53:27Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0958v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.0959v1",
        "title": "Cost-Effective Implementation of Order-Statistics Based Vector Filters\n  Using Minimax Approximations",
        "summary": "  Vector operators based on robust order statistics have proved successful in\ndigital multichannel imaging applications, particularly color image filtering\nand enhancement, in dealing with impulsive noise while preserving edges and\nfine image details. These operators often have very high computational\nrequirements which limits their use in time-critical applications. This paper\nintroduces techniques to speed up vector filters using the minimax\napproximation theory. Extensive experiments on a large and diverse set of color\nimages show that proposed approximations achieve an excellent balance among\nease of implementation, accuracy, and computational speed.\n",
        "published": "2010-09-06T00:02:35Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0959v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.0961v1",
        "title": "A Fast Switching Filter for Impulsive Noise Removal from Color Images",
        "summary": "  In this paper, we present a fast switching filter for impulsive noise removal\nfrom color images. The filter exploits the HSL color space, and is based on the\npeer group concept, which allows for the fast detection of noise in a\nneighborhood without resorting to pairwise distance computations between each\npixel. Experiments on large set of diverse images demonstrate that the proposed\napproach is not only extremely fast, but also gives excellent results in\ncomparison to various state-of-the-art filters.\n",
        "published": "2010-09-06T00:13:25Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0961v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.0962v1",
        "title": "Nonlinear Vector Filtering for Impulsive Noise Removal from Color Images",
        "summary": "  In this paper, a comprehensive survey of 48 filters for impulsive noise\nremoval from color images is presented. The filters are formulated using a\nuniform notation and categorized into 8 families. The performance of these\nfilters is compared on a large set of images that cover a variety of domains\nusing three effectiveness and one efficiency criteria. In order to ensure a\nfair efficiency comparison, a fast and accurate approximation for the inverse\ncosine function is introduced. In addition, commonly used distance measures\n(Minkowski, angular, and directional-distance) are analyzed and evaluated.\nFinally, suggestions are provided on how to choose a filter given certain\nrequirements.\n",
        "published": "2010-09-06T00:22:58Z",
        "pdf_link": "http://arxiv.org/pdf/1009.0962v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.1013v1",
        "title": "Automatic Detection of Blue-White Veil and Related Structures in\n  Dermoscopy Images",
        "summary": "  Dermoscopy is a non-invasive skin imaging technique, which permits\nvisualization of features of pigmented melanocytic neoplasms that are not\ndiscernable by examination with the naked eye. One of the most important\nfeatures for the diagnosis of melanoma in dermoscopy images is the blue-white\nveil (irregular, structureless areas of confluent blue pigmentation with an\noverlying white \"ground-glass\" film). In this article, we present a machine\nlearning approach to the detection of blue-white veil and related structures in\ndermoscopy images. The method involves contextual pixel classification using a\ndecision tree classifier. The percentage of blue-white areas detected in a\nlesion combined with a simple shape descriptor yielded a sensitivity of 69.35%\nand a specificity of 89.97% on a set of 545 dermoscopy images. The sensitivity\nrises to 78.20% for detection of blue veil in those cases where it is a primary\nfeature for melanoma recognition.\n",
        "published": "2010-09-06T10:29:18Z",
        "pdf_link": "http://arxiv.org/pdf/1009.1013v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.1020v1",
        "title": "An Improved Objective Evaluation Measure for Border Detection in\n  Dermoscopy Images",
        "summary": "  Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, dermoscopy image analysis has become\nan important research area. One of the most important steps in dermoscopy image\nanalysis is the automated detection of lesion borders. Although numerous\nmethods have been developed for the detection of lesion borders, very few\nstudies were comprehensive in the evaluation of their results. Methods: In this\npaper, we evaluate five recent border detection methods on a set of 90\ndermoscopy images using three sets of dermatologist-drawn borders as the\nground-truth. In contrast to previous work, we utilize an objective measure,\nthe Normalized Probabilistic Rand Index, which takes into account the\nvariations in the ground-truth images. Conclusion: The results demonstrate that\nthe differences between four of the evaluated border detection methods are in\nfact smaller than those predicted by the commonly used XOR measure.\n",
        "published": "2010-09-06T10:53:21Z",
        "pdf_link": "http://arxiv.org/pdf/1009.1020v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.1362v1",
        "title": "Approximate Lesion Localization in Dermoscopy Images",
        "summary": "  Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, automated analysis of dermoscopy\nimages has become an important research area. Border detection is often the\nfirst step in this analysis. Methods: In this article, we present an\napproximate lesion localization method that serves as a preprocessing step for\ndetecting borders in dermoscopy images. In this method, first the black frame\naround the image is removed using an iterative algorithm. The approximate\nlocation of the lesion is then determined using an ensemble of thresholding\nalgorithms. Results: The method is tested on a set of 428 dermoscopy images.\nThe localization error is quantified by a metric that uses dermatologist\ndetermined borders as the ground truth. Conclusion: The results demonstrate\nthat the method presented here achieves both fast and accurate localization of\nlesions in dermoscopy images.\n",
        "published": "2010-09-06T11:01:53Z",
        "pdf_link": "http://arxiv.org/pdf/1009.1362v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.1983v1",
        "title": "Evolutionary Computational Method of Facial Expression Analysis for\n  Content-based Video Retrieval using 2-Dimensional Cellular Automata",
        "summary": "  In this paper, Deterministic Cellular Automata (DCA) based video shot\nclassification and retrieval is proposed. The deterministic 2D Cellular\nautomata model captures the human facial expressions, both spontaneous and\nposed. The determinism stems from the fact that the facial muscle actions are\nstandardized by the encodings of Facial Action Coding System (FACS) and Action\nUnits (AUs). Based on these encodings, we generate the set of evolutionary\nupdate rules of the DCA for each facial expression. We consider a\nPerson-Independent Facial Expression Space (PIFES) to analyze the facial\nexpressions based on Partitioned 2D-Cellular Automata which capture the\ndynamics of facial expressions and classify the shots based on it. Target video\nshot is retrieved by comparing the similar expression is obtained for the query\nframe's face with respect to the key faces expressions in the database video.\nConsecutive key face expressions in the database that are highly similar to the\nquery frame's face, then the key faces are used to generate the set of\nretrieved video shots from the database. A concrete example of its application\nwhich realizes an affective interaction between the computer and the user is\nproposed. In the affective interaction, the computer can recognize the facial\nexpression of any given video shot. This interaction endows the computer with\ncertain ability to adapt to the user's feedback.\n",
        "published": "2010-09-10T11:25:17Z",
        "pdf_link": "http://arxiv.org/pdf/1009.1983v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.3029v1",
        "title": "Invariant Spectral Hashing of Image Saliency Graph",
        "summary": "  Image hashing is the process of associating a short vector of bits to an\nimage. The resulting summaries are useful in many applications including image\nindexing, image authentication and pattern recognition. These hashes need to be\ninvariant under transformations of the image that result in similar visual\ncontent, but should drastically differ for conceptually distinct contents. This\npaper proposes an image hashing method that is invariant under rotation,\nscaling and translation of the image. The gist of our approach relies on the\ngeometric characterization of salient point distribution in the image. This is\nachieved by the definition of a \"saliency graph\" connecting these points\njointly with an image intensity function on the graph nodes. An invariant hash\nis then obtained by considering the spectrum of this function in the\neigenvector basis of the Laplacian graph, that is, its graph Fourier transform.\nInterestingly, this spectrum is invariant under any relabeling of the graph\nnodes. The graph reveals geometric information of the image, making the hash\nrobust to image transformation, yet distinct for different visual content. The\nefficiency of the proposed method is assessed on a set of MRI 2-D slices and on\na database of faces.\n",
        "published": "2010-09-15T20:11:11Z",
        "pdf_link": "http://arxiv.org/pdf/1009.3029v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.3078v1",
        "title": "Asymmetric Totally-corrective Boosting for Real-time Object Detection",
        "summary": "  Real-time object detection is one of the core problems in computer vision.\nThe cascade boosting framework proposed by Viola and Jones has become the\nstandard for this problem. In this framework, the learning goal for each node\nis asymmetric, which is required to achieve a high detection rate and a\nmoderate false positive rate. We develop new boosting algorithms to address\nthis asymmetric learning problem. We show that our methods explicitly optimize\nasymmetric loss objectives in a totally corrective fashion. The methods are\ntotally corrective in the sense that the coefficients of all selected weak\nclassifiers are updated at each iteration. In contract, conventional boosting\nlike AdaBoost is stage-wise in that only the current weak classifier's\ncoefficient is updated. At the heart of the totally corrective boosting is the\ncolumn generation technique. Experiments on face detection show that our\nmethods outperform the state-of-the-art asymmetric boosting methods.\n",
        "published": "2010-09-16T02:45:59Z",
        "pdf_link": "http://arxiv.org/pdf/1009.3078v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.4581v1",
        "title": "3D-Mesh denoising using an improved vertex based anisotropic diffusion",
        "summary": "  This paper deals with an improvement of vertex based nonlinear diffusion for\nmesh denoising. This method directly filters the position of the vertices using\nLaplace, reduced centered Gaussian and Rayleigh probability density functions\nas diffusivities. The use of these PDFs improves the performance of a\nvertex-based diffusion method which are adapted to the underlying mesh\nstructure. We also compare the proposed method to other mesh denoising methods\nsuch as Laplacian flow, mean, median, min and the adaptive MMSE filtering. To\nevaluate these methods of filtering, we use two error metrics. The first is\nbased on the vertices and the second is based on the normals. Experimental\nresults demonstrate the effectiveness of our proposed method in comparison with\nthe existing methods.\n",
        "published": "2010-09-23T11:26:37Z",
        "pdf_link": "http://arxiv.org/pdf/1009.4581v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.4739v1",
        "title": "Balancing clusters to reduce response time variability in large scale\n  image search",
        "summary": "  Many algorithms for approximate nearest neighbor search in high-dimensional\nspaces partition the data into clusters. At query time, in order to avoid\nexhaustive search, an index selects the few (or a single) clusters nearest to\nthe query point. Clusters are often produced by the well-known $k$-means\napproach since it has several desirable properties. On the downside, it tends\nto produce clusters having quite different cardinalities. Imbalanced clusters\nnegatively impact both the variance and the expectation of query response\ntimes. This paper proposes to modify $k$-means centroids to produce clusters\nwith more comparable sizes without sacrificing the desirable properties.\nExperiments with a large scale collection of image descriptors show that our\nalgorithm significantly reduces the variance of response times without\nseriously impacting the search quality.\n",
        "published": "2010-09-21T11:31:02Z",
        "pdf_link": "http://arxiv.org/pdf/1009.4739v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.4757v3",
        "title": "Modeling Instantaneous Changes In Natural Scenes",
        "summary": "  This project aims to create 3d model of the natural world and model changes\nin it instantaneously. A framework for modeling instantaneous changes natural\nscenes in real time using Lagrangian Particle Framework and a fluid-particle\ngrid approach is presented. This project is presented in the form of a\nproof-based system where we show that the design is very much possible but\ncurrently we only have selective scripts that accomplish the given job, a\ncomplete software however is still under work. This research can be divided\ninto 3 distinct sections: the first one discusses a multi-camera rig that can\nmeasure ego-motion accurately up to 88%, how this device becomes the backbone\nof our framework, and some improvements devised to optimize a know framework\nfor depth maps and 3d structure estimation from a single still image called\nmake3d. The second part discusses the fluid-particle framework to model natural\nscenes, presents some algorithms that we are using to accomplish this task and\nwe show how an application of our framework can extend make3d to model natural\nscenes in real time. This part of the research constructs a bridge between\ncomputer vision and computer graphics so that now ideas, answers and intuitions\nthat arose in the domain of computer graphics can now be applied to computer\nvision and natural modeling. The final part of this research improves upon what\nmight become the first general purpose vision system using deep belief\narchitectures and provides another framework to improve the lower bound on\ntraining images for boosting by using a variation of Restricted Boltzmann\nmachines (RBM). We also discuss other applications that might arise from our\nwork in these areas.\n",
        "published": "2010-09-24T03:32:28Z",
        "pdf_link": "http://arxiv.org/pdf/1009.4757v3"
    },
    {
        "id": "http://arxiv.org/abs/1009.4823v1",
        "title": "Image Segmentation by Discounted Cumulative Ranking on Maximal Cliques",
        "summary": "  We propose a mid-level image segmentation framework that combines multiple\nfigure-ground hypothesis (FG) constrained at different locations and scales,\ninto interpretations that tile the entire image. The problem is cast as\noptimization over sets of maximal cliques sampled from the graph connecting\nnon-overlapping, putative figure-ground segment hypotheses. Potential functions\nover cliques combine unary Gestalt-based figure quality scores and pairwise\ncompatibilities among spatially neighboring segments, constrained by\nT-junctions and the boundary interface statistics resulting from projections of\nreal 3d scenes. Learning the model parameters is formulated as rank\noptimization, alternating between sampling image tilings and optimizing their\npotential function parameters. State of the art results are reported on both\nthe Berkeley and the VOC2009 segmentation dataset, where a 28% improvement was\nachieved.\n",
        "published": "2010-09-24T12:32:02Z",
        "pdf_link": "http://arxiv.org/pdf/1009.4823v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.4974v1",
        "title": "Rotation Invariant Face Detection Using Wavelet, PCA and Radial Basis\n  Function Networks",
        "summary": "  This paper introduces a novel method for human face detection with its\norientation by using wavelet, principle component analysis (PCA) and redial\nbasis networks. The input image is analyzed by two-dimensional wavelet and a\ntwo-dimensional stationary wavelet. The common goals concern are the image\nclearance and simplification, which are parts of de-noising or compression. We\napplied an effective procedure to reduce the dimension of the input vectors\nusing PCA. Radial Basis Function (RBF) neural network is then used as a\nfunction approximation network to detect where either the input image is\ncontained a face or not and if there is a face exists then tell about its\norientation. We will show how RBF can perform well then back-propagation\nalgorithm and give some solution for better regularization of the RBF (GRNN)\nnetwork. Compared with traditional RBF networks, the proposed network\ndemonstrates better capability of approximation to underlying functions, faster\nlearning speed, better size of network, and high robustness to outliers.\n",
        "published": "2010-09-25T05:46:31Z",
        "pdf_link": "http://arxiv.org/pdf/1009.4974v1"
    },
    {
        "id": "http://arxiv.org/abs/1009.5758v1",
        "title": "Face Detection with Effective Feature Extraction",
        "summary": "  There is an abundant literature on face detection due to its important role\nin many vision applications. Since Viola and Jones proposed the first real-time\nAdaBoost based face detector, Haar-like features have been adopted as the\nmethod of choice for frontal face detection. In this work, we show that simple\nfeatures other than Haar-like features can also be applied for training an\neffective face detector. Since, single feature is not discriminative enough to\nseparate faces from difficult non-faces, we further improve the generalization\nperformance of our simple features by introducing feature co-occurrences. We\ndemonstrate that our proposed features yield a performance improvement compared\nto Haar-like features. In addition, our findings indicate that features play a\ncrucial role in the ability of the system to generalize.\n",
        "published": "2010-09-29T03:13:09Z",
        "pdf_link": "http://arxiv.org/pdf/1009.5758v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.0417v1",
        "title": "Visual-hint Boundary to Segment Algorithm for Image Segmentation",
        "summary": "  Image segmentation has been a very active research topic in image analysis\narea. Currently, most of the image segmentation algorithms are designed based\non the idea that images are partitioned into a set of regions preserving\nhomogeneous intra-regions and inhomogeneous inter-regions. However, human\nvisual intuition does not always follow this pattern. A new image segmentation\nmethod named Visual-Hint Boundary to Segment (VHBS) is introduced, which is\nmore consistent with human perceptions. VHBS abides by two visual hint rules\nbased on human perceptions: (i) the global scale boundaries tend to be the real\nboundaries of the objects; (ii) two adjacent regions with quite different\ncolors or textures tend to result in the real boundaries between them. It has\nbeen demonstrated by experiments that, compared with traditional image\nsegmentation method, VHBS has better performance and also preserves higher\ncomputational efficiency.\n",
        "published": "2010-10-03T15:27:56Z",
        "pdf_link": "http://arxiv.org/pdf/1010.0417v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.0422v1",
        "title": "Convolutional Matching Pursuit and Dictionary Training",
        "summary": "  Matching pursuit and K-SVD is demonstrated in the translation invariant\nsetting\n",
        "published": "2010-10-03T16:55:56Z",
        "pdf_link": "http://arxiv.org/pdf/1010.0422v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.3867v1",
        "title": "Joint interpretation of on-board vision and static GPS cartography for\n  determination of correct speed limit",
        "summary": "  We present here a first prototype of a \"Speed Limit Support\" Advance Driving\nAssistance System (ADAS) producing permanent reliable information on the\ncurrent speed limit applicable to the vehicle. Such a module can be used either\nfor information of the driver, or could even serve for automatic setting of the\nmaximum speed of a smart Adaptive Cruise Control (ACC). Our system is based on\na joint interpretation of cartographic information (for static reference\ninformation) with on-board vision, used for traffic sign detection and\nrecognition (including supplementary sub-signs) and visual road lines\nlocalization (for detection of lane changes). The visual traffic sign detection\npart is quite robust (90% global correct detection and recognition for main\nspeed signs, and 80% for exit-lane sub-signs detection). Our approach for joint\ninterpretation with cartography is original, and logic-based rather than\nprobability-based, which allows correct behaviour even in cases, which do\nhappen, when both vision and cartography may provide the same erroneous\ninformation.\n",
        "published": "2010-10-19T12:03:16Z",
        "pdf_link": "http://arxiv.org/pdf/1010.3867v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.3935v1",
        "title": "3-D Rigid Models from Partial Views - Global Factorization",
        "summary": "  The so-called factorization methods recover 3-D rigid structure from motion\nby factorizing an observation matrix that collects 2-D projections of features.\nThese methods became popular due to their robustness - they use a large number\nof views, which constrains adequately the solution - and computational\nsimplicity - the large number of unknowns is computed through an SVD, avoiding\nnon-linear optimization. However, they require that all the entries of the\nobservation matrix are known. This is unlikely to happen in practice, due to\nself-occlusion and limited field of view. Also, when processing long videos,\nregions that become occluded often appear again later. Current factorization\nmethods process these as new regions, leading to less accurate estimates of 3-D\nstructure. In this paper, we propose a global factorization method that infers\ncomplete 3-D models directly from the 2-D projections in the entire set of\navailable video frames. Our method decides whether a region that has become\nvisible is a region that was seen before, or a previously unseen region, in a\nglobal way, i.e., by seeking the simplest rigid object that describes well the\nentire set of observations. This global approach increases significantly the\naccuracy of the estimates of the 3-D shape of the scene and the 3-D motion of\nthe camera. Experiments with artificial and real videos illustrate the good\nperformance of our method.\n",
        "published": "2010-10-19T14:45:55Z",
        "pdf_link": "http://arxiv.org/pdf/1010.3935v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.3947v1",
        "title": "Maximum Likelihood Mosaics",
        "summary": "  The majority of the approaches to the automatic recovery of a panoramic image\nfrom a set of partial views are suboptimal in the sense that the input images\nare aligned, or registered, pair by pair, e.g., consecutive frames of a video\nclip. These approaches lead to propagation errors that may be very severe,\nparticularly when dealing with videos that show the same region at disjoint\ntime intervals. Although some authors have proposed a post-processing step to\nreduce the registration errors in these situations, there have not been\nattempts to compute the optimal solution, i.e., the registrations leading to\nthe panorama that best matches the entire set of partial views}. This is our\ngoal. In this paper, we use a generative model for the partial views of the\npanorama and develop an algorithm to compute in an efficient way the Maximum\nLikelihood estimate of all the unknowns involved: the parameters describing the\nalignment of all the images and the panorama itself.\n",
        "published": "2010-10-19T15:13:40Z",
        "pdf_link": "http://arxiv.org/pdf/1010.3947v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.4021v1",
        "title": "ANSIG - An Analytic Signature for Arbitrary 2D Shapes (or Bags of\n  Unlabeled Points)",
        "summary": "  In image analysis, many tasks require representing two-dimensional (2D)\nshape, often specified by a set of 2D points, for comparison purposes. The\nchallenge of the representation is that it must not only capture the\ncharacteristics of the shape but also be invariant to relevant transformations.\nInvariance to geometric transformations, such as translation, rotation, and\nscale, has received attention in the past, usually under the assumption that\nthe points are previously labeled, i.e., that the shape is characterized by an\nordered set of landmarks. However, in many practical scenarios, the points\ndescribing the shape are obtained from automatic processes, e.g., edge or\ncorner detection, thus without labels or natural ordering. Obviously, the\ncombinatorial problem of computing the correspondences between the points of\ntwo shapes in the presence of the aforementioned geometrical distortions\nbecomes a quagmire when the number of points is large. We circumvent this\nproblem by representing shapes in a way that is invariant to the permutation of\nthe landmarks, i.e., we represent bags of unlabeled 2D points. Within our\nframework, a shape is mapped to an analytic function on the complex plane,\nleading to what we call its analytic signature (ANSIG). To store an ANSIG, it\nsuffices to sample it along a closed contour in the complex plane. We show that\nthe ANSIG is a maximal invariant with respect to the permutation group, i.e.,\nthat different shapes have different ANSIGs and shapes that differ by a\npermutation (or re-labeling) of the landmarks have the same ANSIG. We further\nshow how easy it is to factor out geometric transformations when comparing\nshapes using the ANSIG representation. Finally, we illustrate these\ncapabilities with shape-based image classification experiments.\n",
        "published": "2010-10-19T19:48:41Z",
        "pdf_link": "http://arxiv.org/pdf/1010.4021v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.4203v1",
        "title": "Revisiting Complex Moments For 2D Shape Representation and Image\n  Normalization",
        "summary": "  When comparing 2D shapes, a key issue is their normalization. Translation and\nscale are easily taken care of by removing the mean and normalizing the energy.\nHowever, defining and computing the orientation of a 2D shape is not so simple.\nIn fact, although for elongated shapes the principal axis can be used to define\none of two possible orientations, there is no such tool for general shapes. As\nwe show in the paper, previous approaches fail to compute the orientation of\neven noiseless observations of simple shapes. We address this problem. In the\npaper, we show how to uniquely define the orientation of an arbitrary 2D shape,\nin terms of what we call its Principal Moments. We show that a small subset of\nthese moments suffice to represent the underlying 2D shape and propose a new\nmethod to efficiently compute the shape orientation: Principal Moment Analysis.\nFinally, we discuss how this method can further be applied to normalize\ngrey-level images. Besides the theoretical proof of correctness, we describe\nexperiments demonstrating robustness to noise and illustrating the method with\nreal images.\n",
        "published": "2010-10-18T20:12:29Z",
        "pdf_link": "http://arxiv.org/pdf/1010.4203v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.4314v1",
        "title": "Statistical Compressive Sensing of Gaussian Mixture Models",
        "summary": "  A new framework of compressive sensing (CS), namely statistical compressive\nsensing (SCS), that aims at efficiently sampling a collection of signals that\nfollow a statistical distribution and achieving accurate reconstruction on\naverage, is introduced. For signals following a Gaussian distribution, with\nGaussian or Bernoulli sensing matrices of O(k) measurements, considerably\nsmaller than the O(k log(N/k)) required by conventional CS, where N is the\nsignal dimension, and with an optimal decoder implemented with linear\nfiltering, significantly faster than the pursuit decoders applied in\nconventional CS, the error of SCS is shown tightly upper bounded by a constant\ntimes the k-best term approximation error, with overwhelming probability. The\nfailure probability is also significantly smaller than that of conventional CS.\nStronger yet simpler results further show that for any sensing matrix, the\nerror of Gaussian SCS is upper bounded by a constant times the k-best term\napproximation with probability one, and the bound constant can be efficiently\ncalculated. For signals following Gaussian mixture models, SCS with a piecewise\nlinear decoder is introduced and shown to produce for real images better\nresults than conventional CS based on sparse models.\n",
        "published": "2010-10-20T20:22:26Z",
        "pdf_link": "http://arxiv.org/pdf/1010.4314v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.4893v1",
        "title": "Collaborative Sources Identification in Mixed Signals via Hierarchical\n  Sparse Modeling",
        "summary": "  A collaborative framework for detecting the different sources in mixed\nsignals is presented in this paper. The approach is based on C-HiLasso, a\nconvex collaborative hierarchical sparse model, and proceeds as follows. First,\nwe build a structured dictionary for mixed signals by concatenating a set of\nsub-dictionaries, each one of them learned to sparsely model one of a set of\npossible classes. Then, the coding of the mixed signal is performed by\nefficiently solving a convex optimization problem that combines standard\nsparsity with group and collaborative sparsity. The present sources are\nidentified by looking at the sub-dictionaries automatically selected in the\ncoding. The collaborative filtering in C-HiLasso takes advantage of the\ntemporal/spatial redundancy in the mixed signals, letting collections of\nsamples collaborate in identifying the classes, while allowing individual\nsamples to have different internal sparse representations. This collaboration\nis critical to further stabilize the sparse representation of signals, in\nparticular the class/sub-dictionary selection. The internal sparsity inside the\nsub-dictionaries, as naturally incorporated by the hierarchical aspects of\nC-HiLasso, is critical to make the model consistent with the essence of the\nsub-dictionaries that have been trained for sparse representation of each\nindividual class. We present applications from speaker and instrument\nidentification and texture separation. In the case of audio signals, we use\nsparse modeling to describe the short-term power spectrum envelopes of harmonic\nsounds. The proposed pitch independent method automatically detects the number\nof sources on a recording.\n",
        "published": "2010-10-23T16:47:16Z",
        "pdf_link": "http://arxiv.org/pdf/1010.4893v1"
    },
    {
        "id": "http://arxiv.org/abs/1010.5610v1",
        "title": "Selective Image Super-Resolution",
        "summary": "  In this paper we propose a vision system that performs image Super Resolution\n(SR) with selectivity. Conventional SR techniques, either by multi-image fusion\nor example-based construction, have failed to capitalize on the intrinsic\nstructural and semantic context in the image, and performed \"blind\" resolution\nrecovery to the entire image area. By comparison, we advocate example-based\nselective SR whereby selectivity is exemplified in three aspects: region\nselectivity (SR only at object regions), source selectivity (object SR with\ntrained object dictionaries), and refinement selectivity (object boundaries\nrefinement using matting). The proposed system takes over-segmented\nlow-resolution images as inputs, assimilates recent learning techniques of\nsparse coding (SC) and grouped multi-task lasso (GMTL), and leads eventually to\na framework for joint figure-ground separation and interest object SR. The\nefficiency of our framework is manifested in our experiments with subsets of\nthe VOC2009 and MSRC datasets. We also demonstrate several interesting vision\napplications that can build on our system.\n",
        "published": "2010-10-27T08:58:48Z",
        "pdf_link": "http://arxiv.org/pdf/1010.5610v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.0596v1",
        "title": "Multiple View Reconstruction of Calibrated Images using Singular Value\n  Decomposition",
        "summary": "  Calibration in a multi camera network has widely been studied for over\nseveral years starting from the earlier days of photogrammetry. Many authors\nhave presented several calibration algorithms with their relative advantages\nand disadvantages. In a stereovision system, multiple view reconstruction is a\nchallenging task. However, the total computational procedure in detail has not\nbeen presented before. Here in this work, we are dealing with the problem that,\nwhen a world coordinate point is fixed in space, image coordinates of that 3D\npoint vary for different camera positions and orientations. In computer vision\naspect, this situation is undesirable. That is, the system has to be designed\nin such a way that image coordinate of the world coordinate point will be fixed\nirrespective of the position & orientation of the cameras. We have done it in\nan elegant fashion. Firstly, camera parameters are calculated in its local\ncoordinate system. Then, we use global coordinate data to transfer all local\ncoordinate data of stereo cameras into same global coordinate system, so that\nwe can register everything into this global coordinate system. After all the\ntransformations, when the image coordinate of the world coordinate point is\ncalculated, it gives same coordinate value for all camera positions &\norientations. That is, the whole system is calibrated.\n",
        "published": "2010-11-02T12:25:04Z",
        "pdf_link": "http://arxiv.org/pdf/1011.0596v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.0640v1",
        "title": "Lesion Border Detection in Dermoscopy Images",
        "summary": "  Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, computerized analysis of dermoscopy\nimages has become an important research area. One of the most important steps\nin dermoscopy image analysis is the automated detection of lesion borders.\nMethods: In this article, we present a systematic overview of the recent border\ndetection methods in the literature paying particular attention to\ncomputational issues and evaluation aspects. Conclusion: Common problems with\nthe existing approaches include the acquisition, size, and diagnostic\ndistribution of the test image set, the evaluation of the results, and the\ninadequate description of the employed methods. Border determination by\ndermatologists appears to depend upon higher-level knowledge, therefore it is\nlikely that the incorporation of domain knowledge in automated methods will\nenable them to perform better, especially in sets of images with a variety of\ndiagnoses.\n",
        "published": "2010-10-30T17:17:02Z",
        "pdf_link": "http://arxiv.org/pdf/1011.0640v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.1035v1",
        "title": "Featureless 2D-3D Pose Estimation by Minimising an\n  Illumination-Invariant Loss",
        "summary": "  The problem of identifying the 3D pose of a known object from a given 2D\nimage has important applications in Computer Vision ranging from robotic vision\nto image analysis. Our proposed method of registering a 3D model of a known\nobject on a given 2D photo of the object has numerous advantages over existing\nmethods: It does neither require prior training nor learning, nor knowledge of\nthe camera parameters, nor explicit point correspondences or matching features\nbetween image and model. Unlike techniques that estimate a partial 3D pose (as\nin an overhead view of traffic or machine parts on a conveyor belt), our method\nestimates the complete 3D pose of the object, and works on a single static\nimage from a given view, and under varying and unknown lighting conditions. For\nthis purpose we derive a novel illumination-invariant distance measure between\n2D photo and projected 3D model, which is then minimised to find the best pose\nparameters. Results for vehicle pose detection are presented.\n",
        "published": "2010-11-03T23:44:46Z",
        "pdf_link": "http://arxiv.org/pdf/1011.1035v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.2272v1",
        "title": "Single Frame Image super Resolution using Learned Directionlets",
        "summary": "  In this paper, a new directionally adaptive, learning based, single image\nsuper resolution method using multiple direction wavelet transform, called\nDirectionlets is presented. This method uses directionlets to effectively\ncapture directional features and to extract edge information along different\ndirections of a set of available high resolution images .This information is\nused as the training set for super resolving a low resolution input image and\nthe Directionlet coefficients at finer scales of its high-resolution image are\nlearned locally from this training set and the inverse Directionlet transform\nrecovers the super-resolved high resolution image. The simulation results\nshowed that the proposed approach outperforms standard interpolation techniques\nlike Cubic spline interpolation as well as standard Wavelet-based learning,\nboth visually and in terms of the mean squared error (mse) values. This method\ngives good result with aliased images also.\n",
        "published": "2010-11-10T04:43:44Z",
        "pdf_link": "http://arxiv.org/pdf/1011.2272v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.3019v1",
        "title": "Bounded Multivariate Surfaces On Monovariate Internal Functions",
        "summary": "  Combining the properties of monovariate internal functions as proposed in\nKolmogorov superimposition theorem, in tandem with the bounds wielded by the\nmultivariate formulation of Chebyshev inequality, a hybrid model is presented,\nthat decomposes images into homogeneous probabilistically bounded multivariate\nsurfaces. Given an image, the model shows a novel way of working on reduced\nimage representation while processing and capturing the interaction among the\nmultidimensional information that describes the content of the same. Further,\nit tackles the practical issues of preventing leakage by bounding the growth of\nsurface and reducing the problem sample size. The model if used, also sheds\nlight on how the Chebyshev parameter relates to the number of pixels and the\ndimensionality of the feature space that associates with a pixel. Initial\nsegmentation results on the Berkeley image segmentation benchmark indicate the\neffectiveness of the proposed decomposition algorithm.\n",
        "published": "2010-11-12T19:48:13Z",
        "pdf_link": "http://arxiv.org/pdf/1011.3019v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.3023v4",
        "title": "Classification with Scattering Operators",
        "summary": "  A scattering vector is a local descriptor including multiscale and\nmulti-direction co-occurrence information. It is computed with a cascade of\nwavelet decompositions and complex modulus. This scattering representation is\nlocally translation invariant and linearizes deformations. A supervised\nclassification algorithm is computed with a PCA model selection on scattering\nvectors. State of the art results are obtained for handwritten digit\nrecognition and texture classification.\n",
        "published": "2010-11-12T20:15:25Z",
        "pdf_link": "http://arxiv.org/pdf/1011.3023v4"
    },
    {
        "id": "http://arxiv.org/abs/1011.3177v3",
        "title": "The Data Replication Method for the Classification with Reject Option",
        "summary": "  Classification is one of the most important tasks of machine learning.\nAlthough the most well studied model is the two-class problem, in many\nscenarios there is the opportunity to label critical items for manual revision,\ninstead of trying to automatically classify every item. In this paper we adapt\na paradigm initially proposed for the classification of ordinal data to address\nthe classification problem with reject option. The technique reduces the\nproblem of classifying with reject option to the standard two-class problem.\nThe introduced method is then mapped into support vector machines and neural\nnetworks. Finally, the framework is extended to multiclass ordinal data with\nreject option. An experimental study with synthetic and real data sets,\nverifies the usefulness of the proposed approach.\n",
        "published": "2010-11-14T02:48:02Z",
        "pdf_link": "http://arxiv.org/pdf/1011.3177v3"
    },
    {
        "id": "http://arxiv.org/abs/1011.4321v1",
        "title": "A Fuzzy Clustering Model for Fuzzy Data with Outliers",
        "summary": "  In this paper a fuzzy clustering model for fuzzy data with outliers is\nproposed. The model is based on Wasserstein distance between interval valued\ndata which is generalized to fuzzy data. In addition, Keller's approach is used\nto identify outliers and reduce their influences. We have also defined a\ntransformation to change our distance to the Euclidean distance. With the help\nof this approach, the problem of fuzzy clustering of fuzzy data is reduced to\nfuzzy clustering of crisp data. In order to show the performance of the\nproposed clustering algorithm, two simulation experiments are discussed.\n",
        "published": "2010-11-18T22:20:45Z",
        "pdf_link": "http://arxiv.org/pdf/1011.4321v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.4615v2",
        "title": "Generalized Tree-Based Wavelet Transform",
        "summary": "  In this paper we propose a new wavelet transform applicable to functions\ndefined on graphs, high dimensional data and networks. The proposed method\ngeneralizes the Haar-like transform proposed in [1], and it is defined via a\nhierarchical tree, which is assumed to capture the geometry and structure of\nthe input data. It is applied to the data using a modified version of the\ncommon one-dimensional (1D) wavelet filtering and decimation scheme, which can\nemploy different wavelet filters. In each level of this wavelet decomposition\nscheme, a permutation derived from the tree is applied to the approximation\ncoefficients, before they are filtered. We propose a tree construction method\nthat results in an efficient representation of the input function in the\ntransform domain. We show that the proposed transform is more efficient than\nboth the 1D and two-dimensional (2D) separable wavelet transforms in\nrepresenting images. We also explore the application of the proposed transform\nto image denoising, and show that combined with a subimage averaging scheme, it\nachieves denoising results which are similar to those obtained with the K-SVD\nalgorithm.\n",
        "published": "2010-11-20T21:32:36Z",
        "pdf_link": "http://arxiv.org/pdf/1011.4615v2"
    },
    {
        "id": "http://arxiv.org/abs/1011.5962v1",
        "title": "Edge Preserving Image Denoising in Reproducing Kernel Hilbert Spaces",
        "summary": "  The goal of this paper is the development of a novel approach for the problem\nof Noise Removal, based on the theory of Reproducing Kernels Hilbert Spaces\n(RKHS). The problem is cast as an optimization task in a RKHS, by taking\nadvantage of the celebrated semiparametric Representer Theorem. Examples verify\nthat in the presence of gaussian noise the proposed method performs relatively\nwell compared to wavelet based technics and outperforms them significantly in\nthe presence of impulse or mixed noise.\n  A more detailed version of this work has been published in the IEEE Trans.\nIm. Proc. : P. Bouboulis, K. Slavakis and S. Theodoridis, Adaptive Kernel-based\nImage Denoising employing Semi-Parametric Regularization, IEEE Transactions on\nImage Processing, vol 19(6), 2010, 1465 - 1479.\n",
        "published": "2010-11-27T10:24:12Z",
        "pdf_link": "http://arxiv.org/pdf/1011.5962v1"
    },
    {
        "id": "http://arxiv.org/abs/1011.6656v2",
        "title": "Learning sparse representations of depth",
        "summary": "  This paper introduces a new method for learning and inferring sparse\nrepresentations of depth (disparity) maps. The proposed algorithm relaxes the\nusual assumption of the stationary noise model in sparse coding. This enables\nlearning from data corrupted with spatially varying noise or uncertainty,\ntypically obtained by laser range scanners or structured light depth cameras.\nSparse representations are learned from the Middlebury database disparity maps\nand then exploited in a two-layer graphical model for inferring depth from\nstereo, by including a sparsity prior on the learned features. Since they\ncapture higher-order dependencies in the depth structure, these priors can\ncomplement smoothness priors commonly used in depth inference based on Markov\nRandom Field (MRF) models. Inference on the proposed graph is achieved using an\nalternating iterative optimization technique, where the first layer is solved\nusing an existing MRF-based stereo matching algorithm, then held fixed as the\nsecond layer is solved using the proposed non-stationary sparse coding\nalgorithm. This leads to a general method for improving solutions of state of\nthe art MRF-based depth estimation algorithms. Our experimental results first\nshow that depth inference using learned representations leads to state of the\nart denoising of depth maps obtained from laser range scanners and a time of\nflight camera. Furthermore, we show that adding sparse priors improves the\nresults of two depth estimation methods: the classical graph cut algorithm by\nBoykov et al. and the more recent algorithm of Woodford et al.\n",
        "published": "2010-11-30T19:55:21Z",
        "pdf_link": "http://arxiv.org/pdf/1011.6656v2"
    },
    {
        "id": "http://arxiv.org/abs/1101.0237v1",
        "title": "A Framework for Real-Time Face and Facial Feature Tracking using Optical\n  Flow Pre-estimation and Template Tracking",
        "summary": "  This work presents a framework for tracking head movements and capturing the\nmovements of the mouth and both the eyebrows in real-time. We present a head\ntracker which is a combination of a optical flow and a template based tracker.\nThe estimation of the optical flow head tracker is used as starting point for\nthe template tracker which fine-tunes the head estimation. This approach\ntogether with re-updating the optical flow points prevents the head tracker\nfrom drifting. This combination together with our switching scheme, makes our\ntracker very robust against fast movement and motion-blur. We also propose a\nway to reduce the influence of partial occlusion of the head. In both the\noptical flow and the template based tracker we identify and exclude occluded\npoints.\n",
        "published": "2010-12-31T12:16:29Z",
        "pdf_link": "http://arxiv.org/pdf/1101.0237v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.0242v1",
        "title": "Binary and nonbinary description of hypointensity in human brain MR\n  images",
        "summary": "  Accumulating evidence has shown that iron is involved in the mechanism\nunderlying many neurodegenerative diseases, such as Alzheimer's disease,\nParkinson's disease and Huntington's disease. Abnormal (higher) iron\naccumulation has been detected in the brains of most neurodegenerative\npatients, especially in the basal ganglia region. Presence of iron leads to\nchanges in MR signal in both magnitude and phase. Accordingly, tissues with\nhigh iron concentration appear hypo-intense (darker than usual) in MR\ncontrasts. In this report, we proposed an improved binary hypointensity\ndescription and a novel nonbinary hypointensity description based on principle\ncomponents analysis. Moreover, Kendall's rank correlation coefficient was used\nto compare the complementary and redundant information provided by the two\nmethods in order to better understand the individual descriptions of iron\naccumulation in the brain.\n",
        "published": "2010-12-31T12:26:04Z",
        "pdf_link": "http://arxiv.org/pdf/1101.0242v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.0384v1",
        "title": "Combining Neural Networks for Skin Detection",
        "summary": "  Two types of combining strategies were evaluated namely combining skin\nfeatures and combining skin classifiers. Several combining rules were applied\nwhere the outputs of the skin classifiers are combined using binary operators\nsuch as the AND and the OR operators, \"Voting\", \"Sum of Weights\" and a new\nneural network. Three chrominance components from the YCbCr colour space that\ngave the highest correct detection on their single feature MLP were selected as\nthe combining parameters. A major issue in designing a MLP neural network is to\ndetermine the optimal number of hidden units given a set of training patterns.\nTherefore, a \"coarse to fine search\" method to find the number of neurons in\nthe hidden layer is proposed. The strategy of combining Cb/Cr and Cr features\nimproved the correct detection by 3.01% compared to the best single feature MLP\ngiven by Cb-Cr. The strategy of combining the outputs of three skin classifiers\nusing the \"Sum of Weights\" rule further improved the correct detection by 4.38%\ncompared to the best single feature MLP.\n",
        "published": "2011-01-02T04:53:22Z",
        "pdf_link": "http://arxiv.org/pdf/1101.0384v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.0457v1",
        "title": "Segmentation of Camera Captured Business Card Images for Mobile Devices",
        "summary": "  Due to huge deformation in the camera captured images, variety in nature of\nthe business cards and the computational constraints of the mobile devices,\ndesign of an efficient Business Card Reader (BCR) is challenging to the\nresearchers. Extraction of text regions and segmenting them into characters is\none of such challenges. In this paper, we have presented an efficient character\nsegmentation technique for business card images captured by a cell-phone\ncamera, designed in our present work towards developing an efficient BCR. At\nfirst, text regions are extracted from the card images and then the skewed ones\nare corrected using a computationally efficient skew correction technique. At\nlast, these skew corrected text regions are segmented into lines and characters\nbased on horizontal and vertical histogram. Experiments show that the present\ntechnique is efficient and applicable for mobile devices, and the mean\nsegmentation accuracy of 97.48% is achieved with 3 mega-pixel (500-600 dpi)\nimages. It takes only 1.1 seconds for segmentation including all the\npreprocessing steps on a moderately powerful notebook (DualCore T2370, 1.73\nGHz, 1GB RAM, 1MB L2 Cache).\n",
        "published": "2011-01-03T06:15:08Z",
        "pdf_link": "http://arxiv.org/pdf/1101.0457v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.1602v1",
        "title": "Application of Freeman Chain Codes: An Alternative Recognition Technique\n  for Malaysian Car Plates",
        "summary": "  Various applications of car plate recognition systems have been developed\nusing various kinds of methods and techniques by researchers all over the\nworld. The applications developed were only suitable for specific country due\nto its standard specification endorsed by the transport department of\nparticular countries. The Road Transport Department of Malaysia also has\nendorsed a specification for car plates that includes the font and size of\ncharacters that must be followed by car owners. However, there are cases where\nthis specification is not followed. Several applications have been developed in\nMalaysia to overcome this problem. However, there is still problem in achieving\n100% recognition accuracy. This paper is mainly focused on conducting an\nexperiment using chain codes technique to perform recognition for different\ntypes of fonts used in Malaysian car plates.\n",
        "published": "2011-01-08T16:22:20Z",
        "pdf_link": "http://arxiv.org/pdf/1101.1602v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.2243v1",
        "title": "Illustrating Color Evolution and Color Blindness by the Decoding Model\n  of Color Vision",
        "summary": "  A symmetrical model of color vision, the decoding model as a new version of\nzone model, was introduced. The model adopts new continuous-valued logic and\nworks in a way very similar to the way a 3-8 decoder in a numerical circuit\nworks. By the decoding model, Young and Helmholtz's tri-pigment theory and\nHering's opponent theory are unified more naturally; opponent process, color\nevolution, and color blindness are illustrated more concisely. According to the\ndecoding model, we can obtain a transform from RGB system to HSV system, which\nis formally identical to the popular transform for computer graphics provided\nby Smith (1978). Advantages, problems, and physiological tests of the decoding\nmodel are also discussed.\n",
        "published": "2010-12-12T20:49:00Z",
        "pdf_link": "http://arxiv.org/pdf/1101.2243v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.2312v1",
        "title": "Automatic segmentation of HeLa cell images",
        "summary": "  In this work, the possibilities for segmentation of cells from their\nbackground and each other in digital image were tested, combined and improoved.\nLot of images with young, adult and mixture cells were able to prove the\nquality of described algorithms. Proper segmentation is one of the main task of\nimage analysis and steps order differ from work to work, depending on input\nimages. Reply for biologicaly given question was looking for in this work,\nincluding filtration, details emphasizing, segmentation and sphericity\ncomputing. Order of algorithms and way to searching for them was also\ndescribed. Some questions and ideas for further work were mentioned in the\nconclusion part.\n",
        "published": "2011-01-12T10:16:11Z",
        "pdf_link": "http://arxiv.org/pdf/1101.2312v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.2491v1",
        "title": "A Review of Research on Devnagari Character Recognition",
        "summary": "  English Character Recognition (CR) has been extensively studied in the last\nhalf century and progressed to a level, sufficient to produce technology driven\napplications. But same is not the case for Indian languages which are\ncomplicated in terms of structure and computations. Rapidly growing\ncomputational power may enable the implementation of Indic CR methodologies.\nDigital document processing is gaining popularity for application to office and\nlibrary automation, bank and postal services, publishing houses and\ncommunication technology. Devnagari being the national language of India,\nspoken by more than 500 million people, should be given special attention so\nthat document retrieval and analysis of rich ancient and modern Indian\nliterature can be effectively done. This article is intended to serve as a\nguide and update for the readers, working in the Devnagari Optical Character\nRecognition (DOCR) area. An overview of DOCR systems is presented and the\navailable DOCR techniques are reviewed. The current status of DOCR is discussed\nand directions for future research are suggested.\n",
        "published": "2011-01-13T04:00:30Z",
        "pdf_link": "http://arxiv.org/pdf/1101.2491v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.4301v1",
        "title": "Diffusion framework for geometric and photometric data fusion in\n  non-rigid shape analysis",
        "summary": "  In this paper, we explore the use of the diffusion geometry framework for the\nfusion of geometric and photometric information in local and global shape\ndescriptors. Our construction is based on the definition of a diffusion process\non the shape manifold embedded into a high-dimensional space where the\nembedding coordinates represent the photometric information. Experimental\nresults show that such data fusion is useful in coping with different\nchallenges of shape analysis where pure geometric and pure photometric methods\nfail.\n",
        "published": "2011-01-22T16:41:20Z",
        "pdf_link": "http://arxiv.org/pdf/1101.4301v1"
    },
    {
        "id": "http://arxiv.org/abs/1101.5320v2",
        "title": "A Panorama on Multiscale Geometric Representations, Intertwining\n  Spatial, Directional and Frequency Selectivity",
        "summary": "  The richness of natural images makes the quest for optimal representations in\nimage processing and computer vision challenging. The latter observation has\nnot prevented the design of image representations, which trade off between\nefficiency and complexity, while achieving accurate rendering of smooth regions\nas well as reproducing faithful contours and textures. The most recent ones,\nproposed in the past decade, share an hybrid heritage highlighting the\nmultiscale and oriented nature of edges and patterns in images. This paper\npresents a panorama of the aforementioned literature on decompositions in\nmultiscale, multi-orientation bases or dictionaries. They typically exhibit\nredundancy to improve sparsity in the transformed domain and sometimes its\ninvariance with respect to simple geometric deformations (translation,\nrotation). Oriented multiscale dictionaries extend traditional wavelet\nprocessing and may offer rotation invariance. Highly redundant dictionaries\nrequire specific algorithms to simplify the search for an efficient (sparse)\nrepresentation. We also discuss the extension of multiscale geometric\ndecompositions to non-Euclidean domains such as the sphere or arbitrary meshed\nsurfaces. The etymology of panorama suggests an overview, based on a choice of\npartially overlapping \"pictures\". We hope that this paper will contribute to\nthe appreciation and apprehension of a stream of current research directions in\nimage understanding.\n",
        "published": "2011-01-27T15:53:30Z",
        "pdf_link": "http://arxiv.org/pdf/1101.5320v2"
    },
    {
        "id": "http://arxiv.org/abs/1102.1292v1",
        "title": "Modeling Dynamic Swarms",
        "summary": "  This paper proposes the problem of modeling video sequences of dynamic swarms\n(DS). We define DS as a large layout of stochastically repetitive spatial\nconfigurations of dynamic objects (swarm elements) whose motions exhibit local\nspatiotemporal interdependency and stationarity, i.e., the motions are similar\nin any small spatiotemporal neighborhood. Examples of DS abound in nature,\ne.g., herds of animals and flocks of birds. To capture the local spatiotemporal\nproperties of the DS, we present a probabilistic model that learns both the\nspatial layout of swarm elements and their joint dynamics that are modeled as\nlinear transformations. To this end, a spatiotemporal neighborhood is\nassociated with each swarm element, in which local stationarity is enforced\nboth spatially and temporally. We assume that the prior on the swarm dynamics\nis distributed according to an MRF in both space and time. Embedding this model\nin a MAP framework, we iterate between learning the spatial layout of the swarm\nand its dynamics. We learn the swarm transformations using ICM, which iterates\nbetween estimating these transformations and updating their distribution in the\nspatiotemporal neighborhoods. We demonstrate the validity of our method by\nconducting experiments on real video sequences. Real sequences of birds, geese,\nrobot swarms, and pedestrians evaluate the applicability of our model to real\nworld data.\n",
        "published": "2011-02-07T12:29:30Z",
        "pdf_link": "http://arxiv.org/pdf/1102.1292v1"
    },
    {
        "id": "http://arxiv.org/abs/1102.2743v2",
        "title": "Feature selection via simultaneous sparse approximation for person\n  specific face verification",
        "summary": "  There is an increasing use of some imperceivable and redundant local features\nfor face recognition. While only a relatively small fraction of them is\nrelevant to the final recognition task, the feature selection is a crucial and\nnecessary step to select the most discriminant ones to obtain a compact face\nrepresentation. In this paper, we investigate the sparsity-enforced\nregularization-based feature selection methods and propose a multi-task feature\nselection method for building person specific models for face verification. We\nassume that the person specific models share a common subset of features and\nnovelly reformulated the common subset selection problem as a simultaneous\nsparse approximation problem. To the best of our knowledge, it is the first\ntime to apply the sparsity-enforced regularization methods for person specific\nface verification. The effectiveness of the proposed methods is verified with\nthe challenging LFW face databases.\n",
        "published": "2011-02-14T11:51:35Z",
        "pdf_link": "http://arxiv.org/pdf/1102.2743v2"
    },
    {
        "id": "http://arxiv.org/abs/1102.4258v1",
        "title": "SHREC 2011: robust feature detection and description benchmark",
        "summary": "  Feature-based approaches have recently become very popular in computer vision\nand image analysis applications, and are becoming a promising direction in\nshape retrieval. SHREC'11 robust feature detection and description benchmark\nsimulates the feature detection and description stages of feature-based shape\nretrieval algorithms. The benchmark tests the performance of shape feature\ndetectors and descriptors under a wide variety of transformations. The\nbenchmark allows evaluating how algorithms cope with certain classes of\ntransformations and strength of the transformations that can be dealt with. The\npresent paper is a report of the SHREC'11 robust feature detection and\ndescription benchmark results.\n",
        "published": "2011-02-21T15:43:19Z",
        "pdf_link": "http://arxiv.org/pdf/1102.4258v1"
    },
    {
        "id": "http://arxiv.org/abs/1102.5688v1",
        "title": "A novel super resolution reconstruction of low reoslution images\n  progressively using dct and zonal filter based denoising",
        "summary": "  Due to the factors like processing power limitations and channel capabilities\nimages are often down sampled and transmitted at low bit rates resulting in a\nlow resolution compressed image. High resolution images can be reconstructed\nfrom several blurred, noisy and down sampled low resolution images using a\ncomputational process know as super resolution reconstruction. Super-resolution\nis the process of combining multiple aliased low-quality images to produce a\nhigh resolution, high-quality image. The problem of recovering a high\nresolution image progressively from a sequence of low resolution compressed\nimages is considered. In this paper we propose a novel DCT based progressive\nimage display algorithm by stressing on the encoding and decoding process. At\nthe encoder we consider a set of low resolution images which are corrupted by\nadditive white Gaussian noise and motion blur. The low resolution images are\ncompressed using 8 by 8 blocks DCT and noise is filtered using our proposed\nnovel zonal filter. Multiframe fusion is performed in order to obtain a single\nnoise free image. At the decoder the image is reconstructed progressively by\ntransmitting the coarser image first followed by the detail image. And finally\na super resolution image is reconstructed by applying our proposed novel\nadaptive interpolation technique. We have performed both objective and\nsubjective analysis of the reconstructed image, and the resultant image has\nbetter super resolution factor, and a higher ISNR and PSNR. A comparative study\ndone with Iterative Back Projection (IBP) and Projection on to Convex Sets\n(POCS),Papoulis Grechberg, FFT based Super resolution Reconstruction shows that\nour method has out performed the previous contributions.\n",
        "published": "2011-02-28T15:24:06Z",
        "pdf_link": "http://arxiv.org/pdf/1102.5688v1"
    },
    {
        "id": "http://arxiv.org/abs/1103.0120v2",
        "title": "Automatic Detection of Ringworm using Local Binary Pattern (LBP)",
        "summary": "  In this paper we present a novel approach for automatic recognition of ring\nworm skin disease based on LBP (Local Binary Pattern) feature extracted from\nthe affected skin images. The proposed method is evaluated by extensive\nexperiments on the skin images collected from internet. The dataset is tested\nusing three different classifiers i.e. Bayesian, MLP and SVM. Experimental\nresults show that the proposed methodology efficiently discriminates between a\nring worm skin and a normal skin. It is a low cost technique and does not\nrequire any special imaging devices.\n",
        "published": "2011-03-01T10:06:31Z",
        "pdf_link": "http://arxiv.org/pdf/1103.0120v2"
    },
    {
        "id": "http://arxiv.org/abs/1103.1475v1",
        "title": "A Semi-Automatic Graph-Based Approach for Determining the Boundary of\n  Eloquent Fiber Bundles in the Human Brain",
        "summary": "  Diffusion Tensor Imaging (DTI) allows estimating the position, orientation\nand dimension of bundles of nerve pathways. This non-invasive imaging technique\ntakes advantage of the diffusion of water molecules and determines the\ndiffusion coefficients for every voxel of the data set. The identification of\nthe diffusion coefficients and the derivation of information about fiber\nbundles is of major interest for planning and performing neurosurgical\ninterventions. To minimize the risk of neural deficits during brain surgery as\ntumor resection (e.g. glioma), the segmentation and integration of the results\nin the operating room is of prime importance. In this contribution, a robust\nand efficient graph-based approach for segmentating tubular fiber bundles in\nthe human brain is presented. To define a cost function, the fractional\nanisotropy (FA) is used, derived from the DTI data, but this value may differ\nfrom patient to patient. Besides manually definining seed regions describing\nthe structure of interest, additionally a manual definition of the cost\nfunction by the user is necessary. To improve the approach the contribution\nintroduces a solution for automatically determining the cost function by using\ndifferent 3D masks for each individual data set.\n",
        "published": "2011-03-08T09:39:21Z",
        "pdf_link": "http://arxiv.org/pdf/1103.1475v1"
    },
    {
        "id": "http://arxiv.org/abs/1103.1587v2",
        "title": "All Roads Lead To Rome",
        "summary": "  This short article presents a class of projection-based solution algorithms\nto the problem considered in the pioneering work on compressed sensing -\nperfect reconstruction of a phantom image from 22 radial lines in the frequency\ndomain. Under the framework of projection-based image reconstruction, we will\nshow experimentally that several old and new tools of nonlinear filtering\n(including Perona-Malik diffusion, nonlinear diffusion, Translation-Invariant\nthresholding and SA-DCT thresholding) all lead to perfect reconstruction of the\nphantom image.\n",
        "published": "2011-03-08T17:50:56Z",
        "pdf_link": "http://arxiv.org/pdf/1103.1587v2"
    },
    {
        "id": "http://arxiv.org/abs/1103.1952v1",
        "title": "Ray-Based and Graph-Based Methods for Fiber Bundle Boundary Estimation",
        "summary": "  Diffusion Tensor Imaging (DTI) provides the possibility of estimating the\nlocation and course of eloquent structures in the human brain. Knowledge about\nthis is of high importance for preoperative planning of neurosurgical\ninterventions and for intraoperative guidance by neuronavigation in order to\nminimize postoperative neurological deficits. Therefore, the segmentation of\nthese structures as closed, three-dimensional object is necessary. In this\ncontribution, two methods for fiber bundle segmentation between two defined\nregions are compared using software phantoms (abstract model and anatomical\nphantom modeling the right corticospinal tract). One method uses evaluation\npoints from sampled rays as candidates for boundary points, the other method\nsets up a directed and weighted (depending on a scalar measure) graph and\nperforms a min-cut for optimal segmentation results. Comparison is done by\nusing the Dice Similarity Coefficient (DSC), a measure for spatial overlap of\ndifferent segmentation results.\n",
        "published": "2011-03-10T07:19:23Z",
        "pdf_link": "http://arxiv.org/pdf/1103.1952v1"
    },
    {
        "id": "http://arxiv.org/abs/1103.3440v1",
        "title": "Off-Line Handwritten Signature Identification Using Rotated Complex\n  Wavelet Filters",
        "summary": "  In this paper, a new method for handwritten signature identification based on\nrotated complex wavelet filters is proposed. We have proposed to use the\nrotated complex wavelet filters (RCWF) and dual tree complex wavelet\ntransform(DTCWT) together to derive signature feature extraction, which\ncaptures information in twelve different directions. In identification phase,\nCanberra distance measure is used. The proposed method is compared with\ndiscrete wavelet transform (DWT). From experimental results it is found that\nsignature identification rate of proposed method is superior over DWT\n",
        "published": "2011-03-17T15:52:15Z",
        "pdf_link": "http://arxiv.org/pdf/1103.3440v1"
    },
    {
        "id": "http://arxiv.org/abs/1103.4723v4",
        "title": "Automatic Extraction of Open Space Area from High Resolution Urban\n  Satellite Imagery",
        "summary": "  In the 21st century, Aerial and satellite images are information rich. They\nare also complex to analyze. For GIS systems, many features require fast and\nreliable extraction of open space area from high resolution satellite imagery.\nIn this paper we will study efficient and reliable automatic extraction\nalgorithm to find out the open space area from the high resolution urban\nsatellite imagery. This automatic extraction algorithm uses some filters and\nsegmentations and grouping is applying on satellite images. And the result\nimages may use to calculate the total available open space area and the built\nup area. It may also use to compare the difference between present and past\nopen space area using historical urban satellite images of that same projection\n",
        "published": "2011-03-24T10:40:00Z",
        "pdf_link": "http://arxiv.org/pdf/1103.4723v4"
    },
    {
        "id": "http://arxiv.org/abs/1103.4913v1",
        "title": "Automatic Open Space Area Extraction and Change Detection from High\n  Resolution Urban Satellite Images",
        "summary": "  In this paper, we study efficient and reliable automatic extraction algorithm\nto find out the open space area from the high resolution urban satellite\nimagery, and to detect changes from the extracted open space area during the\nperiod 2003, 2006 and 2008. This automatic extraction and change detection\nalgorithm uses some filters, segmentation and grouping that are applied on\nsatellite images. The resultant images may be used to calculate the total\navailable open space area and the built up area. It may also be used to compare\nthe difference between present and past open space area using historical urban\nsatellite images of that same projection, which is an important geo spatial\ndata management application.\n",
        "published": "2011-03-25T07:02:09Z",
        "pdf_link": "http://arxiv.org/pdf/1103.4913v1"
    },
    {
        "id": "http://arxiv.org/abs/1103.5621v1",
        "title": "Application of Threshold Techniques for Readability Improvement of Jawi\n  Historical Manuscript Images",
        "summary": "  Historical documents such as old books and manuscripts have a high aesthetic\nvalue and highly appreciated. Unfortunately, there are some documents cannot be\nread due to quality problems like faded paper, ink expand, uneven colour tone,\ntorn paper and other elements disruption such as the existence of small spots.\nThe study aims to produce a copy of manuscript that shows clear wordings so\nthey can easily be read and the copy can also be displayed for visitors. 16\nsamples of Jawi historical manuscript with different quality problems were\nobtained from The Royal Museum of Pahang, Malaysia. We applied three\nbinarization techniques; Otsu's method represents global threshold technique;\nSauvola and Niblack method which are categorized as local threshold techniques.\nWe compared the binarized images with the original manuscript to be visually\ninspected by the museum's curator. The unclear features were marked and\nanalyzed. Most of the examined images show that with optimal parameters and\neffective pre processing technique, local thresholding methods are work well\ncompare with the other one. Niblack's and Sauvola's techniques seem to be the\nsuitable approaches for these types of images. Most of binarized images with\nthese two methods show improvement for readability and character recognition.\nFor this research, even the differences of image result were hard to be\ndistinguished by human capabilities, after comparing the time cost and overall\nachievement rate of recognized symbols, Niblack's method is performing better\nthan Sauvola's. We could improve the post processing step by adding edge\ndetection techniques and further enhanced by an innovative image refinement\ntechnique and a formulation of a class proper method.\n",
        "published": "2011-03-29T12:34:53Z",
        "pdf_link": "http://arxiv.org/pdf/1103.5621v1"
    },
    {
        "id": "http://arxiv.org/abs/1103.5808v1",
        "title": "Improved Edge Awareness in Discontinuity Preserving Smoothing",
        "summary": "  Discontinuity preserving smoothing is a fundamentally important procedure\nthat is useful in a wide variety of image processing contexts. It is directly\nuseful for noise reduction, and frequently used as an intermediate step in\nhigher level algorithms. For example, it can be particularly useful in edge\ndetection and segmentation. Three well known algorithms for discontinuity\npreserving smoothing are nonlinear anisotropic diffusion, bilateral filtering,\nand mean shift filtering. Although slight differences make them each better\nsuited to different tasks, all are designed to preserve discontinuities while\nsmoothing. However, none of them satisfy this goal perfectly: they each have\nexception cases in which smoothing may occur across hard edges. The principal\ncontribution of this paper is the identification of a property we call edge\nawareness that should be satisfied by any discontinuity preserving smoothing\nalgorithm. This constraint can be incorporated into existing algorithms to\nimprove quality, and usually has negligible changes in runtime performance\nand/or complexity. We present modifications necessary to augment diffusion and\nmean shift, as well as a new formulation of the bilateral filter that unifies\nthe spatial and range spaces to achieve edge awareness.\n",
        "published": "2011-03-30T01:57:09Z",
        "pdf_link": "http://arxiv.org/pdf/1103.5808v1"
    },
    {
        "id": "http://arxiv.org/abs/1103.6052v1",
        "title": "Internal Constraints of the Trifocal Tensor",
        "summary": "  The fundamental matrix and trifocal tensor are convenient algebraic\nrepresentations of the epipolar geometry of two and three view configurations,\nrespectively. The estimation of these entities is central to most\nreconstruction algorithms, and a solid understanding of their properties and\nconstraints is therefore very important. The fundamental matrix has 1 internal\nconstraint which is well understood, whereas the trifocal tensor has 8\nindependent algebraic constraints. The internal tensor constraints can be\nrepresented in many ways, although there is only one minimal and sufficient set\nof 8 constraints known. In this paper, we derive a second set of minimal and\nsufficient constraints that is simpler. We also show how this can be used in a\nnew parameterization of the trifocal tensor. We hope that this increased\nunderstanding of the internal constraints may lead to improved algorithms for\nestimating the trifocal tensor, although the primary contribution is an\nimproved theoretical understanding.\n",
        "published": "2011-03-30T21:47:41Z",
        "pdf_link": "http://arxiv.org/pdf/1103.6052v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.0579v1",
        "title": "Image Retrieval Method Using Top-surf Descriptor",
        "summary": "  This report presents the results and details of a content-based image\nretrieval project using the Top-surf descriptor. The experimental results are\npreliminary, however, it shows the capability of deducing objects from parts of\nthe objects or from the objects that are similar. This paper uses a dataset\nconsisting of 1200 images of which 800 images are equally divided into 8\ncategories, namely airplane, beach, motorbike, forest, elephants, horses, bus\nand building, while the other 400 images are randomly picked from the Internet.\nThe best results achieved are from building category.\n",
        "published": "2011-04-04T14:14:47Z",
        "pdf_link": "http://arxiv.org/pdf/1104.0579v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.0582v1",
        "title": "Visual Concept Detection and Real Time Object Detection",
        "summary": "  Bag-of-words model is implemented and tried on 10-class visual concept\ndetection problem. The experimental results show that \"DURF+ERT+SVM\"\noutperforms \"SIFT+ERT+SVM\" both in detection performance and computation\nefficiency. Besides, combining DURF and SIFT results in even better detection\nperformance. Real-time object detection using SIFT and RANSAC is also tried on\nsimple objects, e.g. drink can, and good result is achieved.\n",
        "published": "2011-04-04T14:18:51Z",
        "pdf_link": "http://arxiv.org/pdf/1104.0582v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.1237v1",
        "title": "A Statistical Nonparametric Approach of Face Recognition: Combination of\n  Eigenface & Modified k-Means Clustering",
        "summary": "  Facial expressions convey non-verbal cues, which play an important role in\ninterpersonal relations. Automatic recognition of human face based on facial\nexpression can be an important component of natural human-machine interface. It\nmay also be used in behavioural science. Although human can recognize the face\npractically without any effort, but reliable face recognition by machine is a\nchallenge. This paper presents a new approach for recognizing the face of a\nperson considering the expressions of the same human face at different\ninstances of time. This methodology is developed combining Eigenface method for\nfeature extraction and modified k-Means clustering for identification of the\nhuman face. This method endowed the face recognition without using the\nconventional distance measure classifiers. Simulation results show that\nproposed face recognition using perception of k-Means clustering is useful for\nface images with different facial expressions.\n",
        "published": "2011-04-07T03:17:08Z",
        "pdf_link": "http://arxiv.org/pdf/1104.1237v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.1472v1",
        "title": "Gaussian Affine Feature Detector",
        "summary": "  A new method is proposed to get image features' geometric information. Using\nGaussian as an input signal, a theoretical optimal solution to calculate\nfeature's affine shape is proposed. Based on analytic result of a feature\nmodel, the method is different from conventional iterative approaches. From the\nmodel, feature's parameters such as position, orientation, background\nluminance, contrast, area and aspect ratio can be extracted. Tested with\nsynthesized and benchmark data, the method achieves or outperforms existing\napproaches in term of accuracy, speed and stability. The method can detect\nsmall, long or thin objects precisely, and works well under general conditions,\nsuch as for low contrast, blurred or noisy images.\n",
        "published": "2011-04-08T03:15:43Z",
        "pdf_link": "http://arxiv.org/pdf/1104.1472v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.1485v1",
        "title": "Fuzzy Rules and Evidence Theory for Satellite Image Analysis",
        "summary": "  Design of a fuzzy rule based classifier is proposed. The performance of the\nclassifier for multispectral satellite image classification is improved using\nDempster- Shafer theory of evidence that exploits information of the\nneighboring pixels. The classifiers are tested rigorously with two known images\nand their performance are found to be better than the results available in the\nliterature. We also demonstrate the improvement of performance while using D-S\ntheory along with fuzzy rule based classifiers over the basic fuzzy rule based\nclassifiers for all the test cases.\n",
        "published": "2011-04-08T05:18:15Z",
        "pdf_link": "http://arxiv.org/pdf/1104.1485v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.1556v3",
        "title": "Benchmarking the Quality of Diffusion-Weighted Images",
        "summary": "  We present a novel method that allows for measuring the quality of\ndiffusion-weighted MR images dependent on the image resolution and the image\nnoise. For this purpose, we introduce a new thresholding technique so that\nnoise and the signal can automatically be estimated from a single data set.\nThus, no user interaction as well as no double acquisition technique, which\nrequires a time-consuming proper geometrical registration, is needed. As a\ncoarser image resolution or slice thickness leads to a higher signal-to-noise\nratio (SNR), our benchmark determines a resolution-independent quality measure\nso that images with different resolutions can be adequately compared. To\nevaluate our method, a set of diffusion-weighted images from different vendors\nis used. It is shown that the quality can efficiently be determined and that\nthe automatically computed SNR is comparable to the SNR which is measured\nmanually in a manually selected region of interest.\n",
        "published": "2011-04-08T12:03:16Z",
        "pdf_link": "http://arxiv.org/pdf/1104.1556v3"
    },
    {
        "id": "http://arxiv.org/abs/1104.1945v1",
        "title": "Off-Line Handwritten Signature Retrieval using Curvelet Transforms",
        "summary": "  In this paper, a new method for offline handwritten signature retrieval is\nbased on curvelet transform is proposed. Many applications in image processing\nrequire similarity retrieval of an image from a large collection of images. In\nsuch cases, image indexing becomes important for efficient organization and\nretrieval of images. This paper addresses this issue in the context of a\ndatabase of handwritten signature images and describes a system for similarity\nretrieval. The proposed system uses a curvelet based texture features\nextraction. The performance of the system has been tested with an image\ndatabase of 180 signatures. The results obtained indicate that the proposed\nsystem is able to identify signatures with great with accuracy even when a part\nof a signature is missing.\n",
        "published": "2011-04-11T13:37:08Z",
        "pdf_link": "http://arxiv.org/pdf/1104.1945v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.2059v1",
        "title": "Template-based matching using weight maps",
        "summary": "  Template matching is one of the most prevalent pattern recognition methods\nworldwide. It has found uses in most visual concept detection fields. In this\nwork, we investigate methods for improving template matching by adjusting the\nweights of different regions of the template. We compare several weight maps\nand test the methods using the FERET face test set in the context of human eye\ndetection.\n",
        "published": "2011-04-11T20:32:54Z",
        "pdf_link": "http://arxiv.org/pdf/1104.2059v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.2069v1",
        "title": "GEOMIR2K9 - A Similar Scene Finder",
        "summary": "  The main goal of the GEOMIR2K9 project is to create a software program that\nis able to find similar scenic images clustered by geographical location and\nsorted by similarity based only on their visual content. The user should be\nable to input a query image, based on this given query image the program should\nfind relevant visual content and present this to the user in a meaningful way.\nTechnically the goal for the GEOMIR2K9 project is twofold. The first of these\ntwo goals is to create a basic low level visual information retrieval system.\nThis includes feature extraction, post processing of the feature data and\nclassification/ clustering based on similarity with a strong focus on scenic\nimages. The second goal of this project is to provide the user with a novel and\nsuitable interface and visualization method so that the user may interact with\nthe retrieved images in a natural and meaningful way.\n",
        "published": "2011-04-11T21:17:28Z",
        "pdf_link": "http://arxiv.org/pdf/1104.2069v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.2171v1",
        "title": "From a Modified Ambrosio-Tortorelli to a Randomized Part Hierarchy Tree",
        "summary": "  We demonstrate the possibility of coding parts, features that are higher\nlevel than boundaries, using a modified AT field after augmenting the\ninteraction term of the AT energy with a non-local term and weakening the\nseparation into boundary/not-boundary phases. The iteratively extracted parts\nusing the level curves with double point singularities are organized as a\nproper binary tree. Inconsistencies due to non-generic configurations for level\ncurves as well as due to visual changes such as occlusion are successfully\nhandled once the tree is endowed with a probabilistic structure. The work is a\nstep in establishing the AT function as a bridge between low and high level\nvisual processing.\n",
        "published": "2011-04-12T11:20:06Z",
        "pdf_link": "http://arxiv.org/pdf/1104.2171v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.2175v1",
        "title": "Extracting Parts of 2D Shapes Using Local and Global Interactions\n  Simultaneously",
        "summary": "  Perception research provides strong evidence in favor of part based\nrepresentation of shapes in human visual system. Despite considerable\ndifferences among different theories in terms of how part boundaries are found,\nthere is substantial agreement on that the process depends on many local and\nglobal geometric factors. This poses an important challenge from the\ncomputational point of view. In the first part of the chapter, I present a\nnovel decomposition method by taking both local and global interactions within\nthe shape domain into account. At the top of the partitioning hierarchy, the\nshape gets split into two parts capturing, respectively, the gross structure\nand the peripheral structure. The gross structure may be conceived as the least\ndeformable part of the shape which remains stable under visual transformations.\nThe peripheral structure includes limbs, protrusions, and boundary texture.\nSuch a separation is in accord with the behavior of the artists who start with\na gross shape and enrich it with details. The method is particularly\ninteresting from the computational point of view as it does not resort to any\ngeometric notions (e.g. curvature, convexity) explicitly. In the second part of\nthe chapter, I relate the new method to PDE based shape representation schemes.\n",
        "published": "2011-04-12T11:33:20Z",
        "pdf_link": "http://arxiv.org/pdf/1104.2175v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.2745v1",
        "title": "An Axis-Based Representation for Recognition",
        "summary": "  This paper presents a new axis-based shape representation scheme along with a\nmatching framework to address the problem of generic shape recognition. The\nmain idea is to define the relative spatial arrangement of local symmetry axes\nand their metric properties in a shape centered coordinate frame. The resulting\ndescriptions are invariant to scale, rotation, small changes in viewpoint and\narticulations. Symmetry points are extracted from a surface whose level curves\nroughly mimic the motion by curvature. By increasing the amount of smoothing on\nthe evolving curve, only those symmetry axes that correspond to the most\nprominent parts of a shape are extracted. The representation does not suffer\nfrom the common instability problems of the traditional connected skeletons. It\ncaptures the perceptual qualities of shapes well. Therefore finding the\nsimilarities and the differences among shapes becomes easier. The matching\nprocess gives highly successful results on a diverse database of 2D shapes.\n",
        "published": "2011-04-14T12:52:40Z",
        "pdf_link": "http://arxiv.org/pdf/1104.2745v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.2751v1",
        "title": "Disconnected Skeleton: Shape at its Absolute Scale",
        "summary": "  We present a new skeletal representation along with a matching framework to\naddress the deformable shape recognition problem. The disconnectedness arises\nas a result of excessive regularization that we use to describe a shape at an\nattainably coarse scale. Our motivation is to rely on the stable properties of\nthe shape instead of inaccurately measured secondary details. The new\nrepresentation does not suffer from the common instability problems of\ntraditional connected skeletons, and the matching process gives quite\nsuccessful results on a diverse database of 2D shapes. An important difference\nof our approach from the conventional use of the skeleton is that we replace\nthe local coordinate frame with a global Euclidean frame supported by\nadditional mechanisms to handle articulations and local boundary deformations.\nAs a result, we can produce descriptions that are sensitive to any combination\nof changes in scale, position, orientation and articulation, as well as\ninvariant ones.\n",
        "published": "2011-04-14T13:02:43Z",
        "pdf_link": "http://arxiv.org/pdf/1104.2751v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.3742v1",
        "title": "Hue Histograms to Spatiotemporal Local Features for Action Recognition",
        "summary": "  Despite the recent developments in spatiotemporal local features for action\nrecognition in video sequences, local color information has so far been\nignored. However, color has been proved an important element to the success of\nautomated recognition of objects and scenes. In this paper we extend the\nspace-time interest point descriptor STIP to take into account the color\ninformation on the features' neighborhood. We compare the performance of our\ncolor-aware version of STIP (which we have called HueSTIP) with the original\none.\n",
        "published": "2011-04-19T13:36:15Z",
        "pdf_link": "http://arxiv.org/pdf/1104.3742v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.4168v1",
        "title": "A Meshless Method for Variational Nonrigid 2-D Shape Registration",
        "summary": "  We present a method for nonrigid registration of 2-D geometric shapes. Our\ncontribution is twofold. First, we extend the classic chamfer-matching energy\nto a variational functional. Secondly, we introduce a meshless deformation\nmodel that can handle significant high-curvature deformations. We represent 2-D\nshapes implicitly using distance transforms, and registration error is defined\nbased on the shape contours' mutual distances. In addition, we model global\nshape deformation as an approximation blended from local deformation fields\nusing partition-of-unity. The global deformation field is regularized by\npenalizing inconsistencies between local fields. The representation can be made\nadaptive to shape's contour, leading to registration that is both flexible and\nefficient. Finally, registration is achieved by minimizing a variational\nchamfer-energy functional combined with the consistency regularizer. We\ndemonstrate the effectiveness of our method on a number of experiments.\n",
        "published": "2011-04-21T04:48:41Z",
        "pdf_link": "http://arxiv.org/pdf/1104.4168v1"
    },
    {
        "id": "http://arxiv.org/abs/1104.4298v2",
        "title": "Curved Gabor Filters for Fingerprint Image Enhancement",
        "summary": "  Gabor filters play an important role in many application areas for the\nenhancement of various types of images and the extraction of Gabor features.\nFor the purpose of enhancing curved structures in noisy images, we introduce\ncurved Gabor filters which locally adapt their shape to the direction of flow.\nThese curved Gabor filters enable the choice of filter parameters which\nincrease the smoothing power without creating artifacts in the enhanced image.\nIn this paper, curved Gabor filters are applied to the curved ridge and valley\nstructure of low-quality fingerprint images. First, we combine two orientation\nfield estimation methods in order to obtain a more robust estimation for very\nnoisy images. Next, curved regions are constructed by following the respective\nlocal orientation and they are used for estimating the local ridge frequency.\nLastly, curved Gabor filters are defined based on curved regions and they are\napplied for the enhancement of low-quality fingerprint images. Experimental\nresults on the FVC2004 databases show improvements of this approach in\ncomparison to state-of-the-art enhancement methods.\n",
        "published": "2011-04-21T15:52:39Z",
        "pdf_link": "http://arxiv.org/pdf/1104.4298v2"
    },
    {
        "id": "http://arxiv.org/abs/1104.4704v2",
        "title": "Positive Semidefinite Metric Learning Using Boosting-like Algorithms",
        "summary": "  The success of many machine learning and pattern recognition methods relies\nheavily upon the identification of an appropriate distance metric on the input\ndata. It is often beneficial to learn such a metric from the input training\ndata, instead of using a default one such as the Euclidean distance. In this\nwork, we propose a boosting-based technique, termed BoostMetric, for learning a\nquadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance\nmetric requires enforcing the constraint that the matrix parameter to the\nmetric remains positive definite. Semidefinite programming is often used to\nenforce this constraint, but does not scale well and easy to implement.\nBoostMetric is instead based on the observation that any positive semidefinite\nmatrix can be decomposed into a linear combination of trace-one rank-one\nmatrices. BoostMetric thus uses rank-one positive semidefinite matrices as weak\nlearners within an efficient and scalable boosting-based learning process. The\nresulting methods are easy to implement, efficient, and can accommodate various\ntypes of constraints. We extend traditional boosting algorithms in that its\nweak learner is a positive semidefinite matrix with trace and rank being one\nrather than a classifier or regressor. Experiments on various datasets\ndemonstrate that the proposed algorithms compare favorably to those\nstate-of-the-art methods in terms of classification accuracy and running time.\n",
        "published": "2011-04-25T10:38:03Z",
        "pdf_link": "http://arxiv.org/pdf/1104.4704v2"
    },
    {
        "id": "http://arxiv.org/abs/1104.4989v6",
        "title": "Preprocessing: A Step in Automating Early Detection of Cervical Cancer",
        "summary": "  This paper has been withdrawn\n",
        "published": "2011-04-26T18:38:01Z",
        "pdf_link": "http://arxiv.org/pdf/1104.4989v6"
    },
    {
        "id": "http://arxiv.org/abs/1104.5304v1",
        "title": "A supervised clustering approach for fMRI-based inference of brain\n  states",
        "summary": "  We propose a method that combines signals from many brain regions observed in\nfunctional Magnetic Resonance Imaging (fMRI) to predict the subject's behavior\nduring a scanning session. Such predictions suffer from the huge number of\nbrain regions sampled on the voxel grid of standard fMRI data sets: the curse\nof dimensionality. Dimensionality reduction is thus needed, but it is often\nperformed using a univariate feature selection procedure, that handles neither\nthe spatial structure of the images, nor the multivariate nature of the signal.\nBy introducing a hierarchical clustering of the brain volume that incorporates\nconnectivity constraints, we reduce the span of the possible spatial\nconfigurations to a single tree of nested regions tailored to the signal. We\nthen prune the tree in a supervised setting, hence the name supervised\nclustering, in order to extract a parcellation (division of the volume) such\nthat parcel-based signal averages best predict the target information.\nDimensionality reduction is thus achieved by feature agglomeration, and the\nconstructed features now provide a multi-scale representation of the signal.\nComparisons with reference methods on both simulated and real data show that\nour approach yields higher prediction accuracy than standard voxel-based\napproaches. Moreover, the method infers an explicit weighting of the regions\ninvolved in the regression or classification task.\n",
        "published": "2011-04-28T06:12:45Z",
        "pdf_link": "http://arxiv.org/pdf/1104.5304v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.0079v1",
        "title": "An Automated Size Recognition Technique for Acetabular Implant in Total\n  Hip Replacement",
        "summary": "  Preoperative templating in Total Hip Replacement (THR) is a method to\nestimate the optimal size and position of the implant. Today, observational\n(manual) size recognition techniques are still used to find a suitable implant\nfor the patient. Therefore, a digital and automated technique should be\ndeveloped so that the implant size recognition process can be effectively\nimplemented. For this purpose, we have introduced the new technique for\nacetabular implant size recognition in THR preoperative planning based on the\ndiameter of acetabulum size. This technique enables the surgeon to recognise a\ndigital acetabular implant size automatically. Ten randomly selected X-rays of\nunidentified patients were used to test the accuracy and utility of an\nautomated implant size recognition technique. Based on the testing result, the\nnew technique yielded very close results to those obtained by the observational\nmethod in nine studies (90%).\n",
        "published": "2011-04-30T12:07:11Z",
        "pdf_link": "http://arxiv.org/pdf/1105.0079v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.0821v1",
        "title": "Considerations and Results in Multimedia and DVB Application Development\n  on Philips Nexperia Platform",
        "summary": "  This paper presents some experiments regarding applications development on\nhigh performance media processors included in Philips Nexperia Family. The\nPNX1302 dedicated DVB-T kit used has some limitations. Our work has succeeded\nto overcome these limitations and to make possible a general-purpose use of\nthis kit. For exemplification two typical applications, important both for\nmultimedia and DVB, are analyzed: MPEG2 video stream decoding and MP3 audio\ndecoding. These original implementations are compared (in speed, memory\nrequirements and costs) with Philips Nexperia Library.\n",
        "published": "2011-05-04T13:40:16Z",
        "pdf_link": "http://arxiv.org/pdf/1105.0821v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.2491v2",
        "title": "A Multiple Component Matching Framework for Person Re-Identification",
        "summary": "  Person re-identification consists in recognizing an individual that has\nalready been observed over a network of cameras. It is a novel and challenging\nresearch topic in computer vision, for which no reference framework exists yet.\nDespite this, previous works share similar representations of human body based\non part decomposition and the implicit concept of multiple instances. Building\non these similarities, we propose a Multiple Component Matching (MCM) framework\nfor the person re-identification problem, which is inspired by Multiple\nComponent Learning, a framework recently proposed for object detection. We show\nthat previous techniques for person re-identification can be considered\nparticular implementations of our MCM framework. We then present a novel person\nre-identification technique as a direct, simple implementation of our\nframework, focused in particular on robustness to varying lighting conditions,\nand show that it can attain state of the art performances.\n",
        "published": "2011-05-12T14:46:01Z",
        "pdf_link": "http://arxiv.org/pdf/1105.2491v2"
    },
    {
        "id": "http://arxiv.org/abs/1105.2797v1",
        "title": "Face Recognition using 3D Facial Shape and Color Map Information:\n  Comparison and Combination",
        "summary": "  In this paper, we investigate the use of 3D surface geometry for face\nrecognition and compare it to one based on color map information. The 3D\nsurface and color map data are from the CAESAR anthropometric database. We find\nthat the recognition performance is not very different between 3D surface and\ncolor map information using a principal component analysis algorithm. We also\ndiscuss the different techniques for the combination of the 3D surface and\ncolor map information for multi-modal recognition by using different fusion\napproaches and show that there is significant improvement in results. The\neffectiveness of various techniques is compared and evaluated on a dataset with\n200 subjects in two different positions.\n",
        "published": "2011-05-13T18:25:28Z",
        "pdf_link": "http://arxiv.org/pdf/1105.2797v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.3559v4",
        "title": "Invariant Representative Cocycles of Cohomology Generators using\n  Irregular Graph Pyramids",
        "summary": "  Structural pattern recognition describes and classifies data based on the\nrelationships of features and parts. Topological invariants, like the Euler\nnumber, characterize the structure of objects of any dimension. Cohomology can\nprovide more refined algebraic invariants to a topological space than does\nhomology. It assigns `quantities' to the chains used in homology to\ncharacterize holes of any dimension. Graph pyramids can be used to describe\nsubdivisions of the same object at multiple levels of detail. This paper\npresents cohomology in the context of structural pattern recognition and\nintroduces an algorithm to efficiently compute representative cocycles (the\nbasic elements of cohomology) in 2D using a graph pyramid. An extension to\nobtain scanning and rotation invariant cocycles is given.\n",
        "published": "2011-05-18T08:18:42Z",
        "pdf_link": "http://arxiv.org/pdf/1105.3559v4"
    },
    {
        "id": "http://arxiv.org/abs/1105.3828v2",
        "title": "An Algorithmic Solution to the Five-Point Pose Problem Based on the\n  Cayley Representation of Rotations",
        "summary": "  We give a new algorithmic solution to the well-known five-point relative pose\nproblem. Our approach does not deal with the famous cubic constraint on an\nessential matrix. Instead, we use the Cayley representation of rotations in\norder to obtain a polynomial system from epipolar constraints. Solving that\nsystem, we directly get relative rotation and translation parameters of the\ncameras in terms of roots of a 10th degree polynomial.\n",
        "published": "2011-05-19T09:50:01Z",
        "pdf_link": "http://arxiv.org/pdf/1105.3828v2"
    },
    {
        "id": "http://arxiv.org/abs/1105.3834v1",
        "title": "A Multiple-Choice Test Recognition System based on the Gamera Framework",
        "summary": "  This article describes JECT-OMR, a system that analyzes digital images\nrepresenting scans of multiple-choice tests compiled by students. The system\nperforms a structural analysis of the document in order to get the chosen\nanswer for each question, and it also contains a bar-code decoder, used for the\nidentification of additional information encoded in the document. JECT-OMR was\nimplemented using the Python programming language, and leverages the power of\nthe Gamera framework in order to accomplish its task. The system exhibits an\naccuracy of over 99% in the recognition of marked and non-marked squares\nrepresenting answers, thus making it suitable for real world applications\n",
        "published": "2011-05-19T10:09:44Z",
        "pdf_link": "http://arxiv.org/pdf/1105.3834v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.4183v1",
        "title": "Cubical Cohomology Ring of 3D Photographs",
        "summary": "  Cohomology and cohomology ring of three-dimensional (3D) objects are\ntopological invariants that characterize holes and their relations. Cohomology\nring has been traditionally computed on simplicial complexes. Nevertheless,\ncubical complexes deal directly with the voxels in 3D images, no additional\ntriangulation is necessary, facilitating efficient algorithms for the\ncomputation of topological invariants in the image context. In this paper, we\npresent formulas to directly compute the cohomology ring of 3D cubical\ncomplexes without making use of any additional triangulation. Starting from a\ncubical complex $Q$ that represents a 3D binary-valued digital picture whose\nforeground has one connected component, we compute first the cohomological\ninformation on the boundary of the object, $\\partial Q$ by an incremental\ntechnique; then, using a face reduction algorithm, we compute it on the whole\nobject; finally, applying the mentioned formulas, the cohomology ring is\ncomputed from such information.\n",
        "published": "2011-05-20T22:12:41Z",
        "pdf_link": "http://arxiv.org/pdf/1105.4183v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.4354v2",
        "title": "Preprocessing for Automating Early Detection of Cervical Cancer",
        "summary": "  Uterine Cervical Cancer is one of the most common forms of cancer in women\nworldwide. Most cases of cervical cancer can be prevented through screening\nprograms aimed at detecting precancerous lesions. During Digital Colposcopy,\ncolposcopic images or cervigrams are acquired in raw form. They contain\nspecular reflections which appear as bright spots heavily saturated with white\nlight and occur due to the presence of moisture on the uneven cervix surface\nand. The cervix region occupies about half of the raw cervigram image. Other\nparts of the image contain irrelevant information, such as equipment, frames,\ntext and non-cervix tissues. This irrelevant information can confuse automatic\nidentification of the tissues within the cervix. Therefore we focus on the\ncervical borders, so that we have a geometric boundary on the relevant image\narea. Our novel technique eliminates the SR, identifies the region of interest\nand makes the cervigram ready for segmentation algorithms.\n",
        "published": "2011-05-22T17:06:59Z",
        "pdf_link": "http://arxiv.org/pdf/1105.4354v2"
    },
    {
        "id": "http://arxiv.org/abs/1105.4477v1",
        "title": "On the Cohomology of 3D Digital Images",
        "summary": "  We propose a method for computing the cohomology ring of three--dimensional\n(3D) digital binary-valued pictures. We obtain the cohomology ring of a 3D\ndigital binary--valued picture $I$, via a simplicial complex K(I)topologically\nrepresenting (up to isomorphisms of pictures) the picture I. The usefulness of\na simplicial description of the \"digital\" cohomology ring of 3D digital\nbinary-valued pictures is tested by means of a small program visualizing the\ndifferent steps of the method. Some examples concerning topological thinning,\nthe visualization of representative (co)cycles of (co)homology generators and\nthe computation of the cup product on the cohomology of simple pictures are\nshowed.\n",
        "published": "2011-05-23T12:06:18Z",
        "pdf_link": "http://arxiv.org/pdf/1105.4477v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.4480v1",
        "title": "A Tool for Integer Homology Computation: Lambda-At Model",
        "summary": "  In this paper, we formalize the notion of lambda-AT-model (where $\\lambda$ is\na non-null integer) for a given chain complex, which allows the computation of\nhomological information in the integer domain avoiding using the Smith Normal\nForm of the boundary matrices. We present an algorithm for computing such a\nmodel, obtaining Betti numbers, the prime numbers p involved in the invariant\nfactors of the torsion subgroup of homology, the amount of invariant factors\nthat are a power of p and a set of representative cycles of generators of\nhomology mod p, for each p. Moreover, we establish the minimum valid lambda for\nsuch a construction, what cuts down the computational costs related to the\ntorsion subgroup. The tools described here are useful to determine topological\ninformation of nD structured objects such as simplicial, cubical or simploidal\ncomplexes and are applicable to extract such an information from digital\npictures.\n",
        "published": "2011-05-23T12:40:06Z",
        "pdf_link": "http://arxiv.org/pdf/1105.4480v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.4712v1",
        "title": "Image Splicing Detection Using Inherent Lens Radial Distortion",
        "summary": "  Image splicing is a common form of image forgery. Such alterations may leave\nno visual clues of tampering. In recent works camera characteristics\nconsistency across the image has been used to establish the authenticity and\nintegrity of digital images. Such constant camera characteristic properties are\ninherent from camera manufacturing processes and are unique. The majority of\ndigital cameras are equipped with spherical lens and this introduces radial\ndistortions on images. This aberration is often disturbed and fails to be\nconsistent across the image, when an image is spliced. This paper describes the\ndetection of splicing operation on images by estimating radial distortion from\ndifferent portions of the image using line-based calibration. For the first\ntime, the detection of image splicing through the verification of consistency\nof lens radial distortion has been explored in this paper. The conducted\nexperiments demonstrate the efficacy of our proposed approach for the detection\nof image splicing on both synthetic and real images.\n",
        "published": "2011-05-24T09:05:04Z",
        "pdf_link": "http://arxiv.org/pdf/1105.4712v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.6014v1",
        "title": "Neural Networks for Emotion Classification",
        "summary": "  It is argued that for the computer to be able to interact with humans, it\nneeds to have the communication skills of humans. One of these skills is the\nability to understand the emotional state of the person. This thesis describes\na neural network-based approach for emotion classification. We learn a\nclassifier that can recognize six basic emotions with an average accuracy of\n77% over the Cohn-Kanade database. The novelty of this work is that instead of\nempirically selecting the parameters of the neural network, i.e. the learning\nrate, activation function parameter, momentum number, the number of nodes in\none layer, etc. we developed a strategy that can automatically select\ncomparatively better combination of these parameters. We also introduce another\nway to perform back propagation. Instead of using the partial differential of\nthe error function, we use optimal algorithm; namely Powell's direction set to\nminimize the error function. We were also interested in construction an\nauthentic emotion databases. This is a very important task because nowadays\nthere is no such database available. Finally, we perform several experiments\nand show that our neural network approach can be successfully used for emotion\nrecognition.\n",
        "published": "2011-05-30T15:19:55Z",
        "pdf_link": "http://arxiv.org/pdf/1105.6014v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.6060v1",
        "title": "Alignment of Microtubule Imagery",
        "summary": "  This work discusses preliminary work aimed at simulating and visualizing the\ngrowth process of a tiny structure inside the cell---the microtubule.\nDifficulty of recording the process lies in the fact that the tissue\npreparation method for electronic microscopes is highly destructive to live\ncells. Here in this paper, our approach is to take pictures of microtubules at\ndifferent time slots and then appropriately combine these images into a\ncoherent video. Experimental results are given on real data.\n",
        "published": "2011-05-30T18:30:51Z",
        "pdf_link": "http://arxiv.org/pdf/1105.6060v1"
    },
    {
        "id": "http://arxiv.org/abs/1105.6277v1",
        "title": "Incremental Top-k List Comparison Approach to Robust Multi-Structure\n  Model Fitting",
        "summary": "  Random hypothesis sampling lies at the core of many popular robust fitting\ntechniques such as RANSAC. In this paper, we propose a novel hypothesis\nsampling scheme based on incremental computation of distances between partial\nrankings (top-$k$ lists) derived from residual sorting information. Our method\nsimultaneously (1) guides the sampling such that hypotheses corresponding to\nall true structures can be quickly retrieved and (2) filters the hypotheses\nsuch that only a small but very promising subset remain. This permits the usage\nof simple agglomerative clustering on the surviving hypotheses for accurate\nmodel selection. The outcome is a highly efficient multi-structure robust\nestimation technique. Experiments on synthetic and real data show the superior\nperformance of our approach over previous methods.\n",
        "published": "2011-05-31T13:45:46Z",
        "pdf_link": "http://arxiv.org/pdf/1105.6277v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.0371v1",
        "title": "A Novel Image Segmentation Enhancement Technique based on Active Contour\n  and Topological Alignments",
        "summary": "  Topological alignments and snakes are used in image processing, particularly\nin locating object boundaries. Both of them have their own advantages and\nlimitations. To improve the overall image boundary detection system, we focused\non developing a novel algorithm for image processing. The algorithm we propose\nto develop will based on the active contour method in conjunction with\ntopological alignments method to enhance the image detection approach. The\nalgorithm presents novel technique to incorporate the advantages of both\nTopological Alignments and snakes. Where the initial segmentation by\nTopological Alignments is firstly transformed into the input of the snake model\nand begins its evolvement to the interested object boundary. The results show\nthat the algorithm can deal with low contrast images and shape cells,\ndemonstrate the segmentation accuracy under weak image boundaries, which\nresponsible for lacking accuracy in image detecting techniques. We have\nachieved better segmentation and boundary detecting for the image, also the\nability of the system to improve the low contrast and deal with over and under\nsegmentation.\n",
        "published": "2011-06-02T06:31:13Z",
        "pdf_link": "http://arxiv.org/pdf/1106.0371v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.0962v1",
        "title": "An efficient circle detection scheme in digital images using ant system\n  algorithm",
        "summary": "  Detection of geometric features in digital images is an important exercise in\nimage analysis and computer vision. The Hough Transform techniques for\ndetection of circles require a huge memory space for data processing hence\nrequiring a lot of time in computing the locations of the data space, writing\nto and searching through the memory space. In this paper we propose a novel and\nefficient scheme for detecting circles in edge-detected grayscale digital\nimages. We use Ant-system algorithm for this purpose which has not yet found\nmuch application in this field. The main feature of this scheme is that it can\ndetect both intersecting as well as non-intersecting circles with a time\nefficiency that makes it useful in real time applications. We build up an ant\nsystem of new type which finds out closed loops in the image and then tests\nthem for circles.\n",
        "published": "2011-06-06T05:52:09Z",
        "pdf_link": "http://arxiv.org/pdf/1106.0962v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.2357v1",
        "title": "Comparing Haar-Hilbert and Log-Gabor Based Iris Encoders on Bath Iris\n  Image Database",
        "summary": "  This papers introduces a new family of iris encoders which use 2-dimensional\nHaar Wavelet Transform for noise attenuation, and Hilbert Transform to encode\nthe iris texture. In order to prove the usefulness of the newly proposed iris\nencoding approach, the recognition results obtained by using these new encoders\nare compared to those obtained using the classical Log- Gabor iris encoder.\nTwelve tests involving single/multienrollment and conducted on Bath Iris Image\nDatabase are presented here. One of these tests achieves an Equal Error Rate\ncomparable to the lowest value reported so far for this database. New Matlab\ntools for iris image processing are also released together with this paper: a\nsecond version of the Circular Fuzzy Iris Segmentator (CFIS2), a fast Log-Gabor\nencoder and two Haar-Hilbert based encoders.\n",
        "published": "2011-06-12T23:14:05Z",
        "pdf_link": "http://arxiv.org/pdf/1106.2357v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.2695v1",
        "title": "Robust Mobile Object Tracking Based on Multiple Feature Similarity and\n  Trajectory Filtering",
        "summary": "  This paper presents a new algorithm to track mobile objects in different\nscene conditions. The main idea of the proposed tracker includes estimation,\nmulti-features similarity measures and trajectory filtering. A feature set\n(distance, area, shape ratio, color histogram) is defined for each tracked\nobject to search for the best matching object. Its best matching object and its\nstate estimated by the Kalman filter are combined to update position and size\nof the tracked object. However, the mobile object trajectories are usually\nfragmented because of occlusions and misdetections. Therefore, we also propose\na trajectory filtering, named global tracker, aims at removing the noisy\ntrajectories and fusing the fragmented trajectories belonging to a same mobile\nobject. The method has been tested with five videos of different scene\nconditions. Three of them are provided by the ETISEO benchmarking project\n(http://www-sop.inria.fr/orion/ETISEO) in which the proposed tracker\nperformance has been compared with other seven tracking algorithms. The\nadvantages of our approach over the existing state of the art ones are: (i) no\nprior knowledge information is required (e.g. no calibration and no contextual\nmodels are needed), (ii) the tracker is more reliable by combining multiple\nfeature similarities, (iii) the tracker can perform in different scene\nconditions: single/several mobile objects, weak/strong illumination,\nindoor/outdoor scenes, (iv) a trajectory filtering is defined and applied to\nimprove the tracker performance, (v) the tracker performance outperforms many\nalgorithms of the state of the art.\n",
        "published": "2011-06-14T12:45:05Z",
        "pdf_link": "http://arxiv.org/pdf/1106.2695v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.3464v1",
        "title": "Polar Fusion Technique Analysis for Evaluating the Performances of Image\n  Fusion of Thermal and Visual Images for Human Face Recognition",
        "summary": "  This paper presents a comparative study of two different methods, which are\nbased on fusion and polar transformation of visual and thermal images. Here,\ninvestigation is done to handle the challenges of face recognition, which\ninclude pose variations, changes in facial expression, partial occlusions,\nvariations in illumination, rotation through different angles, change in scale\netc. To overcome these obstacles we have implemented and thoroughly examined\ntwo different fusion techniques through rigorous experimentation. In the first\nmethod log-polar transformation is applied to the fused images obtained after\nfusion of visual and thermal images whereas in second method fusion is applied\non log-polar transformed individual visual and thermal images. After this step,\nwhich is thus obtained in one form or another, Principal Component Analysis\n(PCA) is applied to reduce dimension of the fused images. Log-polar transformed\nimages are capable of handling complicacies introduced by scaling and rotation.\nThe main objective of employing fusion is to produce a fused image that\nprovides more detailed and reliable information, which is capable to overcome\nthe drawbacks present in the individual visual and thermal face images.\nFinally, those reduced fused images are classified using a multilayer\nperceptron neural network. The database used for the experiments conducted here\nis Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database\nbenchmark thermal and visual face images. The second method has shown better\nperformance, which is 95.71% (maximum) and on an average 93.81% as correct\nrecognition rate.\n",
        "published": "2011-06-17T12:25:30Z",
        "pdf_link": "http://arxiv.org/pdf/1106.3464v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.3466v1",
        "title": "Next Level of Data Fusion for Human Face Recognition",
        "summary": "  This paper demonstrates two different fusion techniques at two different\nlevels of a human face recognition process. The first one is called data fusion\nat lower level and the second one is the decision fusion towards the end of the\nrecognition process. At first a data fusion is applied on visual and\ncorresponding thermal images to generate fused image. Data fusion is\nimplemented in the wavelet domain after decomposing the images through\nDaubechies wavelet coefficients (db2). During the data fusion maximum of\napproximate and other three details coefficients are merged together. After\nthat Principle Component Analysis (PCA) is applied over the fused coefficients\nand finally two different artificial neural networks namely Multilayer\nPerceptron(MLP) and Radial Basis Function(RBF) networks have been used\nseparately to classify the images. After that, for decision fusion based\ndecisions from both the classifiers are combined together using Bayesian\nformulation. For experiments, IRIS thermal/visible Face Database has been used.\nExperimental results show that the performance of multiple classifier system\nalong with decision fusion works well over the single classifier system.\n",
        "published": "2011-06-17T12:31:30Z",
        "pdf_link": "http://arxiv.org/pdf/1106.3466v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.3467v1",
        "title": "High Performance Human Face Recognition using Independent High Intensity\n  Gabor Wavelet Responses: A Statistical Approach",
        "summary": "  In this paper, we present a technique by which high-intensity feature vectors\nextracted from the Gabor wavelet transformation of frontal face images, is\ncombined together with Independent Component Analysis (ICA) for enhanced face\nrecognition. Firstly, the high-intensity feature vectors are automatically\nextracted using the local characteristics of each individual face from the\nGabor transformed images. Then ICA is applied on these locally extracted\nhigh-intensity feature vectors of the facial images to obtain the independent\nhigh intensity feature (IHIF) vectors. These IHIF forms the basis of the work.\nFinally, the image classification is done using these IHIF vectors, which are\nconsidered as representatives of the images. The importance behind implementing\nICA along with the high-intensity features of Gabor wavelet transformation is\ntwofold. On the one hand, selecting peaks of the Gabor transformed face images\nexhibit strong characteristics of spatial locality, scale, and orientation\nselectivity. Thus these images produce salient local features that are most\nsuitable for face recognition. On the other hand, as the ICA employs locally\nsalient features from the high informative facial parts, it reduces redundancy\nand represents independent features explicitly. These independent features are\nmost useful for subsequent facial discrimination and associative recall. The\nefficiency of IHIF method is demonstrated by the experiment on frontal facial\nimages dataset, selected from the FERET, FRAV2D, and the ORL database.\n",
        "published": "2011-06-17T12:42:26Z",
        "pdf_link": "http://arxiv.org/pdf/1106.3467v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.3517v1",
        "title": "DWT Based Fingerprint Recognition using Non Minutiae Features",
        "summary": "  Forensic applications like criminal investigations, terrorist identification\nand National security issues require a strong fingerprint data base and\nefficient identification system. In this paper we propose DWT based Fingerprint\nRecognition using Non Minutiae (DWTFR) algorithm. Fingerprint image is\ndecomposed into multi resolution sub bands of LL, LH, HL and HH by applying 3\nlevel DWT. The Dominant local orientation angle {\\theta} and Coherence are\ncomputed on LL band only. The Centre Area Features and Edge Parameters are\ndetermined on each DWT level by considering all four sub bands. The comparison\nof test fingerprint with database fingerprint is decided based on the Euclidean\nDistance of all the features. It is observed that the values of FAR, FRR and\nTSR are improved compared to the existing algorithm.\n",
        "published": "2011-06-17T15:52:56Z",
        "pdf_link": "http://arxiv.org/pdf/1106.3517v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.4907v1",
        "title": "Face Identification from Manipulated Facial Images using SIFT",
        "summary": "  Editing on digital images is ubiquitous. Identification of deliberately\nmodified facial images is a new challenge for face identification system. In\nthis paper, we address the problem of identification of a face or person from\nheavily altered facial images. In this face identification problem, the input\nto the system is a manipulated or transformed face image and the system reports\nback the determined identity from a database of known individuals. Such a\nsystem can be useful in mugshot identification in which mugshot database\ncontains two views (frontal and profile) of each criminal. We considered only\nfrontal view from the available database for face identification and the query\nimage is a manipulated face generated by face transformation software tool\navailable online. We propose SIFT features for efficient face identification in\nthis scenario. Further comparative analysis has been given with well known\neigenface approach. Experiments have been conducted with real case images to\nevaluate the performance of both methods.\n",
        "published": "2011-06-24T08:30:15Z",
        "pdf_link": "http://arxiv.org/pdf/1106.4907v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.5156v2",
        "title": "Morphological Reconstruction for Word Level Script Identification",
        "summary": "  A line of a bilingual document page may contain text words in regional\nlanguage and numerals in English. For Optical Character Recognition (OCR) of\nsuch a document page, it is necessary to identify different script forms before\nrunning an individual OCR system. In this paper, we have identified a tool of\nmorphological opening by reconstruction of an image in different directions and\nregional descriptors for script identification at word level, based on the\nobservation that every text has a distinct visual appearance. The proposed\nsystem is developed for three Indian major bilingual documents, Kannada, Telugu\nand Devnagari containing English numerals. The nearest neighbour and k-nearest\nneighbour algorithms are applied to classify new word images. The proposed\nalgorithm is tested on 2625 words with various font styles and sizes. The\nresults obtained are quite encouraging\n",
        "published": "2011-06-25T18:16:59Z",
        "pdf_link": "http://arxiv.org/pdf/1106.5156v2"
    },
    {
        "id": "http://arxiv.org/abs/1106.5186v1",
        "title": "Learning Shape and Texture Characteristics of CT Tree-in-Bud Opacities\n  for CAD Systems",
        "summary": "  Although radiologists can employ CAD systems to characterize malignancies,\npulmonary fibrosis and other chronic diseases; the design of imaging techniques\nto quantify infectious diseases continue to lag behind. There exists a need to\ncreate more CAD systems capable of detecting and quantifying characteristic\npatterns often seen in respiratory tract infections such as influenza,\nbacterial pneumonia, or tuborculosis. One of such patterns is Tree-in-bud (TIB)\nwhich presents \\textit{thickened} bronchial structures surrounding by clusters\nof \\textit{micro-nodules}. Automatic detection of TIB patterns is a challenging\ntask because of their weak boundary, noisy appearance, and small lesion size.\nIn this paper, we present two novel methods for automatically detecting TIB\npatterns: (1) a fast localization of candidate patterns using information from\nlocal scale of the images, and (2) a M\\\"{o}bius invariant feature extraction\nmethod based on learned local shape and texture properties. A comparative\nevaluation of the proposed methods is presented with a dataset of 39 laboratory\nconfirmed viral bronchiolitis human parainfluenza (HPIV) CTs and 21 normal lung\nCTs. Experimental results demonstrate that the proposed CAD system can achieve\nhigh detection rate with an overall accuracy of 90.96%.\n",
        "published": "2011-06-26T03:35:08Z",
        "pdf_link": "http://arxiv.org/pdf/1106.5186v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.5460v1",
        "title": "Automated segmentation of the pulmonary arteries in low-dose CT by\n  vessel tracking",
        "summary": "  We present a fully automated method for top-down segmentation of the\npulmonary arterial tree in low-dose thoracic CT images. The main basal\npulmonary arteries are identified near the lung hilum by searching for\ncandidate vessels adjacent to known airways, identified by our previously\nreported airway segmentation method. Model cylinders are iteratively fit to the\nvessels to track them into the lungs. Vessel bifurcations are detected by\nmeasuring the rate of change of vessel radii, and child vessels are segmented\nby initiating new trackers at bifurcation points. Validation is accomplished\nusing our novel sparse surface (SS) evaluation metric. The SS metric was\ndesigned to quantify the magnitude of the segmentation error per vessel while\nsignificantly decreasing the manual marking burden for the human user. A total\nof 210 arteries and 205 veins were manually marked across seven test cases.\n134/210 arteries were correctly segmented, with a specificity for arteries of\n90%, and average segmentation error of 0.15 mm. This fully-automated\nsegmentation is a promising method for improving lung nodule detection in\nlow-dose CT screening scans, by separating vessels from surrounding\niso-intensity objects.\n",
        "published": "2011-06-27T17:47:23Z",
        "pdf_link": "http://arxiv.org/pdf/1106.5460v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.5569v1",
        "title": "Augmented Reality Implementation Methods in Mainstream Applications",
        "summary": "  Augmented reality has became an useful tool in many areas from space\nexploration to military applications. Although used theoretical principles are\nwell known for almost a decade, the augmented reality is almost exclusively\nused in high budget solutions with a special hardware. However, in last few\nyears we could see rising popularity of many projects focused on deployment of\nthe augmented reality on different mobile devices. Our article is aimed on\ndevelopers who consider development of an augmented reality application for the\nmainstream market. Such developers will be forced to keep the application\nprice, therefore also the development price, at reasonable level. Usage of\nexisting image processing software library could bring a significant cut-down\nof the development costs. In the theoretical part of the article is presented\nan overview of the augmented reality application structure. Further, an\napproach for selection appropriate library as well as the review of the\nexisting software libraries focused in this area is described. The last part of\nthe article outlines our implementation of key parts of the augmented reality\napplication using the OpenCV library.\n",
        "published": "2011-06-28T05:57:37Z",
        "pdf_link": "http://arxiv.org/pdf/1106.5569v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.5571v1",
        "title": "Mobile Augmented Reality Applications",
        "summary": "  Augmented reality have undergone considerable improvement in past years. Many\nspecial techniques and hardware devices were developed, but the crucial\nbreakthrough came with the spread of intelligent mobile phones. This enabled\nmass spread of augmented reality applications. However mobile devices have\nlimited hardware capabilities, which narrows down the methods usable for scene\nanalysis. In this article we propose an augmented reality application which is\nusing cloud computing to enable using of more complex computational methods\nsuch as neural networks. Our goal is to create an affordable augmented reality\napplication suitable which will help car designers in by 'virtualizing' car\nmodifications.\n",
        "published": "2011-06-28T06:08:38Z",
        "pdf_link": "http://arxiv.org/pdf/1106.5571v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.5737v1",
        "title": "Fingerprint: DWT, SVD Based Enhancement and Significant Contrast for\n  Ridges and Valleys Using Fuzzy Measures",
        "summary": "  The performance of the Fingerprint recognition system will be more accurate\nwith respect of enhancement for the fingerprint images. In this paper we\ndevelop a novel method for Fingerprint image contrast enhancement technique\nbased on the discrete wavelet transform (DWT) and singular value decomposition\n(SVD) has been proposed. This technique is compared with conventional image\nequalization techniques such as standard general histogram equalization and\nlocal histogram equalization. An automatic histogram threshold approach based\non a fuzziness measure is presented. Then, using an index of fuzziness, a\nsimilarity process is started to find the threshold point. A significant\ncontrast between ridges and valleys of the best, medium and poor finger image\nfeatures to extract from finger images and get maximum recognition rate using\nfuzzy measures. The experimental results show the recognition of superiority of\nthe proposed method to get maximum performance up gradation to the\nimplementation of this approach.\n",
        "published": "2011-06-23T16:25:22Z",
        "pdf_link": "http://arxiv.org/pdf/1106.5737v1"
    },
    {
        "id": "http://arxiv.org/abs/1106.5928v1",
        "title": "Image denoising assessment using anisotropic stack filtering",
        "summary": "  In this paper we propose a measure of anisotropy as a quality parameter to\nestimate the amount of noise in noisy images. The anisotropy of an image can be\ndetermined through a directional measure, using an appropriate statistical\ndistribution of the information contained in the image. This new measure is\nachieved through a stack filtering paradigm. First, we define a local\ndirectional entropy, based on the distribution of 0's and 1's in the\nneigborhood of every pixel location of each stack level. Then the entropy\nvariation of this directional entropy is used to define an anisotropic measure.\nThe empirical results have shown that this measure can be regarded as an\nexcellent image noise indicator, which is particularly relevant for quality\nassessment of denoising algorithms. The method has been evaluated with\nartificial and real-world degraded images.\n",
        "published": "2011-06-29T13:12:56Z",
        "pdf_link": "http://arxiv.org/pdf/1106.5928v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.0845v4",
        "title": "Automatic Road Lighting System (ARLS) Model Based on Image Processing of\n  Moving Object",
        "summary": "  Using a vehicle toy (in next future called vehicle) as a moving object an\nautomatic road lighting system (ARLS) model is constructed. A digital video\ncamera with 25 fps is used to capture the vehicle motion as it moves in the\ntest segment of the road. Captured images are then processed to calculate\nvehicle speed. This information of the speed together with position of vehicle\nis then used to control the lighting system along the path that passes by the\nvehicle. Length of the road test segment is 1 m, the video camera is positioned\nabout 1.1 m above the test segment, and the vehicle toy dimension is 13 cm\n\\times 9.3 cm. In this model, the maximum speed that ARLS can handle is about\n1.32 m/s, and the highest performance is obtained about 91% at speed 0.93 m/s.\n",
        "published": "2011-07-05T11:06:04Z",
        "pdf_link": "http://arxiv.org/pdf/1107.0845v4"
    },
    {
        "id": "http://arxiv.org/abs/1107.1058v1",
        "title": "Online Vehicle Detection For Estimating Traffic Status",
        "summary": "  We propose a traffic congestion estimation system based on unsupervised\non-line learning algorithm. The system does not rely on background extraction\nor motion detection. It extracts local features inside detection regions of\nvariable size which are drawn on lanes in advance. The extracted features are\nthen clustered into two classes using K-means and Gaussian Mixture Models(GMM).\nA Bayes classifier is used to detect vehicles according to the previous cluster\ninformation which keeps updated whenever system is running by on-line EM\nalgorithm. Experimental result shows that our system can be adapted to various\ntraffic scenes for estimating traffic status.\n",
        "published": "2011-07-06T08:43:38Z",
        "pdf_link": "http://arxiv.org/pdf/1107.1058v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.1081v1",
        "title": "Spatial Features for Multi-Font/Multi-Size Kannada Numerals and Vowels\n  Recognition",
        "summary": "  This paper presents multi-font/multi-size Kannada numerals and vowels\nrecognition based on spatial features. Directional spatial features viz stroke\ndensity, stroke length and the number of stokes in an image are employed as\npotential features to characterize the printed Kannada numerals and vowels.\nBased on these features 1100 numerals and 1400 vowels are classified with\nMulti-class Support Vector Machines (SVM). The proposed system achieves the\nrecognition accuracy as 98.45% and 90.64% for numerals and vowels respectively.\n",
        "published": "2011-07-06T10:02:42Z",
        "pdf_link": "http://arxiv.org/pdf/1107.1081v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.1561v1",
        "title": "Analysis and Improvement of Low Rank Representation for Subspace\n  segmentation",
        "summary": "  We analyze and improve low rank representation (LRR), the state-of-the-art\nalgorithm for subspace segmentation of data. We prove that for the noiseless\ncase, the optimization model of LRR has a unique solution, which is the shape\ninteraction matrix (SIM) of the data matrix. So in essence LRR is equivalent to\nfactorization methods. We also prove that the minimum value of the optimization\nmodel of LRR is equal to the rank of the data matrix. For the noisy case, we\nshow that LRR can be approximated as a factorization method that combines noise\nremoval by column sparse robust PCA. We further propose an improved version of\nLRR, called Robust Shape Interaction (RSI), which uses the corrected data as\nthe dictionary instead of the noisy data. RSI is more robust than LRR when the\ncorruption in data is heavy. Experiments on both synthetic and real data\ntestify to the improved robustness of RSI.\n",
        "published": "2011-07-08T05:44:57Z",
        "pdf_link": "http://arxiv.org/pdf/1107.1561v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.2085v1",
        "title": "Kunchenko's Polynomials for Template Matching",
        "summary": "  This paper reviews Kunchenko's polynomials using as template matching method\nto recognize template in one-dimensional input signal. Kunchenko's polynomials\nmethod is compared with classical methods - cross-correlation and sum of\nsquared differences according to numerical statistical example.\n",
        "published": "2011-07-11T18:44:17Z",
        "pdf_link": "http://arxiv.org/pdf/1107.2085v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.2336v1",
        "title": "A Variation of the Box-Counting Algorithm Applied to Colour Images",
        "summary": "  The box counting method for fractal dimension estimation had not been applied\nto large or colour images thus far due to the processing time required. In this\nletter we present a fast, easy to implement and very easily expandable to any\nnumber of dimensions variation, the box merging method. It is applied here in\nRGB images which are considered as sets in 5-D space.\n",
        "published": "2011-07-12T16:21:06Z",
        "pdf_link": "http://arxiv.org/pdf/1107.2336v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.2553v1",
        "title": "Learning Hypergraph Labeling for Feature Matching",
        "summary": "  This study poses the feature correspondence problem as a hypergraph node\nlabeling problem. Candidate feature matches and their subsets (usually of size\nlarger than two) are considered to be the nodes and hyperedges of a hypergraph.\nA hypergraph labeling algorithm, which models the subset-wise interaction by an\nundirected graphical model, is applied to label the nodes (feature\ncorrespondences) as correct or incorrect. We describe a method to learn the\ncost function of this labeling algorithm from labeled examples using a\ngraphical model training algorithm. The proposed feature matching algorithm is\ndifferent from the most of the existing learning point matching methods in\nterms of the form of the objective function, the cost function to be learned\nand the optimization method applied to minimize it. The results on standard\ndatasets demonstrate how learning over a hypergraph improves the matching\nperformance over existing algorithms, notably one that also uses higher order\ninformation without learning.\n",
        "published": "2011-07-13T14:01:50Z",
        "pdf_link": "http://arxiv.org/pdf/1107.2553v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.2693v1",
        "title": "A Fuzzy View on k-Means Based Signal Quantization with Application in\n  Iris Segmentation",
        "summary": "  This paper shows that the k-means quantization of a signal can be interpreted\nboth as a crisp indicator function and as a fuzzy membership assignment\ndescribing fuzzy clusters and fuzzy boundaries. Combined crisp and fuzzy\nindicator functions are defined here as natural generalizations of the ordinary\ncrisp and fuzzy indicator functions, respectively. An application to iris\nsegmentation is presented together with a demo program.\n",
        "published": "2011-07-13T22:46:58Z",
        "pdf_link": "http://arxiv.org/pdf/1107.2693v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.2696v1",
        "title": "Exploring New Directions in Iris Recognition",
        "summary": "  A new approach in iris recognition based on Circular Fuzzy Iris Segmentation\n(CFIS) and Gabor Analytic Iris Texture Binary Encoder (GAITBE) is proposed and\ntested here. CFIS procedure is designed to guarantee that similar iris segments\nwill be obtained for similar eye images, despite the fact that the degree of\nocclusion may vary from one image to another. Its result is a circular iris\nring (concentric with the pupil) which approximates the actual iris. GAITBE\nproves better encoding of statistical independence between the iris codes\nextracted from different irides using Hilbert Transform. Irides from University\nof Bath Iris Database are binary encoded on two different lengths (768 / 192\nbytes) and tested in both single-enrollment and multi-enrollment identification\nscenarios. All cases illustrate the capacity of the newly proposed methodology\nto narrow down the distribution of inter-class matching scores, and\nconsequently, to guarantee a steeper descent of the False Accept Rate.\n",
        "published": "2011-07-13T23:18:57Z",
        "pdf_link": "http://arxiv.org/pdf/1107.2696v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.2723v1",
        "title": "Topographic Feature Extraction for Bengali and Hindi Character Images",
        "summary": "  Feature selection and extraction plays an important role in different\nclassification based problems such as face recognition, signature verification,\noptical character recognition (OCR) etc. The performance of OCR highly depends\non the proper selection and extraction of feature set. In this paper, we\npresent novel features based on the topography of a character as visible from\ndifferent viewing directions on a 2D plane. By topography of a character we\nmean the structural features of the strokes and their spatial relations. In\nthis work we develop topographic features of strokes visible with respect to\nviews from different directions (e.g. North, South, East, and West). We\nconsider three types of topographic features: closed region, convexity of\nstrokes, and straight line strokes. These features are represented as a\nshape-based graph which acts as an invariant feature set for discriminating\nvery similar type characters efficiently. We have tested the proposed method on\nprinted and handwritten Bengali and Hindi character images. Initial results\ndemonstrate the efficacy of our approach.\n",
        "published": "2011-07-14T04:05:23Z",
        "pdf_link": "http://arxiv.org/pdf/1107.2723v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.2781v1",
        "title": "Face Recognition using Curvelet Transform",
        "summary": "  Face recognition has been studied extensively for more than 20 years now.\nSince the beginning of 90s the subject has became a major issue. This\ntechnology is used in many important real-world applications, such as video\nsurveillance, smart cards, database security, internet and intranet access.\nThis report reviews recent two algorithms for face recognition which take\nadvantage of a relatively new multiscale geometric analysis tool - Curvelet\ntransform, for facial processing and feature extraction. This transform proves\nto be efficient especially due to its good ability to detect curves and lines,\nwhich characterize the human's face. An algorithm which is based on the two\nalgorithms mentioned above is proposed, and its performance is evaluated on\nthree data bases of faces: AT&T (ORL), Essex Grimace and Georgia-Tech.\nk-nearest neighbour (k-NN) and Support vector machine (SVM) classifiers are\nused, along with Principal Component Analysis (PCA) for dimensionality\nreduction. This algorithm shows good results, and it even outperforms other\nalgorithms in some cases.\n",
        "published": "2011-07-14T10:44:01Z",
        "pdf_link": "http://arxiv.org/pdf/1107.2781v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.3194v1",
        "title": "Fingerprint recognition using standardized fingerprint model",
        "summary": "  Fingerprint recognition is one of most popular and accuracy Biometric\ntechnologies. Nowadays, it is used in many real applications. However,\nrecognizing fingerprints in poor quality images is still a very complex\nproblem. In recent years, many algorithms, models...are given to improve the\naccuracy of recognition system. This paper discusses on the standardized\nfingerprint model which is used to synthesize the template of fingerprints. In\nthis model, after pre-processing step, we find the transformation between\ntemplates, adjust parameters, synthesize fingerprint, and reduce noises. Then,\nwe use the final fingerprint to match with others in FVC2004 fingerprint\ndatabase (DB4) to show the capability of the model.\n",
        "published": "2011-07-16T03:04:22Z",
        "pdf_link": "http://arxiv.org/pdf/1107.3194v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.3195v1",
        "title": "Facial Expression Classification Based on Multi Artificial Neural\n  Network and Two Dimensional Principal Component Analysis",
        "summary": "  Facial expression classification is a kind of image classification and it has\nreceived much attention, in recent years. There are many approaches to solve\nthese problems with aiming to increase efficient classification. One of famous\nsuggestions is described as first step, project image to different spaces;\nsecond step, in each of these spaces, images are classified into responsive\nclass and the last step, combine the above classified results into the final\nresult. The advantages of this approach are to reflect fulfill and multiform of\nimage classified. In this paper, we use 2D-PCA and its variants to project the\npattern or image into different spaces with different grouping strategies. Then\nwe develop a model which combines many Neural Networks applied for the last\nstep. This model evaluates the reliability of each space and gives the final\nclassification conclusion. Our model links many Neural Networks together, so we\ncall it Multi Artificial Neural Network (MANN). We apply our proposal model for\n6 basic facial expressions on JAFFE database consisting 213 images posed by 10\nJapanese female models.\n",
        "published": "2011-07-16T03:15:40Z",
        "pdf_link": "http://arxiv.org/pdf/1107.3195v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.3348v2",
        "title": "Arithmetic and Frequency Filtering Methods of Pixel-Based Image Fusion\n  Techniques",
        "summary": "  In remote sensing, image fusion technique is a useful tool used to fuse high\nspatial resolution panchromatic images (PAN) with lower spatial resolution\nmultispectral images (MS) to create a high spatial resolution multispectral of\nimage fusion (F) while preserving the spectral information in the multispectral\nimage (MS).There are many PAN sharpening techniques or Pixel-Based image fusion\ntechniques that have been developed to try to enhance the spatial resolution\nand the spectral property preservation of the MS. This paper attempts to\nundertake the study of image fusion, by using two types of pixel-based image\nfusion techniques i.e. Arithmetic Combination and Frequency Filtering Methods\nof Pixel-Based Image Fusion Techniques. The first type includes Brovey\nTransform (BT), Color Normalized Transformation (CN) and Multiplicative Method\n(MLT). The second type include High-Pass Filter Additive Method (HPFA),\nHigh-Frequency-Addition Method (HFA) High Frequency Modulation Method (HFM) and\nThe Wavelet transform-based fusion method (WT). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including Standard Deviation (SD),\nEntropy(En), Correlation Coefficient (CC), Signal-to Noise Ratio (SNR),\nNormalization Root Mean Square Error (NRMSE) and Deviation Index (DI) to\nestimate the quality and degree of information improvement of a fused image\nquantitatively.\n",
        "published": "2011-07-18T01:41:37Z",
        "pdf_link": "http://arxiv.org/pdf/1107.3348v2"
    },
    {
        "id": "http://arxiv.org/abs/1107.4396v2",
        "title": "The IHS Transformations Based Image Fusion",
        "summary": "  The IHS sharpening technique is one of the most commonly used techniques for\nsharpening. Different transformations have been developed to transfer a color\nimage from the RGB space to the IHS space. Through literature, it appears that,\nvarious scientists proposed alternative IHS transformations and many papers\nhave reported good results whereas others show bad ones as will as not those\nobtained which the formula of IHS transformation were used. In addition to\nthat, many papers show different formulas of transformation matrix such as IHS\ntransformation. This leads to confusion what is the exact formula of the IHS\ntransformation?. Therefore, the main purpose of this work is to explore\ndifferent IHS transformation techniques and experiment it as IHS based image\nfusion. The image fusion performance was evaluated, in this study, using\nvarious methods to estimate the quality and degree of information improvement\nof a fused image quantitatively.\n",
        "published": "2011-07-19T06:18:56Z",
        "pdf_link": "http://arxiv.org/pdf/1107.4396v2"
    },
    {
        "id": "http://arxiv.org/abs/1107.4667v2",
        "title": "Correlation Estimation from Compressed Images",
        "summary": "  This paper addresses the problem of correlation estimation in sets of\ncompressed images. We consider a framework where images are represented under\nthe form of linear measurements due to low complexity sensing or security\nrequirements. We assume that the images are correlated through the displacement\nof visual objects due to motion or viewpoint change and the correlation is\neffectively represented by optical flow or motion field models. The correlation\nis estimated in the compressed domain by jointly processing the linear\nmeasurements. We first show that the correlated images can be efficiently\nrelated using a linear operator. Using this linear relationship we then\ndescribe the dependencies between images in the compressed domain. We further\ncast a regularized optimization problem where the correlation is estimated in\norder to satisfy both data consistency and motion smoothness objectives with a\nGraph Cut algorithm. We analyze in detail the correlation estimation\nperformance and quantify the penalty due to image compression. Extensive\nexperiments in stereo and video imaging applications show that our novel\nsolution stays competitive with methods that implement complex image\nreconstruction steps prior to correlation estimation. We finally use the\nestimated correlation in a novel joint image reconstruction scheme that is\nbased on an optimization problem with sparsity priors on the reconstructed\nimages. Additional experiments show that our correlation estimation algorithm\nleads to an effective reconstruction of pairs of images in distributed image\ncoding schemes that outperform independent reconstruction algorithms by 2 to 4\ndB.\n",
        "published": "2011-07-23T08:51:17Z",
        "pdf_link": "http://arxiv.org/pdf/1107.4667v2"
    },
    {
        "id": "http://arxiv.org/abs/1107.4763v1",
        "title": "Diffeomorphic Metric Mapping of High Angular Resolution Diffusion\n  Imaging based on Riemannian Structure of Orientation Distribution Functions",
        "summary": "  In this paper, we propose a novel large deformation diffeomorphic\nregistration algorithm to align high angular resolution diffusion images\n(HARDI) characterized by orientation distribution functions (ODFs). Our\nproposed algorithm seeks an optimal diffeomorphism of large deformation between\ntwo ODF fields in a spatial volume domain and at the same time, locally\nreorients an ODF in a manner such that it remains consistent with the\nsurrounding anatomical structure. To this end, we first review the Riemannian\nmanifold of ODFs. We then define the reorientation of an ODF when an affine\ntransformation is applied and subsequently, define the diffeomorphic group\naction to be applied on the ODF based on this reorientation. We incorporate the\nRiemannian metric of ODFs for quantifying the similarity of two HARDI images\ninto a variational problem defined under the large deformation diffeomorphic\nmetric mapping (LDDMM) framework. We finally derive the gradient of the cost\nfunction in both Riemannian spaces of diffeomorphisms and the ODFs, and present\nits numerical implementation. Both synthetic and real brain HARDI data are used\nto illustrate the performance of our registration algorithm.\n",
        "published": "2011-07-24T15:34:27Z",
        "pdf_link": "http://arxiv.org/pdf/1107.4763v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.4958v1",
        "title": "Efficient and Accurate Gaussian Image Filtering Using Running Sums",
        "summary": "  This paper presents a simple and efficient method to convolve an image with a\nGaussian kernel. The computation is performed in a constant number of\noperations per pixel using running sums along the image rows and columns. We\ninvestigate the error function used for kernel approximation and its relation\nto the properties of the input signal. Based on natural image statistics we\npropose a quadratic form kernel error function so that the output image l2\nerror is minimized. We apply the proposed approach to approximate the Gaussian\nkernel by linear combination of constant functions. This results in very\nefficient Gaussian filtering method. Our experiments show that the proposed\ntechnique is faster than state of the art methods while preserving a similar\naccuracy.\n",
        "published": "2011-07-25T14:20:34Z",
        "pdf_link": "http://arxiv.org/pdf/1107.4958v1"
    },
    {
        "id": "http://arxiv.org/abs/1107.5850v2",
        "title": "Confidence-Based Dynamic Classifier Combination For Mean-Shift Tracking",
        "summary": "  We introduce a novel tracking technique which uses dynamic confidence-based\nfusion of two different information sources for robust and efficient tracking\nof visual objects. Mean-shift tracking is a popular and well known method used\nin object tracking problems. Originally, the algorithm uses a similarity\nmeasure which is optimized by shifting a search area to the center of a\ngenerated weight image to track objects. Recent improvements on the original\nmean-shift algorithm involves using a classifier that differentiates the object\nfrom its surroundings. We adopt this classifier-based approach and propose an\napplication of a classifier fusion technique within this classifier-based\ncontext in this work. We use two different classifiers, where one comes from a\nbackground modeling method, to generate the weight image and we calculate\ncontributions of the classifiers dynamically using their confidences to\ngenerate a final weight image to be used in tracking. The contributions of the\nclassifiers are calculated by using correlations between histograms of their\nweight images and histogram of a defined ideal weight image in the previous\nframe. We show with experiments that our dynamic combination scheme selects\ngood contributions for classifiers for different cases and improves tracking\naccuracy significantly.\n",
        "published": "2011-07-29T01:08:52Z",
        "pdf_link": "http://arxiv.org/pdf/1107.5850v2"
    },
    {
        "id": "http://arxiv.org/abs/1108.1122v1",
        "title": "Leveraging Billions of Faces to Overcome Performance Barriers in\n  Unconstrained Face Recognition",
        "summary": "  We employ the face recognition technology developed in house at face.com to a\nwell accepted benchmark and show that without any tuning we are able to\nconsiderably surpass state of the art results. Much of the improvement is\nconcentrated in the high-valued performance point of zero false positive\nmatches, where the obtained recall rate almost doubles the best reported result\nto date. We discuss the various components and innovations of our system that\nenable this significant performance gap. These components include extensive\nutilization of an accurate 3D reconstructed shape model dealing with challenges\narising from pose and illumination. In addition, discriminative models based on\nbillions of faces are used in order to overcome aging and facial expression as\nwell as low light and overexposure. Finally, we identify a challenging set of\nidentification queries that might provide useful focus for future research.\n",
        "published": "2011-08-04T15:51:19Z",
        "pdf_link": "http://arxiv.org/pdf/1108.1122v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.1169v1",
        "title": "Learning Representations by Maximizing Compression",
        "summary": "  We give an algorithm that learns a representation of data through\ncompression. The algorithm 1) predicts bits sequentially from those previously\nseen and 2) has a structure and a number of computations similar to an\nautoencoder. The likelihood under the model can be calculated exactly, and\narithmetic coding can be used directly for compression. When training on digits\nthe algorithm learns filters similar to those of restricted boltzman machines\nand denoising autoencoders. Independent samples can be drawn from the model by\na single sweep through the pixels. The algorithm has a good compression\nperformance when compared to other methods that work under random ordering of\npixels.\n",
        "published": "2011-08-04T19:00:14Z",
        "pdf_link": "http://arxiv.org/pdf/1108.1169v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.1353v1",
        "title": "Real time face recognition using adaboost improved fast PCA algorithm",
        "summary": "  This paper presents an automated system for human face recognition in a real\ntime background world for a large homemade dataset of persons face. The task is\nvery difficult as the real time background subtraction in an image is still a\nchallenge. Addition to this there is a huge variation in human face image in\nterms of size, pose and expression. The system proposed collapses most of this\nvariance. To detect real time human face AdaBoost with Haar cascade is used and\na simple fast PCA and LDA is used to recognize the faces detected. The matched\nface is then used to mark attendance in the laboratory, in our case. This\nbiometric system is a real time attendance system based on the human face\nrecognition with a simple and fast algorithms and gaining a high accuracy\nrate..\n",
        "published": "2011-08-05T15:41:31Z",
        "pdf_link": "http://arxiv.org/pdf/1108.1353v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.2632v1",
        "title": "Compressive Imaging using Approximate Message Passing and a Markov-Tree\n  Prior",
        "summary": "  We propose a novel algorithm for compressive imaging that exploits both the\nsparsity and persistence across scales found in the 2D wavelet transform\ncoefficients of natural images. Like other recent works, we model wavelet\nstructure using a hidden Markov tree (HMT) but, unlike other works, ours is\nbased on loopy belief propagation (LBP). For LBP, we adopt a recently proposed\n\"turbo\" message passing schedule that alternates between exploitation of HMT\nstructure and exploitation of compressive-measurement structure. For the\nlatter, we leverage Donoho, Maleki, and Montanari's recently proposed\napproximate message passing (AMP) algorithm. Experiments with a large image\ndatabase suggest that, relative to existing schemes, our turbo LBP approach\nyields state-of-the-art reconstruction performance with substantial reduction\nin complexity.\n",
        "published": "2011-08-12T14:41:49Z",
        "pdf_link": "http://arxiv.org/pdf/1108.2632v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.3250v1",
        "title": "The Statistical methods of Pixel-Based Image Fusion Techniques",
        "summary": "  There are many image fusion methods that can be used to produce\nhigh-resolution mutlispectral images from a high-resolution panchromatic (PAN)\nimage and low-resolution multispectral (MS) of remote sensed images. This paper\nattempts to undertake the study of image fusion techniques with different\nStatistical techniques for image fusion as Local Mean Matching (LMM), Local\nMean and Variance Matching (LMVM), Regression variable substitution (RVS),\nLocal Correlation Modeling (LCM) and they are compared with one another so as\nto choose the best technique, that can be applied on multi-resolution satellite\nimages. This paper also devotes to concentrate on the analytical techniques for\nevaluating the quality of image fusion (F) by using various methods including\nStandard Deviation (SD), Entropy(En), Correlation Coefficient (CC), Signal-to\nNoise Ratio (SNR), Normalization Root Mean Square Error (NRMSE) and Deviation\nIndex (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively.\n",
        "published": "2011-08-12T16:51:21Z",
        "pdf_link": "http://arxiv.org/pdf/1108.3250v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.3251v1",
        "title": "Advanced phase retrieval: maximum likelihood technique with sparse\n  regularization of phase and amplitude",
        "summary": "  Sparse modeling is one of the efficient techniques for imaging that allows\nrecovering lost information. In this paper, we present a novel iterative\nphase-retrieval algorithm using a sparse representation of the object amplitude\nand phase. The algorithm is derived in terms of a constrained maximum\nlikelihood, where the wave field reconstruction is performed using a number of\nnoisy intensity-only observations with a zero-mean additive Gaussian noise. The\ndeveloped algorithm enables the optimal solution for the object wave field\nreconstruction. Our goal is an improvement of the reconstruction quality with\nrespect to the conventional algorithms. Sparse regularization results in\nadvanced reconstruction accuracy, and numerical simulations demonstrate\nsignificant enhancement of imaging.\n",
        "published": "2011-08-15T09:37:15Z",
        "pdf_link": "http://arxiv.org/pdf/1108.3251v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.3605v2",
        "title": "Hierarchical Object Parsing from Structured Noisy Point Clouds",
        "summary": "  Object parsing and segmentation from point clouds are challenging tasks\nbecause the relevant data is available only as thin structures along object\nboundaries or other features, and is corrupted by large amounts of noise. To\nhandle this kind of data, flexible shape models are desired that can accurately\nfollow the object boundaries. Popular models such as Active Shape and Active\nAppearance models lack the necessary flexibility for this task, while recent\napproaches such as the Recursive Compositional Models make model\nsimplifications in order to obtain computational guarantees. This paper\ninvestigates a hierarchical Bayesian model of shape and appearance in a\ngenerative setting. The input data is explained by an object parsing layer,\nwhich is a deformation of a hidden PCA shape model with Gaussian prior. The\npaper also introduces a novel efficient inference algorithm that uses informed\ndata-driven proposals to initialize local searches for the hidden variables.\nApplied to the problem of object parsing from structured point clouds such as\nedge detection images, the proposed approach obtains state of the art parsing\nerrors on two standard datasets without using any intensity information.\n",
        "published": "2011-08-18T02:11:34Z",
        "pdf_link": "http://arxiv.org/pdf/1108.3605v2"
    },
    {
        "id": "http://arxiv.org/abs/1108.4098v1",
        "title": "Multisensor Images Fusion Based on Feature-Level",
        "summary": "  Until now, of highest relevance for remote sensing data processing and\nanalysis have been techniques for pixel level image fusion. So, This paper\nattempts to undertake the study of Feature-Level based image fusion. For this\npurpose, feature based fusion techniques, which are usually based on empirical\nor heuristic rules, are employed. Hence, in this paper we consider feature\nextraction (FE) for fusion. It aims at finding a transformation of the original\nspace that would produce such new features, which preserve or improve as much\nas possible. This study introduces three different types of Image fusion\ntechniques including Principal Component Analysis based Feature Fusion (PCA),\nSegment Fusion (SF) and Edge fusion (EF). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including (SD), (En), (CC), (SNR), (NRMSE)\nand (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively.\n",
        "published": "2011-08-20T07:43:46Z",
        "pdf_link": "http://arxiv.org/pdf/1108.4098v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.4315v1",
        "title": "Edge detection based on morphological amoebas",
        "summary": "  Detecting the edges of objects within images is critical for quality image\nprocessing. We present an edge-detecting technique that uses morphological\namoebas that adjust their shape based on variation in image contours. We\nevaluate the method both quantitatively and qualitatively for edge detection of\nimages, and compare it to classic morphological methods. Our amoeba-based\nedge-detection system performed better than the classic edge detectors.\n",
        "published": "2011-08-22T13:49:57Z",
        "pdf_link": "http://arxiv.org/pdf/1108.4315v1"
    },
    {
        "id": "http://arxiv.org/abs/1108.6294v1",
        "title": "Biometric Authorization System using Gait Biometry",
        "summary": "  Human gait, which is a new biometric aimed to recognize individuals by the\nway they walk have come to play an increasingly important role in visual\nsurveillance applications. In this paper a novel hybrid holistic approach is\nproposed to show how behavioural walking characteristics can be used to\nrecognize unauthorized and suspicious persons when they enter a surveillance\narea. Initially background is modelled from the input video captured from\ncameras deployed for security and the foreground moving object in the\nindividual frames are segmented using the background subtraction algorithm.\nThen gait representing spatial, temporal and wavelet components are extracted\nand fused for training and testing multi class support vector machine models\n(SVM). The proposed system is evaluated using side view videos of NLPR\ndatabase. The experimental results demonstrate that the proposed system\nachieves a pleasing recognition rate and also the results indicate that the\nclassification ability of SVM with Radial Basis Function (RBF) is better than\nwith other kernel functions.\n",
        "published": "2011-08-31T17:22:51Z",
        "pdf_link": "http://arxiv.org/pdf/1108.6294v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.0090v1",
        "title": "An Efficient Codebook Initialization Approach for LBG Algorithm",
        "summary": "  In VQ based image compression technique has three major steps namely (i)\nCodebook Design, (ii) VQ Encoding Process and (iii) VQ Decoding Process. The\nperformance of VQ based image compression technique depends upon the\nconstructed codebook. A widely used technique for VQ codebook design is the\nLinde-Buzo-Gray (LBG) algorithm. However the performance of the standard LBG\nalgorithm is highly dependent on the choice of the initial codebook. In this\npaper, we have proposed a simple and very effective approach for codebook\ninitialization for LBG algorithm. The simulation results show that the proposed\nscheme is computationally efficient and gives expected performance as compared\nto the standard LBG algorithm.\n",
        "published": "2011-09-01T04:47:08Z",
        "pdf_link": "http://arxiv.org/pdf/1109.0090v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.0138v1",
        "title": "Automatic Application Level Set Approach in Detection Calcifications in\n  Mammographic Image",
        "summary": "  Breast cancer is considered as one of a major health problem that constitutes\nthe strongest cause behind mortality among women in the world. So, in this\ndecade, breast cancer is the second most common type of cancer, in term of\nappearance frequency, and the fifth most common cause of cancer related death.\nIn order to reduce the workload on radiologists, a variety of CAD systems;\nComputer-Aided Diagnosis (CADi) and Computer-Aided Detection (CADe) have been\nproposed. In this paper, we interested on CADe tool to help radiologist to\ndetect cancer. The proposed CADe is based on a three-step work flow; namely,\ndetection, analysis and classification. This paper deals with the problem of\nautomatic detection of Region Of Interest (ROI) based on Level Set approach\ndepended on edge and region criteria. This approach gives good visual\ninformation from the radiologist. After that, the features extraction using\ntextures characteristics and the vector classification using Multilayer\nPerception (MLP) and k-Nearest Neighbours (KNN) are adopted to distinguish\ndifferent ACR (American College of Radiology) classification. Moreover, we use\nthe Digital Database for Screening Mammography (DDSM) for experiments and these\nresults in term of accuracy varied between 60 % and 70% are acceptable and must\nbe ameliorated to aid radiologist.\n",
        "published": "2011-09-01T09:51:42Z",
        "pdf_link": "http://arxiv.org/pdf/1109.0138v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.0882v2",
        "title": "Moving Object Detection by Detecting Contiguous Outliers in the Low-Rank\n  Representation",
        "summary": "  Object detection is a fundamental step for automated video analysis in many\nvision applications. Object detection in a video is usually performed by object\ndetectors or background subtraction techniques. Often, an object detector\nrequires manually labeled examples to train a binary classifier, while\nbackground subtraction needs a training sequence that contains no objects to\nbuild a background model. To automate the analysis, object detection without a\nseparate training phase becomes a critical task. People have tried to tackle\nthis task by using motion information. But existing motion-based methods are\nusually limited when coping with complex scenarios such as nonrigid motion and\ndynamic background. In this paper, we show that above challenges can be\naddressed in a unified framework named DEtecting Contiguous Outliers in the\nLOw-rank Representation (DECOLOR). This formulation integrates object detection\nand background learning into a single process of optimization, which can be\nsolved by an alternating algorithm efficiently. We explain the relations\nbetween DECOLOR and other sparsity-based methods. Experiments on both simulated\ndata and real sequences demonstrate that DECOLOR outperforms the\nstate-of-the-art approaches and it can work effectively on a wide range of\ncomplex scenarios.\n",
        "published": "2011-09-05T13:08:24Z",
        "pdf_link": "http://arxiv.org/pdf/1109.0882v2"
    },
    {
        "id": "http://arxiv.org/abs/1109.1057v1",
        "title": "Toward Designing Intelligent PDEs for Computer Vision: An Optimal\n  Control Approach",
        "summary": "  Many computer vision and image processing problems can be posed as solving\npartial differential equations (PDEs). However, designing PDE system usually\nrequires high mathematical skills and good insight into the problems. In this\npaper, we consider designing PDEs for various problems arising in computer\nvision and image processing in a lazy manner: \\emph{learning PDEs from real\ndata via data-based optimal control}. We first propose a general intelligent\nPDE system which holds the basic translational and rotational invariance rule\nfor most vision problems. By introducing a PDE-constrained optimal control\nframework, it is possible to use the training data resulting from multiple ways\n(ground truth, results from other methods, and manual results from humans) to\nlearn PDEs for different computer vision tasks. The proposed optimal control\nbased training framework aims at learning a PDE-based regressor to approximate\nthe unknown (and usually nonlinear) mapping of different vision tasks. The\nexperimental results show that the learnt PDEs can solve different vision\nproblems reasonably well. In particular, we can obtain PDEs not only for\nproblems that traditional PDEs work well but also for problems that PDE-based\nmethods have never been tried before, due to the difficulty in describing those\nproblems in a mathematical way.\n",
        "published": "2011-09-06T04:26:44Z",
        "pdf_link": "http://arxiv.org/pdf/1109.1057v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.1067v1",
        "title": "Automatic Diagnosis of Abnormal Tumor Region from Brain Computed\n  Tomography Images Using Wavelet Based Statistical Texture Features",
        "summary": "  The research work presented in this paper is to achieve the tissue\nclassification and automatically diagnosis the abnormal tumor region present in\nComputed Tomography (CT) images using the wavelet based statistical texture\nanalysis method. Comparative studies of texture analysis method are performed\nfor the proposed wavelet based texture analysis method and Spatial Gray Level\nDependence Method (SGLDM). Our proposed system consists of four phases i)\nDiscrete Wavelet Decomposition (ii) Feature extraction (iii) Feature selection\n(iv) Analysis of extracted texture features by classifier. A wavelet based\nstatistical texture feature set is derived from normal and tumor regions.\nGenetic Algorithm (GA) is used to select the optimal texture features from the\nset of extracted texture features. We construct the Support Vector Machine\n(SVM) based classifier and evaluate the performance of classifier by comparing\nthe classification results of the SVM based classifier with the Back\nPropagation Neural network classifier(BPN). The results of Support Vector\nMachine (SVM), BPN classifiers for the texture analysis methods are evaluated\nusing Receiver Operating Characteristic (ROC) analysis. Experimental results\nshow that the classification accuracy of SVM is 96% for 10 fold cross\nvalidation method. The system has been tested with a number of real Computed\nTomography brain images and has achieved satisfactory results.\n",
        "published": "2011-09-06T05:31:26Z",
        "pdf_link": "http://arxiv.org/pdf/1109.1067v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.1068v1",
        "title": "An Automatic Clustering Technique for Optimal Clusters",
        "summary": "  This paper proposes a simple, automatic and efficient clustering algorithm,\nnamely, Automatic Merging for Optimal Clusters (AMOC) which aims to generate\nnearly optimal clusters for the given datasets automatically. The AMOC is an\nextension to standard k-means with a two phase iterative procedure combining\ncertain validation techniques in order to find optimal clusters with automation\nof merging of clusters. Experiments on both synthetic and real data have proved\nthat the proposed algorithm finds nearly optimal clustering structures in terms\nof number of clusters, compactness and separation.\n",
        "published": "2011-09-06T05:34:28Z",
        "pdf_link": "http://arxiv.org/pdf/1109.1068v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.1247v1",
        "title": "Devnagari document segmentation using histogram approach",
        "summary": "  Document segmentation is one of the critical phases in machine recognition of\nany language. Correct segmentation of individual symbols decides the accuracy\nof character recognition technique. It is used to decompose image of a sequence\nof characters into sub images of individual symbols by segmenting lines and\nwords. Devnagari is the most popular script in India. It is used for writing\nHindi, Marathi, Sanskrit and Nepali languages. Moreover, Hindi is the third\nmost popular language in the world. Devnagari documents consist of vowels,\nconsonants and various modifiers. Hence proper segmentation of Devnagari word\nis challenging. A simple histogram based approach to segment Devnagari\ndocuments is proposed in this paper. Various challenges in segmentation of\nDevnagari script are also discussed.\n",
        "published": "2011-09-06T17:56:58Z",
        "pdf_link": "http://arxiv.org/pdf/1109.1247v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.1480v1",
        "title": "Curvature Prior for MRF-based Segmentation and Shape Inpainting",
        "summary": "  Most image labeling problems such as segmentation and image reconstruction\nare fundamentally ill-posed and suffer from ambiguities and noise. Higher order\nimage priors encode high level structural dependencies between pixels and are\nkey to overcoming these problems. However, these priors in general lead to\ncomputationally intractable models. This paper addresses the problem of\ndiscovering compact representations of higher order priors which allow\nefficient inference. We propose a framework for solving this problem which uses\na recently proposed representation of higher order functions where they are\nencoded as lower envelopes of linear functions. Maximum a Posterior inference\non our learned models reduces to minimizing a pairwise function of discrete\nvariables, which can be done approximately using standard methods. Although\nthis is a primarily theoretical paper, we also demonstrate the practical\neffectiveness of our framework on the problem of learning a shape prior for\nimage segmentation and reconstruction. We show that our framework can learn a\ncompact representation that approximates a prior that encourages low curvature\nshapes. We evaluate the approximation accuracy, discuss properties of the\ntrained model, and show various results for shape inpainting and image\nsegmentation.\n",
        "published": "2011-09-07T14:53:51Z",
        "pdf_link": "http://arxiv.org/pdf/1109.1480v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.1865v1",
        "title": "Progressive versus Random Projections for Compressive Capture of Images,\n  Lightfields and Higher Dimensional Visual Signals",
        "summary": "  Computational photography involves sophisticated capture methods. A new trend\nis to capture projection of higher dimensional visual signals such as videos,\nmulti-spectral data and lightfields on lower dimensional sensors. Carefully\ndesigned capture methods exploit the sparsity of the underlying signal in a\ntransformed domain to reduce the number of measurements and use an appropriate\nreconstruction method. Traditional progressive methods may capture successively\nmore detail using a sequence of simple projection basis, such as DCT or\nwavelets and employ straightforward backprojection for reconstruction.\nRandomized projection methods do not use any specific sequence and use L0\nminimization for reconstruction. In this paper, we analyze the statistical\nproperties of natural images, videos, multi-spectral data and light-fields and\ncompare the effectiveness of progressive and random projections. We define\neffectiveness by plotting reconstruction SNR against compression factor. The\nkey idea is a procedure to measure best-case effectiveness that is fast,\nindependent of specific hardware and independent of the reconstruction\nprocedure. We believe this is the first empirical study to compare different\nlossy capture strategies without the complication of hardware or reconstruction\nambiguity. The scope is limited to linear non-adaptive sensing. The results\nshow that random projections produce significant advantages over other\nprojections only for higher dimensional signals, and suggest more research to\nnascent adaptive and non-linear projection methods.\n",
        "published": "2011-09-09T00:33:10Z",
        "pdf_link": "http://arxiv.org/pdf/1109.1865v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.2449v4",
        "title": "Multi-Hypothesis CRF-Segmentation of Neural Tissue in Anisotropic EM\n  Volumes",
        "summary": "  We present an approach for the joint segmentation and grouping of similar\ncomponents in anisotropic 3D image data and use it to segment neural tissue in\nserial sections electron microscopy (EM) images.\n  We first construct a nested set of neuron segmentation hypotheses for each\nslice. A conditional random field (CRF) then allows us to evaluate both the\ncompatibility of a specific segmentation and a specific inter-slice assignment\nof neuron candidates with the underlying observations. The model is solved\noptimally for an entire image stack simultaneously using integer linear\nprogramming (ILP), which yields the maximum a posteriori solution in amortized\nlinear time in the number of slices.\n  We evaluate the performance of our approach on an annotated sample of the\nDrosophila larva neuropil and show that the consideration of different\nsegmentation hypotheses in each slice leads to a significant improvement in the\nsegmentation and assignment accuracy.\n",
        "published": "2011-09-12T12:57:25Z",
        "pdf_link": "http://arxiv.org/pdf/1109.2449v4"
    },
    {
        "id": "http://arxiv.org/abs/1109.3126v1",
        "title": "A Non-Iterative Solution to the Four-Point Three-Views Pose Problem in\n  Case of Collinear Cameras",
        "summary": "  We give a non-iterative solution to a particular case of the four-point\nthree-views pose problem when three camera centers are collinear. Using the\nwell-known Cayley representation of orthogonal matrices, we derive from the\nepipolar constraints a system of three polynomial equations in three variables.\nThe eliminant of that system is a multiple of a 36th degree univariate\npolynomial. The true (unique) solution to the problem can be expressed in terms\nof one of real roots of that polynomial. Experiments on synthetic data confirm\nthat our method is robust enough even in case of planar configurations.\n",
        "published": "2011-09-14T16:24:26Z",
        "pdf_link": "http://arxiv.org/pdf/1109.3126v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.3317v1",
        "title": "Design of an Optical Character Recognition System for Camera-based\n  Handheld Devices",
        "summary": "  This paper presents a complete Optical Character Recognition (OCR) system for\ncamera captured image/graphics embedded textual documents for handheld devices.\nAt first, text regions are extracted and skew corrected. Then, these regions\nare binarized and segmented into lines and characters. Characters are passed\ninto the recognition module. Experimenting with a set of 100 business card\nimages, captured by cell phone camera, we have achieved a maximum recognition\naccuracy of 92.74%. Compared to Tesseract, an open source desktop-based\npowerful OCR engine, present recognition accuracy is worth contributing.\nMoreover, the developed technique is computationally efficient and consumes low\nmemory so as to be applicable on handheld devices.\n",
        "published": "2011-09-15T11:24:41Z",
        "pdf_link": "http://arxiv.org/pdf/1109.3317v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.3637v1",
        "title": "Connectivity-Enforcing Hough Transform for the Robust Extraction of Line\n  Segments",
        "summary": "  Global voting schemes based on the Hough transform (HT) have been widely used\nto robustly detect lines in images. However, since the votes do not take line\nconnectivity into account, these methods do not deal well with cluttered\nimages. In opposition, the so-called local methods enforce connectivity but\nlack robustness to deal with challenging situations that occur in many\nrealistic scenarios, e.g., when line segments cross or when long segments are\ncorrupted. In this paper, we address the critical limitations of the HT as a\nline segment extractor by incorporating connectivity in the voting process.\nThis is done by only accounting for the contributions of edge points lying in\nincreasingly larger neighborhoods and whose position and directional content\nagree with potential line segments. As a result, our method, which we call\nSTRAIGHT (Segment exTRAction by connectivity-enforcInG HT), extracts the\nlongest connected segments in each location of the image, thus also integrating\ninto the HT voting process the usually separate step of individual segment\nextraction. The usage of the Hough space mapping and a corresponding\nhierarchical implementation make our approach computationally feasible. We\npresent experiments that illustrate, with synthetic and real images, how\nSTRAIGHT succeeds in extracting complete segments in several situations where\ncurrent methods fail.\n",
        "published": "2011-09-16T14:56:25Z",
        "pdf_link": "http://arxiv.org/pdf/1109.3637v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.3767v1",
        "title": "Generalised Object Detection and Semantic Analysis: Casino Example using\n  Matlab",
        "summary": "  Matlab version 7.1 had been used to detect playing cards on a Casino table\nand the suits and ranks of these cards had been identified. The process gives\nan example of an application of computer vision to a problem where rectangular\nobjects are to be detected and the information content of the objects are\nextracted out. In the case of playing cards, it is the suit and rank of each\ncard. The image processing system is done in two passes. Pass 1 detects\nrectangular shapes and template matched with a template of the left and right\nedges of the cards. Pass 2 extracts the suit and rank of the cards by matching\nthe top left portion of the card that contains both rank and suit information,\nwith stored templates of ranks and suits of the playing cards using a series of\nif-then statements.\n",
        "published": "2011-09-17T10:09:02Z",
        "pdf_link": "http://arxiv.org/pdf/1109.3767v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.3850v2",
        "title": "Digital (co)homology modules and digital Pontryagin algebras",
        "summary": "  In the current study, we explore digital homology and cohomology modules, and\ninvestigate their fundamental properties on pointed digital images. We also\nexamine pointed digital Hopf spaces and base point preserving digital Hopf\nfunctions between the pointed digital Hopf spaces with suitable digital\nmultiplications, and explore the digital primitive homology and cohomology\nclasses, the digital Pontryagin algebras and coalgebras on the digital Hopf\nspaces as digital images.\n",
        "published": "2011-09-18T07:48:36Z",
        "pdf_link": "http://arxiv.org/pdf/1109.3850v2"
    },
    {
        "id": "http://arxiv.org/abs/1109.4683v1",
        "title": "Detachable Object Detection: Segmentation and Depth Ordering From\n  Short-Baseline Video",
        "summary": "  We describe an approach for segmenting an image into regions that correspond\nto surfaces in the scene that are partially surrounded by the medium. It\nintegrates both appearance and motion statistics into a cost functional, that\nis seeded with occluded regions and minimized efficiently by solving a linear\nprogramming problem. Where a short observation time is insufficient to\ndetermine whether the object is detachable, the results of the minimization can\nbe used to seed a more costly optimization based on a longer sequence of video\ndata. The result is an entirely unsupervised scheme to detect and segment an\narbitrary and unknown number of objects. We test our scheme to highlight the\npotential, as well as limitations, of our approach.\n",
        "published": "2011-09-22T00:55:32Z",
        "pdf_link": "http://arxiv.org/pdf/1109.4683v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.4744v1",
        "title": "Probabilistic prototype models for attributed graphs",
        "summary": "  This contribution proposes a new approach towards developing a class of\nprobabilistic methods for classifying attributed graphs. The key concept is\nrandom attributed graph, which is defined as an attributed graph whose nodes\nand edges are annotated by random variables. Every node/edge has two random\nprocesses associated with it- occurence probability and the probability\ndistribution over the attribute values. These are estimated within the maximum\nlikelihood framework. The likelihood of a random attributed graph to generate\nan outcome graph is used as a feature for classification. The proposed approach\nis fast and robust to noise.\n",
        "published": "2011-09-22T09:26:23Z",
        "pdf_link": "http://arxiv.org/pdf/1109.4744v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.4909v1",
        "title": "Sparse Online Low-Rank Projection and Outlier Rejection (SOLO) for 3-D\n  Rigid-Body Motion Registration",
        "summary": "  Motivated by an emerging theory of robust low-rank matrix representation, in\nthis paper, we introduce a novel solution for online rigid-body motion\nregistration. The goal is to develop algorithmic techniques that enable a\nrobust, real-time motion registration solution suitable for low-cost, portable\n3-D camera devices. Assuming 3-D image features are tracked via a standard\ntracker, the algorithm first utilizes Robust PCA to initialize a low-rank shape\nrepresentation of the rigid body. Robust PCA finds the global optimal solution\nof the initialization, while its complexity is comparable to singular value\ndecomposition. In the online update stage, we propose a more efficient\nalgorithm for sparse subspace projection to sequentially project new feature\nobservations onto the shape subspace. The lightweight update stage guarantees\nthe real-time performance of the solution while maintaining good registration\neven when the image sequence is contaminated by noise, gross data corruption,\noutlying features, and missing data. The state-of-the-art accuracy of the\nsolution is validated through extensive simulation and a real-world experiment,\nwhile the system enjoys one to two orders of magnitude speed-up compared to\nwell-established RANSAC solutions. The new algorithm will be released online to\naid peer evaluation.\n",
        "published": "2011-09-22T18:41:00Z",
        "pdf_link": "http://arxiv.org/pdf/1109.4909v1"
    },
    {
        "id": "http://arxiv.org/abs/1109.5114v3",
        "title": "Improvements on \"Fast space-variant elliptical filtering using box\n  splines\"",
        "summary": "  It is well-known that box filters can be efficiently computed using\npre-integrations and local finite-differences\n[Crow1984,Heckbert1986,Viola2001]. By generalizing this idea and by combining\nit with a non-standard variant of the Central Limit Theorem, a constant-time or\nO(1) algorithm was proposed in [Chaudhury2010] that allowed one to perform\nspace-variant filtering using Gaussian-like kernels. The algorithm was based on\nthe observation that both isotropic and anisotropic Gaussians could be\napproximated using certain bivariate splines called box splines. The attractive\nfeature of the algorithm was that it allowed one to continuously control the\nshape and size (covariance) of the filter, and that it had a fixed\ncomputational cost per pixel, irrespective of the size of the filter. The\nalgorithm, however, offered a limited control on the covariance and accuracy of\nthe Gaussian approximation. In this work, we propose some improvements by\nappropriately modifying the algorithm in [Chaudhury2010].\n",
        "published": "2011-09-23T15:43:21Z",
        "pdf_link": "http://arxiv.org/pdf/1109.5114v3"
    },
    {
        "id": "http://arxiv.org/abs/1109.5453v4",
        "title": "Posterior Mean Super-resolution with a Causal Gaussian Markov Random\n  Field Prior",
        "summary": "  We propose a Bayesian image super-resolution (SR) method with a causal\nGaussian Markov random field (MRF) prior. SR is a technique to estimate a\nspatially high-resolution image from given multiple low-resolution images. An\nMRF model with the line process supplies a preferable prior for natural images\nwith edges. We improve the existing image transformation model, the compound\nMRF model, and its hyperparameter prior model. We also derive the optimal\nestimator -- not the joint maximum a posteriori (MAP) or marginalized maximum\nlikelihood (ML), but the posterior mean (PM) -- from the objective function of\nthe L2-norm (mean square error) -based peak signal-to-noise ratio (PSNR). Point\nestimates such as MAP and ML are generally not stable in ill-posed\nhigh-dimensional problems because of overfitting, while PM is a stable\nestimator because all the parameters in the model are evaluated as\ndistributions. The estimator is numerically determined by using variational\nBayes. Variational Bayes is a widely used method that approximately determines\na complicated posterior distribution, but it is generally hard to use because\nit needs the conjugate prior. We solve this problem with simple Taylor\napproximations. Experimental results have shown that the proposed method is\nmore accurate or comparable to existing methods.\n",
        "published": "2011-09-26T06:23:09Z",
        "pdf_link": "http://arxiv.org/pdf/1109.5453v4"
    },
    {
        "id": "http://arxiv.org/abs/1109.6442v2",
        "title": "ABHIVYAKTI: A Vision Based Intelligent System for Elder and Sick Persons",
        "summary": "  This paper describes an intelligent system ABHIVYAKTI, which would be\npervasive in nature and based on the Computer Vision. It would be very easy in\nuse and deployment. Elder and sick people who are not able to talk or walk,\nthey are dependent on other human beings and need continuous monitoring, while\nour system provides flexibility to the sick or elder person to announce his or\nher need to their caretaker by just showing a particular gesture with the\ndeveloped system, if the caretaker is not nearby. This system will use\nfingertip detection techniques for acquiring gesture and Artificial Neural\nNetworks (ANNs) will be used for gesture recognition.\n",
        "published": "2011-09-29T08:59:29Z",
        "pdf_link": "http://arxiv.org/pdf/1109.6442v2"
    },
    {
        "id": "http://arxiv.org/abs/1109.6840v1",
        "title": "A Novel comprehensive method for real time Video Motion Detection\n  Surveillance",
        "summary": "  This article describes a comprehensive system for surveillance and monitoring\napplications. The development of an efficient real time video motion detection\nsystem is motivated by their potential for deployment in the areas where\nsecurity is the main concern. The paper presents a platform for real time video\nmotion detection and subsequent generation of an alarm condition as set by the\nparameters of the control system. The prototype consists of a mobile platform\nmounted with RF camera which provides continuous feedback of the environment.\nThe received visual information is then analyzed by user for appropriate\ncontrol action, thus enabling the user to operate the system from a remote\nlocation. The system is also equipped with the ability to process the image of\nan object and generate control signals which are automatically transmitted to\nthe mobile platform to track the object.\n",
        "published": "2011-09-30T14:48:51Z",
        "pdf_link": "http://arxiv.org/pdf/1109.6840v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.0264v1",
        "title": "Face Recognition using Optimal Representation Ensemble",
        "summary": "  Recently, the face recognizers based on linear representations have been\nshown to deliver state-of-the-art performance. In real-world applications,\nhowever, face images usually suffer from expressions, disguises and random\nocclusions. The problematic facial parts undermine the validity of the\nlinear-subspace assumption and thus the recognition performance deteriorates\nsignificantly. In this work, we address the problem in a\nlearning-inference-mixed fashion. By observing that the linear-subspace\nassumption is more reliable on certain face patches rather than on the holistic\nface, some Bayesian Patch Representations (BPRs) are randomly generated and\ninterpreted according to the Bayes' theory. We then train an ensemble model\nover the patch-representations by minimizing the empirical risk w.r.t the\n\"leave-one-out margins\". The obtained model is termed Optimal Representation\nEnsemble (ORE), since it guarantees the optimality from the perspective of\nEmpirical Risk Minimization. To handle the unknown patterns in test faces, a\nrobust version of BPR is proposed by taking the non-face category into\nconsideration. Equipped with the Robust-BPRs, the inference ability of ORE is\nincreased dramatically and several record-breaking accuracies (99.9% on Yale-B\nand 99.5% on AR) and desirable efficiencies (below 20 ms per face in Matlab)\nare achieved. It also overwhelms other modular heuristics on the faces with\nrandom occlusions, extreme expressions and disguises. Furthermore, to\naccommodate immense BPRs sets, a boosting-like algorithm is also derived. The\nboosted model, a.k.a Boosted-ORE, obtains similar performance to its prototype.\nBesides the empirical superiorities, two desirable features of the proposed\nmethods, namely, the training-determined model-selection and the\ndata-weight-free boosting procedure, are also theoretically verified.\n",
        "published": "2011-10-03T04:44:47Z",
        "pdf_link": "http://arxiv.org/pdf/1110.0264v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.0585v1",
        "title": "Discriminately Decreasing Discriminability with Learned Image Filters",
        "summary": "  In machine learning and computer vision, input images are often filtered to\nincrease data discriminability. In some situations, however, one may wish to\npurposely decrease discriminability of one classification task (a \"distractor\"\ntask), while simultaneously preserving information relevant to another (the\ntask-of-interest): For example, it may be important to mask the identity of\npersons contained in face images before submitting them to a crowdsourcing site\n(e.g., Mechanical Turk) when labeling them for certain facial attributes.\nAnother example is inter-dataset generalization: when training on a dataset\nwith a particular covariance structure among multiple attributes, it may be\nuseful to suppress one attribute while preserving another so that a trained\nclassifier does not learn spurious correlations between attributes. In this\npaper we present an algorithm that finds optimal filters to give high\ndiscriminability to one task while simultaneously giving low discriminability\nto a distractor task. We present results showing the effectiveness of the\nproposed technique on both simulated data and natural face images.\n",
        "published": "2011-10-04T06:48:29Z",
        "pdf_link": "http://arxiv.org/pdf/1110.0585v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.0872v1",
        "title": "Non-Gaussian Scale Space Filtering with 2 by 2 Matrix of Linear Filters",
        "summary": "  Construction of a scale space with a convolution filter has been studied\nextensively in the past. It has been proven that the only convolution kernel\nthat satisfies the scale space requirements is a Gaussian type. In this paper,\nwe consider a matrix of convolution filters introduced in [1] as a building\nkernel for a scale space, and shows that we can construct a non-Gaussian scale\nspace with a $2\\times 2$ matrix of filters. The paper derives sufficient\nconditions for the matrix of filters for being a scale space kernel, and\npresent some numerical demonstrations.\n",
        "published": "2011-10-04T23:58:55Z",
        "pdf_link": "http://arxiv.org/pdf/1110.0872v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.1485v1",
        "title": "A Face Recognition Scheme using Wavelet Based Dominant Features",
        "summary": "  In this paper, a multi-resolution feature extraction algorithm for face\nrecognition is proposed based on two-dimensional discrete wavelet transform\n(2D-DWT), which efficiently exploits the local spatial variations in a face\nimage. For the purpose of feature extraction, instead of considering the entire\nface image, an entropy-based local band selection criterion is developed, which\nselects high-informative horizontal segments from the face image. In order to\ncapture the local spatial variations within these highinformative horizontal\nbands precisely, the horizontal band is segmented into several small spatial\nmodules. Dominant wavelet coefficients corresponding to each local region\nresiding inside those horizontal bands are selected as features. In the\nselection of the dominant coefficients, a threshold criterion is proposed,\nwhich not only drastically reduces the feature dimension but also provides high\nwithin-class compactness and high between-class separability. A principal\ncomponent analysis is performed to further reduce the dimensionality of the\nfeature space. Extensive experimentation is carried out upon standard face\ndatabases and a very high degree of recognition accuracy is achieved by the\nproposed method in comparison to those obtained by some of the existing\nmethods.\n",
        "published": "2011-10-07T11:16:17Z",
        "pdf_link": "http://arxiv.org/pdf/1110.1485v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.1509v1",
        "title": "A Comparative Experiment of Several Shape Methods in Recognizing Plants",
        "summary": "  Shape is an important aspects in recognizing plants. Several approaches have\nbeen introduced to identify objects, including plants. Combination of geometric\nfeatures such as aspect ratio, compactness, and dispersion, or moments such as\nmoment invariants were usually used toidentify plants. In this research, a\ncomparative experiment of 4 methods to identify plants using shape features was\naccomplished. Two approaches have never been used in plants identification yet,\nZernike moments and Polar Fourier Transform (PFT), were incorporated. The\nexperimental comparison was done on 52 kinds of plants with various shapes. The\nresult, PFT gave best performance with 64% in accuracy and outperformed the\nother methods.\n",
        "published": "2011-10-07T12:43:38Z",
        "pdf_link": "http://arxiv.org/pdf/1110.1509v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.1513v1",
        "title": "Foliage Plant Retrieval using Polar Fourier Transform, Color Moments and\n  Vein Features",
        "summary": "  This paper proposed a method that combines Polar Fourier Transform, color\nmoments, and vein features to retrieve leaf images based on a leaf image. The\nmethod is very useful to help people in recognizing foliage plants. Foliage\nplants are plants that have various colors and unique patterns in the leaf.\nTherefore, the colors and its patterns are information that should be counted\non in the processing of plant identification. To compare the performance of\nretrieving system to other result, the experiments used Flavia dataset, which\nis very popular in recognizing plants. The result shows that the method gave\nbetter performance than PNN, SVM, and Fourier Transform. The method was also\ntested using foliage plants with various colors. The accuracy was 90.80% for 50\nkinds of plants.\n",
        "published": "2011-10-07T13:00:03Z",
        "pdf_link": "http://arxiv.org/pdf/1110.1513v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.2053v4",
        "title": "Steps Towards a Theory of Visual Information: Active Perception,\n  Signal-to-Symbol Conversion and the Interplay Between Sensing and Control",
        "summary": "  This manuscript describes the elements of a theory of information tailored to\ncontrol and decision tasks and specifically to visual data. The concept of\nActionable Information is described, that relates to a notion of information\nchampioned by J. Gibson, and a notion of \"complete information\" that relates to\nthe minimal sufficient statistics of a complete representation. It is shown\nthat the \"actionable information gap\" between the two can be reduced by\nexercising control on the sensing process. Thus, senging, control and\ninformation are inextricably tied. This has consequences in the so-called\n\"signal-to-symbol barrier\" problem, as well as in the analysis and design of\nactive sensing systems. It has ramifications in vision-based control,\nnavigation, 3-D reconstruction and rendering, as well as detection,\nlocalization, recognition and categorization of objects and scenes in live\nvideo.\n  This manuscript has been developed from a set of lecture notes for a summer\ncourse at the First International Computer Vision Summer School (ICVSS) in\nScicli, Italy, in July of 2008. They were later expanded and amended for\nsubsequent lectures in the same School in July 2009. Starting on November 1,\n2009, they were further expanded for a special topics course, CS269, taught at\nUCLA in the Spring term of 2010.\n",
        "published": "2011-10-10T14:28:41Z",
        "pdf_link": "http://arxiv.org/pdf/1110.2053v4"
    },
    {
        "id": "http://arxiv.org/abs/1110.2210v1",
        "title": "Closed-Loop Learning of Visual Control Policies",
        "summary": "  In this paper we present a general, flexible framework for learning mappings\nfrom images to actions by interacting with the environment. The basic idea is\nto introduce a feature-based image classifier in front of a reinforcement\nlearning algorithm. The classifier partitions the visual space according to the\npresence or absence of few highly informative local descriptors that are\nincrementally selected in a sequence of attempts to remove perceptual aliasing.\nWe also address the problem of fighting overfitting in such a greedy algorithm.\nFinally, we show how high-level visual features can be generated when the power\nof local descriptors is insufficient for completely disambiguating the aliased\nstates. This is done by building a hierarchy of composite features that consist\nof recursive spatial combinations of visual features. We demonstrate the\nefficacy of our algorithms by solving three visual navigation tasks and a\nvisual version of the classical Car on the Hill control problem.\n",
        "published": "2011-10-10T21:56:36Z",
        "pdf_link": "http://arxiv.org/pdf/1110.2210v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.3194v1",
        "title": "Controlled Total Variation regularization for inverse problems",
        "summary": "  This paper provides a new algorithm for solving inverse problems, based on\nthe minimization of the $L^2$ norm and on the control of the Total Variation.\nIt consists in relaxing the role of the Total Variation in the classical Total\nVariation minimization approach, which permits us to get better approximation\nto the inverse problems. The numerical results on the deconvolution problem\nshow that our method outperforms some previous ones.\n",
        "published": "2011-10-14T13:02:36Z",
        "pdf_link": "http://arxiv.org/pdf/1110.3194v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.4970v1",
        "title": "Studying Satellite Image Quality Based on the Fusion Techniques",
        "summary": "  Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. However,\nthe jury is still out on the benefits of a fused image compared to its original\nimages. There is also a lack of measures for assessing the objective quality of\nthe spatial resolution for the fusion methods. Therefore, an objective quality\nof the spatial resolution assessment for fusion images is required. So, this\nstudy attempts to develop a new qualitative assessment to evaluate the spatial\nquality of the pan sharpened images by many spatial quality metrics. Also, this\npaper deals with a comparison of various image fusion techniques based on pixel\nand feature fusion techniques.\n",
        "published": "2011-10-22T13:26:00Z",
        "pdf_link": "http://arxiv.org/pdf/1110.4970v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.5404v1",
        "title": "Face Recognition Based on SVM and 2DPCA",
        "summary": "  The paper will present a novel approach for solving face recognition problem.\nOur method combines 2D Principal Component Analysis (2DPCA), one of the\nprominent methods for extracting feature vectors, and Support Vector Machine\n(SVM), the most powerful discriminative method for classification. Experiments\nbased on proposed method have been conducted on two public data sets FERET and\nAT&T; the results show that the proposed method could improve the\nclassification rates.\n",
        "published": "2011-10-25T03:54:51Z",
        "pdf_link": "http://arxiv.org/pdf/1110.5404v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.5450v1",
        "title": "Hand Tracking based on Hierarchical Clustering of Range Data",
        "summary": "  Fast and robust hand segmentation and tracking is an essential basis for\ngesture recognition and thus an important component for contact-less\nhuman-computer interaction (HCI). Hand gesture recognition based on 2D video\ndata has been intensively investigated. However, in practical scenarios purely\nintensity based approaches suffer from uncontrollable environmental conditions\nlike cluttered background colors. In this paper we present a real-time hand\nsegmentation and tracking algorithm using Time-of-Flight (ToF) range cameras\nand intensity data. The intensity and range information is fused into one pixel\nvalue, representing its combined intensity-depth homogeneity. The scene is\nhierarchically clustered using a GPU based parallel merging algorithm, allowing\na robust identification of both hands even for inhomogeneous backgrounds. After\nthe detection, both hands are tracked on the CPU. Our tracking algorithm can\ncope with the situation that one hand is temporarily covered by the other hand.\n",
        "published": "2011-10-25T09:24:25Z",
        "pdf_link": "http://arxiv.org/pdf/1110.5450v1"
    },
    {
        "id": "http://arxiv.org/abs/1110.5945v1",
        "title": "A New Similarity Measure for Non-Local Means Filtering of MRI Images",
        "summary": "  The acquisition of MRI images offers a trade-off in terms of acquisition\ntime, spatial/temporal resolution and signal-to-noise ratio (SNR). Thus, for\ninstance, increasing the time efficiency of MRI often comes at the expense of\nreduced SNR. This, in turn, necessitates the use of post-processing tools for\nnoise rejection, which makes image de-noising an indispensable component of\ncomputer assistance diagnosis. In the field of MRI, a multitude of image\nde-noising methods have been proposed hitherto. In this paper, the application\nof a particular class of de-noising algorithms - known as non-local mean (NLM)\nfilters - is investigated. Such filters have been recently applied for MRI data\nenhancement and they have been shown to provide more accurate results as\ncompared to many alternative de-noising algorithms. Unfortunately, virtually\nall existing methods for NLM filtering have been derived under the assumption\nof additive white Gaussian (AWG) noise contamination. Since this assumption is\nknown to fail at low values of SNR, an alternative formulation of NLM filtering\nis required, which would take into consideration the correct Rician statistics\nof MRI noise. Accordingly, the contribution of the present paper is two-fold.\nFirst, it points out some principal disadvantages of the earlier methods of NLM\nfiltering of MRI images and suggests means to rectify them. Second, the paper\nintroduces a new similarity measure for NLM filtering of MRI Images, which is\nderived under bona fide statistical assumptions and results in more accurate\nreconstruction of MR scans as compared to alternative NLM approaches. Finally,\nthe utility and viability of the proposed method is demonstrated through a\nseries of numerical experiments using both in silico and in vivo MRI data.\n",
        "published": "2011-10-26T23:14:57Z",
        "pdf_link": "http://arxiv.org/pdf/1110.5945v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.0885v1",
        "title": "Graph Regularized Nonnegative Matrix Factorization for Hyperspectral\n  Data Unmixing",
        "summary": "  Spectral unmixing is an important tool in hyperspectral data analysis for\nestimating endmembers and abundance fractions in a mixed pixel. This paper\nexamines the applicability of a recently developed algorithm called graph\nregularized nonnegative matrix factorization (GNMF) for this aim. The proposed\napproach exploits the intrinsic geometrical structure of the data besides\nconsidering positivity and full additivity constraints. Simulated data based on\nthe measured spectral signatures, is used for evaluating the proposed\nalgorithm. Results in terms of abundance angle distance (AAD) and spectral\nangle distance (SAD) show that this method can effectively unmix hyperspectral\ndata.\n",
        "published": "2011-11-03T15:46:47Z",
        "pdf_link": "http://arxiv.org/pdf/1111.0885v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.1014v1",
        "title": "Sparsity and Robustness in Face Recognition",
        "summary": "  This report concerns the use of techniques for sparse signal representation\nand sparse error correction for automatic face recognition. Much of the recent\ninterest in these techniques comes from the paper \"Robust Face Recognition via\nSparse Representation\" by Wright et al. (2009), which showed how, under certain\ntechnical conditions, one could cast the face recognition problem as one of\nseeking a sparse representation of a given input face image in terms of a\n\"dictionary\" of training images and images of individual pixels. In this\nreport, we have attempted to clarify some frequently encountered questions\nabout this work and particularly, on the validity of using sparse\nrepresentation techniques for face recognition.\n",
        "published": "2011-11-03T23:50:36Z",
        "pdf_link": "http://arxiv.org/pdf/1111.1014v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.1311v1",
        "title": "Covariant fractional extension of the modified Laplace-operator used in\n  3D-shape recovery",
        "summary": "  Extending the Liouville-Caputo definition of a fractional derivative to a\nnonlocal covariant generalization of arbitrary bound operators acting on\nmultidimensional Riemannian spaces an appropriate approach for the 3D shape\nrecovery of aperture afflicted 2D slide sequences is proposed. We demonstrate,\nthat the step from a local to a nonlocal algorithm yields an order of magnitude\nin accuracy and by using the specific fractional approach an additional factor\n2 in accuracy of the derived results.\n",
        "published": "2011-11-05T14:09:05Z",
        "pdf_link": "http://arxiv.org/pdf/1111.1311v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.1461v1",
        "title": "Multimodal diff-hash",
        "summary": "  Many applications require comparing multimodal data with different structure\nand dimensionality that cannot be compared directly. Recently, there has been\nincreasing interest in methods for learning and efficiently representing such\nmultimodal similarity. In this paper, we present a simple algorithm for\nmultimodal similarity-preserving hashing, trying to map multimodal data into\nthe Hamming space while preserving the intra- and inter-modal similarities. We\nshow that our method significantly outperforms the state-of-the-art method in\nthe field.\n",
        "published": "2011-11-07T00:28:37Z",
        "pdf_link": "http://arxiv.org/pdf/1111.1461v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.1562v1",
        "title": "Iris Recognition Based on LBP and Combined LVQ Classifier",
        "summary": "  Iris recognition is considered as one of the best biometric methods used for\nhuman identification and verification, this is because of its unique features\nthat differ from one person to another, and its importance in the security\nfield. This paper proposes an algorithm for iris recognition and classification\nusing a system based on Local Binary Pattern and histogram properties as a\nstatistical approaches for feature extraction, and Combined Learning Vector\nQuantization Classifier as Neural Network approach for classification, in order\nto build a hybrid model depends on both features. The localization and\nsegmentation techniques are presented using both Canny edge detection and Hough\nCircular Transform in order to isolate an iris from the whole eye image and for\nnoise detection .Feature vectors results from LBP is applied to a Combined LVQ\nclassifier with different classes to determine the minimum acceptable\nperformance, and the result is based on majority voting among several LVQ\nclassifier. Different iris datasets CASIA, MMU1, MMU2, and LEI with different\nextensions and size are presented. Since LBP is working on a grayscale level so\ncolored iris images should be transformed into a grayscale level. The proposed\nsystem gives a high recognition rate 99.87 % on different iris datasets\ncompared with other methods.\n",
        "published": "2011-11-07T12:35:29Z",
        "pdf_link": "http://arxiv.org/pdf/1111.1562v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.1599v1",
        "title": "Efficient Hierarchical Markov Random Fields for Object Detection on a\n  Mobile Robot",
        "summary": "  Object detection and classification using video is necessary for intelligent\nplanning and navigation on a mobile robot. However, current methods can be too\nslow or not sufficient for distinguishing multiple classes. Techniques that\nrely on binary (foreground/background) labels incorrectly identify areas with\nmultiple overlapping objects as single segment. We propose two Hierarchical\nMarkov Random Field models in efforts to distinguish connected objects using\ntiered, binary label sets. Near-realtime performance has been achieved using\nefficient optimization methods which runs up to 11 frames per second on a dual\ncore 2.2 Ghz processor. Evaluation of both models is done using footage taken\nfrom a robot obstacle course at the 2010 Intelligent Ground Vehicle\nCompetition.\n",
        "published": "2011-11-07T14:46:16Z",
        "pdf_link": "http://arxiv.org/pdf/1111.1599v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.1752v1",
        "title": "New Method for 3D Shape Retrieval",
        "summary": "  The recent technological progress in acquisition, modeling and processing of\n3D data leads to the proliferation of a large number of 3D objects databases.\nConsequently, the techniques used for content based 3D retrieval has become\nnecessary. In this paper, we introduce a new method for 3D objects recognition\nand retrieval by using a set of binary images CLI (Characteristic level\nimages). We propose a 3D indexing and search approach based on the similarity\nbetween characteristic level images using Hu moments for it indexing. To\nmeasure the similarity between 3D objects we compute the Hausdorff distance\nbetween a vectors descriptor. The performance of this new approach is evaluated\nat set of 3D object of well known database, is NTU (National Taiwan University)\ndatabase.\n",
        "published": "2011-11-07T21:24:36Z",
        "pdf_link": "http://arxiv.org/pdf/1111.1752v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.1947v1",
        "title": "Discriminative Local Sparse Representations for Robust Face Recognition",
        "summary": "  A key recent advance in face recognition models a test face image as a sparse\nlinear combination of a set of training face images. The resulting sparse\nrepresentations have been shown to possess robustness against a variety of\ndistortions like random pixel corruption, occlusion and disguise. This approach\nhowever makes the restrictive (in many scenarios) assumption that test faces\nmust be perfectly aligned (or registered) to the training data prior to\nclassification. In this paper, we propose a simple yet robust local block-based\nsparsity model, using adaptively-constructed dictionaries from local features\nin the training data, to overcome this misalignment problem. Our approach is\ninspired by human perception: we analyze a series of local discriminative\nfeatures and combine them to arrive at the final classification decision. We\npropose a probabilistic graphical model framework to explicitly mine the\nconditional dependencies between these distinct sparse local features. In\nparticular, we learn discriminative graphs on sparse representations obtained\nfrom distinct local slices of a face. Conditional correlations between these\nsparse features are first discovered (in the training phase), and subsequently\nexploited to bring about significant improvements in recognition rates.\nExperimental results obtained on benchmark face databases demonstrate the\neffectiveness of the proposed algorithms in the presence of multiple\nregistration errors (such as translation, rotation, and scaling) as well as\nunder variations of pose and illumination.\n",
        "published": "2011-11-08T16:04:58Z",
        "pdf_link": "http://arxiv.org/pdf/1111.1947v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.2391v1",
        "title": "A Novel Approach to Texture classification using statistical feature",
        "summary": "  Texture is an important spatial feature which plays a vital role in content\nbased image retrieval. The enormous growth of the internet and the wide use of\ndigital data have increased the need for both efficient image database creation\nand retrieval procedure. This paper describes a new approach for texture\nclassification by combining statistical texture features of Local Binary\nPattern and Texture spectrum. Since most significant information of a texture\noften appears in the high frequency channels, the features are extracted by the\ncomputation of LBP and Texture Spectrum and Legendre Moments. Euclidean\ndistance is used for similarity measurement. The experimental result shows that\n97.77% classification accuracy is obtained by the proposed method.\n",
        "published": "2011-11-10T04:28:08Z",
        "pdf_link": "http://arxiv.org/pdf/1111.2391v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.3818v1",
        "title": "Good Pairs of Adjacency Relations in Arbitrary Dimensions",
        "summary": "  In this text we show, that the notion of a \"good pair\" that was introduced in\nthe paper \"Digital Manifolds and the Theorem of Jordan-Brouwer\" has actually\nknown models. We will show, how to choose cubical adjacencies, the\ngeneralizations of the well known 4- and 8-neighborhood to arbitrary\ndimensions, in order to find good pairs. Furthermore, we give another proof for\nthe well known fact that the Khalimsky-topology implies good pairs. The outcome\nis consistent with the known theory as presented by T.Y. Kong, A. Rosenfeld,\nG.T. Herman and M. Khachan et.al and gives new insights in higher dimensions.\n",
        "published": "2011-11-16T14:37:07Z",
        "pdf_link": "http://arxiv.org/pdf/1111.3818v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.4052v1",
        "title": "A Facial Expression Classification System Integrating Canny, Principal\n  Component Analysis and Artificial Neural Network",
        "summary": "  Facial Expression Classification is an interesting research problem in recent\nyears. There are a lot of methods to solve this problem. In this research, we\npropose a novel approach using Canny, Principal Component Analysis (PCA) and\nArtificial Neural Network. Firstly, in preprocessing phase, we use Canny for\nlocal region detection of facial images. Then each of local region's features\nwill be presented based on Principal Component Analysis (PCA). Finally, using\nArtificial Neural Network (ANN)applies for Facial Expression Classification. We\napply our proposal method (Canny_PCA_ANN) for recognition of six basic facial\nexpressions on JAFFE database consisting 213 images posed by 10 Japanese female\nmodels. The experimental result shows the feasibility of our proposal method.\n",
        "published": "2011-11-17T10:43:08Z",
        "pdf_link": "http://arxiv.org/pdf/1111.4052v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.4290v1",
        "title": "A Single Euler Number Feature for Multi-font Multi-size Kannada Numeral\n  Recognition",
        "summary": "  In this paper a novel approach is proposed based on single Euler number\nfeature which is free from thinning and size normalization for multi-font and\nmulti-size Kannada numeral recognition system. A nearest neighbor\nclassification is used for classification of Kannada numerals by considering\nthe Euclidian distance. A total 1500 numeral images with different font sizes\nbetween (10..84) are tested for algorithm efficiency and the overall the\nclassification accuracy is found to be 99.00% .The said method is thinning\nfree, fast, and showed encouraging results on varying font styles and sizes of\nKannada numerals.\n",
        "published": "2011-11-18T06:34:07Z",
        "pdf_link": "http://arxiv.org/pdf/1111.4290v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.4291v1",
        "title": "Multi-font Multi-size Kannada Numeral Recognition Based on Structural\n  Features",
        "summary": "  In this paper a fast and novel method is proposed for multi-font multi-size\nKannada numeral recognition which is thinning free and without size\nnormalization approach. The different structural feature are used for numeral\nrecognition namely, directional density of pixels in four directions, water\nreservoirs, maximum profile distances, and fill hole density are used for the\nrecognition of Kannada numerals. A Euclidian minimum distance criterion is used\nto find minimum distances and K-nearest neighbor classifier is used to classify\nthe Kannada numerals by varying the size of numeral image from 16 to 50 font\nsizes for the 20 different font styles from NUDI and BARAHA popular word\nprocessing Kannada software. The total 1150 numeral images are tested and the\noverall accuracy of classification is found to be 100%. The average time taken\nby this method is 0.1476 seconds.\n",
        "published": "2011-11-18T06:59:35Z",
        "pdf_link": "http://arxiv.org/pdf/1111.4291v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.4619v1",
        "title": "Redundant Wavelets on Graphs and High Dimensional Data Clouds",
        "summary": "  In this paper, we propose a new redundant wavelet transform applicable to\nscalar functions defined on high dimensional coordinates, weighted graphs and\nnetworks. The proposed transform utilizes the distances between the given data\npoints. We modify the filter-bank decomposition scheme of the redundant wavelet\ntransform by adding in each decomposition level linear operators that reorder\nthe approximation coefficients. These reordering operators are derived by\norganizing the tree-node features so as to shorten the path that passes through\nthese points. We explore the use of the proposed transform to image denoising,\nand show that it achieves denoising results that are close to those obtained\nwith the BM3D algorithm.\n",
        "published": "2011-11-20T08:58:45Z",
        "pdf_link": "http://arxiv.org/pdf/1111.4619v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.4654v1",
        "title": "A self-portrait of young Leonardo",
        "summary": "  One of the most famous drawings by Leonardo da Vinci is a self-portrait in\nred chalk, where he looks quite old. In fact, there is a sketch in one of his\nnotebooks, partially covered by written notes, that can be a self-portrait of\nthe artist when he was young. The use of image processing, to remove the\nhandwritten text and improve the image, allows a comparison of the two\nportraits.\n",
        "published": "2011-11-20T17:41:01Z",
        "pdf_link": "http://arxiv.org/pdf/1111.4654v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.4676v1",
        "title": "Facial Asymmetry and Emotional Expression",
        "summary": "  This report is about facial asymmetry, its connection to emotional\nexpression, and methods of measuring facial asymmetry in videos of faces. The\nresearch was motivated by two factors: firstly, there was a real opportunity to\ndevelop a novel measure of asymmetry that required minimal human involvement\nand that improved on earlier measures in the literature; and secondly, the\nstudy of the relationship between facial asymmetry and emotional expression is\nboth interesting in its own right, and important because it can inform\nneuropsychological theory and answer open questions concerning emotional\nprocessing in the brain. The two aims of the research were: first, to develop\nan automatic frame-by-frame measure of facial asymmetry in videos of faces that\nimproved on previous measures; and second, to use the measure to analyse the\nrelationship between facial asymmetry and emotional expression, and connect our\nfindings with previous research of the relationship.\n",
        "published": "2011-11-20T20:55:07Z",
        "pdf_link": "http://arxiv.org/pdf/1111.4676v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.5108v1",
        "title": "A Theory for Optical flow-based Transport on Image Manifolds",
        "summary": "  An image articulation manifold (IAM) is the collection of images formed when\nan object is articulated in front of a camera. IAMs arise in a variety of image\nprocessing and computer vision applications, where they provide a natural\nlow-dimensional embedding of the collection of high-dimensional images. To date\nIAMs have been studied as embedded submanifolds of Euclidean spaces.\nUnfortunately, their promise has not been realized in practice, because real\nworld imagery typically contains sharp edges that render an IAM\nnon-differentiable and hence non-isometric to the low-dimensional parameter\nspace under the Euclidean metric. As a result, the standard tools from\ndifferential geometry, in particular using linear tangent spaces to transport\nalong the IAM, have limited utility. In this paper, we explore a nonlinear\ntransport operator for IAMs based on the optical flow between images and\ndevelop new analytical tools reminiscent of those from differential geometry\nusing the idea of optical flow manifolds (OFMs). We define a new metric for\nIAMs that satisfies certain local isometry conditions, and we show how to use\nthis metric to develop a new tools such as flow fields on IAMs, parallel flow\nfields, parallel transport, as well as a intuitive notion of curvature. The\nspace of optical flow fields along a path of constant curvature has a natural\nmulti-scale structure via a monoid structure on the space of all flow fields\nalong a path. We also develop lower bounds on approximation errors while\napproximating non-parallel flow fields by parallel flow fields.\n",
        "published": "2011-11-22T05:55:25Z",
        "pdf_link": "http://arxiv.org/pdf/1111.5108v1"
    },
    {
        "id": "http://arxiv.org/abs/1111.6030v2",
        "title": "An image processing of a Raphael's portrait of Leonardo",
        "summary": "  In one of his paintings, the School of Athens, Raphael is depicting Leonardo\nda Vinci as the philosopher Plato. Some image processing tools can help us in\ncomparing this portrait with two Leonardo's portraits, considered as\nself-portraits.\n",
        "published": "2011-11-25T15:46:37Z",
        "pdf_link": "http://arxiv.org/pdf/1111.6030v2"
    },
    {
        "id": "http://arxiv.org/abs/1111.7271v1",
        "title": "Invariant texture analysis through Local Binary Patterns",
        "summary": "  In many image processing applications, such as segmentation and\nclassification, the selection of robust features descriptors is crucial to\nimprove the discrimination capabilities in real world scenarios. In particular,\nit is well known that image textures constitute power visual cues for feature\nextraction and classification. In the past few years the local binary pattern\n(LBP) approach, a texture descriptor method proposed by Ojala et al., has\ngained increased acceptance due to its computational simplicity and more\nimportantly for encoding a powerful signature for describing textures. However,\nthe original algorithm presents some limitations such as noise sensitivity and\nits lack of rotational invariance which have led to many proposals or\nextensions in order to overcome such limitations. In this paper we performed a\nquantitative study of the Ojala's original LBP proposal together with other\nrecently proposed LBP extensions in the presence of rotational, illumination\nand noisy changes. In the experiments we have considered two different\ndatabases: Brodatz and CUReT for different sizes of LBP masks. Experimental\nresults demonstrated the effectiveness and robustness of the described texture\ndescriptors for images that are subjected to geometric or radiometric changes.\n",
        "published": "2011-11-30T18:58:53Z",
        "pdf_link": "http://arxiv.org/pdf/1111.7271v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.0059v1",
        "title": "Local Naive Bayes Nearest Neighbor for Image Classification",
        "summary": "  We present Local Naive Bayes Nearest Neighbor, an improvement to the NBNN\nimage classification algorithm that increases classification accuracy and\nimproves its ability to scale to large numbers of object classes. The key\nobservation is that only the classes represented in the local neighborhood of a\ndescriptor contribute significantly and reliably to their posterior probability\nestimates. Instead of maintaining a separate search structure for each class,\nwe merge all of the reference data together into one search structure, allowing\nquick identification of a descriptor's local neighborhood. We show an increase\nin classification accuracy when we ignore adjustments to the more distant\nclasses and show that the run time grows with the log of the number of classes\nrather than linearly in the number of classes as did the original. This gives a\n100 times speed-up over the original method on the Caltech 256 dataset. We also\nprovide the first head-to-head comparison of NBNN against spatial pyramid\nmethods using a common set of input features. We show that local NBNN\noutperforms all previous NBNN based methods and the original spatial pyramid\nmodel. However, we find that local NBNN, while competitive with, does not beat\nstate-of-the-art spatial pyramid methods that use local soft assignment and\nmax-pooling.\n",
        "published": "2011-12-01T01:19:08Z",
        "pdf_link": "http://arxiv.org/pdf/1112.0059v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.0655v1",
        "title": "A Biomimetic Model of the Outer Plexiform Layer by Incorporating\n  Memristive Devices",
        "summary": "  In this paper we present a biorealistic model for the first part of the early\nvision processing by incorporating memristive nanodevices. The architecture of\nthe proposed network is based on the organisation and functioning of the outer\nplexiform layer (OPL) in the vertebrate retina. We demonstrate that memristive\ndevices are indeed a valuable building block for neuromorphic architectures, as\ntheir highly non-linear and adaptive response could be exploited for\nestablishing ultra-dense networks with similar dynamics to their biological\ncounterparts. We particularly show that hexagonal memristive grids can be\nemployed for faithfully emulating the smoothing-effect occurring at the OPL for\nenhancing the dynamic range of the system. In addition, we employ a\nmemristor-based thresholding scheme for detecting the edges of grayscale\nimages, while the proposed system is also evaluated for its adaptation and\nfault tolerance capacity against different light or noise conditions as well as\ndistinct device yields.\n",
        "published": "2011-12-03T13:53:54Z",
        "pdf_link": "http://arxiv.org/pdf/1112.0655v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.1200v1",
        "title": "A multi-feature tracking algorithm enabling adaptation to context\n  variations",
        "summary": "  We propose in this paper a tracking algorithm which is able to adapt itself\nto different scene contexts. A feature pool is used to compute the matching\nscore between two detected objects. This feature pool includes 2D, 3D\ndisplacement distances, 2D sizes, color histogram, histogram of oriented\ngradient (HOG), color covariance and dominant color. An offline learning\nprocess is proposed to search for useful features and to estimate their weights\nfor each context. In the online tracking process, a temporal window is defined\nto establish the links between the detected objects. This enables to find the\nobject trajectories even if the objects are misdetected in some frames. A\ntrajectory filter is proposed to remove noisy trajectories. Experimentation on\ndifferent contexts is shown. The proposed tracker has been tested in videos\nbelonging to three public datasets and to the Caretaker European project. The\nexperimental results prove the effect of the proposed feature weight learning,\nand the robustness of the proposed tracker compared to some methods in the\nstate of the art. The contributions of our approach over the state of the art\ntrackers are: (i) a robust tracking algorithm based on a feature pool, (ii) a\nsupervised learning scheme to learn feature weights for each context, (iii) a\nnew method to quantify the reliability of HOG descriptor, (iv) a combination of\ncolor covariance and dominant color features with spatial pyramid distance to\nmanage the case of object occlusion.\n",
        "published": "2011-12-06T09:19:17Z",
        "pdf_link": "http://arxiv.org/pdf/1112.1200v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.1484v1",
        "title": "POCS Based Super-Resolution Image Reconstruction Using an Adaptive\n  Regularization Parameter",
        "summary": "  Crucial information barely visible to the human eye is often embedded in a\nseries of low-resolution images taken of the same scene. Super-resolution\nenables the extraction of this information by reconstructing a single image, at\na high resolution than is present in any of the individual images. This is\nparticularly useful in forensic imaging, where the extraction of minute details\nin an image can help to solve a crime. Super-resolution image restoration has\nbeen one of the most important research areas in recent years which goals to\nobtain a high resolution (HR) image from several low resolutions (LR) blurred,\nnoisy, under sampled and displaced images. Relation of the HR image and LR\nimages can be modeled by a linear system using a transformation matrix and\nadditive noise. However, a unique solution may not be available because of the\nsingularity of transformation matrix. To overcome this problem, POCS method has\nbeen used. However, their performance is not good because the effect of noise\nenergy has been ignored. In this paper, we propose an adaptive regularization\napproach based on the fact that the regularization parameter should be a linear\nfunction of noise variance. The performance of the proposed approach has been\ntested on several images and the obtained results demonstrate the superiority\nof our approach compared with existing methods.\n",
        "published": "2011-12-07T06:29:07Z",
        "pdf_link": "http://arxiv.org/pdf/1112.1484v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.1496v3",
        "title": "Re-initialization Free Level Set Evolution via Reaction Diffusion",
        "summary": "  This paper presents a novel reaction-diffusion (RD) method for implicit\nactive contours, which is completely free of the costly re-initialization\nprocedure in level set evolution (LSE). A diffusion term is introduced into\nLSE, resulting in a RD-LSE equation, to which a piecewise constant solution can\nbe derived. In order to have a stable numerical solution of the RD based LSE,\nwe propose a two-step splitting method (TSSM) to iteratively solve the RD-LSE\nequation: first iterating the LSE equation, and then solving the diffusion\nequation. The second step regularizes the level set function obtained in the\nfirst step to ensure stability, and thus the complex and costly\nre-initialization procedure is completely eliminated from LSE. By successfully\napplying diffusion to LSE, the RD-LSE model is stable by means of the simple\nfinite difference method, which is very easy to implement. The proposed RD\nmethod can be generalized to solve the LSE for both variational level set\nmethod and PDE-based level set method. The RD-LSE method shows very good\nperformance on boundary anti-leakage, and it can be readily extended to high\ndimensional level set method. The extensive and promising experimental results\non synthetic and real images validate the effectiveness of the proposed RD-LSE\napproach.\n",
        "published": "2011-12-07T08:16:48Z",
        "pdf_link": "http://arxiv.org/pdf/1112.1496v3"
    },
    {
        "id": "http://arxiv.org/abs/1112.2386v1",
        "title": "Improvement of BM3D Algorithm and Employment to Satellite and CFA Images\n  Denoising",
        "summary": "  This paper proposes a new procedure in order to improve the performance of\nblock matching and 3-D filtering (BM3D) image denoising algorithm. It is\ndemonstrated that it is possible to achieve a better performance than that of\nBM3D algorithm in a variety of noise levels. This method changes BM3D algorithm\nparameter values according to noise level, removes prefiltering, which is used\nin high noise level; therefore Peak Signal-to-Noise Ratio (PSNR) and visual\nquality get improved, and BM3D complexities and processing time are reduced.\nThis improved BM3D algorithm is extended and used to denoise satellite and\ncolor filter array (CFA) images. Output results show that the performance has\nupgraded in comparison with current methods of denoising satellite and CFA\nimages. In this regard this algorithm is compared with Adaptive PCA algorithm,\nthat has led to superior performance for denoising CFA images, on the subject\nof PSNR and visual quality. Also the processing time has decreased\nsignificantly.\n",
        "published": "2011-12-11T18:57:10Z",
        "pdf_link": "http://arxiv.org/pdf/1112.2386v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.2903v1",
        "title": "Large Scale Correlation Clustering Optimization",
        "summary": "  Clustering is a fundamental task in unsupervised learning. The focus of this\npaper is the Correlation Clustering functional which combines positive and\nnegative affinities between the data points. The contribution of this paper is\ntwo fold: (i) Provide a theoretic analysis of the functional. (ii) New\noptimization algorithms which can cope with large scale problems (>100K\nvariables) that are infeasible using existing methods. Our theoretic analysis\nprovides a probabilistic generative interpretation for the functional, and\njustifies its intrinsic \"model-selection\" capability. Furthermore, we draw an\nanalogy between optimizing this functional and the well known Potts energy\nminimization. This analogy allows us to suggest several new optimization\nalgorithms, which exploit the intrinsic \"model-selection\" capability of the\nfunctional to automatically recover the underlying number of clusters. We\ncompare our algorithms to existing methods on both synthetic and real data. In\naddition we suggest two new applications that are made possible by our\nalgorithms: unsupervised face identification and interactive multi-object\nsegmentation by rough boundary delineation.\n",
        "published": "2011-12-13T14:28:12Z",
        "pdf_link": "http://arxiv.org/pdf/1112.2903v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.2988v2",
        "title": "Supervised Generative Reconstruction: An Efficient Way To Flexibly Store\n  and Recognize Patterns",
        "summary": "  Matching animal-like flexibility in recognition and the ability to quickly\nincorporate new information remains difficult. Limits are yet to be adequately\naddressed in neural models and recognition algorithms. This work proposes a\nconfiguration for recognition that maintains the same function of conventional\nalgorithms but avoids combinatorial problems. Feedforward recognition\nalgorithms such as classical artificial neural networks and machine learning\nalgorithms are known to be subject to catastrophic interference and forgetting.\nModifying or learning new information (associations between patterns and\nlabels) causes loss of previously learned information. I demonstrate using\nmathematical analysis how supervised generative models, with feedforward and\nfeedback connections, can emulate feedforward algorithms yet avoid catastrophic\ninterference and forgetting. Learned information in generative models is stored\nin a more intuitive form that represents the fixed points or solutions of the\nnetwork and moreover displays similar difficulties as cognitive phenomena.\nBrain-like capabilities and limits associated with generative models suggest\nthe brain may perform recognition and store information using a similar\napproach. Because of the central role of recognition, progress understanding\nthe underlying principles may reveal significant insight on how to better study\nand integrate with the brain.\n",
        "published": "2011-12-13T18:10:11Z",
        "pdf_link": "http://arxiv.org/pdf/1112.2988v2"
    },
    {
        "id": "http://arxiv.org/abs/1112.3697v1",
        "title": "Insights from Classifying Visual Concepts with Multiple Kernel Learning",
        "summary": "  Combining information from various image features has become a standard\ntechnique in concept recognition tasks. However, the optimal way of fusing the\nresulting kernel functions is usually unknown in practical applications.\nMultiple kernel learning (MKL) techniques allow to determine an optimal linear\ncombination of such similarity matrices. Classical approaches to MKL promote\nsparse mixtures. Unfortunately, so-called 1-norm MKL variants are often\nobserved to be outperformed by an unweighted sum kernel. The contribution of\nthis paper is twofold: We apply a recently developed non-sparse MKL variant to\nstate-of-the-art concept recognition tasks within computer vision. We provide\ninsights on benefits and limits of non-sparse MKL and compare it against its\ndirect competitors, the sum kernel SVM and the sparse MKL. We report empirical\nresults for the PASCAL VOC 2009 Classification and ImageCLEF2010 Photo\nAnnotation challenge data sets. About to be submitted to PLoS ONE.\n",
        "published": "2011-12-16T01:06:47Z",
        "pdf_link": "http://arxiv.org/pdf/1112.3697v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.4060v1",
        "title": "A real time vehicles detection algorithm for vision based sensors",
        "summary": "  A vehicle detection plays an important role in the traffic control at\nsignalised intersections. This paper introduces a vision-based algorithm for\nvehicles presence recognition in detection zones. The algorithm uses linguistic\nvariables to evaluate local attributes of an input image. The image attributes\nare categorised as vehicle, background or unknown features. Experimental\nresults on complex traffic scenes show that the proposed algorithm is effective\nfor a real-time vehicles detection.\n",
        "published": "2011-12-17T14:50:50Z",
        "pdf_link": "http://arxiv.org/pdf/1112.4060v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.4064v1",
        "title": "Vehicles Recognition Using Fuzzy Descriptors of Image Segments",
        "summary": "  In this paper a vision-based vehicles recognition method is presented.\nProposed method uses fuzzy description of image segments for automatic\nrecognition of vehicles recorded in image data. The description takes into\naccount selected geometrical properties and shape coefficients determined for\nsegments of reference image (vehicle model). The proposed method was\nimplemented using reasoning system with fuzzy rules. A vehicles recognition\nalgorithm was developed based on the fuzzy rules describing shape and\narrangement of the image segments that correspond to visible parts of a\nvehicle. An extension of the algorithm with set of fuzzy rules defined for\ndifferent reference images (and various vehicle shapes) enables vehicles\nclassification in traffic scenes. The devised method is suitable for\napplication in video sensors for road traffic control and surveillance systems.\n",
        "published": "2011-12-17T15:21:22Z",
        "pdf_link": "http://arxiv.org/pdf/1112.4064v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.4135v1",
        "title": "A Reduced Reference Image Quality Measure Using Bessel K Forms Model for\n  Tetrolet Coefficients",
        "summary": "  In this paper, we introduce a Reduced Reference Image Quality Assessment\n(RRIQA) measure based on the natural image statistic approach. A new adaptive\ntransform called \"Tetrolet\" is applied to both reference and distorted images.\nTo model the marginal distribution of tetrolet coefficients Bessel K Forms\n(BKF) density is proposed. Estimating the parameters of this distribution\nallows to summarize the reference image with a small amount of side\ninformation. Five distortion measures based on the BKF parameters of the\noriginal and processed image are used to predict quality scores. A comparison\nbetween these measures is presented showing a good consistency with human\njudgment.\n",
        "published": "2011-12-18T08:11:59Z",
        "pdf_link": "http://arxiv.org/pdf/1112.4135v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.4164v5",
        "title": "A Geometric Approach For Fully Automatic Chromosome Segmentation",
        "summary": "  A fundamental task in human chromosome analysis is chromosome segmentation.\nSegmentation plays an important role in chromosome karyotyping. The first step\nin segmentation is to remove intrusive objects such as stain debris and other\nnoises. The next step is detection of touching and overlapping chromosomes, and\nthe final step is separation of such chromosomes. Common methods for separation\nbetween touching chromosomes are interactive and require human intervention for\ncorrect separation between touching and overlapping chromosomes. In this paper,\na geometric-based method is used for automatic detection of touching and\noverlapping chromosomes and separating them. The proposed scheme performs\nsegmentation in two phases. In the first phase, chromosome clusters are\ndetected using three geometric criteria, and in the second phase, chromosome\nclusters are separated using a cut-line. Most of earlier methods did not work\nproperly in case of chromosome clusters that contained more than two\nchromosomes. Our method, on the other hand, is quite efficient in separation of\nsuch chromosome clusters. At each step, one separation will be performed and\nthis algorithm is repeated until all individual chromosomes are separated.\nAnother important point about the proposed method is that it uses the geometric\nfeatures of chromosomes which are independent of the type of images and it can\neasily be applied to any type of images such as binary images and does not\nrequire multispectral images as well. We have applied our method to a database\ncontaining 62 touching and partially overlapping chromosomes and a success rate\nof 91.9% is achieved.\n",
        "published": "2011-12-18T15:46:18Z",
        "pdf_link": "http://arxiv.org/pdf/1112.4164v5"
    },
    {
        "id": "http://arxiv.org/abs/1112.5298v1",
        "title": "Zero-Temperature Limit of a Convergent Algorithm to Minimize the Bethe\n  Free Energy",
        "summary": "  After the discovery that fixed points of loopy belief propagation coincide\nwith stationary points of the Bethe free energy, several researchers proposed\nprovably convergent algorithms to directly minimize the Bethe free energy.\nThese algorithms were formulated only for non-zero temperature (thus finding\nfixed points of the sum-product algorithm) and their possible extension to zero\ntemperature is not obvious. We present the zero-temperature limit of the\ndouble-loop algorithm by Heskes, which converges a max-product fixed point. The\ninner loop of this algorithm is max-sum diffusion. Under certain conditions,\nthe algorithm combines the complementary advantages of the max-product belief\npropagation and max-sum diffusion (LP relaxation): it yields good approximation\nof both ground states and max-marginals.\n",
        "published": "2011-12-22T13:10:05Z",
        "pdf_link": "http://arxiv.org/pdf/1112.5298v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.5638v1",
        "title": "Discretization of Parametrizable Signal Manifolds",
        "summary": "  Transformation-invariant analysis of signals often requires the computation\nof the distance from a test pattern to a transformation manifold. In\nparticular, the estimation of the distances between a transformed query signal\nand several transformation manifolds representing different classes provides\nessential information for the classification of the signal. In many\napplications the computation of the exact distance to the manifold is costly,\nwhereas an efficient practical solution is the approximation of the manifold\ndistance with the aid of a manifold grid. In this paper, we consider a setting\nwith transformation manifolds of known parameterization. We first present an\nalgorithm for the selection of samples from a single manifold that permits to\nminimize the average error in the manifold distance estimation. Then we propose\na method for the joint discretization of multiple manifolds that represent\ndifferent signal classes, where we optimize the transformation-invariant\nclassification accuracy yielded by the discrete manifold representation.\nExperimental results show that sampling each manifold individually by\nminimizing the manifold distance estimation error outperforms baseline sampling\nsolutions with respect to registration and classification accuracy. Performing\nan additional joint optimization on all samples improves the classification\nperformance further. Moreover, given a fixed total number of samples to be\nselected from all manifolds, an asymmetric distribution of samples to different\nmanifolds depending on their geometric structures may also increase the\nclassification accuracy in comparison with the equal distribution of samples.\n",
        "published": "2011-12-23T19:08:10Z",
        "pdf_link": "http://arxiv.org/pdf/1112.5638v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.5640v5",
        "title": "Learning Smooth Pattern Transformation Manifolds",
        "summary": "  Manifold models provide low-dimensional representations that are useful for\nprocessing and analyzing data in a transformation-invariant way. In this paper,\nwe study the problem of learning smooth pattern transformation manifolds from\nimage sets that represent observations of geometrically transformed signals. In\norder to construct a manifold, we build a representative pattern whose\ntransformations accurately fit various input images. We examine two objectives\nof the manifold building problem, namely, approximation and classification. For\nthe approximation problem, we propose a greedy method that constructs a\nrepresentative pattern by selecting analytic atoms from a continuous dictionary\nmanifold. We present a DC (Difference-of-Convex) optimization scheme that is\napplicable to a wide range of transformation and dictionary models, and\ndemonstrate its application to transformation manifolds generated by rotation,\ntranslation and anisotropic scaling of a reference pattern. Then, we generalize\nthis approach to a setting with multiple transformation manifolds, where each\nmanifold represents a different class of signals. We present an iterative\nmultiple manifold building algorithm such that the classification accuracy is\npromoted in the learning of the representative patterns. Experimental results\nsuggest that the proposed methods yield high accuracy in the approximation and\nclassification of data compared to some reference methods, while the invariance\nto geometric transformations is achieved due to the transformation manifold\nmodel.\n",
        "published": "2011-12-23T19:13:31Z",
        "pdf_link": "http://arxiv.org/pdf/1112.5640v5"
    },
    {
        "id": "http://arxiv.org/abs/1112.5895v1",
        "title": "Online Adaptive Statistical Compressed Sensing of Gaussian Mixture\n  Models",
        "summary": "  A framework of online adaptive statistical compressed sensing is introduced\nfor signals following a mixture model. The scheme first uses non-adaptive\nmeasurements, from which an online decoding scheme estimates the model\nselection. As soon as a candidate model has been selected, an optimal sensing\nscheme for the selected model continues to apply. The final signal\nreconstruction is calculated from the ensemble of both the non-adaptive and the\nadaptive measurements. For signals generated from a Gaussian mixture model, the\nonline adaptive sensing algorithm is given and its performance is analyzed. On\nboth synthetic and real image data, the proposed adaptive scheme considerably\nreduces the average reconstruction error with respect to standard statistical\ncompressed sensing that uses fully random measurements, at a marginally\nincreased computational complexity.\n",
        "published": "2011-12-26T21:42:22Z",
        "pdf_link": "http://arxiv.org/pdf/1112.5895v1"
    },
    {
        "id": "http://arxiv.org/abs/1112.5997v3",
        "title": "Multispectral Palmprint Recognition Using a Hybrid Feature",
        "summary": "  Personal identification problem has been a major field of research in recent\nyears. Biometrics-based technologies that exploit fingerprints, iris, face,\nvoice and palmprints, have been in the center of attention to solve this\nproblem. Palmprints can be used instead of fingerprints that have been of the\nearliest of these biometrics technologies. A palm is covered with the same skin\nas the fingertips but has a larger surface, giving us more information than the\nfingertips. The major features of the palm are palm-lines, including principal\nlines, wrinkles and ridges. Using these lines is one of the most popular\napproaches towards solving the palmprint recognition problem. Another robust\nfeature is the wavelet energy of palms. In this paper we used a hybrid feature\nwhich combines both of these features. %Moreover, multispectral analysis is\napplied to improve the performance of the system. At the end, minimum distance\nclassifier is used to match test images with one of the training samples. The\nproposed algorithm has been tested on a well-known multispectral palmprint\ndataset and achieved an average accuracy of 98.8\\%.\n",
        "published": "2011-12-27T18:19:04Z",
        "pdf_link": "http://arxiv.org/pdf/1112.5997v3"
    },
    {
        "id": "http://arxiv.org/abs/1112.6269v1",
        "title": "Automated PolyU Palmprint sample Registration and Coarse Classification",
        "summary": "  Biometric based authentication for secured access to resources has gained\nimportance, due to their reliable, invariant and discriminating features.\nPalmprint is one such biometric entity. Prior to classification and\nidentification registering a sample palmprint is an important activity. In this\npaper we propose a computationally effective method for automated registration\nof samples from PlolyU palmprint database. In our approach we preprocess the\nsample and trace the border to find the nearest point from center of sample.\nAngle between vector representing the nearest point and vector passing through\nthe center is used for automated palm sample registration. The angle of\ninclination between start and end point of heart line and life line is used for\nbasic classification of palmprint samples in left class and right class.\n",
        "published": "2011-12-29T10:35:01Z",
        "pdf_link": "http://arxiv.org/pdf/1112.6269v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.0566v2",
        "title": "Learning joint intensity-depth sparse representations",
        "summary": "  This paper presents a method for learning overcomplete dictionaries composed\nof two modalities that describe a 3D scene: image intensity and scene depth. We\npropose a novel Joint Basis Pursuit (JBP) algorithm that finds related sparse\nfeatures in two modalities using conic programming and integrate it into a\ntwo-step dictionary learning algorithm. JBP differs from related convex\nalgorithms because it finds joint sparsity models with different atoms and\ndifferent coefficient values for intensity and depth. This is crucial for\nrecovering generative models where the same sparse underlying causes (3D\nfeatures) give rise to different signals (intensity and depth). We give a\ntheoretical bound for the sparse coefficient recovery error obtained by JBP,\nand show experimentally that JBP is far superior to the state of the art Group\nLasso algorithm. When applied to the Middlebury depth-intensity database, our\nlearning algorithm converges to a set of related features, such as pairs of\ndepth and intensity edges or image textures and depth slants. Finally, we show\nthat the learned dictionary and JBP achieve the state of the art depth\ninpainting performance on time-of-flight 3D data.\n",
        "published": "2012-01-03T03:47:09Z",
        "pdf_link": "http://arxiv.org/pdf/1201.0566v2"
    },
    {
        "id": "http://arxiv.org/abs/1201.1417v1",
        "title": "Picture Collage with Genetic Algorithm and Stereo vision",
        "summary": "  In this paper, a salient region extraction method for creating picture\ncollage based on stereo vision is proposed. Picture collage is a kind of visual\nimage summary to arrange all input images on a given canvas, allowing overlay,\nto maximize visible visual information. The salient regions of each image are\nfirstly extracted and represented as a depth map. The output picture collage\nshows as many visible salient regions (without being overlaid by others) from\nall images as possible. A very efficient Genetic algorithm is used here for the\noptimization. The experimental results showed the superior performance of the\nproposed method.\n",
        "published": "2011-11-29T06:24:33Z",
        "pdf_link": "http://arxiv.org/pdf/1201.1417v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.1571v3",
        "title": "A United Image Force for Deformable Models and Direct Transforming\n  Geometric Active Contorus to Snakes by Level Sets",
        "summary": "  A uniform distribution of the image force field around the object fasts the\nconvergence speed of the segmentation process. However, to achieve this aim, it\ncauses the force constructed from the heat diffusion model unable to indicate\nthe object boundaries accurately. The image force based on electrostatic field\nmodel can perform an exact shape recovery. First, this study introduces a\nfusion scheme of these two image forces, which is capable of extracting the\nobject boundary with high precision and fast speed. Until now, there is no\nsatisfied analysis about the relationship between Snakes and Geometric Active\nContours (GAC). The second contribution of this study addresses that the GAC\nmodel can be deduced directly from Snakes model. It proves that each term in\nGAC and Snakes is correspondent and has similar function. However, the two\nmodels are expressed using different mathematics. Further, since losing the\nability of rotating the contour, adoption of level sets can limits the usage of\nGAC in some circumstances.\n",
        "published": "2012-01-07T15:58:18Z",
        "pdf_link": "http://arxiv.org/pdf/1201.1571v3"
    },
    {
        "id": "http://arxiv.org/abs/1201.2050v1",
        "title": "Adaptive Noise Reduction Scheme for Salt and Pepper",
        "summary": "  In this paper, a new adaptive noise reduction scheme for images corrupted by\nimpulse noise is presented. The proposed scheme efficiently identifies and\nreduces salt and pepper noise. MAG (Mean Absolute Gradient) is used to identify\npixels which are most likely corrupted by salt and pepper noise that are\ncandidates for further median based noise reduction processing. Directional\nfiltering is then applied after noise reduction to achieve a good tradeoff\nbetween detail preservation and noise removal. The proposed scheme can remove\nsalt and pepper noise with noise density as high as 90% and produce better\nresult in terms of qualitative and quantitative measures of images.\n",
        "published": "2012-01-10T13:41:56Z",
        "pdf_link": "http://arxiv.org/pdf/1201.2050v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.2843v1",
        "title": "Nonparametric Sparse Representation",
        "summary": "  This paper suggests a nonparametric scheme to find the sparse solution of the\nunderdetermined system of linear equations in the presence of unknown impulsive\nor non-Gaussian noise. This approach is robust against any variations of the\nnoise model and its parameters. It is based on minimization of rank pseudo norm\nof the residual signal and l_1-norm of the signal of interest, simultaneously.\nWe use the steepest descent method to find the sparse solution via an iterative\nalgorithm. Simulation results show that our proposed method outperforms the\nexistence methods like OMP, BP, Lasso, and BCS whenever the observation vector\nis contaminated with measurement or environmental non-Gaussian noise with\nunknown parameters. Furthermore, for low SNR condition, the proposed method has\nbetter performance in the presence of Gaussian noise.\n",
        "published": "2012-01-13T14:05:59Z",
        "pdf_link": "http://arxiv.org/pdf/1201.2843v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.2905v2",
        "title": "NegCut: Automatic Image Segmentation based on MRF-MAP",
        "summary": "  Solving the Maximum a Posteriori on Markov Random Field, MRF-MAP, is a\nprevailing method in recent interactive image segmentation tools. Although\nmathematically explicit in its computational targets, and impressive for the\nsegmentation quality, MRF-MAP is hard to accomplish without the interactive\ninformation from users. So it is rarely adopted in the automatic style up to\ntoday. In this paper, we present an automatic image segmentation algorithm,\nNegCut, based on the approximation to MRF-MAP. First we prove MRF-MAP is\nNP-hard when the probabilistic models are unknown, and then present an\napproximation function in the form of minimum cuts on graphs with negative\nweights. Finally, the binary segmentation is taken from the largest eigenvector\nof the target matrix, with a tuned version of the Lanczos eigensolver. It is\nshown competitive at the segmentation quality in our experiments.\n",
        "published": "2012-01-13T18:18:03Z",
        "pdf_link": "http://arxiv.org/pdf/1201.2905v2"
    },
    {
        "id": "http://arxiv.org/abs/1201.2995v1",
        "title": "G-Lets: Signal Processing Using Transformation Groups",
        "summary": "  We present an algorithm using transformation groups and their irreducible\nrepresentations to generate an orthogonal basis for a signal in the vector\nspace of the signal. It is shown that multiresolution analysis can be done with\namplitudes using a transformation group. G-lets is thus not a single transform,\nbut a group of linear transformations related by group theory. The algorithm\nalso specifies that a multiresolution and multiscale analysis for each\nresolution is possible in terms of frequencies. Separation of low and high\nfrequency components of each amplitude resolution is facilitated by G-lets.\nUsing conjugacy classes of the transformation group, more than one set of basis\nmay be generated, giving a different perspective of the signal through each\nbasis. Applications for this algorithm include edge detection, feature\nextraction, denoising, face recognition, compression, and more. We analyze this\nalgorithm using dihedral groups as an example. We demonstrate the results with\nan ECG signal and the standard `Lena' image.\n",
        "published": "2012-01-14T07:18:06Z",
        "pdf_link": "http://arxiv.org/pdf/1201.2995v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.3109v1",
        "title": "Automatic system for counting cells with elliptical shape",
        "summary": "  This paper presents a new method for automatic quantification of ellipse-like\ncells in images, an important and challenging problem that has been studied by\nthe computer vision community. The proposed method can be described by two main\nsteps. Initially, image segmentation based on the k-means algorithm is\nperformed to separate different types of cells from the background. Then, a\nrobust and efficient strategy is performed on the blob contour for touching\ncells splitting. Due to the contour processing, the method achieves excellent\nresults of detection compared to manual detection performed by specialists.\n",
        "published": "2012-01-15T17:42:07Z",
        "pdf_link": "http://arxiv.org/pdf/1201.3109v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.3153v1",
        "title": "Fractal and Multi-Scale Fractal Dimension analysis: a comparative study\n  of Bouligand-Minkowski method",
        "summary": "  Shape is one of the most important visual attributes to characterize objects,\nplaying a important role in pattern recognition. There are various approaches\nto extract relevant information of a shape. An approach widely used in shape\nanalysis is the complexity, and Fractal Dimension and Multi-Scale Fractal\nDimension are both well-known methodologies to estimate it. This papers\npresents a comparative study between Fractal Dimension and Multi-Scale Fractal\nDimension in a shape analysis context. Through experimental comparison using a\nshape database previously classified, both methods are compared. Different\nparameters configuration of each method are considered and a discussion about\nthe results of each method is also presented.\n",
        "published": "2012-01-16T03:18:22Z",
        "pdf_link": "http://arxiv.org/pdf/1201.3153v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.3233v2",
        "title": "Variations of images to increase their visibility",
        "summary": "  The calculus of variations applied to the image processing requires some\nnumerical models able to perform the variations of images and the extremization\nof appropriate actions. To produce the variations of images, there are several\npossibilities based on the brightness maps. Before a numerical model, I propose\nan experimental approach, based on a tool of Gimp, GNU Image Manipulation\nProgram, in order to visualize how the image variations can be. After the\ndiscussion of this tool, which is able to strongly increase the visibility of\nimages, the variations and a possible functional for the visibility are\nproposed in the framework of a numerical model. The visibility functional is\nanalogous to the fringe visibility of the optical interference.\n",
        "published": "2012-01-16T12:31:27Z",
        "pdf_link": "http://arxiv.org/pdf/1201.3233v2"
    },
    {
        "id": "http://arxiv.org/abs/1201.3612v1",
        "title": "Spatiotemporal Gabor filters: a new method for dynamic texture\n  recognition",
        "summary": "  This paper presents a new method for dynamic texture recognition based on\nspatiotemporal Gabor filters. Dynamic textures have emerged as a new field of\ninvestigation that extends the concept of self-similarity of texture image to\nthe spatiotemporal domain. To model a dynamic texture, we convolve the sequence\nof images to a bank of spatiotemporal Gabor filters. For each response, a\nfeature vector is built by calculating the energy statistic. As far as the\nauthors know, this paper is the first to report an effective method for dynamic\ntexture recognition using spatiotemporal Gabor filters. We evaluate the\nproposed method on two challenging databases and the experimental results\nindicate that the proposed method is a robust approach for dynamic texture\nrecognition.\n",
        "published": "2012-01-17T20:26:04Z",
        "pdf_link": "http://arxiv.org/pdf/1201.3612v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.3720v1",
        "title": "A Multimodal Biometric System Using Linear Discriminant Analysis For\n  Improved Performance",
        "summary": "  Essentially a biometric system is a pattern recognition system which\nrecognizes a user by determining the authenticity of a specific anatomical or\nbehavioral characteristic possessed by the user. With the ever increasing\nintegration of computers and Internet into daily life style, it has become\nnecessary to protect sensitive and personal data. This paper proposes a\nmultimodal biometric system which incorporates more than one biometric trait to\nattain higher security and to handle failure to enroll situations for some\nusers. This paper is aimed at investigating a multimodal biometric identity\nsystem using Linear Discriminant Analysis as backbone to both facial and speech\nrecognition and implementing such system in real-time using SignalWAVE.\n",
        "published": "2012-01-18T08:20:00Z",
        "pdf_link": "http://arxiv.org/pdf/1201.3720v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.3803v1",
        "title": "Image Labeling and Segmentation using Hierarchical Conditional Random\n  Field Model",
        "summary": "  The use of hierarchical Conditional Random Field model deal with the problem\nof labeling images . At the time of labeling a new image, selection of the\nnearest cluster and using the related CRF model to label this image. When one\ngive input image, one first use the CRF model to get initial pixel labels then\nfinding the cluster with most similar images. Then at last relabeling the input\nimage by the CRF model associated with this cluster. This paper presents a\napproach to label and segment specific image having correct information.\n",
        "published": "2012-01-16T07:33:56Z",
        "pdf_link": "http://arxiv.org/pdf/1201.3803v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.3821v1",
        "title": "A PCA-Based Super-Resolution Algorithm for Short Image Sequences",
        "summary": "  In this paper, we present a novel, learning-based, two-step super-resolution\n(SR) algorithm well suited to solve the specially demanding problem of\nobtaining SR estimates from short image sequences. The first step, devoted to\nincrease the sampling rate of the incoming images, is performed by fitting\nlinear combinations of functions generated from principal components (PC) to\nreproduce locally the sparse projected image data, and using these models to\nestimate image values at nodes of the high-resolution grid. PCs were obtained\nfrom local image patches sampled at sub-pixel level, which were generated in\nturn from a database of high-resolution images by application of a physically\nrealistic observation model. Continuity between local image models is enforced\nby minimizing an adequate functional in the space of model coefficients. The\nsecond step, dealing with restoration, is performed by a linear filter with\ncoefficients learned to restore residual interpolation artifacts in addition to\nlow-resolution blurring, providing an effective coupling between both steps of\nthe method. Results on a demanding five-image scanned sequence of graphics and\ntext are presented, showing the excellent performance of the proposed method\ncompared to several state-of-the-art two-step and Bayesian Maximum a Posteriori\nSR algorithms.\n",
        "published": "2012-01-18T15:19:03Z",
        "pdf_link": "http://arxiv.org/pdf/1201.3821v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.3972v1",
        "title": "A Novel Approach to Fast Image Filtering Algorithm of Infrared Images\n  based on Intro Sort Algorithm",
        "summary": "  In this study we investigate the fast image filtering algorithm based on\nIntro sort algorithm and fast noise reduction of infrared images. Main feature\nof the proposed approach is that no prior knowledge of noise required. It is\ndeveloped based on Stefan- Boltzmann law and the Fourier law. We also\ninvestigate the fast noise reduction approach that has advantage of less\ncomputation load. In addition, it can retain edges, details, text information\neven if the size of the window increases. Intro sort algorithm begins with\nQuick sort and switches to heap sort when the recursion depth exceeds a level\nbased on the number of elements being sorted. This approach has the advantage\nof fast noise reduction by reducing the comparison time. It also significantly\nspeed up the noise reduction process and can apply to real-time image\nprocessing. This approach will extend the Infrared images applications for\nmedicine and video conferencing.\n",
        "published": "2012-01-19T04:57:36Z",
        "pdf_link": "http://arxiv.org/pdf/1201.3972v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.4139v1",
        "title": "Image decomposition with anisotropic diffusion applied to leaf-texture\n  analysis",
        "summary": "  Texture analysis is an important field of investigation that has received a\ngreat deal of interest from computer vision community. In this paper, we\npropose a novel approach for texture modeling based on partial differential\nequation (PDE). Each image $f$ is decomposed into a family of derived\nsub-images. $f$ is split into the $u$ component, obtained with anisotropic\ndiffusion, and the $v$ component which is calculated by the difference between\nthe original image and the $u$ component. After enhancing the texture attribute\n$v$ of the image, Gabor features are computed as descriptors. We validate the\nproposed approach on two texture datasets with high variability. We also\nevaluate our approach on an important real-world application: leaf-texture\nanalysis. Experimental results indicate that our approach can be used to\nproduce higher classification rates and can be successfully employed for\ndifferent texture applications.\n",
        "published": "2012-01-19T18:39:41Z",
        "pdf_link": "http://arxiv.org/pdf/1201.4139v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.4895v2",
        "title": "Compressive Acquisition of Dynamic Scenes",
        "summary": "  Compressive sensing (CS) is a new approach for the acquisition and recovery\nof sparse signals and images that enables sampling rates significantly below\nthe classical Nyquist rate. Despite significant progress in the theory and\nmethods of CS, little headway has been made in compressive video acquisition\nand recovery. Video CS is complicated by the ephemeral nature of dynamic\nevents, which makes direct extensions of standard CS imaging architectures and\nsignal models difficult. In this paper, we develop a new framework for video CS\nfor dynamic textured scenes that models the evolution of the scene as a linear\ndynamical system (LDS). This reduces the video recovery problem to first\nestimating the model parameters of the LDS from compressive measurements, and\nthen reconstructing the image frames. We exploit the low-dimensional dynamic\nparameters (the state sequence) and high-dimensional static parameters (the\nobservation matrix) of the LDS to devise a novel compressive measurement\nstrategy that measures only the dynamic part of the scene at each instant and\naccumulates measurements over time to estimate the static parameters. This\nenables us to lower the compressive measurement rate considerably. We validate\nour approach with a range of experiments involving both video recovery, sensing\nhyper-spectral data, and classification of dynamic scenes from compressive\ndata. Together, these applications demonstrate the effectiveness of the\napproach.\n",
        "published": "2012-01-23T23:19:59Z",
        "pdf_link": "http://arxiv.org/pdf/1201.4895v2"
    },
    {
        "id": "http://arxiv.org/abs/1201.5227v1",
        "title": "A New Local Adaptive Thresholding Technique in Binarization",
        "summary": "  Image binarization is the process of separation of pixel values into two\ngroups, white as background and black as foreground. Thresholding plays a major\nin binarization of images. Thresholding can be categorized into global\nthresholding and local thresholding. In images with uniform contrast\ndistribution of background and foreground like document images, global\nthresholding is more appropriate. In degraded document images, where\nconsiderable background noise or variation in contrast and illumination exists,\nthere exists many pixels that cannot be easily classified as foreground or\nbackground. In such cases, binarization with local thresholding is more\nappropriate. This paper describes a locally adaptive thresholding technique\nthat removes background by using local mean and mean deviation. Normally the\nlocal mean computational time depends on the window size. Our technique uses\nintegral sum image as a prior processing to calculate local mean. It does not\ninvolve calculations of standard deviations as in other local adaptive\ntechniques. This along with the fact that calculations of mean is independent\nof window size speed up the process as compared to other local thresholding\ntechniques.\n",
        "published": "2012-01-25T10:17:30Z",
        "pdf_link": "http://arxiv.org/pdf/1201.5227v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.5404v1",
        "title": "Task-Driven Adaptive Statistical Compressive Sensing of Gaussian Mixture\n  Models",
        "summary": "  A framework for adaptive and non-adaptive statistical compressive sensing is\ndeveloped, where a statistical model replaces the standard sparsity model of\nclassical compressive sensing. We propose within this framework optimal\ntask-specific sensing protocols specifically and jointly designed for\nclassification and reconstruction. A two-step adaptive sensing paradigm is\ndeveloped, where online sensing is applied to detect the signal class in the\nfirst step, followed by a reconstruction step adapted to the detected class and\nthe observed samples. The approach is based on information theory, here\ntailored for Gaussian mixture models (GMMs), where an information-theoretic\nobjective relationship between the sensed signals and a representation of the\nspecific task of interest is maximized. Experimental results using synthetic\nsignals, Landsat satellite attributes, and natural images of different sizes\nand with different noise levels show the improvements achieved using the\nproposed framework when compared to more standard sensing protocols. The\nunderlying formulation can be applied beyond GMMs, at the price of higher\nmathematical and computational complexity.\n",
        "published": "2012-01-25T22:25:27Z",
        "pdf_link": "http://arxiv.org/pdf/1201.5404v1"
    },
    {
        "id": "http://arxiv.org/abs/1201.5938v1",
        "title": "Comparing Methods for segmentation of Microcalcification Clusters in\n  Digitized Mammograms",
        "summary": "  The appearance of microcalcifications in mammograms is one of the early signs\nof breast cancer. So, early detection of microcalcification clusters (MCCs) in\nmammograms can be helpful for cancer diagnosis and better treatment of breast\ncancer. In this paper a computer method has been proposed to support\nradiologists in detection MCCs in digital mammography. First, in order to\nfacilitate and improve the detection step, mammogram images have been enhanced\nwith wavelet transformation and morphology operation. Then for segmentation of\nsuspicious MCCs, two methods have been investigated. The considered methods\nare: adaptive threshold and watershed segmentation. Finally, the detected MCCs\nareas in different algorithms will be compared to find out which segmentation\nmethod is more appropriate for extracting MCCs in mammograms.\n",
        "published": "2012-01-28T09:51:23Z",
        "pdf_link": "http://arxiv.org/pdf/1201.5938v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.0216v1",
        "title": "The watershed concept and its use in segmentation : a brief history",
        "summary": "  The watershed is one of the most used tools in image segmentation. We present\nhow its concept is born and developed over time. Its implementation as an\nalgorithm or a hardwired device evolved together with the technology which\nallowed it. We present also how it is used in practice, first together with\nmarkers, and later introduced in a multiscale framework, in order to produce\nnot a unique partition but a complete hierarchy.\n",
        "published": "2012-02-01T17:00:45Z",
        "pdf_link": "http://arxiv.org/pdf/1202.0216v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.0492v3",
        "title": "Resolving Implementation Ambiguity and Improving SURF",
        "summary": "  Speeded Up Robust Features (SURF) has emerged as one of the more popular\nfeature descriptors and detectors in recent years. Performance and algorithmic\ndetails vary widely between implementations due to SURF's complexity and\nambiguities found in its description. To resolve these ambiguities, a set of\ngeneral techniques for feature stability is defined based on the smoothness\nrule. Additional improvements to SURF are proposed for speed and stability. To\nillustrate the importance of these implementation details, a performance study\nof popular SURF implementations is done. By utilizing all the suggested\nimprovements, it is possible to create a SURF implementation that is several\ntimes faster and more stable.\n",
        "published": "2012-02-02T17:10:56Z",
        "pdf_link": "http://arxiv.org/pdf/1202.0492v3"
    },
    {
        "id": "http://arxiv.org/abs/1202.0549v1",
        "title": "Comparing Background Subtraction Algorithms and Method of Car Counting",
        "summary": "  In this paper, we compare various image background subtraction algorithms\nwith the ground truth of cars counted. We have given a sample of thousand\nimages, which are the snap shots of current traffic as records at various\nintersections and highways. We have also counted an approximate number of cars\nthat are visible in these images. In order to ascertain the accuracy of\nalgorithms to be used for the processing of million images, we compare them on\nmany metrics that includes (i) Scalability (ii) Accuracy (iii) Processing time.\n",
        "published": "2012-01-29T19:19:33Z",
        "pdf_link": "http://arxiv.org/pdf/1202.0549v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.0609v1",
        "title": "Wavelet-based deconvolution of ultrasonic signals in nondestructive\n  evaluation",
        "summary": "  In this paper, the inverse problem of reconstructing reflectivity function of\na medium is examined within a blind deconvolution framework. The ultrasound\npulse is estimated using higher-order statistics, and Wiener filter is used to\nobtain the ultrasonic reflectivity function through wavelet-based models. A new\napproach to the parameter estimation of the inverse filtering step is proposed\nin the nondestructive evaluation field, which is based on the theory of\nFourier-Wavelet regularized deconvolution (ForWaRD). This new approach can be\nviewed as a solution to the open problem of adaptation of the ForWaRD framework\nto perform the convolution kernel estimation and deconvolution\ninterdependently. The results indicate stable solutions of the estimated pulse\nand an improvement in the radio-frequency (RF) signal taking into account its\nsignal-to-noise ratio (SNR) and axial resolution. Simulations and experiments\nshowed that the proposed approach can provide robust and optimal estimates of\nthe reflectivity function.\n",
        "published": "2012-02-03T05:43:46Z",
        "pdf_link": "http://arxiv.org/pdf/1202.0609v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.1587v1",
        "title": "Automatic Clustering with Single Optimal Solution",
        "summary": "  Determining optimal number of clusters in a dataset is a challenging task.\nThough some methods are available, there is no algorithm that produces unique\nclustering solution. The paper proposes an Automatic Merging for Single Optimal\nSolution (AMSOS) which aims to generate unique and nearly optimal clusters for\nthe given datasets automatically. The AMSOS is iteratively merges the closest\nclusters automatically by validating with cluster validity measure to find\nsingle and nearly optimal clusters for the given data set. Experiments on both\nsynthetic and real data have proved that the proposed algorithm finds single\nand nearly optimal clustering structure in terms of number of clusters,\ncompactness and separation.\n",
        "published": "2012-02-08T03:26:01Z",
        "pdf_link": "http://arxiv.org/pdf/1202.1587v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.1685v1",
        "title": "Combined Haar-Hilbert and Log-Gabor Based Iris Encoders",
        "summary": "  This chapter shows that combining Haar-Hilbert and Log-Gabor improves iris\nrecognition performance leading to a less ambiguous biometric decision\nlandscape in which the overlap between the experimental intra- and interclass\nscore distributions diminishes or even vanishes. Haar-Hilbert, Log-Gabor and\ncombined Haar-Hilbert and Log-Gabor encoders are tested here both for single\nand dual iris approach. The experimental results confirm that the best\nperformance is obtained for the dual iris approach when the iris code is\ngenerated using the combined Haar-Hilbert and Log-Gabor encoder, and when the\nmatching score fuses the information from both Haar-Hilbert and Log-Gabor\nchannels of the combined encoder.\n",
        "published": "2012-02-08T13:07:10Z",
        "pdf_link": "http://arxiv.org/pdf/1202.1685v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.1943v1",
        "title": "3D Model Assisted Image Segmentation",
        "summary": "  The problem of segmenting a given image into coherent regions is important in\nComputer Vision and many industrial applications require segmenting a known\nobject into its components. Examples include identifying individual parts of a\ncomponent for process control work in a manufacturing plant and identifying\nparts of a car from a photo for automatic damage detection. Unfortunately most\nof an object's parts of interest in such applications share the same pixel\ncharacteristics, having similar colour and texture. This makes segmenting the\nobject into its components a non-trivial task for conventional image\nsegmentation algorithms. In this paper, we propose a \"Model Assisted\nSegmentation\" method to tackle this problem. A 3D model of the object is\nregistered over the given image by optimising a novel gradient based loss\nfunction. This registration obtains the full 3D pose from an image of the\nobject. The image can have an arbitrary view of the object and is not limited\nto a particular set of views. The segmentation is subsequently performed using\na level-set based method, using the projected contours of the registered 3D\nmodel as initialisation curves. The method is fully automatic and requires no\nuser interaction. Also, the system does not require any prior training. We\npresent our results on photographs of a real car.\n",
        "published": "2012-02-09T10:53:11Z",
        "pdf_link": "http://arxiv.org/pdf/1202.1943v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.1990v1",
        "title": "Non-parametric convolution based image-segmentation of ill-posed objects\n  applying context window approach",
        "summary": "  Context-dependence in human cognition process is a well-established fact.\nFollowing this, we introduced the image segmentation method that can use\ncontext to classify a pixel on the basis of its membership to a particular\nobject-class of the concerned image. In the broad methodological steps, each\npixel was defined by its context window (CW) surrounding it the size of which\nwas fixed heuristically. CW texture defined by the intensities of its pixels\nwas convoluted with weights optimized through a non-parametric function\nsupported by a backpropagation network. Result of convolution was used to\nclassify them. The training data points (i.e., pixels) were carefully chosen to\ninclude all variety of contexts of types, i) points within the object, ii)\npoints near the edge but inside the objects, iii) points at the border of the\nobjects, iv) points near the edge but outside the objects, v) points near or at\nthe edge of the image frame. Moreover the training data points were selected\nfrom all the images within image-dataset. CW texture information for 1000\npixels from face area and background area of images were captured, out of which\n700 CWs were used as training input data, and remaining 300 for testing. Our\nwork gives the first time foundation of quantitative enumeration of efficiency\nof image-segmentation which is extendable to segment out more than 2 objects\nwithin an image.\n",
        "published": "2012-02-09T14:02:26Z",
        "pdf_link": "http://arxiv.org/pdf/1202.1990v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.2528v1",
        "title": "Using Covariance Matrices as Feature Descriptors for Vehicle Detection\n  from a Fixed Camera",
        "summary": "  A method is developed to distinguish between cars and trucks present in a\nvideo feed of a highway. The method builds upon previously done work using\ncovariance matrices as an accurate descriptor for regions. Background\nsubtraction and other similar proven image processing techniques are used to\nidentify the regions where the vehicles are most likely to be, and a distance\nmetric comparing the vehicle inside the region to a fixed library of vehicles\nis used to determine the class of vehicle.\n",
        "published": "2012-02-12T13:40:11Z",
        "pdf_link": "http://arxiv.org/pdf/1202.2528v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.3021v1",
        "title": "No-reference image quality assessment through the von Mises distribution",
        "summary": "  An innovative way of calculating the von Mises distribution (VMD) of image\nentropy is introduced in this paper. The VMD's concentration parameter and some\nfitness parameter that will be later defined, have been analyzed in the\nexperimental part for determining their suitability as a image quality\nassessment measure in some particular distortions such as Gaussian blur or\nadditive Gaussian noise. To achieve such measure, the local R\\'{e}nyi entropy\nis calculated in four equally spaced orientations and used to determine the\nparameters of the von Mises distribution of the image entropy. Considering\ncontextual images, experimental results after applying this model show that the\nbest-in-focus noise-free images are associated with the highest values for the\nvon Mises distribution concentration parameter and the highest approximation of\nimage data to the von Mises distribution model. Our defined von Misses fitness\nparameter experimentally appears also as a suitable no-reference image quality\nassessment indicator for no-contextual images.\n",
        "published": "2012-02-14T12:50:35Z",
        "pdf_link": "http://arxiv.org/pdf/1202.3021v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.3684v1",
        "title": "Generalized Boundaries from Multiple Image Interpretations",
        "summary": "  Boundary detection is essential for a variety of computer vision tasks such\nas segmentation and recognition. In this paper we propose a unified formulation\nand a novel algorithm that are applicable to the detection of different types\nof boundaries, such as intensity edges, occlusion boundaries or object category\nspecific boundaries. Our formulation leads to a simple method with\nstate-of-the-art performance and significantly lower computational cost than\nexisting methods. We evaluate our algorithm on different types of boundaries,\nfrom low-level boundaries extracted in natural images, to occlusion boundaries\nobtained using motion cues and RGB-D cameras, to boundaries from\nsoft-segmentation. We also propose a novel method for figure/ground\nsoft-segmentation that can be used in conjunction with our boundary detection\nmethod and improve its accuracy at almost no extra computational cost.\n",
        "published": "2012-02-16T20:08:11Z",
        "pdf_link": "http://arxiv.org/pdf/1202.3684v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.3884v1",
        "title": "A feature extraction technique based on character geometry for character\n  recognition",
        "summary": "  This paper describes a geometry based technique for feature extraction\napplicable to segmentation-based word recognition systems. The proposed system\nextracts the geometric features of the character contour. This features are\nbased on the basic line types that forms the character skeleton. The system\ngives a feature vector as its output. The feature vectors so generated from a\ntraining set, were then used to train a pattern recognition engine based on\nNeural Networks so that the system can be benchmarked.\n",
        "published": "2012-02-17T11:41:28Z",
        "pdf_link": "http://arxiv.org/pdf/1202.3884v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.4107v1",
        "title": "Unsupervised Threshold for Automatic Extraction of Dolphin Dorsal Fin\n  Outlines from Digital Photographs in DARWIN (Digital Analysis and Recognition\n  of Whale Images on a Network)",
        "summary": "  At least two software packages---DARWIN, Eckerd College, and FinScan, Texas\nA&M---exist to facilitate the identification of cetaceans---whales, dolphins,\nporpoises---based upon the naturally occurring features along the edges of\ntheir dorsal fins. Such identification is useful for biological studies of\npopulation, social interaction, migration, etc. The process whereby fin\noutlines are extracted in current fin-recognition software packages is manually\nintensive and represents a major user input bottleneck: it is both time\nconsuming and visually fatiguing. This research aims to develop automated\nmethods (employing unsupervised thresholding and morphological processing\ntechniques) to extract cetacean dorsal fin outlines from digital photographs\nthereby reducing manual user input. Ideally, automatic outline generation will\nimprove the overall user experience and improve the ability of the software to\ncorrectly identify cetaceans. Various transformations from color to gray space\nwere examined to determine which produced a grayscale image in which a suitable\nthreshold could be easily identified. To assist with unsupervised thresholding,\na new metric was developed to evaluate the jaggedness of figures (\"pixelarity\")\nin an image after thresholding. The metric indicates how cleanly a threshold\nsegments background and foreground elements and hence provides a good measure\nof the quality of a given threshold. This research results in successful\nextractions in roughly 93% of images, and significantly reduces user-input\ntime.\n",
        "published": "2012-02-18T21:42:24Z",
        "pdf_link": "http://arxiv.org/pdf/1202.4107v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.4207v2",
        "title": "Regularized Robust Coding for Face Recognition",
        "summary": "  Recently the sparse representation based classification (SRC) has been\nproposed for robust face recognition (FR). In SRC, the testing image is coded\nas a sparse linear combination of the training samples, and the representation\nfidelity is measured by the l2-norm or l1-norm of the coding residual. Such a\nsparse coding model assumes that the coding residual follows Gaussian or\nLaplacian distribution, which may not be effective enough to describe the\ncoding residual in practical FR systems. Meanwhile, the sparsity constraint on\nthe coding coefficients makes SRC's computational cost very high. In this\npaper, we propose a new face coding model, namely regularized robust coding\n(RRC), which could robustly regress a given signal with regularized regression\ncoefficients. By assuming that the coding residual and the coding coefficient\nare respectively independent and identically distributed, the RRC seeks for a\nmaximum a posterior solution of the coding problem. An iteratively reweighted\nregularized robust coding (IR3C) algorithm is proposed to solve the RRC model\nefficiently. Extensive experiments on representative face databases demonstrate\nthat the RRC is much more effective and efficient than state-of-the-art sparse\nrepresentation based methods in dealing with face occlusion, corruption,\nlighting and expression changes, etc.\n",
        "published": "2012-02-20T02:02:26Z",
        "pdf_link": "http://arxiv.org/pdf/1202.4207v2"
    },
    {
        "id": "http://arxiv.org/abs/1202.4237v1",
        "title": "A Simple Unsupervised Color Image Segmentation Method based on MRF-MAP",
        "summary": "  Color image segmentation is an important topic in the image processing field.\nMRF-MAP is often adopted in the unsupervised segmentation methods, but their\nperformance are far behind recent interactive segmentation tools supervised by\nuser inputs. Furthermore, the existing related unsupervised methods also suffer\nfrom the low efficiency, and high risk of being trapped in the local optima,\nbecause MRF-MAP is currently solved by iterative frameworks with inaccurate\ninitial color distribution models. To address these problems, the letter\ndesigns an efficient method to calculate the energy functions approximately in\nthe non-iteration style, and proposes a new binary segmentation algorithm based\non the slightly tuned Lanczos eigensolver. The experiments demonstrate that the\nnew algorithm achieves competitive performance compared with two state-of-art\nsegmentation methods.\n",
        "published": "2012-02-20T06:56:26Z",
        "pdf_link": "http://arxiv.org/pdf/1202.4237v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.4495v1",
        "title": "Stochastic-Based Pattern Recognition Analysis",
        "summary": "  In this work we review the basic principles of stochastic logic and propose\nits application to probabilistic-based pattern-recognition analysis. The\nproposed technique is intrinsically a parallel comparison of input data to\nvarious pre-stored categories using Bayesian techniques. We design smart\npulse-based stochastic-logic blocks to provide an efficient pattern recognition\nanalysis. The proposed rchitecture is applied to a specific navigation problem.\nThe resulting system is orders of magnitude faster than processor-based\nsolutions.\n",
        "published": "2012-02-20T23:48:38Z",
        "pdf_link": "http://arxiv.org/pdf/1202.4495v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.6384v1",
        "title": "Fast approximations to structured sparse coding and applications to\n  object classification",
        "summary": "  We describe a method for fast approximation of sparse coding. The input space\nis subdivided by a binary decision tree, and we simultaneously learn a\ndictionary and assignment of allowed dictionary elements for each leaf of the\ntree. We store a lookup table with the assignments and the pseudoinverses for\neach node, allowing for very fast inference. We give an algorithm for learning\nthe tree, the dictionary and the dictionary element assignment, and In the\nprocess of describing this algorithm, we discuss the more general problem of\nlearning the groups in group structured sparse modelling. We show that our\nmethod creates good sparse representations by using it in the object\nrecognition framework of \\cite{lazebnik06,yang-cvpr-09}. Implementing our own\nfast version of the SIFT descriptor the whole system runs at 20 frames per\nsecond on $321 \\times 481$ sized images on a laptop with a quad-core cpu, while\nsacrificing very little accuracy on the Caltech 101 and 15 scenes benchmarks.\n",
        "published": "2012-02-28T21:27:14Z",
        "pdf_link": "http://arxiv.org/pdf/1202.6384v1"
    },
    {
        "id": "http://arxiv.org/abs/1202.6586v1",
        "title": "Filling-Based Techniques Applied to Object Projection Feature Estimation",
        "summary": "  3D motion tracking is a critical task in many computer vision applications.\nUnsupervised markerless 3D motion tracking systems determine the most relevant\nobject in the screen and then track it by continuously estimating its\nprojection features (center and area) from the edge image and a point inside\nthe relevant object projection (namely, inner point), until the tracking fails.\nExisting object projection feature estimation techniques are based on\nray-casting from the inner point. These techniques present three main\ndrawbacks: when the inner point is surrounded by edges, rays may not reach\nother relevant areas; as a consequence of that issue, the estimated features\nmay greatly vary depending on the position of the inner point relative to the\nobject projection; and finally, increasing the number of rays being casted and\nthe ray-casting iterations (which would make the results more accurate and\nstable) increases the processing time to the point the tracking cannot be\nperformed on the fly. In this paper, we analyze an intuitive filling-based\nobject projection feature estimation technique that solves the aforementioned\nproblems but is too sensitive to edge miscalculations. Then, we propose a less\ncomputing-intensive modification to that technique that would not be affected\nby the existing techniques issues and would be no more sensitive to edge\nmiscalculations than ray-casting-based techniques.\n",
        "published": "2012-02-29T16:10:10Z",
        "pdf_link": "http://arxiv.org/pdf/1202.6586v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.0076v1",
        "title": "Using Barriers to Reduce the Sensitivity to Edge Miscalculations of\n  Casting-Based Object Projection Feature Estimation",
        "summary": "  3D motion tracking is a critical task in many computer vision applications.\nUnsupervised markerless 3D motion tracking systems determine the most relevant\nobject in the screen and then track it by continuously estimating its\nprojection features (center and area) from the edge image and a point inside\nthe relevant object projection (namely, inner point), until the tracking fails.\nExisting reliable object projection feature estimation techniques are based on\nray-casting or grid-filling from the inner point. These techniques assume the\nedge image to be accurate. However, in real case scenarios, edge\nmiscalculations may arise from low contrast between the target object and its\nsurroundings or motion blur caused by low frame rates or fast moving target\nobjects. In this paper, we propose a barrier extension to casting-based\ntechniques that mitigates the effect of edge miscalculations.\n",
        "published": "2012-03-01T02:32:28Z",
        "pdf_link": "http://arxiv.org/pdf/1203.0076v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.0265v1",
        "title": "Image Fusion and Re-Modified SPIHT for Fused Image",
        "summary": "  This paper presents the Discrete Wavelet based fusion techniques for\ncombining perceptually important image features. SPIHT (Set Partitioning in\nHierarchical Trees) algorithm is an efficient method for lossy and lossless\ncoding of fused image. This paper presents some modifications on the SPIHT\nalgorithm. It is based on the idea of insignificant correlation of wavelet\ncoefficient among the medium and high frequency sub bands. In RE-MSPIHT\nalgorithm, wavelet coefficients are scaled prior to SPIHT coding based on the\nsub band importance, with the goal of minimizing the MSE.\n",
        "published": "2012-02-29T17:57:12Z",
        "pdf_link": "http://arxiv.org/pdf/1203.0265v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.0744v1",
        "title": "A Report on Multilinear PCA Plus Multilinear LDA to Deal with Tensorial\n  Data: Visual Classification as An Example",
        "summary": "  In practical applications, we often have to deal with high order data, such\nas a grayscale image and a video sequence are intrinsically 2nd-order tensor\nand 3rd-order tensor, respectively. For doing clustering or classification of\nthese high order data, it is a conventional way to vectorize these data before\nhand, as PCA or FDA does, which often induce the curse of dimensionality\nproblem. For this reason, experts have developed many methods to deal with the\ntensorial data, such as multilinear PCA, multilinear LDA, and so on. In this\npaper, we still address the problem of high order data representation and\nrecognition, and propose to study the result of merging multilinear PCA and\nmultilinear LDA into one scenario, we name it \\textbf{GDA} for the abbreviation\nof Generalized Discriminant Analysis. To evaluate GDA, we perform a series of\nexperiments, and the experimental results demonstrate our GDA outperforms a\nselection of competing methods such (2D)$^2$PCA, (2D)$^2$LDA, and MDA.\n",
        "published": "2012-03-04T15:00:16Z",
        "pdf_link": "http://arxiv.org/pdf/1203.0744v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.0781v3",
        "title": "Posterior Mean Super-Resolution with a Compound Gaussian Markov Random\n  Field Prior",
        "summary": "  This manuscript proposes a posterior mean (PM) super-resolution (SR) method\nwith a compound Gaussian Markov random field (MRF) prior. SR is a technique to\nestimate a spatially high-resolution image from observed multiple\nlow-resolution images. A compound Gaussian MRF model provides a preferable\nprior for natural images that preserves edges. PM is the optimal estimator for\nthe objective function of peak signal-to-noise ratio (PSNR). This estimator is\nnumerically determined by using variational Bayes (VB). We then solve the\nconjugate prior problem on VB and the exponential-order calculation cost\nproblem of a compound Gaussian MRF prior with simple Taylor approximations. In\nexperiments, the proposed method roughly overcomes existing methods.\n",
        "published": "2012-03-04T22:12:54Z",
        "pdf_link": "http://arxiv.org/pdf/1203.0781v3"
    },
    {
        "id": "http://arxiv.org/abs/1203.0856v1",
        "title": "Online Discriminative Dictionary Learning for Image Classification Based\n  on Block-Coordinate Descent Method",
        "summary": "  Previous researches have demonstrated that the framework of dictionary\nlearning with sparse coding, in which signals are decomposed as linear\ncombinations of a few atoms of a learned dictionary, is well adept to\nreconstruction issues. This framework has also been used for discrimination\ntasks such as image classification. To achieve better performances of\nclassification, experts develop several methods to learn a discriminative\ndictionary in a supervised manner. However, another issue is that when the data\nbecome extremely large in scale, these methods will be no longer effective as\nthey are all batch-oriented approaches. For this reason, we propose a novel\nonline algorithm for discriminative dictionary learning, dubbed \\textbf{ODDL}\nin this paper. First, we introduce a linear classifier into the conventional\ndictionary learning formulation and derive a discriminative dictionary learning\nproblem. Then, we exploit an online algorithm to solve the derived problem.\nUnlike the most existing approaches which update dictionary and classifier\nalternately via iteratively solving sub-problems, our approach directly\nexplores them jointly. Meanwhile, it can largely shorten the runtime for\ntraining and is also particularly suitable for large-scale classification\nissues. To evaluate the performance of the proposed ODDL approach in image\nrecognition, we conduct some experiments on three well-known benchmarks, and\nthe experimental results demonstrate ODDL is fairly promising for image\nclassification tasks.\n",
        "published": "2012-03-05T10:43:15Z",
        "pdf_link": "http://arxiv.org/pdf/1203.0856v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.0905v2",
        "title": "Autocalibration with the Minimum Number of Cameras with Known Pixel\n  Shape",
        "summary": "  In 3D reconstruction, the recovery of the calibration parameters of the\ncameras is paramount since it provides metric information about the observed\nscene, e.g., measures of angles and ratios of distances. Autocalibration\nenables the estimation of the camera parameters without using a calibration\ndevice, but by enforcing simple constraints on the camera parameters. In the\nabsence of information about the internal camera parameters such as the focal\nlength and the principal point, the knowledge of the camera pixel shape is\nusually the only available constraint. Given a projective reconstruction of a\nrigid scene, we address the problem of the autocalibration of a minimal set of\ncameras with known pixel shape and otherwise arbitrarily varying intrinsic and\nextrinsic parameters. We propose an algorithm that only requires 5 cameras (the\ntheoretical minimum), thus halving the number of cameras required by previous\nalgorithms based on the same constraint. To this purpose, we introduce as our\nbasic geometric tool the six-line conic variety (SLCV), consisting in the set\nof planes intersecting six given lines of 3D space in points of a conic. We\nshow that the set of solutions of the Euclidean upgrading problem for three\ncameras with known pixel shape can be parameterized in a computationally\nefficient way. This parameterization is then used to solve autocalibration from\nfive or more cameras, reducing the three-dimensional search space to a\ntwo-dimensional one. We provide experiments with real images showing the good\nperformance of the technique.\n",
        "published": "2012-03-05T13:18:44Z",
        "pdf_link": "http://arxiv.org/pdf/1203.0905v2"
    },
    {
        "id": "http://arxiv.org/abs/1203.1513v2",
        "title": "Invariant Scattering Convolution Networks",
        "summary": "  A wavelet scattering network computes a translation invariant image\nrepresentation, which is stable to deformations and preserves high frequency\ninformation for classification. It cascades wavelet transform convolutions with\nnon-linear modulus and averaging operators. The first network layer outputs\nSIFT-type descriptors whereas the next layers provide complementary invariant\ninformation which improves classification. The mathematical analysis of wavelet\nscattering networks explains important properties of deep convolution networks\nfor classification.\n  A scattering representation of stationary processes incorporates higher order\nmoments and can thus discriminate textures having the same Fourier power\nspectrum. State of the art classification results are obtained for handwritten\ndigits and texture discrimination, using a Gaussian kernel SVM and a generative\nPCA classifier.\n",
        "published": "2012-03-05T17:12:42Z",
        "pdf_link": "http://arxiv.org/pdf/1203.1513v2"
    },
    {
        "id": "http://arxiv.org/abs/1203.1765v1",
        "title": "A comparative evaluation of two algorithms of detection of masses on\n  mammograms",
        "summary": "  In this paper, we implement and carry out the comparison of two methods of\ncomputer-aided-detection of masses on mammograms. The two algorithms basically\nconsist of 3 steps each: segmentation, binarization and noise suppression using\ndifferent techniques for each step. A database of 60 images was used to compare\nthe performance of the two algorithms in terms of general detection efficiency,\nconservation of size and shape of detected masses.\n",
        "published": "2012-03-08T12:07:27Z",
        "pdf_link": "http://arxiv.org/pdf/1203.1765v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.1985v1",
        "title": "Substructure and Boundary Modeling for Continuous Action Recognition",
        "summary": "  This paper introduces a probabilistic graphical model for continuous action\nrecognition with two novel components: substructure transition model and\ndiscriminative boundary model. The first component encodes the sparse and\nglobal temporal transition prior between action primitives in state-space model\nto handle the large spatial-temporal variations within an action class. The\nsecond component enforces the action duration constraint in a discriminative\nway to locate the transition boundaries between actions more accurately. The\ntwo components are integrated into a unified graphical structure to enable\neffective training and inference. Our comprehensive experimental results on\nboth public and in-house datasets show that, with the capability to incorporate\nadditional information that had not been explicitly or efficiently modeled by\nprevious methods, our proposed algorithm achieved significantly improved\nperformance for continuous action recognition.\n",
        "published": "2012-03-09T04:16:33Z",
        "pdf_link": "http://arxiv.org/pdf/1203.1985v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.2404v1",
        "title": "Video Object Tracking and Analysis for Computer Assisted Surgery",
        "summary": "  Pedicle screw insertion technique has made revolution in the surgical\ntreatment of spinal fractures and spinal disorders. Although X- ray fluoroscopy\nbased navigation is popular, there is risk of prolonged exposure to X- ray\nradiation. Systems that have lower radiation risk are generally quite\nexpensive. The position and orientation of the drill is clinically very\nimportant in pedicle screw fixation. In this paper, the position and\norientation of the marker on the drill is determined using pattern recognition\nbased methods, using geometric features, obtained from the input video sequence\ntaken from CCD camera. A search is then performed on the video frames after\npreprocessing, to obtain the exact position and orientation of the drill.\nAnimated graphics, showing the instantaneous position and orientation of the\ndrill is then overlaid on the processed video for real time drill control and\nnavigation.\n",
        "published": "2012-03-12T05:39:34Z",
        "pdf_link": "http://arxiv.org/pdf/1203.2404v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.2514v1",
        "title": "Enhancement of Images using Morphological Transformation",
        "summary": "  This paper deals with enhancement of images with poor contrast and detection\nof background. Proposes a frame work which is used to detect the background in\nimages characterized by poor contrast. Image enhancement has been carried out\nby the two methods based on the Weber's law notion. The first method employs\ninformation from image background analysis by blocks, while the second\ntransformation method utilizes the opening operation, closing operation, which\nis employed to define the multi-background gray scale images. The complete\nimage processing is done using MATLAB simulation model. Finally, this paper is\norganized as follows as Morphological transformation and Weber's law. Image\nbackground approximation to the background by means of block analysis in\nconjunction with transformations that enhance images with poor lighting. The\nmultibackground notion is introduced by means of the opening by reconstruction\nshows a comparison among several techniques to improve contrast in images.\nFinally, conclusions are presented.\n",
        "published": "2012-03-09T13:22:25Z",
        "pdf_link": "http://arxiv.org/pdf/1203.2514v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.2839v1",
        "title": "Square-Cut: A Segmentation Algorithm on the Basis of a Rectangle Shape",
        "summary": "  We present a rectangle-based segmentation algorithm that sets up a graph and\nperforms a graph cut to separate an object from the background. However,\ngraph-based algorithms distribute the graph's nodes uniformly and equidistantly\non the image. Then, a smoothness term is added to force the cut to prefer a\nparticular shape. This strategy does not allow the cut to prefer a certain\nstructure, especially when areas of the object are indistinguishable from the\nbackground. We solve this problem by referring to a rectangle shape of the\nobject when sampling the graph nodes, i.e., the nodes are distributed\nnonuniformly and non-equidistantly on the image. This strategy can be useful,\nwhen areas of the object are indistinguishable from the background. For\nevaluation, we focus on vertebrae images from Magnetic Resonance Imaging (MRI)\ndatasets to support the time consuming manual slice-by-slice segmentation\nperformed by physicians. The ground truth of the vertebrae boundaries were\nmanually extracted by two clinical experts (neurological surgeons) with several\nyears of experience in spine surgery and afterwards compared with the automatic\nsegmentation results of the proposed scheme yielding an average Dice Similarity\nCoefficient (DSC) of 90.97\\pm62.2%.\n",
        "published": "2012-03-13T15:41:14Z",
        "pdf_link": "http://arxiv.org/pdf/1203.2839v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.3114v1",
        "title": "Integrated three-dimensional reconstruction using reflectance fields",
        "summary": "  A method to obtain three-dimensional data of real-world objects by\nintegrating their material properties is presented. The material properties are\ndefined by capturing the Reflectance Fields of the real-world objects. It is\nshown, unlike conventional reconstruction methods, the method is able to use\nthe reflectance information to recover surface depth for objects having a\nnon-Lambertian surface reflectance. It is, for recovering 3D data of objects\nexhibiting an anisotropic BRDF with an error less than 0.3%.\n",
        "published": "2012-03-14T15:31:16Z",
        "pdf_link": "http://arxiv.org/pdf/1203.3114v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.3170v1",
        "title": "Single Reduct Generation Based on Relative Indiscernibility of Rough Set\n  Theory",
        "summary": "  In real world everything is an object which represents particular classes.\nEvery object can be fully described by its attributes. Any real world dataset\ncontains large number of attributes and objects. Classifiers give poor\nperformance when these huge datasets are given as input to it for proper\nclassification. So from these huge dataset most useful attributes need to be\nextracted that contribute the maximum to the decision. In the paper, attribute\nset is reduced by generating reducts using the indiscernibility relation of\nRough Set Theory (RST). The method measures similarity among the attributes\nusing relative indiscernibility relation and computes attribute similarity set.\nThen the set is minimized and an attribute similarity table is constructed from\nwhich attribute similar to maximum number of attributes is selected so that the\nresultant minimum set of selected attributes (called reduct) cover all\nattributes of the attribute similarity table. The method has been applied on\nglass dataset collected from the UCI repository and the classification accuracy\nis calculated by various classifiers. The result shows the efficiency of the\nproposed method.\n",
        "published": "2012-03-14T18:34:05Z",
        "pdf_link": "http://arxiv.org/pdf/1203.3170v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.3230v1",
        "title": "Reconstruction error in a motion capture system",
        "summary": "  Marker-based motion capture (MoCap) systems can be composed by several dozens\nof cameras with the purpose of reconstructing the trajectories of hundreds of\ntargets. With a large amount of cameras it becomes interesting to determine the\noptimal reconstruction strategy. For such aim it is of fundamental importance\nto understand the information provided by different camera measurements and how\nthey are combined, i.e. how the reconstruction error changes by considering\ndifferent cameras. In this work, first, an approximation of the reconstruction\nerror variance is derived. The results obtained in some simulations suggest\nthat the proposed strategy allows to obtain a good approximation of the real\nerror variance with significant reduction of the computational time.\n",
        "published": "2012-03-14T22:46:29Z",
        "pdf_link": "http://arxiv.org/pdf/1203.3230v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.3270v1",
        "title": "Extraction of Facial Feature Points Using Cumulative Histogram",
        "summary": "  This paper proposes a novel adaptive algorithm to extract facial feature\npoints automatically such as eyebrows corners, eyes corners, nostrils, nose\ntip, and mouth corners in frontal view faces, which is based on cumulative\nhistogram approach by varying different threshold values. At first, the method\nadopts the Viola-Jones face detector to detect the location of face and also\ncrops the face region in an image. From the concept of the human face\nstructure, the six relevant regions such as right eyebrow, left eyebrow, right\neye, left eye, nose, and mouth areas are cropped in a face image. Then the\nhistogram of each cropped relevant region is computed and its cumulative\nhistogram value is employed by varying different threshold values to create a\nnew filtering image in an adaptive way. The connected component of interested\narea for each relevant filtering image is indicated our respective feature\nregion. A simple linear search algorithm for eyebrows, eyes and mouth filtering\nimages and contour algorithm for nose filtering image are applied to extract\nour desired corner points automatically. The method was tested on a large BioID\nfrontal face database in different illuminations, expressions and lighting\nconditions and the experimental results have achieved average success rates of\n95.27%.\n",
        "published": "2012-03-15T05:20:27Z",
        "pdf_link": "http://arxiv.org/pdf/1203.3270v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.4204v1",
        "title": "Clustering Using Isoperimetric Number of Trees",
        "summary": "  In this paper we propose a graph-based data clustering algorithm which is\nbased on exact clustering of a minimum spanning tree in terms of a minimum\nisoperimetry criteria. We show that our basic clustering algorithm runs in $O(n\n\\log n)$ and with post-processing in $O(n^2)$ (worst case) time where $n$ is\nthe size of the data set. We also show that our generalized graph model which\nalso allows the use of potentials at vertices can be used to extract a more\ndetailed pack of information as the {\\it outlier profile} of the data set. In\nthis direction we show that our approach can be used to define the concept of\nan outlier-set in a precise way and we propose approximation algorithms for\nfinding such sets. We also provide a comparative performance analysis of our\nalgorithm with other related ones and we show that the new clustering algorithm\n(without the outlier extraction procedure) behaves quite effectively even on\nhard benchmarks and handmade examples.\n",
        "published": "2012-03-19T19:15:25Z",
        "pdf_link": "http://arxiv.org/pdf/1203.4204v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.4874v1",
        "title": "A Co-Prime Blur Scheme for Data Security in Video Surveillance",
        "summary": "  This paper presents a novel Coprime Blurred Pair (CBP) model for visual\ndata-hiding for security in camera surveillance. While most previous approaches\nhave focused on completely encrypting the video stream, we introduce a spatial\nencryption scheme by blurring the image/video contents to create a CBP. Our\ngoal is to obscure detail in public video streams by blurring while allowing\nbehavior to be recognized and to quickly deblur the stream so that details are\navailable if behavior is recognized as suspicious. We create a CBP by blurring\nthe same latent image with two unknown kernels. The two kernels are coprime\nwhen mapped to bivariate polynomials in the z domain. To deblur the CBP we\nfirst use the coprime constraint to approximate the kernels and sample the\nbivariate CBP polynomials in one dimension on the unit circle. At each sample\npoint, we factor the 1D polynomial pair and compose the results into a 2D\nkernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of\nthe kernel matrices to recover the coprime kernels and then the latent video\nstream. It is therefore only possible to deblur the video stream if a user has\naccess to both streams. To improve the practicability of our algorithm, we\nimplement our algorithm using a graphics processing unit (GPU) to decrypt the\nblurred video streams in real-time, and extensive experimental results\ndemonstrate that our new scheme can effectively protect sensitive identity\ninformation in surveillance videos and faithfully reconstruct the unblurred\nvideo stream when two blurred sequences are available.\n",
        "published": "2012-03-22T02:57:53Z",
        "pdf_link": "http://arxiv.org/pdf/1203.4874v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.5078v1",
        "title": "Kernel Density Feature Points Estimator for Content-Based Image\n  Retrieval",
        "summary": "  Research is taking place to find effective algorithms for content-based image\nrepresentation and description. There is a substantial amount of algorithms\navailable that use visual features (color, shape, texture). Shape feature has\nattracted much attention from researchers that there are many shape\nrepresentation and description algorithms in literature. These shape image\nrepresentation and description algorithms are usually not application\nindependent or robust, making them undesirable for generic shape description.\nThis paper presents an object shape representation using Kernel Density Feature\nPoints Estimator (KDFPE). In this method, the density of feature points within\ndefined rings around the centroid of the image is obtained. The KDFPE is then\napplied to the vector of the image. KDFPE is invariant to translation, scale\nand rotation. This method of image representation shows improved retrieval rate\nwhen compared to Density Histogram Feature Points (DHFP) method. Analytic\nanalysis is done to justify our method, which was compared with the DHFP to\nprove its robustness.\n",
        "published": "2012-03-22T18:47:57Z",
        "pdf_link": "http://arxiv.org/pdf/1203.5078v1"
    },
    {
        "id": "http://arxiv.org/abs/1203.6329v2",
        "title": "Analysis of Magnification in Depth from Defocus",
        "summary": "  In depth from defocus (DFD), when images are captured with different camera\nparameters, a relative magnification is induced between them. Image warping is\na simpler solution to account for magnification than seemingly more accurate\noptical approaches. This work is an investigation into the effects of\nmagnification on the accuracy of DFD. We comment on issues regarding scaling\neffect on relative blur computation. We statistically analyze accountability of\nscale factor, commenting on the bias and efficiency of the estimator that does\nnot consider scale. We also discuss the effect of interpolation errors on blur\nestimation in a warping based solution to handle magnification and carry out\nexperimental analysis to comment on the blur estimation accuracy.\n",
        "published": "2012-03-28T18:16:46Z",
        "pdf_link": "http://arxiv.org/pdf/1203.6329v2"
    },
    {
        "id": "http://arxiv.org/abs/1203.6722v1",
        "title": "Face Expression Recognition and Analysis: The State of the Art",
        "summary": "  The automatic recognition of facial expressions has been an active research\ntopic since the early nineties. There have been several advances in the past\nfew years in terms of face detection and tracking, feature extraction\nmechanisms and the techniques used for expression classification. This paper\nsurveys some of the published work since 2001 till date. The paper presents a\ntime-line view of the advances made in this field, the applications of\nautomatic face expression recognizers, the characteristics of an ideal system,\nthe databases that have been used and the advances made in terms of their\nstandardization and a detailed summary of the state of the art. The paper also\ndiscusses facial parameterization using FACS Action Units (AUs) and MPEG-4\nFacial Animation Parameters (FAPs) and the recent advances in face detection,\ntracking and feature extraction methods. Notes have also been presented on\nemotions, expressions and facial features, discussion on the six prototypic\nexpressions and the recent studies on expression classifiers. The paper ends\nwith a note on the challenges and the future work. This paper has been written\nin a tutorial style with the intention of helping students and researchers who\nare new to this field.\n",
        "published": "2012-03-30T05:47:59Z",
        "pdf_link": "http://arxiv.org/pdf/1203.6722v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.0767v2",
        "title": "Efficient Fruit Defect Detection and Glare removal Algorithm by\n  anisotropic diffusion and 2D Gabor filter",
        "summary": "  This paper focuses on fruit defect detection and glare removal using\nmorphological operations, Glare removal can be considered as an important\npreprocessing step as uneven lighting may introduce it in images, which hamper\nthe results produced through segmentation by Gabor filters .The problem of\nglare in images is very pronounced sometimes due to the unusual reflectance\nfrom the camera sensor or stray light entering, this method counteracts this\nproblem and makes the defect detection much more pronounced. Anisotropic\ndiffusion is used for further smoothening of the images and removing the high\nenergy regions in an image for better defect detection and makes the defects\nmore retrievable. Our algorithm is robust and scalable the employability of a\nparticular mask for glare removal has been checked and proved useful for\ncounteracting.this problem, anisotropic diffusion further enhances the defects\nwith its use further Optimal Gabor filter at various orientations is used for\ndefect detection.\n",
        "published": "2012-04-03T19:02:54Z",
        "pdf_link": "http://arxiv.org/pdf/1204.0767v2"
    },
    {
        "id": "http://arxiv.org/abs/1204.1177v1",
        "title": "Principal Component Analysis-Linear Discriminant Analysis Feature\n  Extractor for Pattern Recognition",
        "summary": "  Robustness of embedded biometric systems is of prime importance with the\nemergence of fourth generation communication devices and advancement in\nsecurity systems This paper presents the realization of such technologies which\ndemands reliable and error-free biometric identity verification systems. High\ndimensional patterns are not permitted due to eigen-decomposition in high\ndimensional image space and degeneration of scattering matrices in small size\nsample. Generalization, dimensionality reduction and maximizing the margins are\ncontrolled by minimizing weight vectors. Results show good pattern by\nmultimodal biometric system proposed in this paper. This paper is aimed at\ninvestigating a biometric identity system using Principal Component Analysis\nand Lindear Discriminant Analysis with K-Nearest Neighbor and implementing such\nsystem in real-time using SignalWAVE.\n",
        "published": "2012-04-05T10:48:09Z",
        "pdf_link": "http://arxiv.org/pdf/1204.1177v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.1198v1",
        "title": "A Complete Workflow for Development of Bangla OCR",
        "summary": "  Developing a Bangla OCR requires bunch of algorithm and methods. There were\nmany effort went on for developing a Bangla OCR. But all of them failed to\nprovide an error free Bangla OCR. Each of them has some lacking. We discussed\nabout the problem scope of currently existing Bangla OCR's. In this paper, we\npresent the basic steps required for developing a Bangla OCR and a complete\nworkflow for development of a Bangla OCR with mentioning all the possible\nalgorithms required.\n",
        "published": "2012-04-05T12:28:11Z",
        "pdf_link": "http://arxiv.org/pdf/1204.1198v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.1393v1",
        "title": "Continuous Markov Random Fields for Robust Stereo Estimation",
        "summary": "  In this paper we present a novel slanted-plane MRF model which reasons\njointly about occlusion boundaries as well as depth. We formulate the problem\nas the one of inference in a hybrid MRF composed of both continuous (i.e.,\nslanted 3D planes) and discrete (i.e., occlusion boundaries) random variables.\nThis allows us to define potentials encoding the ownership of the pixels that\ncompose the boundary between segments, as well as potentials encoding which\njunctions are physically possible. Our approach outperforms the\nstate-of-the-art on Middlebury high resolution imagery as well as in the more\nchallenging KITTI dataset, while being more efficient than existing slanted\nplane MRF-based methods, taking on average 2 minutes to perform inference on\nhigh resolution imagery.\n",
        "published": "2012-04-06T01:40:21Z",
        "pdf_link": "http://arxiv.org/pdf/1204.1393v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.1611v1",
        "title": "Vision-based Human Gender Recognition: A Survey",
        "summary": "  Gender is an important demographic attribute of people. This paper provides a\nsurvey of human gender recognition in computer vision. A review of approaches\nexploiting information from face and whole body (either from a still image or\ngait sequence) is presented. We highlight the challenges faced and survey the\nrepresentative methods of these approaches. Based on the results, good\nperformance have been achieved for datasets captured under controlled\nenvironments, but there is still much work that can be done to improve the\nrobustness of gender recognition under real-life environments.\n",
        "published": "2012-04-07T08:17:40Z",
        "pdf_link": "http://arxiv.org/pdf/1204.1611v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.1629v1",
        "title": "Image segmentation by adaptive distance based on EM algorithm",
        "summary": "  This paper introduces a Bayesian image segmentation algorithm based on finite\nmixtures. An EM algorithm is developed to estimate parameters of the Gaussian\nmixtures. The finite mixture is a flexible and powerful probabilistic modeling\ntool. It can be used to provide a model-based clustering in the field of\npattern recognition. However, the application of finite mixtures to image\nsegmentation presents some difficulties; especially it's sensible to noise. In\nthis paper we propose a variant of this method which aims to resolve this\nproblem. Our approach proceeds by the characterization of pixels by two\nfeatures: the first one describes the intrinsic properties of the pixel and the\nsecond characterizes the neighborhood of pixel. Then the classification is made\non the base on adaptive distance which privileges the one or the other features\naccording to the spatial position of the pixel in the image. The obtained\nresults have shown a significant improvement of our approach compared to the\nstandard version of EM algorithm.\n",
        "published": "2012-04-07T13:04:24Z",
        "pdf_link": "http://arxiv.org/pdf/1204.1629v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.1634v1",
        "title": "Automatic liver segmentation method in CT images",
        "summary": "  The aim of this work is to develop a method for automatic segmentation of the\nliver based on a priori knowledge of the image, such as location and shape of\nthe liver.\n",
        "published": "2012-04-07T13:46:24Z",
        "pdf_link": "http://arxiv.org/pdf/1204.1634v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.1678v1",
        "title": "A New Approach for Arabic Handwritten Postal Addresses Recognition",
        "summary": "  In this paper, we propose an automatic analysis system for the Arabic\nhandwriting postal addresses recognition, by using the beta elliptical model.\nOur system is divided into different steps: analysis, pre-processing and\nclassification. The first operation is the filtering of image. In the second,\nwe remove the border print, stamps and graphics. After locating the address on\nthe envelope, the address segmentation allows the extraction of postal code and\ncity name separately. The pre-processing system and the modeling approach are\nbased on two basic steps. The first step is the extraction of the temporal\norder in the image of the handwritten trajectory. The second step is based on\nthe use of Beta-Elliptical model for the representation of handwritten script.\nThe recognition system is based on Graph-matching algorithm. Our modeling and\nrecognition approaches were validated by using the postal code and city names\nextracted from the Tunisian postal envelopes data. The recognition rate\nobtained is about 98%.\n",
        "published": "2012-04-07T20:45:06Z",
        "pdf_link": "http://arxiv.org/pdf/1204.1678v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.1704v1",
        "title": "Multi-Level Coding Efficiency with Improved Quality for Image\n  Compression based on AMBTC",
        "summary": "  In this paper, we have proposed an extended version of Absolute Moment Block\nTruncation Coding (AMBTC) to compress images. Generally the elements of a\nbitplane used in the variants of Block Truncation Coding (BTC) are of size 1\nbit. But it has been extended to two bits in the proposed method. Number of\nstatistical moments preserved to reconstruct the compressed has also been\nraised from 2 to 4. Hence, the quality of the reconstructed images has been\nimproved significantly from 33.62 to 38.12 with the increase in bpp by 1. The\nincreased bpp (3) is further reduced to 1.75in multiple levels: in one level,\nby dropping 4 elements of the bitplane in such a away that the pixel values of\nthe dropped elements can easily be interpolated with out much of loss in the\nquality, in level two, eight elements are dropped and reconstructed later and\nin level three, the size of the statistical moments is reduced. The experiments\nwere carried over standard images of varying intensities. In all the cases, the\nproposed method outperforms the existing AMBTC technique in terms of both PSNR\nand bpp.\n",
        "published": "2012-04-08T03:44:13Z",
        "pdf_link": "http://arxiv.org/pdf/1204.1704v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.2062v1",
        "title": "SVD-EBP Algorithm for Iris Pattern Recognition",
        "summary": "  This paper proposes a neural network approach based on Error Back Propagation\n(EBP) for classification of different eye images. To reduce the complexity of\nlayered neural network the dimensions of input vectors are optimized using\nSingular Value Decomposition (SVD). The main of this work is to provide for\nbest method for feature extraction and classification. The details of this\ncombined system named as SVD-EBP system, and results thereof are presented in\nthis paper.\n  Keywords- Singular value decomposition(SVD), Error back Propagation(EBP).\n",
        "published": "2012-04-10T07:10:06Z",
        "pdf_link": "http://arxiv.org/pdf/1204.2062v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.2073v1",
        "title": "Automatic facial feature extraction and expression recognition based on\n  neural network",
        "summary": "  In this paper, an approach to the problem of automatic facial feature\nextraction from a still frontal posed image and classification and recognition\nof facial expression and hence emotion and mood of a person is presented. Feed\nforward back propagation neural network is used as a classifier for classifying\nthe expressions of supplied face into seven basic categories like surprise,\nneutral, sad, disgust, fear, happy and angry. For face portion segmentation and\nlocalization, morphological image processing operations are used. Permanent\nfacial features like eyebrows, eyes, mouth and nose are extracted using SUSAN\nedge detection operator, facial geometry, edge projection analysis. Experiments\nare carried out on JAFFE facial expression database and gives better\nperformance in terms of 100% accuracy for training set and 95.26% accuracy for\ntest set.\n",
        "published": "2012-04-10T07:57:53Z",
        "pdf_link": "http://arxiv.org/pdf/1204.2073v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.2114v1",
        "title": "Image-based Vehicle Classification System",
        "summary": "  Electronic toll collection (ETC) system has been a common trend used for toll\ncollection on toll road nowadays. The implementation of electronic toll\ncollection allows vehicles to travel at low or full speed during the toll\npayment, which help to avoid the traffic delay at toll road. One of the major\ncomponents of an electronic toll collection is the automatic vehicle detection\nand classification (AVDC) system which is important to classify the vehicle so\nthat the toll is charged according to the vehicle classes. Vision-based vehicle\nclassification system is one type of vehicle classification system which adopt\ncamera as the input sensing device for the system. This type of system has\nadvantage over the rest for it is cost efficient as low cost camera is used.\nThe implementation of vision-based vehicle classification system requires lower\ninitial investment cost and very suitable for the toll collection trend\nmigration in Malaysia from single ETC system to full-scale multi-lane free flow\n(MLFF). This project includes the development of an image-based vehicle\nclassification system as an effort to seek for a robust vision-based vehicle\nclassification system. The techniques used in the system include\nscale-invariant feature transform (SIFT) technique, Canny's edge detector,\nK-means clustering as well as Euclidean distance matching. In this project, a\nunique way to image description as matching medium is proposed. This\ndistinctiveness of method is analogous to the human DNA concept which is highly\nunique. The system is evaluated on open datasets and return promising results.\n",
        "published": "2012-04-10T11:59:10Z",
        "pdf_link": "http://arxiv.org/pdf/1204.2114v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.2134v1",
        "title": "The steepest watershed: from graphs to images",
        "summary": "  The watershed is a powerful tool for segmenting objects whose contours appear\nas crest lines on a gradient image. The watershed transform associates to a\ntopographic surface a partition into catchment basins, defined as attraction\nzones of a drop of water falling on the relief and following a line of steepest\ndescent. Unfortunately, catchment basins may overlap and do not form a\npartition. Moreover, current watershed algorithms, being shortsighted, do not\ncorrectly estimate the steepness of the downwards trajectories and overestimate\nthe overlapping zones of catchment basins. An arbitrary division of these zones\nbetween adjacent catchment basin results in a poor localization of the\ncontours. We propose an algorithm without myopia, which considers the total\nlength of a trajectory for estimating its steepness. We first consider\ntopographic surfaces defined on node weighted graphs. The graphs are pruned in\norder to eliminate all downwards trajectories which are not the steepest. An\niterative algorithm with simple neighborhood operations performs the pruning\nand constructs the catchment basins. The algorithm is then adapted to gray tone\nimages. The graph structure itself is encoded as an image thanks to the fixed\nneighborhood structure of grids. A pair of adaptative erosions and dilations\nprune the graph and extend the catchment basins. As a result one obtains a\nprecise detection of the catchment basins and a graph of the steepest\ntrajectories. A last iterative algorithm allows to follow selected downwards\ntrajectories in order to detect particular structures such as rivers or thalweg\nlines of the topographic surface.\n",
        "published": "2012-04-10T13:08:34Z",
        "pdf_link": "http://arxiv.org/pdf/1204.2134v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.2294v1",
        "title": "Ubiquitous WLAN/Camera Positioning using Inverse Intensity Chromaticity\n  Space-based Feature Detection and Matching: A Preliminary Result",
        "summary": "  This paper present our new intensity chromaticity space-based feature\ndetection and matching algorithm. This approach utilizes hybridization of\nwireless local area network and camera internal sensor which to receive signal\nstrength from a access point and the same time retrieve interest point\ninformation from hallways. This information is combined by model fitting\napproach in order to find the absolute of user target position. No conventional\nsearching algorithm is required, thus it is expected reducing the computational\ncomplexity. Finally we present pre-experimental results to illustrate the\nperformance of the localization system for an indoor environment set-up.\n",
        "published": "2012-04-10T22:05:34Z",
        "pdf_link": "http://arxiv.org/pdf/1204.2294v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.2336v1",
        "title": "Feature Extraction Methods for Color Image Similarity",
        "summary": "  Many User interactive systems are proposed all methods are trying to\nimplement as a user friendly and various approaches proposed but most of the\nsystems not reached to the use specifications like user friendly systems with\nuser interest, all proposed method implemented basic techniques some are\nimproved methods also propose but not reaching to the user specifications. In\nthis proposed paper we concentrated on image retrieval system with in early\ndays many user interactive systems performed with basic concepts but such\nsystems are not reaching to the user specifications and not attracted to the\nuser so a lot of research interest in recent years with new specifications,\nrecent approaches have user is interested in friendly interacted methods are\nexpecting, many are concentrated for improvement in all methods. In this\nproposed system we focus on the retrieval of images within a large image\ncollection based on color projections and different mathematical approaches are\nintroduced and applied for retrieval of images. before Appling proposed methods\nimages are sub grouping using threshold values, in this paper R G B color\ncombinations considered for retrieval of images, in proposed methods are\nimplemented and results are included, through results it is observed that we\nobtaining efficient results comparatively previous and existing.\n",
        "published": "2012-04-11T04:45:51Z",
        "pdf_link": "http://arxiv.org/pdf/1204.2336v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.2358v2",
        "title": "Collaborative Representation based Classification for Face Recognition",
        "summary": "  By coding a query sample as a sparse linear combination of all training\nsamples and then classifying it by evaluating which class leads to the minimal\ncoding residual, sparse representation based classification (SRC) leads to\ninteresting results for robust face recognition. It is widely believed that the\nl1- norm sparsity constraint on coding coefficients plays a key role in the\nsuccess of SRC, while its use of all training samples to collaboratively\nrepresent the query sample is rather ignored. In this paper we discuss how SRC\nworks, and show that the collaborative representation mechanism used in SRC is\nmuch more crucial to its success of face classification. The SRC is a special\ncase of collaborative representation based classification (CRC), which has\nvarious instantiations by applying different norms to the coding residual and\ncoding coefficient. More specifically, the l1 or l2 norm characterization of\ncoding residual is related to the robustness of CRC to outlier facial pixels,\nwhile the l1 or l2 norm characterization of coding coefficient is related to\nthe degree of discrimination of facial features. Extensive experiments were\nconducted to verify the face recognition accuracy and efficiency of CRC with\ndifferent instantiations.\n",
        "published": "2012-04-11T07:13:20Z",
        "pdf_link": "http://arxiv.org/pdf/1204.2358v2"
    },
    {
        "id": "http://arxiv.org/abs/1204.2912v1",
        "title": "Non-sparse Linear Representations for Visual Tracking with Online\n  Reservoir Metric Learning",
        "summary": "  Most sparse linear representation-based trackers need to solve a\ncomputationally expensive L1-regularized optimization problem. To address this\nproblem, we propose a visual tracker based on non-sparse linear\nrepresentations, which admit an efficient closed-form solution without\nsacrificing accuracy. Moreover, in order to capture the correlation information\nbetween different feature dimensions, we learn a Mahalanobis distance metric in\nan online fashion and incorporate the learned metric into the optimization\nproblem for obtaining the linear representation. We show that online metric\nlearning using proximity comparison significantly improves the robustness of\nthe tracking, especially on those sequences exhibiting drastic appearance\nchanges. Furthermore, in order to prevent the unbounded growth in the number of\ntraining samples for the metric learning, we design a time-weighted reservoir\nsampling method to maintain and update limited-sized foreground and background\nsample buffers for balancing sample diversity and adaptability. Experimental\nresults on challenging videos demonstrate the effectiveness and robustness of\nthe proposed tracker.\n",
        "published": "2012-04-13T08:16:41Z",
        "pdf_link": "http://arxiv.org/pdf/1204.2912v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.4257v1",
        "title": "Speech Recognition: Increasing Efficiency of Support Vector Machines",
        "summary": "  With the advancement of communication and security technologies, it has\nbecome crucial to have robustness of embedded biometric systems. This paper\npresents the realization of such technologies which demands reliable and\nerror-free biometric identity verification systems. High dimensional patterns\nare not permitted due to eigen-decomposition in high dimensional feature space\nand degeneration of scattering matrices in small size sample. Generalization,\ndimensionality reduction and maximizing the margins are controlled by\nminimizing weight vectors. Results show good pattern by multimodal biometric\nsystem proposed in this paper. This paper is aimed at investigating a biometric\nidentity system using Support Vector Machines(SVMs) and Lindear Discriminant\nAnalysis(LDA) with MFCCs and implementing such system in real-time using\nSignalWAVE.\n",
        "published": "2012-04-19T06:10:02Z",
        "pdf_link": "http://arxiv.org/pdf/1204.4257v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.5416v1",
        "title": "A New Approach of Improving CFA Image for Digital Camera's",
        "summary": "  This paper work directly towards the improving the quality of the image for\nthe digital cameras and other visual capturing products. In this Paper, the\nauthors clearly defines the problems occurs in the CFA image. A different\nmethodology for removing the noise is discuses in the paper for color\ncorrection and color balancing of the image. At the same time, the authors also\nproposed a new methodology of providing denoisiing process before the\ndemosaickingfor the improving the image quality of CFA which is much efficient\nthen the other previous defined. The demosaicking process for producing the\ncolors in the image in a best way is also discuss.\n",
        "published": "2012-04-24T15:45:37Z",
        "pdf_link": "http://arxiv.org/pdf/1204.5416v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.5431v2",
        "title": "Robust Head Pose Estimation Using Contourlet Transform",
        "summary": "  Estimating pose of the head is an important preprocessing step in many\npattern recognition and computer vision systems such as face recognition. Since\nthe performance of the face recognition systems is greatly affected by the\nposes of the face, how to estimate the accurate pose of the face in human face\nimage is still a challenging problem. In this paper, we represent a novel\nmethod for head pose estimation. To enhance the efficiency of the estimation we\nuse contourlet transform for feature extraction. Contourlet transform is\nmulti-resolution, multi-direction transform. In order to reduce the feature\nspace dimension and obtain appropriate features we use LDA (Linear Discriminant\nAnalysis) and PCA (Principal Component Analysis) to remove ineffcient features.\nThen, we apply different classifiers such as k-nearest neighborhood (knn) and\nminimum distance. We use the public available FERET database to evaluate the\nperformance of proposed method. Simulation results indicate the superior\nrobustness of the proposed method.\n",
        "published": "2012-04-24T17:08:04Z",
        "pdf_link": "http://arxiv.org/pdf/1204.5431v2"
    },
    {
        "id": "http://arxiv.org/abs/1204.6326v2",
        "title": "Background subtraction based on Local Shape",
        "summary": "  We present a novel approach to background subtraction that is based on the\nlocal shape of small image regions. In our approach, an image region centered\non a pixel is mod-eled using the local self-similarity descriptor. We aim at\nobtaining a reliable change detection based on local shape change in an image\nwhen foreground objects are moving. The method first builds a background model\nand compares the local self-similarities between the background model and the\nsubsequent frames to distinguish background and foreground objects.\nPost-processing is then used to refine the boundaries of moving objects.\nResults show that this approach is promising as the foregrounds obtained are\ncom-plete, although they often include shadows.\n",
        "published": "2012-04-27T20:26:34Z",
        "pdf_link": "http://arxiv.org/pdf/1204.6326v2"
    },
    {
        "id": "http://arxiv.org/abs/1204.6458v1",
        "title": "Active Contour with A Tangential Component",
        "summary": "  Conventional edge-based active contours often require the normal component of\nan edge indicator function on the optimal contours to approximate zero, while\nthe tangential component can still be significant. In real images, the full\ngradients of the edge indicator function along the object boundaries are often\nsmall. Hence, the curve evolution of edge-based active contours can terminate\nearly before converging to the object boundaries with a careless contour\ninitialization. We propose a novel Geodesic Snakes (GeoSnakes) active contour\nthat requires the full gradients of the edge indicator to vanish at the optimal\nsolution. Besides, the conventional curve evolution approach for minimizing\nactive contour energy cannot fully solve the Euler-Lagrange (EL) equation of\nour GeoSnakes active contour, causing a Pseudo Stationary Phenomenon (PSP). To\naddress the PSP problem, we propose an auxiliary curve evolution equation,\nnamed the equilibrium flow (EF) equation. Based on the EF and the conventional\ncurve evolution, we obtain a solution to the full EL equation of GeoSnakes\nactive contour. Experimental results validate the proposed geometrical\ninterpretation of the early termination problem, and they also show that the\nproposed method overcomes the problem.\n",
        "published": "2012-04-29T07:17:28Z",
        "pdf_link": "http://arxiv.org/pdf/1204.6458v1"
    },
    {
        "id": "http://arxiv.org/abs/1204.6563v2",
        "title": "Parametric annealing: a stochastic search method for human pose tracking",
        "summary": "  Model based methods to marker-free motion capture have a very high\ncomputational overhead that make them unattractive. In this paper we describe a\nmethod that improves on existing global optimization techniques to tracking\narticulated objects. Our method improves on the state-of-the-art Annealed\nParticle Filter (APF) by reusing samples across annealing layers and by using\nan adaptive parametric density for diffusion. We compare the proposed method\nwith APF on a scalable problem and study how the two methods scale with the\ndimensionality, multi-modality and the range of search. Then we perform\nsensitivity analysis on the parameters of our algorithm and show that it\ntolerates a wide range of parameter settings. We also show results on tracking\nhuman pose from the widely-used Human Eva I dataset. Our results show that the\nproposed method reduces the tracking error despite using less than 50% of the\ncomputational resources as APF. The tracked output also shows a significant\nqualitative improvement over APF as demonstrated through image and video\nresults.\n",
        "published": "2012-04-30T07:04:08Z",
        "pdf_link": "http://arxiv.org/pdf/1204.6563v2"
    },
    {
        "id": "http://arxiv.org/abs/1204.6653v1",
        "title": "Elimination of Glass Artifacts and Object Segmentation",
        "summary": "  Many images nowadays are captured from behind the glasses and may have\ncertain stains discrepancy because of glass and must be processed to make\ndifferentiation between the glass and objects behind it. This research paper\nproposes an algorithm to remove the damaged or corrupted part of the image and\nmake it consistent with other part of the image and to segment objects behind\nthe glass. The damaged part is removed using total variation inpainting method\nand segmentation is done using kmeans clustering, anisotropic diffusion and\nwatershed transformation. The final output is obtained by interpolation. This\nalgorithm can be useful to applications in which some part of the images are\ncorrupted due to data transmission or needs to segment objects from an image\nfor further processing.\n",
        "published": "2012-04-30T14:47:45Z",
        "pdf_link": "http://arxiv.org/pdf/1204.6653v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.1644v1",
        "title": "DBC based Face Recognition using DWT",
        "summary": "  The applications using face biometric has proved its reliability in last\ndecade. In this paper, we propose DBC based Face Recognition using DWT (DBC-\nFR) model. The Poly-U Near Infra Red (NIR) database images are scanned and\ncropped to get only the face part in pre-processing. The face part is resized\nto 100*100 and DWT is applied to derive LL, LH, HL and HH subbands. The LL\nsubband of size 50*50 is converted into 100 cells with 5*5 dimention of each\ncell. The Directional Binary Code (DBC) is applied on each 5*5 cell to derive\n100 features. The Euclidian distance measure is used to compare the features of\ntest image and database images. The proposed algorithm render better percentage\nrecognition rate compared to the existing algorithm.\n",
        "published": "2012-05-08T09:44:03Z",
        "pdf_link": "http://arxiv.org/pdf/1205.1644v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2031v1",
        "title": "M-FISH Karyotyping - A New Approach Based on Watershed Transform",
        "summary": "  Karyotyping is a process in which chromosomes in a dividing cell are properly\nstained, identified and displayed in a standard format, which helps geneticist\nto study and diagnose genetic factors behind various genetic diseases and for\nstudying cancer. M-FISH (Multiplex Fluorescent In-Situ Hybridization) provides\ncolor karyotyping. In this paper, an automated method for M-FISH chromosome\nsegmentation based on watershed transform followed by naive Bayes\nclassification of each region using the features, mean and standard deviation,\nis presented. Also, a post processing step is added to re-classify the small\nchromosome segments to the neighboring larger segment for reducing the chances\nof misclassification. The approach provided improved accuracy when compared to\nthe pixel-by-pixel approach. The approach was tested on 40 images from the\ndataset and achieved an accuracy of 84.21 %.\n",
        "published": "2012-05-09T16:52:23Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2031v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2164v1",
        "title": "Discrimination of English to other Indian languages (Kannada and Hindi)\n  for OCR system",
        "summary": "  India is a multilingual multi-script country. In every state of India there\nare two languages one is state local language and the other is English. For\nexample in Andhra Pradesh, a state in India, the document may contain text\nwords in English and Telugu script. For Optical Character Recognition (OCR) of\nsuch a bilingual document, it is necessary to identify the script before\nfeeding the text words to the OCRs of individual scripts. In this paper, we are\nintroducing a simple and efficient technique of script identification for\nKannada, English and Hindi text words of a printed document. The proposed\napproach is based on the horizontal and vertical projection profile for the\ndiscrimination of the three scripts. The feature extraction is done based on\nthe horizontal projection profile of each text words. We analysed 700 different\nwords of Kannada, English and Hindi in order to extract the discrimination\nfeatures and for the development of knowledge base. We use the horizontal\nprojection profile of each text word and based on the horizontal projection\nprofile we extract the appropriate features. The proposed system is tested on\n100 different document images containing more than 1000 text words of each\nscript and a classification rate of 98.25%, 99.25% and 98.87% is achieved for\nKannada, English and Hindi respectively.\n",
        "published": "2012-05-10T06:14:51Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2164v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.2663v1",
        "title": "Are visual dictionaries generalizable?",
        "summary": "  Mid-level features based on visual dictionaries are today a cornerstone of\nsystems for classification and retrieval of images. Those state-of-the-art\nrepresentations depend crucially on the choice of a codebook (visual\ndictionary), which is usually derived from the dataset. In general-purpose,\ndynamic image collections (e.g., the Web), one cannot have the entire\ncollection in order to extract a representative dictionary. However, based on\nthe hypothesis that the dictionary reflects only the diversity of low-level\nappearances and does not capture semantics, we argue that a dictionary based on\na small subset of the data, or even on an entirely different dataset, is able\nto produce a good representation, provided that the chosen images span a\ndiverse enough portion of the low-level feature space. Our experiments confirm\nthat hypothesis, opening the opportunity to greatly alleviate the burden in\ngenerating the codebook, and confirming the feasibility of employing visual\ndictionaries in large-scale dynamic environments.\n",
        "published": "2012-05-11T18:54:12Z",
        "pdf_link": "http://arxiv.org/pdf/1205.2663v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.3766v1",
        "title": "Efficient Topology-Controlled Sampling of Implicit Shapes",
        "summary": "  Sampling from distributions of implicitly defined shapes enables analysis of\nvarious energy functionals used for image segmentation. Recent work describes a\ncomputationally efficient Metropolis-Hastings method for accomplishing this\ntask. Here, we extend that framework so that samples are accepted at every\niteration of the sampler, achieving an order of magnitude speed up in\nconvergence. Additionally, we show how to incorporate topological constraints.\n",
        "published": "2012-05-16T19:11:51Z",
        "pdf_link": "http://arxiv.org/pdf/1205.3766v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.3999v1",
        "title": "Optimal Weights Mixed Filter for Removing Mixture of Gaussian and\n  Impulse Noises",
        "summary": "  According to the character of Gaussian, we modify the Rank-Ordered Absolute\nDifferences (ROAD) to Rank-Ordered Absolute Differences of mixture of Gaussian\nand impulse noises (ROADG). It will be more effective to detect impulse noise\nwhen the impulse is mixed with Gaussian noise. Combining rightly the ROADG with\nOptimal Weights Filter (OWF), we obtain a new method to deal with the mixed\nnoise, called Optimal Weights Mixed Filter (OWMF). The simulation results show\nthat the method is effective to remove the mixed noise.\n",
        "published": "2012-05-17T18:15:45Z",
        "pdf_link": "http://arxiv.org/pdf/1205.3999v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.4336v2",
        "title": "Fuzzy - Rough Feature Selection With - Membership Function For\n  Mammogram Classification",
        "summary": "  Breast cancer is the second leading cause for death among women and it is\ndiagnosed with the help of mammograms. Oncologists are miserably failed in\nidentifying the micro calcification at the early stage with the help of the\nmammogram visually. In order to improve the performance of the breast cancer\nscreening, most of the researchers have proposed Computer Aided Diagnosis using\nimage processing. In this study mammograms are preprocessed and features are\nextracted, then the abnormality is identified through the classification. If\nall the extracted features are used, most of the cases are misidentified. Hence\nfeature selection procedure is sought. In this paper, Fuzzy-Rough feature\nselection with {\\pi} membership function is proposed. The selected features are\nused to classify the abnormalities with help of Ant-Miner and Weka tools. The\nexperimental analysis shows that the proposed method improves the mammograms\nclassification accuracy.\n",
        "published": "2012-05-19T15:19:38Z",
        "pdf_link": "http://arxiv.org/pdf/1205.4336v2"
    },
    {
        "id": "http://arxiv.org/abs/1205.4450v3",
        "title": "Spectral Graph Cut from a Filtering Point of View",
        "summary": "  Spectral graph theory is well known and widely used in computer vision. In\nthis paper, we analyze image segmentation algorithms that are based on spectral\ngraph theory, e.g., normalized cut, and show that there is a natural connection\nbetween spectural graph theory based image segmentationand and edge preserving\nfiltering. Based on this connection we show that the normalized cut algorithm\nis equivalent to repeated iterations of bilateral filtering. Then, using this\nequivalence we present and implement a fast normalized cut algorithm for image\nsegmentation. Experiments show that our implementation can solve the original\noptimization problem in the normalized cut algorithm 10 to 100 times faster.\nFurthermore, we present a new algorithm called conditioned normalized cut for\nimage segmentation that can easily incorporate color image patches and\ndemonstrate how this segmentation problem can be solved with edge preserving\nfiltering.\n",
        "published": "2012-05-20T19:30:26Z",
        "pdf_link": "http://arxiv.org/pdf/1205.4450v3"
    },
    {
        "id": "http://arxiv.org/abs/1205.4831v1",
        "title": "Gray Level Co-Occurrence Matrices: Generalisation and Some New Features",
        "summary": "  Gray Level Co-occurrence Matrices (GLCM) are one of the earliest techniques\nused for image texture analysis. In this paper we defined a new feature called\ntrace extracted from the GLCM and its implications in texture analysis are\ndiscussed in the context of Content Based Image Retrieval (CBIR). The\ntheoretical extension of GLCM to n-dimensional gray scale images are also\ndiscussed. The results indicate that trace features outperform Haralick\nfeatures when applied to CBIR.\n",
        "published": "2012-05-22T08:00:45Z",
        "pdf_link": "http://arxiv.org/pdf/1205.4831v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.5097v1",
        "title": "Neural Network Approach for Eye Detection",
        "summary": "  Driving support systems, such as car navigation systems are becoming common\nand they support driver in several aspects. Non-intrusive method of detecting\nFatigue and drowsiness based on eye-blink count and eye directed instruction\ncontrolhelps the driver to prevent from collision caused by drowsy driving. Eye\ndetection and tracking under various conditions such as illumination,\nbackground, face alignment and facial expression makes the problem\ncomplex.Neural Network based algorithm is proposed in this paper to detect the\neyes efficiently. In the proposed algorithm, first the neural Network is\ntrained to reject the non-eye regionbased on images with features of eyes and\nthe images with features of non-eye using Gabor filter and Support Vector\nMachines to reduce the dimension and classify efficiently. In the algorithm,\nfirst the face is segmented using L*a*btransform color space, then eyes are\ndetected using HSV and Neural Network approach. The algorithm is tested on\nnearly 100 images of different persons under different conditions and the\nresults are satisfactory with success rate of 98%.The Neural Network is trained\nwith 50 non-eye images and 50 eye images with different angles using Gabor\nfilter. This paper is a part of research work on \"Development of Non-Intrusive\nsystem for real-time Monitoring and Prediction of Driver Fatigue and\ndrowsiness\" project sponsored by Department of Science & Technology, Govt. of\nIndia, New Delhi at Vignan Institute of Technology and Sciences, Vignan Hills,\nHyderabad.\n",
        "published": "2012-05-23T05:14:20Z",
        "pdf_link": "http://arxiv.org/pdf/1205.5097v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.5351v2",
        "title": "Linearized Alternating Direction Method with Adaptive Penalty and Warm\n  Starts for Fast Solving Transform Invariant Low-Rank Textures",
        "summary": "  Transform Invariant Low-rank Textures (TILT) is a novel and powerful tool\nthat can effectively rectify a rich class of low-rank textures in 3D scenes\nfrom 2D images despite significant deformation and corruption. The existing\nalgorithm for solving TILT is based on the alternating direction method (ADM).\nIt suffers from high computational cost and is not theoretically guaranteed to\nconverge to a correct solution. In this paper, we propose a novel algorithm to\nspeed up solving TILT, with guaranteed convergence. Our method is based on the\nrecently proposed linearized alternating direction method with adaptive penalty\n(LADMAP). To further reduce computation, warm starts are also introduced to\ninitialize the variables better and cut the cost on singular value\ndecomposition. Extensive experimental results on both synthetic and real data\ndemonstrate that this new algorithm works much more efficiently and robustly\nthan the existing algorithm. It could be at least five times faster than the\nprevious method.\n",
        "published": "2012-05-24T07:16:14Z",
        "pdf_link": "http://arxiv.org/pdf/1205.5351v2"
    },
    {
        "id": "http://arxiv.org/abs/1205.5425v1",
        "title": "Locally Orderless Registration",
        "summary": "  Image registration is an important tool for medical image analysis and is\nused to bring images into the same reference frame by warping the coordinate\nfield of one image, such that some similarity measure is minimized. We study\nsimilarity in image registration in the context of Locally Orderless Images\n(LOI), which is the natural way to study density estimates and reveals the 3\nfundamental scales: the measurement scale, the intensity scale, and the\nintegration scale.\n  This paper has three main contributions: Firstly, we rephrase a large set of\npopular similarity measures into a common framework, which we refer to as\nLocally Orderless Registration, and which makes full use of the features of\nlocal histograms. Secondly, we extend the theoretical understanding of the\nlocal histograms. Thirdly, we use our framework to compare two state-of-the-art\nintensity density estimators for image registration: The Parzen Window (PW) and\nthe Generalized Partial Volume (GPV), and we demonstrate their differences on a\npopular similarity measure, Normalized Mutual Information (NMI).\n  We conclude, that complicated similarity measures such as NMI may be\nevaluated almost as fast as simple measures such as Sum of Squared Distances\n(SSD) regardless of the choice of PW and GPV. Also, GPV is an asymmetric\nmeasure, and PW is our preferred choice.\n",
        "published": "2012-05-24T12:56:45Z",
        "pdf_link": "http://arxiv.org/pdf/1205.5425v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.6352v4",
        "title": "Generalized sequential tree-reweighted message passing",
        "summary": "  This paper addresses the problem of approximate MAP-MRF inference in general\ngraphical models. Following [36], we consider a family of linear programming\nrelaxations of the problem where each relaxation is specified by a set of\nnested pairs of factors for which the marginalization constraint needs to be\nenforced. We develop a generalization of the TRW-S algorithm [9] for this\nproblem, where we use a decomposition into junction chains, monotonic w.r.t.\nsome ordering on the nodes. This generalizes the monotonic chains in [9] in a\nnatural way. We also show how to deal with nested factors in an efficient way.\nExperiments show an improvement over min-sum diffusion, MPLP and subgradient\nascent algorithms on a number of computer vision and natural language\nprocessing problems.\n",
        "published": "2012-05-29T13:06:58Z",
        "pdf_link": "http://arxiv.org/pdf/1205.6352v4"
    },
    {
        "id": "http://arxiv.org/abs/1205.6391v2",
        "title": "A Brief Summary of Dictionary Learning Based Approach for Classification",
        "summary": "  This note presents some representative methods which are based on dictionary\nlearning (DL) for classification. We do not review the sophisticated methods or\nframeworks that involve DL for classification, such as online DL and spatial\npyramid matching (SPM), but rather, we concentrate on the direct DL-based\nclassification methods. Here, the \"so-called direct DL-based method\" is the\napproach directly deals with DL framework by adding some meaningful penalty\nterms. By listing some representative methods, we can roughly divide them into\ntwo categories, i.e. (1) directly making the dictionary discriminative and (2)\nforcing the sparse coefficients discriminative to push the discrimination power\nof the dictionary. From this taxonomy, we can expect some extensions of them as\nfuture researches.\n",
        "published": "2012-05-29T15:28:54Z",
        "pdf_link": "http://arxiv.org/pdf/1205.6391v2"
    },
    {
        "id": "http://arxiv.org/abs/1205.6572v1",
        "title": "An Unsupervised Dynamic Image Segmentation using Fuzzy Hopfield Neural\n  Network based Genetic Algorithm",
        "summary": "  This paper proposes a Genetic Algorithm based segmentation method that can\nautomatically segment gray-scale images. The proposed method mainly consists of\nspatial unsupervised grayscale image segmentation that divides an image into\nregions. The aim of this algorithm is to produce precise segmentation of images\nusing intensity information along with neighborhood relationships. In this\npaper, Fuzzy Hopfield Neural Network (FHNN) clustering helps in generating the\npopulation of Genetic algorithm which there by automatically segments the\nimage. This technique is a powerful method for image segmentation and works for\nboth single and multiple-feature data with spatial information. Validity index\nhas been utilized for introducing a robust technique for finding the optimum\nnumber of components in an image. Experimental results shown that the algorithm\ngenerates good quality segmented image.\n",
        "published": "2012-05-30T08:10:59Z",
        "pdf_link": "http://arxiv.org/pdf/1205.6572v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.6605v1",
        "title": "Template-Cut: A Pattern-Based Segmentation Paradigm",
        "summary": "  We present a scale-invariant, template-based segmentation paradigm that sets\nup a graph and performs a graph cut to separate an object from the background.\nTypically graph-based schemes distribute the nodes of the graph uniformly and\nequidistantly on the image, and use a regularizer to bias the cut towards a\nparticular shape. The strategy of uniform and equidistant nodes does not allow\nthe cut to prefer more complex structures, especially when areas of the object\nare indistinguishable from the background. We propose a solution by introducing\nthe concept of a \"template shape\" of the target object in which the nodes are\nsampled non-uniformly and non-equidistantly on the image. We evaluate it on\n2D-images where the object's textures and backgrounds are similar, and large\nareas of the object have the same gray level appearance as the background. We\nalso evaluate it in 3D on 60 brain tumor datasets for neurosurgical planning\npurposes.\n",
        "published": "2012-05-30T09:44:43Z",
        "pdf_link": "http://arxiv.org/pdf/1205.6605v1"
    },
    {
        "id": "http://arxiv.org/abs/1205.6745v1",
        "title": "Fingerprint Gender Classification using Wavelet Transform and Singular\n  Value Decomposition",
        "summary": "  A novel method of gender Classification from fingerprint is proposed based on\ndiscrete wavelet transform (DWT) and singular value decomposition (SVD). The\nclassification is achieved by extracting the energy computed from all the\nsub-bands of DWT combined with the spatial features of non-zero singular values\nobtained from the SVD of fingerprint images. K nearest neighbor (KNN) used as a\nclassifier. This method is experimented with the internal database of 3570\nfingerprints finger prints in which 1980 were male fingerprints and 1590 were\nfemale fingerprints. Finger-wise gender classification is achieved which is\n94.32% for the left hand little fingers of female persons and 95.46% for the\nleft hand index finger of male persons. Gender classification for any finger of\nmale persons tested is attained as 91.67% and 84.69% for female persons\nrespectively. Overall classification rate is 88.28% has been achieved.\n",
        "published": "2012-05-30T16:26:23Z",
        "pdf_link": "http://arxiv.org/pdf/1205.6745v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.0805v3",
        "title": "Anatomical Structure Segmentation in Liver MRI Images",
        "summary": "  Segmentation of medical images is a challenging task owing to their\ncomplexity. A standard segmentation problem within Magnetic Resonance Imaging\n(MRI) is the task of labeling voxels according to their tissue type. Image\nsegmentation provides volumetric quantification of liver area and thus helps in\nthe diagnosis of disorders, such as Hepatitis, Cirrhosis, Jaundice,\nHemochromatosis etc.This work deals with comparison of segmentation by applying\nLevel Set Method,Fuzzy Level Information C-Means Clustering Algorithm and\nGradient Vector Flow Snake Algorithm.The results are compared using the\nparameters such as Number of pixels correctly classified, and percentage of\narea segmented.\n",
        "published": "2012-07-03T14:32:20Z",
        "pdf_link": "http://arxiv.org/pdf/1207.0805v3"
    },
    {
        "id": "http://arxiv.org/abs/1207.1114v3",
        "title": "A Fast Projected Fixed-Point Algorithm for Large Graph Matching",
        "summary": "  We propose a fast approximate algorithm for large graph matching. A new\nprojected fixed-point method is defined and a new doubly stochastic projection\nis adopted to derive the algorithm. Previous graph matching algorithms suffer\nfrom high computational complexity and therefore do not have good scalability\nwith respect to graph size. For matching two weighted graphs of $n$ nodes, our\nalgorithm has time complexity only $O(n^3)$ per iteration and space complexity\n$O(n^2)$. In addition to its scalability, our algorithm is easy to implement,\nrobust, and able to match undirected weighted attributed graphs of different\nsizes. While the convergence rate of previous iterative graph matching\nalgorithms is unknown, our algorithm is theoretically guaranteed to converge at\na linear rate. Extensive experiments on large synthetic and real graphs (more\nthan 1,000 nodes) were conducted to evaluate the performance of various\nalgorithms. Results show that in most cases our proposed algorithm achieves\nbetter performance than previous state-of-the-art algorithms in terms of both\nspeed and accuracy in large graph matching. In particular, with high accuracy,\nour algorithm takes only a few seconds (in a PC) to match two graphs of 1,000\nnodes.\n",
        "published": "2012-07-03T18:20:25Z",
        "pdf_link": "http://arxiv.org/pdf/1207.1114v3"
    },
    {
        "id": "http://arxiv.org/abs/1207.1551v1",
        "title": "An Innovative Skin Detection Approach Using Color Based Image Retrieval\n  Technique",
        "summary": "  From The late 90th, \"Skin Detection\" becomes one of the major problems in\nimage processing. If \"Skin Detection\" will be done in high accuracy, it can be\nused in many cases as face recognition, Human Tracking and etc. Until now so\nmany methods were presented for solving this problem. In most of these methods,\ncolor space was used to extract feature vector for classifying pixels, but the\nmost of them have not good accuracy in detecting types of skin. The proposed\napproach in this paper is based on \"Color based image retrieval\" (CBIR)\ntechnique. In this method, first by means of CBIR method and image tiling and\nconsidering the relation between pixel and its neighbors, a feature vector\nwould be defined and then with using a training step, detecting the skin in the\ntest stage. The result shows that the presenting approach, in addition to its\nhigh accuracy in detecting type of skin, has no sensitivity to illumination\nintensity and moving face orientation.\n",
        "published": "2012-07-06T08:04:38Z",
        "pdf_link": "http://arxiv.org/pdf/1207.1551v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.1649v1",
        "title": "Analysis of Multi-Scale Fractal Dimension to Classify Human Motion",
        "summary": "  In recent years there has been considerable interest in human action\nrecognition. Several approaches have been developed in order to enhance the\nautomatic video analysis. Although some developments have been achieved by the\ncomputer vision community, the properly classification of human motion is still\na hard and challenging task. The objective of this study is to investigate the\nuse of 3D multi-scale fractal dimension to recognize motion patterns in videos.\nIn order to develop a robust strategy for human motion classification, we\nproposed a method where the Fourier transform is used to calculate the\nderivative in which all data points are deemed. Our results shown that\ndifferent accuracy rates can be found for different databases. We believe that\nin specific applications our results are the first step to develop an automatic\nmonitoring system, which can be applied in security systems, traffic\nmonitoring, biology, physical therapy, cardiovascular disease among many\nothers.\n",
        "published": "2012-07-06T15:10:49Z",
        "pdf_link": "http://arxiv.org/pdf/1207.1649v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.1922v1",
        "title": "Spatial And Spectral Quality Evaluation Based On Edges Regions Of\n  Satellite Image Fusion",
        "summary": "  The Quality of image fusion is an essential determinant of the value of\nprocessing images fusion for many applications. Spatial and spectral qualities\nare the two important indexes that used to evaluate the quality of any fused\nimage. However, the jury is still out of fused image's benefits if it compared\nwith its original images. In addition, there is a lack of measures for\nassessing the objective quality of the spatial resolution for the fusion\nmethods. Therefore, an objective quality of the spatial resolution assessment\nfor fusion images is required. Most important details of the image are in edges\nregions, but most standards of image estimation do not depend upon specifying\nthe edges in the image and measuring their edges. However, they depend upon the\ngeneral estimation or estimating the uniform region, so this study deals with\nnew method proposed to estimate the spatial resolution by Contrast Statistical\nAnalysis (CSA) depending upon calculating the contrast of the edge, non edge\nregions and the rate for the edges regions. Specifying the edges in the image\nis made by using Soble operator with different threshold values. In addition,\nestimating the color distortion added by image fusion based on Histogram\nAnalysis of the edge brightness values of all RGB-color bands and Lcomponent.\n",
        "published": "2012-07-08T23:06:38Z",
        "pdf_link": "http://arxiv.org/pdf/1207.1922v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.2346v3",
        "title": "Cups Products in Z2-Cohomology of 3D Polyhedral Complexes",
        "summary": "  Let $I=(\\mathbb{Z}^3,26,6,B)$ be a 3D digital image, let $Q(I)$ be the\nassociated cubical complex and let $\\partial Q(I)$ be the subcomplex of $Q(I)$\nwhose maximal cells are the quadrangles of $Q(I)$ shared by a voxel of $B$ in\nthe foreground -- the object under study -- and by a voxel of\n$\\mathbb{Z}^3\\smallsetminus B$ in the background -- the ambient space. We show\nhow to simplify the combinatorial structure of $\\partial Q(I)$ and obtain a 3D\npolyhedral complex $P(I)$ homeomorphic to $\\partial Q(I)$ but with fewer cells.\nWe introduce an algorithm that computes cup products on\n$H^*(P(I);\\mathbb{Z}_2)$ directly from the combinatorics. The computational\nmethod introduced here can be effectively applied to any polyhedral complex\nembedded in $\\mathbb{R}^3$.\n",
        "published": "2012-07-10T13:40:40Z",
        "pdf_link": "http://arxiv.org/pdf/1207.2346v3"
    },
    {
        "id": "http://arxiv.org/abs/1207.2426v1",
        "title": "A Multi-Agents Architecture to Learn Vision Operators and their\n  Parameters",
        "summary": "  In a vision system, every task needs that the operators to apply should be\n{\\guillemotleft} well chosen {\\guillemotright} and their parameters should be\nalso {\\guillemotleft} well adjusted {\\guillemotright}. The diversity of\noperators and the multitude of their parameters constitute a big challenge for\nusers. As it is very difficult to make the {\\guillemotleft} right\n{\\guillemotright} choice, lack of a specific rule, many disadvantages appear\nand affect the computation time and especially the quality of results. In this\npaper we present a multi-agent architecture to learn the best operators to\napply and their best parameters for a class of images. Our architecture\nconsists of three types of agents: User Agent, Operator Agent and Parameter\nAgent. The User Agent determines the phases of treatment, a library of\noperators and the possible values of their parameters. The Operator Agent\nconstructs all possible combinations of operators and the Parameter Agent, the\ncore of the architecture, adjusts the parameters of each combination by\ntreating a large number of images. Through the reinforcement learning\nmechanism, our architecture does not consider only the system opportunities but\nalso the user preferences.\n",
        "published": "2012-07-10T17:56:00Z",
        "pdf_link": "http://arxiv.org/pdf/1207.2426v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.2537v1",
        "title": "Face Recognition Algorithms based on Transformed Shape Features",
        "summary": "  Human face recognition is, indeed, a challenging task, especially under the\nillumination and pose variations. We examine in the present paper effectiveness\nof two simple algorithms using coiflet packet and Radon transforms to recognize\nhuman faces from some databases of still gray level images, under the\nenvironment of illumination and pose variations. Both the algorithms convert\n2-D gray level training face images into their respective depth maps or\nphysical shape which are subsequently transformed by Coiflet packet and Radon\ntransforms to compute energy for feature extraction. Experiments show that such\ntransformed shape features are robust to illumination and pose variations. With\nthe features extracted, training classes are optimally separated through linear\ndiscriminant analysis (LDA), while classification for test face images is made\nthrough a k-NN classifier, based on L1 norm and Mahalanobis distance measures.\nProposed algorithms are then tested on face images that differ in\nillumination,expression or pose separately, obtained from three\ndatabases,namely, ORL, Yale and Essex-Grimace databases. Results, so obtained,\nare compared with two different existing algorithms.Performance using\nDaubechies wavelets is also examined. It is seen that the proposed Coiflet\npacket and Radon transform based algorithms have significant performance,\nespecially under different illumination conditions and pose variation.\nComparison shows the proposed algorithms are superior.\n",
        "published": "2012-07-11T03:45:18Z",
        "pdf_link": "http://arxiv.org/pdf/1207.2537v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.2602v2",
        "title": "A Novel Approach Coloured Object Tracker with Adaptive Model and\n  Bandwidth using Mean Shift Algorithm",
        "summary": "  The traditional color-based mean-shift tracking algorithm is popular among\ntracking methods due to its simple and efficient procedure, however, the lack\nof dynamism in its target model makes it unsuitable for tracking objects which\nhave changes in their sizes and shapes. In this paper, we propose a fast novel\nthreephase colored object tracker algorithm based on mean shift idea while\nutilizing adaptive model. The proposed method can improve the mentioned\nweaknesses of the original mean-shift algorithm. The experimental results show\nthat the new method is feasible, robust and has acceptable speed in comparison\nwith other algorithms.15 page,\n",
        "published": "2012-07-11T11:29:36Z",
        "pdf_link": "http://arxiv.org/pdf/1207.2602v2"
    },
    {
        "id": "http://arxiv.org/abs/1207.2641v2",
        "title": "Camera identification by grouping images from database, based on shared\n  noise patterns",
        "summary": "  Previous research showed that camera specific noise patterns, so-called\nPRNU-patterns, are extracted from images and related images could be found. In\nthis particular research the focus is on grouping images from a database, based\non a shared noise pattern as an identification method for cameras. Using the\nmethod as described in this article, groups of images, created using the same\ncamera, could be linked from a large database of images. Using MATLAB\nprogramming, relevant image noise patterns are extracted from images much\nquicker than common methods by the use of faster noise extraction filters and\nimprovements to reduce the calculation costs. Relating noise patterns, with a\ncorrelation above a certain threshold value, can quickly be matched. Hereby,\nfrom a database of images, groups of relating images could be linked and the\nmethod could be used to scan a large number of images for suspect noise\npatterns.\n",
        "published": "2012-07-11T13:58:35Z",
        "pdf_link": "http://arxiv.org/pdf/1207.2641v2"
    },
    {
        "id": "http://arxiv.org/abs/1207.3142v2",
        "title": "Color Constancy based on Image Similarity via Bilayer Sparse Coding",
        "summary": "  Computational color constancy is a very important topic in computer vision\nand has attracted many researchers' attention. Recently, lots of research has\nshown the effects of high level visual content information for illumination\nestimation. However, all of these existing methods are essentially\ncombinational strategies in which image's content analysis is only used to\nguide the combination or selection from a variety of individual illumination\nestimation methods. In this paper, we propose a novel bilayer sparse coding\nmodel for illumination estimation that considers image similarity in terms of\nboth low level color distribution and high level image scene content\nsimultaneously. For the purpose, the image's scene content information is\nintegrated with its color distribution to obtain optimal illumination\nestimation model. The experimental results on two real-world image sets show\nthat our algorithm is superior to other prevailing illumination estimation\nmethods, even better than combinational methods.\n",
        "published": "2012-07-13T04:46:19Z",
        "pdf_link": "http://arxiv.org/pdf/1207.3142v2"
    },
    {
        "id": "http://arxiv.org/abs/1207.3370v1",
        "title": "Deconvolution of vibroacoustic images using a simulation model based on\n  a three dimensional point spread function",
        "summary": "  Vibro-acoustography (VA) is a medical imaging method based on the\ndifference-frequency generation produced by the mixture of two focused\nultrasound beams. VA has been applied to different problems in medical imaging\nsuch as imaging bones, microcalcifications in the breast, mass lesions, and\ncalcified arteries. The obtained images may have a resolution of 0.7--0.8 mm.\nCurrent VA systems based on confocal or linear array transducers generate\nC-scan images at the beam focal plane. Images on the axial plane are also\npossible, however the system resolution along depth worsens when compared to\nthe lateral one. Typical axial resolution is about 1.0 cm. Furthermore, the\nelevation resolution of linear array systems is larger than that in lateral\ndirection. This asymmetry degrades C-scan images obtained using linear arrays.\nThe purpose of this article is to study VA image restoration based on a 3D\npoint spread function (PSF) using classical deconvolution algorithms: Wiener,\nconstrained least-squares (CLSs), and geometric mean filters. To assess the\nfilters' performance, we use an image quality index that accounts for\ncorrelation loss, luminance and contrast distortion. Results for simulated VA\nimages show that the quality index achieved with the Wiener filter is 0.9 (1\nindicates perfect restoration). This filter yielded the best result in\ncomparison with the other ones. Moreover, the deconvolution algorithms were\napplied to an experimental VA image of a phantom composed of three stretched\n0.5 mm wires. Experiments were performed using transducer driven at two\nfrequencies, 3075 kHz and 3125 kHz, which resulted in the difference-frequency\nof 50 kHz. Restorations with the theoretical line spread function (LSF) did not\nrecover sufficient information to identify the wires in the images. However,\nusing an estimated LSF the obtained results displayed enough information to\nspot the wires in the images.\n",
        "published": "2012-07-13T21:37:04Z",
        "pdf_link": "http://arxiv.org/pdf/1207.3370v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.3510v2",
        "title": "HMRF-EM-image: Implementation of the Hidden Markov Random Field Model\n  and its Expectation-Maximization Algorithm",
        "summary": "  In this project, we study the hidden Markov random field (HMRF) model and its\nexpectation-maximization (EM) algorithm. We implement a MATLAB toolbox named\nHMRF-EM-image for 2D image segmentation using the HMRF-EM framework. This\ntoolbox also implements edge-prior-preserving image segmentation, and can be\neasily reconfigured for other problems, such as 3D image segmentation.\n",
        "published": "2012-07-15T14:50:17Z",
        "pdf_link": "http://arxiv.org/pdf/1207.3510v2"
    },
    {
        "id": "http://arxiv.org/abs/1207.3538v3",
        "title": "Kernel Principal Component Analysis and its Applications in Face\n  Recognition and Active Shape Models",
        "summary": "  Principal component analysis (PCA) is a popular tool for linear\ndimensionality reduction and feature extraction. Kernel PCA is the nonlinear\nform of PCA, which better exploits the complicated spatial structure of\nhigh-dimensional features. In this paper, we first review the basic ideas of\nPCA and kernel PCA. Then we focus on the reconstruction of pre-images for\nkernel PCA. We also give an introduction on how PCA is used in active shape\nmodels (ASMs), and discuss how kernel PCA can be applied to improve traditional\nASMs. Then we show some experimental results to compare the performance of\nkernel PCA and standard PCA for classification problems. We also implement the\nkernel PCA-based ASMs, and use it to construct human face models.\n",
        "published": "2012-07-15T20:28:26Z",
        "pdf_link": "http://arxiv.org/pdf/1207.3538v3"
    },
    {
        "id": "http://arxiv.org/abs/1207.3576v2",
        "title": "Hierarchical Approach for Total Variation Digital Image Inpainting",
        "summary": "  The art of recovering an image from damage in an undetectable form is known\nas inpainting. The manual work of inpainting is most often a very time\nconsuming process. Due to digitalization of this technique, it is automatic and\nfaster. In this paper, after the user selects the regions to be reconstructed,\nthe algorithm automatically reconstruct the lost regions with the help of the\ninformation surrounding them. The existing methods perform very well when the\nregion to be reconstructed is very small, but fails in proper reconstruction as\nthe area increases. This paper describes a Hierarchical method by which the\narea to be inpainted is reduced in multiple levels and Total Variation(TV)\nmethod is used to inpaint in each level. This algorithm gives better\nperformance when compared with other existing algorithms such as nearest\nneighbor interpolation, Inpainting through Blurring and Sobolev Inpainting.\n",
        "published": "2012-07-16T04:51:07Z",
        "pdf_link": "http://arxiv.org/pdf/1207.3576v2"
    },
    {
        "id": "http://arxiv.org/abs/1207.4129v1",
        "title": "Recovering Articulated Object Models from 3D Range Data",
        "summary": "  We address the problem of unsupervised learning of complex articulated object\nmodels from 3D range data. We describe an algorithm whose input is a set of\nmeshes corresponding to different configurations of an articulated object. The\nalgorithm automatically recovers a decomposition of the object into\napproximately rigid parts, the location of the parts in the different object\ninstances, and the articulated object skeleton linking the parts. Our algorithm\nfirst registers allthe meshes using an unsupervised non-rigid technique\ndescribed in a companion paper. It then segments the meshes using a graphical\nmodel that captures the spatial contiguity of parts. The segmentation is done\nusing the EM algorithm, iterating between finding a decomposition of the object\ninto rigid parts, and finding the location of the parts in the object\ninstances. Although the graphical model is densely connected, the object\ndecomposition step can be performed optimally and efficiently, allowing us to\nidentify a large number of object parts while avoiding local maxima. We\ndemonstrate the algorithm on real world datasets, recovering a 15-part\narticulated model of a human puppet from just 7 different puppet\nconfigurations, as well as a 4 part model of a fiexing arm where significant\nnon-rigid deformation was present.\n",
        "published": "2012-07-11T14:48:13Z",
        "pdf_link": "http://arxiv.org/pdf/1207.4129v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.4179v1",
        "title": "Probabilistic index maps for modeling natural signals",
        "summary": "  One of the major problems in modeling natural signals is that signals with\nvery similar structure may locally have completely different measurements,\ne.g., images taken under different illumination conditions, or the speech\nsignal captured in different environments. While there have been many\nsuccessful attempts to address these problems in application-specific settings,\nwe believe that underlying a large set of problems in signal representation is\na representational deficiency of intensity-derived local measurements that are\nthe basis of most efficient models. We argue that interesting structure in\nsignals is better captured when the signal is de- fined as a matrix whose\nentries are discrete indices to a separate palette of possible measurements. In\norder to model the variability in signal structure, we define a signal class\nnot by a single index map, but by a probability distribution over the index\nmaps, which can be estimated from the data, and which we call probabilistic\nindex maps. The existing algorithm can be adapted to work with this\nrepresentation. Furthermore, the probabilistic index map representation leads\nto algorithms with computational costs proportional to either the size of the\npalette or the log of the size of the palette, making the cost of significantly\nincreased invariance to non-structural changes quite bearable. We illustrate\nthe benefits of the probabilistic index map representation in several\napplications in computer vision and speech processing.\n",
        "published": "2012-07-12T19:47:14Z",
        "pdf_link": "http://arxiv.org/pdf/1207.4179v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.4308v1",
        "title": "Assessment of SAR Image Filtering using Adaptive Stack Filters",
        "summary": "  Stack filters are a special case of non-linear filters. They have a good\nperformance for filtering images with different types of noise while preserving\nedges and details. A stack filter decomposes an input image into several binary\nimages according to a set of thresholds. Each binary image is then filtered by\na Boolean function, which characterizes the filter. Adaptive stack filters can\nbe designed to be optimal; they are computed from a pair of images consisting\nof an ideal noiseless image and its noisy version. In this work we study the\nperformance of adaptive stack filters when they are applied to Synthetic\nAperture Radar (SAR) images. This is done by evaluating the quality of the\nfiltered images through the use of suitable image quality indexes and by\nmeasuring the classification accuracy of the resulting images.\n",
        "published": "2012-07-18T09:16:07Z",
        "pdf_link": "http://arxiv.org/pdf/1207.4308v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.5007v1",
        "title": "Multisegmentation through wavelets: Comparing the efficacy of Daubechies\n  vs Coiflets",
        "summary": "  In this paper, we carry out a comparative study of the efficacy of wavelets\nbelonging to Daubechies and Coiflet family in achieving image segmentation\nthrough a fast statistical algorithm.The fact that wavelets belonging to\nDaubechies family optimally capture the polynomial trends and those of Coiflet\nfamily satisfy mini-max condition, makes this comparison interesting. In the\ncontext of the present algorithm, it is found that the performance of Coiflet\nwavelets is better, as compared to Daubechies wavelet.\n",
        "published": "2012-07-20T17:37:27Z",
        "pdf_link": "http://arxiv.org/pdf/1207.5007v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.5064v1",
        "title": "A Novel Metric Approach Evaluation For The Spatial Enhancement Of\n  Pan-Sharpened Images",
        "summary": "  Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. The\nQuality of image fusion is an essential determinant of the value of processing\nimages fusion for many applications. Spatial and spectral qualities are the two\nimportant indexes that used to evaluate the quality of any fused image.\nHowever, the jury is still out of fused image's benefits if it compared with\nits original images. In addition, there is a lack of measures for assessing the\nobjective quality of the spatial resolution for the fusion methods. So, an\nobjective quality of the spatial resolution assessment for fusion images is\nrequired. Therefore, this paper describes a new approach proposed to estimate\nthe spatial resolution improve by High Past Division Index (HPDI) upon\ncalculating the spatial-frequency of the edge regions of the image and it deals\nwith a comparison of various analytical techniques for evaluating the Spatial\nquality, and estimating the colour distortion added by image fusion including:\nMG, SG, FCC, SD, En, SNR, CC and NRMSE. In addition, this paper devotes to\nconcentrate on the comparison of various image fusion techniques based on pixel\nand feature fusion technique.\n",
        "published": "2012-07-20T21:30:35Z",
        "pdf_link": "http://arxiv.org/pdf/1207.5064v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.5113v1",
        "title": "Piecewise Linear Patch Reconstruction for Segmentation and Description\n  of Non-smooth Image Structures",
        "summary": "  In this paper, we propose a unified energy minimization model for the\nsegmentation of non-smooth image structures. The energy of piecewise linear\npatch reconstruction is considered as an objective measure of the quality of\nthe segmentation of non-smooth structures. The segmentation is achieved by\nminimizing the single energy without any separate process of feature\nextraction. We also prove that the error of segmentation is bounded by the\nproposed energy functional, meaning that minimizing the proposed energy leads\nto reducing the error of segmentation. As a by-product, our method produces a\ndictionary of optimized orthonormal descriptors for each segmented region. The\nunique feature of our method is that it achieves the simultaneous segmentation\nand description for non-smooth image structures under the same optimization\nframework. The experiments validate our theoretical claims and show the clear\nsuperior performance of our methods over other related methods for segmentation\nof various image textures. We show that our model can be coupled with the\npiecewise smooth model to handle both smooth and non-smooth structures, and we\ndemonstrate that the proposed model is capable of coping with multiple\ndifferent regions through the one-against-all strategy.\n",
        "published": "2012-07-21T09:38:45Z",
        "pdf_link": "http://arxiv.org/pdf/1207.5113v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.6774v1",
        "title": "A Survey Of Activity Recognition And Understanding The Behavior In Video\n  Survelliance",
        "summary": "  This paper presents a review of human activity recognition and behaviour\nunderstanding in video sequence. The key objective of this paper is to provide\na general review on the overall process of a surveillance system used in the\ncurrent trend. Visual surveillance system is directed on automatic\nidentification of events of interest, especially on tracking and classification\nof moving objects. The processing step of the video surveillance system\nincludes the following stages: Surrounding model, object representation, object\ntracking, activity recognition and behaviour understanding. It describes\ntechniques that use to define a general set of activities that are applicable\nto a wide range of scenes and environments in video sequence.\n",
        "published": "2012-07-29T13:07:09Z",
        "pdf_link": "http://arxiv.org/pdf/1207.6774v1"
    },
    {
        "id": "http://arxiv.org/abs/1207.7244v1",
        "title": "Visual Vocabulary Learning and Its Application to 3D and Mobile Visual\n  Search",
        "summary": "  In this technical report, we review related works and recent trends in visual\nvocabulary based web image search, object recognition, mobile visual search,\nand 3D object retrieval. Especial focuses would be also given for the recent\ntrends in supervised/unsupervised vocabulary optimization, compact descriptor\nfor visual search, as well as in multi-view based 3D object representation.\n",
        "published": "2012-06-29T15:07:26Z",
        "pdf_link": "http://arxiv.org/pdf/1207.7244v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.0967v1",
        "title": "Human Activity Learning using Object Affordances from RGB-D Videos",
        "summary": "  Human activities comprise several sub-activities performed in a sequence and\ninvolve interactions with various objects. This makes reasoning about the\nobject affordances a central task for activity recognition. In this work, we\nconsider the problem of jointly labeling the object affordances and human\nactivities from RGB-D videos. We frame the problem as a Markov Random Field\nwhere the nodes represent objects and sub-activities, and the edges represent\nthe relationships between object affordances, their relations with\nsub-activities, and their evolution over time. We formulate the learning\nproblem using a structural SVM approach, where labeling over various alternate\ntemporal segmentations are considered as latent variables. We tested our method\non a dataset comprising 120 activity videos collected from four subjects, and\nobtained an end-to-end precision of 81.8% and recall of 80.0% for labeling the\nactivities.\n",
        "published": "2012-08-04T23:44:07Z",
        "pdf_link": "http://arxiv.org/pdf/1208.0967v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.1670v1",
        "title": "Performance Measurement and Method Analysis (PMMA) for Fingerprint\n  Reconstruction",
        "summary": "  Fingerprint reconstruction is one of the most well-known and publicized\nbiometrics. Because of their uniqueness and consistency over time, fingerprints\nhave been used for identification over a century, more recently becoming\nautomated due to advancements in computed capabilities. Fingerprint\nreconstruction is popular because of the inherent ease of acquisition, the\nnumerous sources (e.g. ten fingers) available for collection, and their\nestablished use and collections by law enforcement and immigration.\nFingerprints have always been the most practical and positive means of\nidentification. Offenders, being well aware of this, have been coming up with\nways to escape identification by that means. Erasing left over fingerprints,\nusing gloves, fingerprint forgery; are certain examples of methods tried by\nthem, over the years. Failing to prevent themselves, they moved to an extent of\nmutilating their finger skin pattern, to remain unidentified. This article is\nbased upon obliteration of finger ridge patterns and discusses some known cases\nin relation to the same, in chronological order; highlighting the reasons why\noffenders go to an extent of performing such act. The paper gives an overview\nof different methods and performance measurement of the fingerprint\nreconstruction.\n",
        "published": "2012-08-08T14:15:38Z",
        "pdf_link": "http://arxiv.org/pdf/1208.1670v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.1672v1",
        "title": "An Efficient Automatic Attendance System Using Fingerprint\n  Reconstruction Technique",
        "summary": "  Biometric time and attendance system is one of the most successful\napplications of biometric technology. One of the main advantage of a biometric\ntime and attendance system is it avoids \"buddy-punching\". Buddy punching was a\nmajor loophole which will be exploiting in the traditional time attendance\nsystems. Fingerprint recognition is an established field today, but still\nidentifying individual from a set of enrolled fingerprints is a time taking\nprocess. Most fingerprint-based biometric systems store the minutiae template\nof a user in the database. It has been traditionally assumed that the minutiae\ntemplate of a user does not reveal any information about the original\nfingerprint. This belief has now been shown to be false; several algorithms\nhave been proposed that can reconstruct fingerprint images from minutiae\ntemplates. In this paper, a novel fingerprint reconstruction algorithm is\nproposed to reconstruct the phase image, which is then converted into the\ngrayscale image. The proposed reconstruction algorithm reconstructs the phase\nimage from minutiae. The proposed reconstruction algorithm is used to automate\nthe whole process of taking attendance, manually which is a laborious and\ntroublesome work and waste a lot of time, with its managing and maintaining the\nrecords for a period of time is also a burdensome task. The proposed\nreconstruction algorithm has been evaluated with respect to the success rates\nof type-I attack (match the reconstructed fingerprint against the original\nfingerprint) and type-II attack (match the reconstructed fingerprint against\ndifferent impressions of the original fingerprint) using a commercial\nfingerprint recognition system. Given the reconstructed image from our\nalgorithm, we show that both types of attacks can be effectively launched\nagainst a fingerprint recognition system.\n",
        "published": "2012-08-08T14:23:50Z",
        "pdf_link": "http://arxiv.org/pdf/1208.1672v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.2655v1",
        "title": "Stable Segmentation of Digital Image",
        "summary": "  In the paper the optimal image segmentation by means of piecewise constant\napproximations is considered. The optimality is defined by a minimum value of\nthe total squared error or by equivalent value of standard deviation of the\napproximation from the image. The optimal approximations are defined\nindependently on the method of their obtaining and might be generated in\ndifferent algorithms. We investigate the computation of the optimal\napproximation on the grounds of stability with respect to a given set of\nmodifications. To obtain the optimal approximation the Mumford-Shuh model is\ngeneralized and developed, which in the computational part is combined with the\nOtsu method in multi-thresholding version. The proposed solution is proved\nanalytically and experimentally on the example of the standard image.\n",
        "published": "2012-08-13T18:21:05Z",
        "pdf_link": "http://arxiv.org/pdf/1208.2655v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.3133v1",
        "title": "Color Image Compression Algorithm Based on the DCT Blocks",
        "summary": "  This paper presents the performance of different blockbased discrete cosine\ntransform (DCT) algorithms for compressing color image. In this RGB component\nof color image are converted to YCbCr before DCT transform is applied. Y is\nluminance component;Cb and Cr are chrominance components of the image. The\nmodification of the image data is done based on the classification of image\nblocks to edge blocks and non-edge blocks, then the edge block of the image is\ncompressed with low compression and the nonedge blocks is compressed with high\ncompression. The analysis results have indicated that the performance of the\nsuggested method is much better, where the constructed images are less\ndistorted and compressed with higher factor.\n",
        "published": "2012-08-15T14:51:45Z",
        "pdf_link": "http://arxiv.org/pdf/1208.3133v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.3512v1",
        "title": "Contour Completion Around a Fixation Point",
        "summary": "  The paper presents two edge grouping algorithms for finding a closed contour\nstarting from a particular edge point and enclosing a fixation point. Both\nalgorithms search a shortest simple cycle in \\textit{an angularly ordered\ngraph} derived from an edge image where a vertex is an end point of a contour\nfragment and an undirected arc is drawn between a pair of end-points whose\nvisual angle from the fixation point is less than a threshold value, which is\nset to $\\pi/2$ in our experiments. The first algorithm restricts the search\nspace by disregarding arcs that cross the line extending from the fixation\npoint to the starting point. The second algorithm improves the solution of the\nfirst algorithm in a greedy manner. The algorithms were tested with a large\nnumber of natural images with manually placed fixation and starting points. The\nresults are promising.\n",
        "published": "2012-08-16T23:22:50Z",
        "pdf_link": "http://arxiv.org/pdf/1208.3512v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.3665v2",
        "title": "An Evaluation of Popular Copy-Move Forgery Detection Approaches",
        "summary": "  A copy-move forgery is created by copying and pasting content within the same\nimage, and potentially post-processing it. In recent years, the detection of\ncopy-move forgeries has become one of the most actively researched topics in\nblind image forensics. A considerable number of different algorithms have been\nproposed focusing on different types of postprocessed copies. In this paper, we\naim to answer which copy-move forgery detection algorithms and processing steps\n(e.g., matching, filtering, outlier detection, affine transformation\nestimation) perform best in various postprocessing scenarios. The focus of our\nanalysis is to evaluate the performance of previously proposed feature sets. We\nachieve this by casting existing algorithms in a common pipeline. In this\npaper, we examined the 15 most prominent feature sets. We analyzed the\ndetection performance on a per-image basis and on a per-pixel basis. We created\na challenging real-world copy-move dataset, and a software framework for\nsystematic image manipulation. Experiments show, that the keypoint-based\nfeatures SIFT and SURF, as well as the block-based DCT, DWT, KPCA, PCA and\nZernike features perform very well. These feature sets exhibit the best\nrobustness against various noise sources and downsampling, while reliably\nidentifying the copied regions.\n",
        "published": "2012-08-17T19:41:23Z",
        "pdf_link": "http://arxiv.org/pdf/1208.3665v2"
    },
    {
        "id": "http://arxiv.org/abs/1208.3670v1",
        "title": "A Survey of Recent View-based 3D Model Retrieval Methods",
        "summary": "  Extensive research efforts have been dedicated to 3D model retrieval in\nrecent decades. Recently, view-based methods have attracted much research\nattention due to the high discriminative property of multi-views for 3D object\nrepresentation. In this report, we summarize the view-based 3D model methods\nand provide the further research trends. This paper focuses on the scheme for\nmatching between multiple views of 3D models and the application of\nbag-of-visual-words method in 3D model retrieval. For matching between multiple\nviews, the many-to-many matching, probabilistic matching and semisupervised\nlearning methods are introduced. For bag-of-visual-words application in 3D\nmodel retrieval, we first briefly review the bag-of-visual-words works on\nmultimedia and computer vision tasks, where the visual dictionary has been\ndetailed introduced. Then a series of 3D model retrieval methods by using\nbag-of-visual-words description are surveyed in this paper. At last, we\nsummarize the further research content in view-based 3D model retrieval.\n",
        "published": "2012-08-08T04:45:42Z",
        "pdf_link": "http://arxiv.org/pdf/1208.3670v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.3716v2",
        "title": "Improved Total Variation based Image Compressive Sensing Recovery by\n  Nonlocal Regularization",
        "summary": "  Recently, total variation (TV) based minimization algorithms have achieved\ngreat success in compressive sensing (CS) recovery for natural images due to\nits virtue of preserving edges. However, the use of TV is not able to recover\nthe fine details and textures, and often suffers from undesirable staircase\nartifact. To reduce these effects, this letter presents an improved TV based\nimage CS recovery algorithm by introducing a new nonlocal regularization\nconstraint into CS optimization problem. The nonlocal regularization is built\non the well known nonlocal means (NLM) filtering and takes advantage of\nself-similarity in images, which helps to suppress the staircase effect and\nrestore the fine details. Furthermore, an efficient augmented Lagrangian based\nalgorithm is developed to solve the above combined TV and nonlocal\nregularization constrained problem. Experimental results demonstrate that the\nproposed algorithm achieves significant performance improvements over the\nstate-of-the-art TV based algorithm in both PSNR and visual perception.\n",
        "published": "2012-08-18T01:48:05Z",
        "pdf_link": "http://arxiv.org/pdf/1208.3716v2"
    },
    {
        "id": "http://arxiv.org/abs/1208.3723v1",
        "title": "Image Super-Resolution via Dual-Dictionary Learning And Sparse\n  Representation",
        "summary": "  Learning-based image super-resolution aims to reconstruct high-frequency (HF)\ndetails from the prior model trained by a set of high- and low-resolution image\npatches. In this paper, HF to be estimated is considered as a combination of\ntwo components: main high-frequency (MHF) and residual high-frequency (RHF),\nand we propose a novel image super-resolution method via dual-dictionary\nlearning and sparse representation, which consists of the main dictionary\nlearning and the residual dictionary learning, to recover MHF and RHF\nrespectively. Extensive experimental results on test images validate that by\nemploying the proposed two-layer progressive scheme, more image details can be\nrecovered and much better results can be achieved than the state-of-the-art\nalgorithms in terms of both PSNR and visual perception.\n",
        "published": "2012-08-18T03:00:03Z",
        "pdf_link": "http://arxiv.org/pdf/1208.3723v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.3901v3",
        "title": "Trace transform based method for color image domain identification",
        "summary": "  Context categorization is a fundamental pre-requisite for multi-domain\nmultimedia content analysis applications in order to manage contextual\ninformation in an efficient manner. In this paper, we introduce a new color\nimage context categorization method (DITEC) based on the trace transform. The\nproblem of dimensionality reduction of the obtained trace transform signal is\naddressed through statistical descriptors that keep the underlying information.\nThese extracted features offer a highly discriminant behavior for content\ncategorization. The theoretical properties of the method are analyzed and\nvalidated experimentally through two different datasets.\n",
        "published": "2012-08-19T22:21:19Z",
        "pdf_link": "http://arxiv.org/pdf/1208.3901v3"
    },
    {
        "id": "http://arxiv.org/abs/1208.4316v1",
        "title": "An Online Character Recognition System to Convert Grantha Script to\n  Malayalam",
        "summary": "  This paper presents a novel approach to recognize Grantha, an ancient script\nin South India and converting it to Malayalam, a prevalent language in South\nIndia using online character recognition mechanism. The motivation behind this\nwork owes its credit to (i) developing a mechanism to recognize Grantha script\nin this modern world and (ii) affirming the strong connection among Grantha and\nMalayalam. A framework for the recognition of Grantha script using online\ncharacter recognition is designed and implemented. The features extracted from\nthe Grantha script comprises mainly of time-domain features based on writing\ndirection and curvature. The recognized characters are mapped to corresponding\nMalayalam characters. The framework was tested on a bed of medium length\nmanuscripts containing 9-12 sample lines and printed pages of a book titled\nSoundarya Lahari writtenin Grantha by Sri Adi Shankara to recognize the words\nand sentences. The manuscript recognition rates with the system are for Grantha\nas 92.11%, Old Malayalam 90.82% and for new Malayalam script 89.56%. The\nrecognition rates of pages of the printed book are for Grantha as 96.16%, Old\nMalayalam script 95.22% and new Malayalam script as 92.32% respectively. These\nresults show the efficiency of the developed system.\n",
        "published": "2012-08-21T17:40:15Z",
        "pdf_link": "http://arxiv.org/pdf/1208.4316v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.4842v1",
        "title": "The Segmentation Fusion Method On10 Multi-Sensors",
        "summary": "  The most significant problem may be undesirable effects for the spectral\nsignatures of fused images as well as the benefits of using fused images mostly\ncompared to their source images were acquired at the same time by one sensor.\nThey may or may not be suitable for the fusion of other images. It becomes\ntherefore increasingly important to investigate techniques that allow\nmulti-sensor, multi-date image fusion to make final conclusions can be drawn on\nthe most suitable method of fusion. So, In this study we present a new method\nSegmentation Fusion method (SF) for remotely sensed images is presented by\nconsidering the physical characteristics of sensors, which uses a feature level\nprocessing paradigm. In a particularly, attempts to test the proposed method\nperformance on 10 multi-sensor images and comparing it with different fusion\ntechniques for estimating the quality and degree of information improvement\nquantitatively by using various spatial and spectral metrics.\n",
        "published": "2012-08-23T14:55:30Z",
        "pdf_link": "http://arxiv.org/pdf/1208.4842v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.5016v1",
        "title": "WESD - Weighted Spectral Distance for Measuring Shape Dissimilarity",
        "summary": "  This article presents a new distance for measuring shape dissimilarity\nbetween objects. Recent publications introduced the use of eigenvalues of the\nLaplace operator as compact shape descriptors. Here, we revisit the eigenvalues\nto define a proper distance, called Weighted Spectral Distance (WESD), for\nquantifying shape dissimilarity. The definition of WESD is derived through\nanalysing the heat-trace. This analysis provides the proposed distance an\nintuitive meaning and mathematically links it to the intrinsic geometry of\nobjects. We analyse the resulting distance definition, present and prove its\nimportant theoretical properties. Some of these properties include: i) WESD is\ndefined over the entire sequence of eigenvalues yet it is guaranteed to\nconverge, ii) it is a pseudometric, iii) it is accurately approximated with a\nfinite number of eigenvalues, and iv) it can be mapped to the [0,1) interval.\nLastly, experiments conducted on synthetic and real objects are presented.\nThese experiments highlight the practical benefits of WESD for applications in\nvision and medical image analysis.\n",
        "published": "2012-08-24T17:38:46Z",
        "pdf_link": "http://arxiv.org/pdf/1208.5016v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.5451v1",
        "title": "Are You Imitating Me? Unsupervised Sparse Modeling for Group Activity\n  Analysis from a Single Video",
        "summary": "  A framework for unsupervised group activity analysis from a single video is\nhere presented. Our working hypothesis is that human actions lie on a union of\nlow-dimensional subspaces, and thus can be efficiently modeled as sparse linear\ncombinations of atoms from a learned dictionary representing the action's\nprimitives. Contrary to prior art, and with the primary goal of spatio-temporal\naction grouping, in this work only one single video segment is available for\nboth unsupervised learning and analysis without any prior training information.\nAfter extracting simple features at a single spatio-temporal scale, we learn a\ndictionary for each individual in the video during each short time lapse. These\ndictionaries allow us to compare the individuals' actions by producing an\naffinity matrix which contains sufficient discriminative information about the\nactions in the scene leading to grouping with simple and efficient tools. With\ndiverse publicly available real videos, we demonstrate the effectiveness of the\nproposed framework and its robustness to cluttered backgrounds, changes of\nhuman appearance, and action variability.\n",
        "published": "2012-08-27T17:21:39Z",
        "pdf_link": "http://arxiv.org/pdf/1208.5451v1"
    },
    {
        "id": "http://arxiv.org/abs/1208.6137v1",
        "title": "Benchmarking recognition results on word image datasets",
        "summary": "  We have benchmarked the maximum obtainable recognition accuracy on various\nword image datasets using manual segmentation and a currently available\ncommercial OCR. We have developed a Matlab program, with graphical user\ninterface, for semi-automated pixel level segmentation of word images. We\ndiscuss the advantages of pixel level annotation. We have covered five\ndatabases adding up to over 3600 word images. These word images have been\ncropped from camera captured scene, born-digital and street view images. We\nrecognize the segmented word image using the trial version of Nuance Omnipage\nOCR. We also discuss, how the degradations introduced during acquisition or\ninaccuracies introduced during creation of word images affect the recognition\nof the word present in the image. Word images for different kinds of\ndegradations and correction for slant and curvy nature of words are also\ndiscussed. The word recognition rates obtained on ICDAR 2003, Sign evaluation,\nStreet view, Born-digital and ICDAR 2011 datasets are 83.9%, 89.3%, 79.6%,\n88.5% and 86.7% respectively.\n",
        "published": "2012-08-30T11:24:44Z",
        "pdf_link": "http://arxiv.org/pdf/1208.6137v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.1181v1",
        "title": "FCM Based Blood Vessel Segmentation Method for Retinal Images",
        "summary": "  Segmentation of blood vessels in retinal images provides early diagnosis of\ndiseases like glaucoma, diabetic retinopathy and macular degeneration. Among\nthese diseases occurrence of Glaucoma is most frequent and has serious ocular\nconsequences that can even lead to blindness, if it is not detected early. The\nclinical criteria for the diagnosis of glaucoma include intraocular pressure\nmeasurement, optic nerve head evaluation, retinal nerve fiber layer and visual\nfield defects. This form of blood vessel segmentation helps in early detection\nfor ophthalmic diseases, and potentially reduces the risk of blindness. The\nlow-contrast images at the retina owing to narrow blood vessels of the retina\nare difficult to extract. These low contrast images are, however useful in\nrevealing certain systemic diseases. Motivated by the goals of improving\ndetection of such vessels, this present work proposes an algorithm for\nsegmentation of blood vessels and compares the results between expert\nophthalmologist hand-drawn ground-truths and segmented image(i.e. the output of\nthe present work).Sensitivity, specificity, positive predictive value (PPV),\npositive likelihood ratio (PLR) and accuracy are used to evaluate overall\nperformance.It is found that this work segments blood vessels successfully with\nsensitivity, specificity, PPV, PLR and accuracy of 99.62%, 54.66%, 95.08%,\n219.72 and 95.03%, respectively.\n",
        "published": "2012-09-06T05:12:53Z",
        "pdf_link": "http://arxiv.org/pdf/1209.1181v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.1224v1",
        "title": "Wavelet Based Normal and Abnormal Heart Sound Identification using\n  Spectrogram Analysis",
        "summary": "  The present work proposes a computer-aided normal and abnormal heart sound\nidentification based on Discrete Wavelet Transform (DWT), it being useful for\ntele-diagnosis of heart diseases. Due to the presence of Cumulative Frequency\ncomponents in the spectrogram, DWT is applied on the spectro-gram up to n level\nto extract the features from the individual approximation components. One\ndimensional feature vector is obtained by evaluating the Row Mean of the\napproximation components of these spectrograms. For this present approach, the\nset of spectrograms has been considered as the database, rather than raw sound\nsamples. Minimum Euclidean distance is computed between feature vector of the\ntest sample and the feature vectors of the stored samples to identify the heart\nsound. By applying this algorithm, almost 82% of accuracy was achieved.\n",
        "published": "2012-09-06T08:37:44Z",
        "pdf_link": "http://arxiv.org/pdf/1209.1224v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.1558v1",
        "title": "A Comparative Study between Moravec and Harris Corner Detection of Noisy\n  Images Using Adaptive Wavelet Thresholding Technique",
        "summary": "  In this paper a comparative study between Moravec and Harris Corner Detection\nhas been done for obtaining features required to track and recognize objects\nwithin a noisy image. Corner detection of noisy images is a challenging task in\nimage processing. Natural images often get corrupted by noise during\nacquisition and transmission. As Corner detection of these noisy images does\nnot provide desired results, hence de-noising is required. Adaptive wavelet\nthresholding approach is applied for the same.\n",
        "published": "2012-09-07T14:52:02Z",
        "pdf_link": "http://arxiv.org/pdf/1209.1558v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.1563v1",
        "title": "Wavelet Based QRS Complex Detection of ECG Signal",
        "summary": "  The Electrocardiogram (ECG) is a sensitive diagnostic tool that is used to\ndetect various cardiovascular diseases by measuring and recording the\nelectrical activity of the heart in exquisite detail. A wide range of heart\ncondition is determined by thorough examination of the features of the ECG\nreport. Automatic extraction of time plane features is important for\nidentification of vital cardiac diseases. This paper presents a\nmulti-resolution wavelet transform based system for detection 'P', 'Q', 'R',\n'S', 'T' peaks complex from original ECG signal. 'R-R' time lapse is an\nimportant minutia of the ECG signal that corresponds to the heartbeat of the\nconcerned person. Abrupt increase in height of the 'R' wave or changes in the\nmeasurement of the 'R-R' denote various anomalies of human heart. Similarly\n'P-P', 'Q-Q', 'S-S', 'T-T' also corresponds to different anomalies of heart and\ntheir peak amplitude also envisages other cardiac diseases. In this proposed\nmethod the 'PQRST' peaks are marked and stored over the entire signal and the\ntime interval between two consecutive 'R' peaks and other peaks interval are\nmeasured to detect anomalies in behavior of heart, if any. The peaks are\nachieved by the composition of Daubeheissub bands wavelet of original ECG\nsignal. The accuracy of the 'PQRST' complex detection and interval measurement\nis achieved up to 100% with high exactitude by processing and thresholding the\noriginal ECG signal.\n",
        "published": "2012-09-07T15:05:57Z",
        "pdf_link": "http://arxiv.org/pdf/1209.1563v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.1759v1",
        "title": "Difference of Normals as a Multi-Scale Operator in Unorganized Point\n  Clouds",
        "summary": "  A novel multi-scale operator for unorganized 3D point clouds is introduced.\nThe Difference of Normals (DoN) provides a computationally efficient,\nmulti-scale approach to processing large unorganized 3D point clouds. The\napplication of DoN in the multi-scale filtering of two different real-world\noutdoor urban LIDAR scene datasets is quantitatively and qualitatively\ndemonstrated. In both datasets the DoN operator is shown to segment large 3D\npoint clouds into scale-salient clusters, such as cars, people, and lamp posts\ntowards applications in semi-automatic annotation, and as a pre-processing step\nin automatic object recognition. The application of the operator to\nsegmentation is evaluated on a large public dataset of outdoor LIDAR scenes\nwith ground truth annotations.\n",
        "published": "2012-09-08T22:43:28Z",
        "pdf_link": "http://arxiv.org/pdf/1209.1759v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.1788v1",
        "title": "On the Use of Lee's Protocol for Speckle-Reducing Techniques",
        "summary": "  This paper presents two new MAP (Maximum a Posteriori) filters for speckle\nnoise reduction and a Monte Carlo procedure for the assessment of their\nperformance. In order to quantitatively evaluate the results obtained using\nthese new filters, with respect to classical ones, a Monte Carlo extension of\nLee's protocol is proposed. This extension of the protocol shows that its\noriginal version leads to inconsistencies that hamper its use as a general\nprocedure for filter assessment. Some solutions for these inconsistencies are\nproposed, and a consistent comparison of speckle-reducing filters is provided.\n",
        "published": "2012-09-09T10:30:08Z",
        "pdf_link": "http://arxiv.org/pdf/1209.1788v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.2082v3",
        "title": "Blind Image Deblurring by Spectral Properties of Convolution Operators",
        "summary": "  In this paper, we study the problem of recovering a sharp version of a given\nblurry image when the blur kernel is unknown. Previous methods often introduce\nan image-independent regularizer (such as Gaussian or sparse priors) on the\ndesired blur kernel. We shall show that the blurry image itself encodes rich\ninformation about the blur kernel. Such information can be found through\nanalyzing and comparing how the spectrum of an image as a convolution operator\nchanges before and after blurring. Our analysis leads to an effective convex\nregularizer on the blur kernel which depends only on the given blurry image. We\nshow that the minimizer of this regularizer guarantees to give good\napproximation to the blur kernel if the original image is sharp enough. By\ncombining this powerful regularizer with conventional image deblurring\ntechniques, we show how we could significantly improve the deblurring results\nthrough simulations and experiments on real images. In addition, our analysis\nand experiments help explaining a widely accepted doctrine; that is, the edges\nare good features for deblurring.\n",
        "published": "2012-09-10T18:19:36Z",
        "pdf_link": "http://arxiv.org/pdf/1209.2082v3"
    },
    {
        "id": "http://arxiv.org/abs/1209.2515v1",
        "title": "Wavelet Based Image Coding Schemes : A Recent Survey",
        "summary": "  A variety of new and powerful algorithms have been developed for image\ncompression over the years. Among them the wavelet-based image compression\nschemes have gained much popularity due to their overlapping nature which\nreduces the blocking artifacts that are common phenomena in JPEG compression\nand multiresolution character which leads to superior energy compaction with\nhigh quality reconstructed images. This paper provides a detailed survey on\nsome of the popular wavelet coding techniques such as the Embedded Zerotree\nWavelet (EZW) coding, Set Partitioning in Hierarchical Tree (SPIHT) coding, the\nSet Partitioned Embedded Block (SPECK) Coder, and the Embedded Block Coding\nwith Optimized Truncation (EBCOT) algorithm. Other wavelet-based coding\ntechniques like the Wavelet Difference Reduction (WDR) and the Adaptive Scanned\nWavelet Difference Reduction (ASWDR) algorithms, the Space Frequency\nQuantization (SFQ) algorithm, the Embedded Predictive Wavelet Image Coder\n(EPWIC), Compression with Reversible Embedded Wavelet (CREW), the Stack-Run\n(SR) coding and the recent Geometric Wavelet (GW) coding are also discussed.\nBased on the review, recommendations and discussions are presented for\nalgorithm development and implementation.\n",
        "published": "2012-09-12T08:08:50Z",
        "pdf_link": "http://arxiv.org/pdf/1209.2515v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.2816v1",
        "title": "Hirarchical Digital Image Inpainting Using Wavelets",
        "summary": "  Inpainting is the technique of reconstructing unknown or damaged portions of\nan image in a visually plausible way. Inpainting algorithm automatically fills\nthe damaged region in an image using the information available in undamaged\nregion. Propagation of structure and texture information becomes a challenge as\nthe size of damaged area increases. In this paper, a hierarchical inpainting\nalgorithm using wavelets is proposed. The hierarchical method tries to keep the\nmask size smaller while wavelets help in handling the high pass structure\ninformation and low pass texture information separately. The performance of the\nproposed algorithm is tested using different factors. The results of our\nalgorithm are compared with existing methods such as interpolation, diffusion\nand exemplar techniques.\n",
        "published": "2012-09-13T08:40:17Z",
        "pdf_link": "http://arxiv.org/pdf/1209.2816v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.2903v1",
        "title": "A Novel Approach of Harris Corner Detection of Noisy Images using\n  Adaptive Wavelet Thresholding Technique",
        "summary": "  In this paper we propose a method of corner detection for obtaining features\nwhich is required to track and recognize objects within a noisy image. Corner\ndetection of noisy images is a challenging task in image processing. Natural\nimages often get corrupted by noise during acquisition and transmission. Though\nCorner detection of these noisy images does not provide desired results, hence\nde-noising is required. Adaptive wavelet thresholding approach is applied for\nthe same.\n",
        "published": "2012-09-13T14:15:16Z",
        "pdf_link": "http://arxiv.org/pdf/1209.2903v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.3113v1",
        "title": "Detection and Classification of Viewer Age Range Smart Signs at TV\n  Broadcast",
        "summary": "  In this paper, the identification and classification of Viewer Age Range\nSmart Signs, designed by the Radio and Television Supreme Council of Turkey, to\ngive age range information for the TV viewers, are realized. Therefore, the\nautomatic detection at the broadcast will be possible, enabling the\nmanufacturing of TV receivers which are sensible to these signs. The most\nimportant step at this process is the pattern recognition. Since the symbols\nthat must be identified are circular, various circle detection techniques can\nbe employed. In our study, first, two different circle segmentation methods for\nstill images are analyzed, their advantages and drawbacks are discussed. A\npopular neural network structure called Multilayer Perceptron is employed for\nthe classification. Afterwards, the same procedures are carried out for\nstreaming video. All of the steps depicted above are realized on a standard PC.\n",
        "published": "2012-09-14T07:52:09Z",
        "pdf_link": "http://arxiv.org/pdf/1209.3113v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.4317v1",
        "title": "Image Super-Resolution via Sparse Bayesian Modeling of Natural Images",
        "summary": "  Image super-resolution (SR) is one of the long-standing and active topics in\nimage processing community. A large body of works for image super resolution\nformulate the problem with Bayesian modeling techniques and then obtain its\nMaximum-A-Posteriori (MAP) solution, which actually boils down to a regularized\nregression task over separable regularization term. Although straightforward,\nthis approach cannot exploit the full potential offered by the probabilistic\nmodeling, as only the posterior mode is sought. Also, the separable property of\nthe regularization term can not capture any correlations between the sparse\ncoefficients, which sacrifices much on its modeling accuracy. We propose a\nBayesian image SR algorithm via sparse modeling of natural images. The sparsity\nproperty of the latent high resolution image is exploited by introducing latent\nvariables into the high-order Markov Random Field (MRF) which capture the\ncontent adaptive variance by pixel-wise adaptation. The high-resolution image\nis estimated via Empirical Bayesian estimation scheme, which is substantially\nfaster than our previous approach based on Markov Chain Monte Carlo sampling\n[1]. It is shown that the actual cost function for the proposed approach\nactually incorporates a non-factorial regularization term over the sparse\ncoefficients. Experimental results indicate that the proposed method can\ngenerate competitive or better results than \\emph{state-of-the-art} SR\nalgorithms.\n",
        "published": "2012-09-19T18:02:41Z",
        "pdf_link": "http://arxiv.org/pdf/1209.4317v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.4419v1",
        "title": "Head Frontal-View Identification Using Extended LLE",
        "summary": "  Automatic head frontal-view identification is challenging due to appearance\nvariations caused by pose changes, especially without any training samples. In\nthis paper, we present an unsupervised algorithm for identifying frontal view\namong multiple facial images under various yaw poses (derived from the same\nperson). Our approach is based on Locally Linear Embedding (LLE), with the\nassumption that with yaw pose being the only variable, the facial images should\nlie in a smooth and low dimensional manifold. We horizontally flip the facial\nimages and present two K-nearest neighbor protocols for the original images and\nthe flipped images, respectively. In the proposed extended LLE, for any facial\nimage (original or flipped one), we search (1) the Ko nearest neighbors among\nthe original facial images and (2) the Kf nearest neighbors among the flipped\nfacial images to construct the same neighborhood graph. The extended LLE\neliminates the differences (because of background, face position and scale in\nthe whole image and some asymmetry of left-right face) between the original\nfacial image and the flipped facial image at the same yaw pose so that the\nflipped facial images can be used effectively. Our approach does not need any\ntraining samples as prior information. The experimental results show that the\nfrontal view of head can be identified reliably around the lowest point of the\npose manifold for multiple facial images, especially the cropped facial images\n(little background and centered face).\n",
        "published": "2012-09-20T04:15:39Z",
        "pdf_link": "http://arxiv.org/pdf/1209.4419v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.4420v1",
        "title": "An Efficient Color Face Verification Based on 2-Directional\n  2-Dimensional Feature Extraction",
        "summary": "  A novel and uniform framework for face verification is presented in this\npaper. First of all, a 2-directional 2-dimensional feature extraction method is\nadopted to extract client-specific template - 2D discrimant projection matrix.\nThen the face skin color information is utilized as an additive feature to\nenhance decision making strategy that makes use of not only 2D grey feature but\nalso 2D skin color feature. A fusion decision of both is applied to experiment\nthe performance on the XM2VTS database according to Lausanne protocol.\nExperimental results show that the framework achieves high verification\naccuracy and verification speed.\n",
        "published": "2012-09-20T04:20:40Z",
        "pdf_link": "http://arxiv.org/pdf/1209.4420v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.5039v1",
        "title": "Creation of Digital Test Form for Prepress Department",
        "summary": "  The main problem in colour management in prepress department is lack of\navailability of literature on colour management and knowledge gap between\nprepress department and press department. So a digital test from has been\ncreated by Adobe Photoshop to analyse the ICC profile and to create a new\nprofile and this analysed data is used to study about various grey scale of RGB\nand CMYK images. That helps in conversion of image from RGB to CMYK in prepress\ndepartment.\n",
        "published": "2012-09-23T07:52:01Z",
        "pdf_link": "http://arxiv.org/pdf/1209.5039v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.5040v1",
        "title": "Image Classification and Optimized Image Reproduction",
        "summary": "  By taking into account the properties and limitations of the human visual\nsystem, images can be more efficiently compressed, colors more accurately\nreproduced, prints better rendered. To show all these advantages in this paper\nnew adapted color charts have been created based on technical and visual image\ncategory analysis. A number of tests have been carried out using extreme images\nwith their key information strictly in dark and light areas. It was shown that\nthe image categorization using the adapted color charts improves the analysis\nof relevant image information with regard to both the image gradation and the\ndetail reproduction. The images with key information in hi-key areas were also\ntest printed using the adapted color charts.\n",
        "published": "2012-09-23T08:11:27Z",
        "pdf_link": "http://arxiv.org/pdf/1209.5040v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.5041v1",
        "title": "An Implementation of Computer Graphics as Prepress Image Enhancement\n  Process",
        "summary": "  The production of a printed product involves three stages: prepress, the\nprinting process (press) itself, and finishing (post press). There are various\ntypes of equipments (printers, scanners) and various qualities image are\npresent in the market. These give different color rendering each time during\nreproduction. So, a color key tool has been developed keeping Color Management\nScheme (CMS) in mind so that during reproduction no color rendering takes place\nirrespective of use of any device and resolution level has also been improved.\n",
        "published": "2012-09-23T09:15:20Z",
        "pdf_link": "http://arxiv.org/pdf/1209.5041v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.5417v1",
        "title": "Model based neuro-fuzzy ASR on Texas processor",
        "summary": "  In this paper an algorithm for recognizing speech has been proposed. The\nrecognized speech is used to execute related commands which use the MFCC and\ntwo kind of classifiers, first one uses MLP and second one uses fuzzy inference\nsystem as a classifier. The experimental results demonstrate the high gain and\nefficiency of the proposed algorithm. We have implemented this system based on\ngraphical design and tested on a fix point digital signal processor (DSP) of\n600 MHz, with reference DM6437-EVM of Texas instrument.\n",
        "published": "2012-09-24T20:47:27Z",
        "pdf_link": "http://arxiv.org/pdf/1209.5417v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.5494v1",
        "title": "Segmentation of Breast Regions in Mammogram Based on Density: A Review",
        "summary": "  The focus of this paper is to review approaches for segmentation of breast\nregions in mammograms according to breast density. Studies based on density\nhave been undertaken because of the relationship between breast cancer and\ndensity. Breast cancer usually occurs in the fibroglandular area of breast\ntissue, which appears bright on mammograms and is described as breast density.\nMost of the studies are focused on the classification methods for glandular\ntissue detection. Others highlighted on the segmentation methods for\nfibroglandular tissue, while few researchers performed segmentation of the\nbreast anatomical regions based on density. There have also been works on the\nsegmentation of other specific parts of breast regions such as either detection\nof nipple position, skin-air interface or pectoral muscles. The problems on the\nevaluation performance of the segmentation results in relation to ground truth\nare also discussed in this paper.\n",
        "published": "2012-09-25T04:58:55Z",
        "pdf_link": "http://arxiv.org/pdf/1209.5494v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.5756v1",
        "title": "Environmental Sounds Spectrogram Classification using Log-Gabor Filters\n  and Multiclass Support Vector Machines",
        "summary": "  This paper presents novel approaches for efficient feature extraction using\nenvironmental sound magnitude spectrogram. We propose approach based on the\nvisual domain. This approach included three methods. The first method is based\non extraction for each spectrogram a single log-Gabor filter followed by mutual\ninformation procedure. In the second method, the spectrogram is passed by the\nsame steps of the first method but with an averaged bank of 12 log-Gabor\nfilter. The third method consists of spectrogram segmentation into three\npatches, and after that for each spectrogram patch we applied the second\nmethod. The classification results prove that the second method is the most\nefficient in our environmental sound classification system.\n",
        "published": "2012-09-25T20:11:23Z",
        "pdf_link": "http://arxiv.org/pdf/1209.5756v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.6037v1",
        "title": "Reproduction of Images by Gamut Mapping and Creation of New Test Charts\n  in Prepress Process",
        "summary": "  With the advent of digital images the problem of keeping picture\nvisualization uniformity arises because each printing or scanning device has\nits own color chart. So, universal color profiles are made by ICC to bring\nuniformity in various types of devices. Keeping that color profile in mind\nvarious new color charts are created and calibrated with the help of standard\nIT8 test charts available in the market. The main objective to color\nreproduction is to produce the identical picture at device output. For that\nprinciples for gamut mapping has been designed\n",
        "published": "2012-09-26T19:25:56Z",
        "pdf_link": "http://arxiv.org/pdf/1209.6037v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.6151v1",
        "title": "Face Alignment Using Active Shape Model And Support Vector Machine",
        "summary": "  The Active Shape Model (ASM) is one of the most popular local texture models\nfor face alignment. It applies in many fields such as locating facial features\nin the image, face synthesis, etc. However, the experimental results show that\nthe accuracy of the classical ASM for some applications is not high. This paper\nsuggests some improvements on the classical ASM to increase the performance of\nthe model in the application: face alignment. Four of our major improvements\ninclude: i) building a model combining Sobel filter and the 2-D profile in\nsearching face in image; ii) applying Canny algorithm for the enhancement edge\non image; iii) Support Vector Machine (SVM) is used to classify landmarks on\nface, in order to determine exactly location of these landmarks support for\nASM; iv)automatically adjust 2-D profile in the multi-level model based on the\nsize of the input image. The experimental results on Caltech face database and\nTechnical University of Denmark database (imm_face) show that our proposed\nimprovement leads to far better performance.\n",
        "published": "2012-09-27T07:58:10Z",
        "pdf_link": "http://arxiv.org/pdf/1209.6151v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.6189v1",
        "title": "The Biometric Menagerie - A Fuzzy and Inconsistent Concept",
        "summary": "  This paper proves that in iris recognition, the concepts of sheep, goats,\nlambs and wolves - as proposed by Doddington and Yager in the so-called\nBiometric Menagerie, are at most fuzzy and at least not quite well defined.\nThey depend not only on the users or on their biometric templates, but also on\nthe parameters that calibrate the iris recognition system. This paper shows\nthat, in the case of iris recognition, the extensions of these concepts have\nvery unsharp and unstable (non-stationary) boundaries. The membership of a user\nto these categories is more often expressed as a degree (as a fuzzy value)\nrather than as a crisp value. Moreover, they are defined by fuzzy Sugeno rules\ninstead of classical (crisp) definitions. For these reasons, we said that the\nBiometric Menagerie proposed by Doddington and Yager could be at most a fuzzy\nconcept of biometry, but even this status is conditioned by improving its\ndefinition. All of these facts are confirmed experimentally in a series of 12\nexhaustive iris recognition tests undertaken for University of Bath Iris Image\nDatabase while using three different iris code dimensions (256x16, 128x8 and\n64x4), two different iris texture encoders (Log-Gabor and Haar-Hilbert) and two\ndifferent types of safety models.\n",
        "published": "2012-09-27T11:24:28Z",
        "pdf_link": "http://arxiv.org/pdf/1209.6189v1"
    },
    {
        "id": "http://arxiv.org/abs/1209.6190v1",
        "title": "Noise Influence on the Fuzzy-Linguistic Partitioning of Iris Code Space",
        "summary": "  This paper analyses the set of iris codes stored or used in an iris\nrecognition system as an f-granular space. The f-granulation is given by\nidentifying in the iris code space the extensions of the fuzzy concepts wolves,\ngoats, lambs and sheep (previously introduced by Doddington as 'animals' of the\nbiometric menagerie) - which together form a partitioning of the iris code\nspace. The main question here is how objective (stable / stationary) this\npartitioning is when the iris segments are subject to noisy acquisition. In\norder to prove that the f-granulation of iris code space with respect to the\nfuzzy concepts that define the biometric menagerie is unstable in noisy\nconditions (is sensitive to noise), three types of noise (localvar, motion\nblur, salt and pepper) have been alternatively added to the iris segments\nextracted from University of Bath Iris Image Database. The results of 180\nexhaustive (all-to-all) iris recognition tests are presented and commented\nhere.\n",
        "published": "2012-09-27T11:31:25Z",
        "pdf_link": "http://arxiv.org/pdf/1209.6190v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.0115v2",
        "title": "Demosaicing and Superresolution for Color Filter Array via Residual\n  Image Reconstruction and Sparse Representation",
        "summary": "  A framework of demosaicing and superresolution for color filter array (CFA)\nvia residual image reconstruction and sparse representation is presented.Given\nthe intermediate image produced by certain demosaicing and interpolation\ntechnique, a residual image between the final reconstruction image and the\nintermediate image is reconstructed using sparse representation.The final\nreconstruction image has richer edges and details than that of the intermediate\nimage. Specifically, a generic dictionary is learned from a large set of\ncomposite training data composed of intermediate data and residual data. The\nlearned dictionary implies a mapping between the two data. A specific\ndictionary adaptive to the input CFA is learned thereafter. Using the adaptive\ndictionary, the sparse coefficients of intermediate data are computed and\ntransformed to predict residual image. The residual image is added back into\nthe intermediate image to obtain the final reconstruction image. Experimental\nresults demonstrate the state-of-the-art performance in terms of PSNR and\nsubjective visual perception.\n",
        "published": "2012-09-29T15:24:37Z",
        "pdf_link": "http://arxiv.org/pdf/1210.0115v2"
    },
    {
        "id": "http://arxiv.org/abs/1210.0310v2",
        "title": "Intra-Retinal Layer Segmentation of 3D Optical Coherence Tomography\n  Using Coarse Grained Diffusion Map",
        "summary": "  Optical coherence tomography (OCT) is a powerful and noninvasive method for\nretinal imaging. In this paper, we introduce a fast segmentation method based\non a new variant of spectral graph theory named diffusion maps. The research is\nperformed on spectral domain (SD) OCT images depicting macular and optic nerve\nhead appearance. The presented approach does not require edge-based image\ninformation and relies on regional image texture. Consequently, the proposed\nmethod demonstrates robustness in situations of low image contrast or poor\nlayer-to-layer image gradients. Diffusion mapping is applied to 2D and 3D OCT\ndatasets composed of two steps, one for partitioning the data into important\nand less important sections, and another one for localization of internal\nlayers.In the first step, the pixels/voxels are grouped in rectangular/cubic\nsets to form a graph node.The weights of a graph are calculated based on\ngeometric distances between pixels/voxels and differences of their mean\nintensity.The first diffusion map clusters the data into three parts, the\nsecond of which is the area of interest. The other two sections are eliminated\nfrom the remaining calculations. In the second step, the remaining area is\nsubjected to another diffusion map assessment and the internal layers are\nlocalized based on their textural similarities.The proposed method was tested\non 23 datasets from two patient groups (glaucoma and normals). The mean\nunsigned border positioning errors(mean - SD) was 8.52 - 3.13 and 7.56 - 2.95\nmicrometer for the 2D and 3D methods, respectively.\n",
        "published": "2012-10-01T08:52:29Z",
        "pdf_link": "http://arxiv.org/pdf/1210.0310v2"
    },
    {
        "id": "http://arxiv.org/abs/1210.0347v1",
        "title": "Enhanced Techniques for PDF Image Segmentation and Text Extraction",
        "summary": "  Extracting text objects from the PDF images is a challenging problem. The\ntext data present in the PDF images contain certain useful information for\nautomatic annotation, indexing etc. However variations of the text due to\ndifferences in text style, font, size, orientation, alignment as well as\ncomplex structure make the problem of automatic text extraction extremely\ndifficult and challenging job. This paper presents two techniques under\nblock-based classification. After a brief introduction of the classification\nmethods, two methods were enhanced and results were evaluated. The performance\nmetrics for segmentation and time consumption are tested for both the models.\n",
        "published": "2012-10-01T10:38:08Z",
        "pdf_link": "http://arxiv.org/pdf/1210.0347v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.0386v3",
        "title": "Combined Descriptors in Spatial Pyramid Domain for Image Classification",
        "summary": "  Recently spatial pyramid matching (SPM) with scale invariant feature\ntransform (SIFT) descriptor has been successfully used in image classification.\nUnfortunately, the codebook generation and feature quantization procedures\nusing SIFT feature have the high complexity both in time and space. To address\nthis problem, in this paper, we propose an approach which combines local binary\npatterns (LBP) and three-patch local binary patterns (TPLBP) in spatial pyramid\ndomain. The proposed method does not need to learn the codebook and feature\nquantization processing, hence it becomes very efficient. Experiments on two\npopular benchmark datasets demonstrate that the proposed method always\nsignificantly outperforms the very popular SPM based SIFT descriptor method\nboth in time and classification accuracy.\n",
        "published": "2012-10-01T13:05:20Z",
        "pdf_link": "http://arxiv.org/pdf/1210.0386v3"
    },
    {
        "id": "http://arxiv.org/abs/1210.0528v1",
        "title": "Band Selection and Classification of Hyperspectral Images using Mutual\n  Information: An algorithm based on minimizing the error probability using the\n  inequality of Fano",
        "summary": "  Hyperspectral image is a substitution of more than a hundred images, called\nbands, of the same region. They are taken at juxtaposed frequencies. The\nreference image of the region is called Ground Truth map (GT). the problematic\nis how to find the good bands to classify the pixels of regions; because the\nbands can be not only redundant, but a source of confusion, and decreasing so\nthe accuracy of classification. Some methods use Mutual Information (MI) and\nthreshold, to select relevant bands. Recently there's an algorithm selection\nbased on mutual information, using bandwidth rejection and a threshold to\ncontrol and eliminate redundancy. The band top ranking the MI is selected, and\nif its neighbors have sensibly the same MI with the GT, they will be considered\nredundant and so discarded. This is the most inconvenient of this method,\nbecause this avoids the advantage of hyperspectral images: some precious\ninformation can be discarded. In this paper we'll make difference between\nuseful and useless redundancy. A band contains useful redundancy if it\ncontributes to decreasing error probability. According to this scheme, we\nintroduce new algorithm using also mutual information, but it retains only the\nbands minimizing the error probability of classification. To control\nredundancy, we introduce a complementary threshold. So the good band candidate\nmust contribute to decrease the last error probability augmented by the\nthreshold. This process is a wrapper strategy; it gets high performance of\nclassification accuracy but it is expensive than filter strategy.\n",
        "published": "2012-09-28T23:36:26Z",
        "pdf_link": "http://arxiv.org/pdf/1210.0528v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.0818v1",
        "title": "Multibiometric: Feature Level Fusion Using FKP Multi-Instance biometric",
        "summary": "  This paper proposed the use of multi-instance feature level fusion as a means\nto improve the performance of Finger Knuckle Print (FKP) verification. A\nlog-Gabor filter has been used to extract the image local orientation\ninformation, and represent the FKP features. Experiments are performed using\nthe FKP database, which consists of 7,920 images. Results indicate that the\nmulti-instance verification approach outperforms higher performance than using\nany single instance. The influence on biometric performance using feature level\nfusion under different fusion rules have been demonstrated in this paper.\n",
        "published": "2012-10-02T16:03:58Z",
        "pdf_link": "http://arxiv.org/pdf/1210.0818v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.0829v1",
        "title": "A Survey of Multibiometric Systems",
        "summary": "  Most biometric systems deployed in real-world applications are unimodal.\nUsing unimodal biometric systems have to contend with a variety of problems\nsuch as: Noise in sensed data; Intra-class variations; Inter-class\nsimilarities; Non-universality; Spoof attacks. These problems have addressed by\nusing multibiometric systems, which expected to be more reliable due to the\npresence of multiple, independent pieces of evidence.\n",
        "published": "2012-10-02T16:26:39Z",
        "pdf_link": "http://arxiv.org/pdf/1210.0829v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.1029v1",
        "title": "Blurred Image Classification based on Adaptive Dictionary",
        "summary": "  Two types of framework for blurred image classification based on adaptive\ndictionary are proposed. Given a blurred image, instead of image deblurring,\nthe semantic category of the image is determined by blur insensitive sparse\ncoefficients calculated depending on an adaptive dictionary. The dictionary is\nadaptive to the Point Spread Function (PSF) estimated from input blurred image.\nThe PSF is assumed to be space invariant and inferred separately in one\nframework or updated combining with sparse coefficients calculation in an\nalternative and iterative algorithm in the other framework. The experiment has\nevaluated three types of blur, naming defocus blur, simple motion blur and\ncamera shake blur. The experiment results confirm the effectiveness of the\nproposed frameworks.\n",
        "published": "2012-10-03T08:54:01Z",
        "pdf_link": "http://arxiv.org/pdf/1210.1029v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.1033v1",
        "title": "Robust Degraded Face Recognition Using Enhanced Local Frequency\n  Descriptor and Multi-scale Competition",
        "summary": "  Recognizing degraded faces from low resolution and blurred images are common\nyet challenging task. Local Frequency Descriptor (LFD) has been proved to be\neffective for this task yet it is extracted from a spatial neighborhood of a\npixel of a frequency plane independently regardless of correlations between\nfrequencies. In addition, it uses a fixed window size named single scale of\nshort-term Frequency transform (STFT). To explore the frequency correlations\nand preserve low resolution and blur insensitive simultaneously, we propose\nEnhanced LFD in which information in space and frequency is jointly utilized so\nas to be more descriptive and discriminative than LFD. The multi-scale\ncompetition strategy that extracts multiple descriptors corresponding to\nmultiple window sizes of STFT and take one corresponding to maximum confidence\nas the final recognition result. The experiments conducted on Yale and FERET\ndatabases demonstrate that promising results have been achieved by the proposed\nEnhanced LFD and multi-scale competition strategy.\n",
        "published": "2012-10-03T09:02:51Z",
        "pdf_link": "http://arxiv.org/pdf/1210.1033v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.1316v2",
        "title": "Learning Locality-Constrained Collaborative Representation for Face\n  Recognition",
        "summary": "  The model of low-dimensional manifold and sparse representation are two\nwell-known concise models that suggest each data can be described by a few\ncharacteristics. Manifold learning is usually investigated for dimension\nreduction by preserving some expected local geometric structures from the\noriginal space to a low-dimensional one. The structures are generally\ndetermined by using pairwise distance, e.g., Euclidean distance. Alternatively,\nsparse representation denotes a data point as a linear combination of the\npoints from the same subspace. In practical applications, however, the nearby\npoints in terms of pairwise distance may not belong to the same subspace, and\nvice versa. Consequently, it is interesting and important to explore how to get\na better representation by integrating these two models together. To this end,\nthis paper proposes a novel coding algorithm, called Locality-Constrained\nCollaborative Representation (LCCR), which improves the robustness and\ndiscrimination of data representation by introducing a kind of local\nconsistency. The locality term derives from a biologic observation that the\nsimilar inputs have similar code. The objective function of LCCR has an\nanalytical solution, and it does not involve local minima. The empirical\nstudies based on four public facial databases, ORL, AR, Extended Yale B, and\nMultiple PIE, show that LCCR is promising in recognizing human faces from\nfrontal views with varying expression and illumination, as well as various\ncorruptions and occlusions.\n",
        "published": "2012-10-04T07:12:49Z",
        "pdf_link": "http://arxiv.org/pdf/1210.1316v2"
    },
    {
        "id": "http://arxiv.org/abs/1210.1916v1",
        "title": "A comparative study on face recognition techniques and neural network",
        "summary": "  In modern times, face recognition has become one of the key aspects of\ncomputer vision. There are at least two reasons for this trend; the first is\nthe commercial and law enforcement applications, and the second is the\navailability of feasible technologies after years of research. Due to the very\nnature of the problem, computer scientists, neuro-scientists and psychologists\nall share a keen interest in this field. In plain words, it is a computer\napplication for automatically identifying a person from a still image or video\nframe. One of the ways to accomplish this is by comparing selected features\nfrom the image and a facial database. There are hundreds if not thousand\nfactors associated with this. In this paper some of the most common techniques\navailable including applications of neural network in facial recognition are\nstudied and compared with respect to their performance.\n",
        "published": "2012-10-06T06:37:51Z",
        "pdf_link": "http://arxiv.org/pdf/1210.1916v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.3165v1",
        "title": "Computationally Efficient Implementation of Convolution-based Locally\n  Adaptive Binarization Techniques",
        "summary": "  One of the most important steps of document image processing is binarization.\nThe computational requirements of locally adaptive binarization techniques make\nthem unsuitable for devices with limited computing facilities. In this paper,\nwe have presented a computationally efficient implementation of convolution\nbased locally adaptive binarization techniques keeping the performance\ncomparable to the original implementation. The computational complexity has\nbeen reduced from O(W2N2) to O(WN2) where WxW is the window size and NxN is the\nimage size. Experiments over benchmark datasets show that the computation time\nhas been reduced by 5 to 15 times depending on the window size while memory\nconsumption remains the same with respect to the state-of-the-art algorithmic\nimplementation.\n",
        "published": "2012-10-11T10:04:44Z",
        "pdf_link": "http://arxiv.org/pdf/1210.3165v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.3350v1",
        "title": "Enhanced Compressed Sensing Recovery with Level Set Normals",
        "summary": "  We propose a compressive sensing algorithm that exploits geometric properties\nof images to recover images of high quality from few measurements. The image\nreconstruction is done by iterating the two following steps: 1) estimation of\nnormal vectors of the image level curves and 2) reconstruction of an image\nfitting the normal vectors, the compressed sensing measurements and the\nsparsity constraint. The proposed technique can naturally extend to non local\noperators and graphs to exploit the repetitive nature of textured images in\norder to recover fine detail structures. In both cases, the problem is reduced\nto a series of convex minimization problems that can be efficiently solved with\na combination of variable splitting and augmented Lagrangian methods, leading\nto fast and easy-to-code algorithms. Extended experiments show a clear\nimprovement over related state-of-the-art algorithms in the quality of the\nreconstructed images and the robustness of the proposed method to noise,\ndifferent kind of images and reduced measurements.\n",
        "published": "2012-10-11T19:53:44Z",
        "pdf_link": "http://arxiv.org/pdf/1210.3350v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.3404v2",
        "title": "A polygon-based interpolation operator for super-resolution imaging",
        "summary": "  We outline the super-resolution reconstruction problem posed as a\nmaximization of probability. We then introduce an interpolation method based on\npolygonal pixel overlap, express it as a linear operator, and use it to improve\nreconstruction. Polygon interpolation outperforms the simpler bilinear\ninterpolation operator and, unlike Gaussian modeling of pixels, requires no\nparameter estimation. A free software implementation that reproduces the\nresults shown is provided.\n",
        "published": "2012-10-12T00:31:46Z",
        "pdf_link": "http://arxiv.org/pdf/1210.3404v2"
    },
    {
        "id": "http://arxiv.org/abs/1210.3832v1",
        "title": "Image Processing using Smooth Ordering of its Patches",
        "summary": "  We propose an image processing scheme based on reordering of its patches. For\na given corrupted image, we extract all patches with overlaps, refer to these\nas coordinates in high-dimensional space, and order them such that they are\nchained in the \"shortest possible path\", essentially solving the traveling\nsalesman problem. The obtained ordering applied to the corrupted image, implies\na permutation of the image pixels to what should be a regular signal. This\nenables us to obtain good recovery of the clean image by applying relatively\nsimple 1D smoothing operations (such as filtering or interpolation) to the\nreordered set of pixels. We explore the use of the proposed approach to image\ndenoising and inpainting, and show promising results in both cases.\n",
        "published": "2012-10-14T20:17:33Z",
        "pdf_link": "http://arxiv.org/pdf/1210.3832v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.4863v1",
        "title": "DBN-Based Combinatorial Resampling for Articulated Object Tracking",
        "summary": "  Particle Filter is an effective solution to track objects in video sequences\nin complex situations. Its key idea is to estimate the density over the\npossible states of the object using a weighted sample whose elements are called\nparticles. One of its crucial step is a resampling step in which particles are\nresampled to avoid some degeneracy problem. In this paper, we introduce a new\nresampling method called Combinatorial Resampling that exploits some features\nof articulated objects to resample over an implicitly created sample of an\nexponential size better representing the density to estimate. We prove that it\nis sound and, through experimentations both on challenging synthetic and real\nvideo sequences, we show that it outperforms all classical resampling methods\nboth in terms of the quality of its results and in terms of response times.\n",
        "published": "2012-10-16T17:38:55Z",
        "pdf_link": "http://arxiv.org/pdf/1210.4863v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.5653v1",
        "title": "Identifications of concealed weapon in a Human Body",
        "summary": "  The detection of weapons concealed underneath a person cloths is very much\nimportant to the improvement of the security of the public as well as the\nsafety of public assets like airports, buildings and railway stations etc.\n",
        "published": "2012-10-20T20:37:22Z",
        "pdf_link": "http://arxiv.org/pdf/1210.5653v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.5732v1",
        "title": "Developing ICC Profile Using Gray Level Control In Offset Printing\n  Process",
        "summary": "  In prepress department RGB image has to be converted to CMYK image. To\ncontrol that amount of black, cyan, magenta and yellow has to be controlled by\nusing color separation method. Graycolor separation method is selected to\ncontrol the amounts of these colors because it increase the quality of printing\nalso. A single printer used for printing the same image on different paper also\nresults in different printed images. To remove this problem a different ICC\nprofile based on gray level control is developedand a sheet offset printer is\ncalibrated using that profile and a subjective evaluation shows satisfactory\nresults for different quality papers.\n",
        "published": "2012-10-21T14:49:30Z",
        "pdf_link": "http://arxiv.org/pdf/1210.5732v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.6157v1",
        "title": "Novel Architecture for 3D model in virtual communities from detected\n  face",
        "summary": "  In this research paper we suggest how to extract a face from an image, modify\nit, characterize it in terms of high-level properties, and apply it to the\ncreation of a personalized avatar. In this research work we tested, we\nimplemented the algorithm on several hundred facial images, including many\ntaken under uncontrolled acquisition conditions, and found to exhibit\nsatisfactory performance for immediate practical use.\n",
        "published": "2012-10-23T07:57:24Z",
        "pdf_link": "http://arxiv.org/pdf/1210.6157v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.7014v2",
        "title": "Computer vision tools for the non-invasive assessment of autism-related\n  behavioral markers",
        "summary": "  The early detection of developmental disorders is key to child outcome,\nallowing interventions to be initiated that promote development and improve\nprognosis. Research on autism spectrum disorder (ASD) suggests behavioral\nmarkers can be observed late in the first year of life. Many of these studies\ninvolved extensive frame-by-frame video observation and analysis of a child's\nnatural behavior. Although non-intrusive, these methods are extremely\ntime-intensive and require a high level of observer training; thus, they are\nimpractical for clinical and large population research purposes. Diagnostic\nmeasures for ASD are available for infants but are only accurate when used by\nspecialists experienced in early diagnosis. This work is a first milestone in a\nlong-term multidisciplinary project that aims at helping clinicians and general\npractitioners accomplish this early detection/measurement task automatically.\nWe focus on providing computer vision tools to measure and identify ASD\nbehavioral markers based on components of the Autism Observation Scale for\nInfants (AOSI). In particular, we develop algorithms to measure three critical\nAOSI activities that assess visual attention. We augment these AOSI activities\nwith an additional test that analyzes asymmetrical patterns in unsupported\ngait. The first set of algorithms involves assessing head motion by tracking\nfacial features, while the gait analysis relies on joint foreground\nsegmentation and 2D body pose estimation in video. We show results that provide\ninsightful knowledge to augment the clinician's behavioral observations\nobtained from real in-clinic assessments.\n",
        "published": "2012-10-25T22:30:40Z",
        "pdf_link": "http://arxiv.org/pdf/1210.7014v2"
    },
    {
        "id": "http://arxiv.org/abs/1210.7102v1",
        "title": "3D Face Recognition using Significant Point based SULD Descriptor",
        "summary": "  In this work, we present a new 3D face recognition method based on Speeded-Up\nLocal Descriptor (SULD) of significant points extracted from the range images\nof faces. The proposed model consists of a method for extracting distinctive\ninvariant features from range images of faces that can be used to perform\nreliable matching between different poses of range images of faces. For a given\n3D face scan, range images are computed and the potential interest points are\nidentified by searching at all scales. Based on the stability of the interest\npoint, significant points are extracted. For each significant point we compute\nthe SULD descriptor which consists of vector made of values from the convolved\nHaar wavelet responses located on concentric circles centred on the significant\npoint, and where the amount of Gaussian smoothing is proportional to the radii\nof the circles. Experimental results show that the newly proposed method\nprovides higher recognition rate compared to other existing contemporary models\ndeveloped for 3D face recognition.\n",
        "published": "2012-10-26T11:27:33Z",
        "pdf_link": "http://arxiv.org/pdf/1210.7102v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.7403v1",
        "title": "Resolution Enhancement of Range Images via Color-Image Segmentation",
        "summary": "  We report a method for super-resolution of range images. Our approach\nleverages the interpretation of LR image as sparse samples on the HR grid.\nBased on this interpretation, we demonstrate that our recently reported\napproach, which reconstructs dense range images from sparse range data by\nexploiting a registered colour image, can be applied for the task of resolution\nenhancement of range images. Our method only uses a single colour image in\naddition to the range observation in the super-resolution process. Using the\nproposed approach, we demonstrate super-resolution results for large factors\n(e.g. 4) with good localization accuracy.\n",
        "published": "2012-10-28T05:27:55Z",
        "pdf_link": "http://arxiv.org/pdf/1210.7403v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.7631v1",
        "title": "The fortresses of Ejin: an example of outlining a site from satellite\n  images",
        "summary": "  From 1960's to 1970's, the Chinese Army built some fortified artificial\nhills. Some of them are located in the Inner Mongolia, Western China. These\nlarge fortresses are surrounded by moats. For some of them it is still possible\nto see earthworks, trenches and ditches, the planning of which could have a\nsymbolic meaning. We can argue this result form their digital outlining,\nobtained after an image processing of satellite images, based on edge\ndetection.\n",
        "published": "2012-10-29T11:53:35Z",
        "pdf_link": "http://arxiv.org/pdf/1210.7631v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.7669v1",
        "title": "Performance Evaluation of Different Techniques for texture\n  Classification",
        "summary": "  Texture is the term used to characterize the surface of a given object or\nphenomenon and is an important feature used in image processing and pattern\nrecognition. Our aim is to compare various Texture analyzing methods and\ncompare the results based on time complexity and accuracy of classification.\nThe project describes texture classification using Wavelet Transform and Co\noccurrence Matrix. Comparison of features of a sample texture with database of\ndifferent textures is performed. In wavelet transform we use the Haar, Symlets\nand Daubechies wavelets. We find that, thee Haar wavelet proves to be the most\nefficient method in terms of performance assessment parameters mentioned above.\nComparison of Haar wavelet and Co-occurrence matrix method of classification\nalso goes in the favor of Haar. Though the time requirement is high in the\nlater method, it gives excellent results for classification accuracy except if\nthe image is rotated.\n",
        "published": "2012-10-29T14:05:27Z",
        "pdf_link": "http://arxiv.org/pdf/1210.7669v1"
    },
    {
        "id": "http://arxiv.org/abs/1210.8262v1",
        "title": "On the Relation Between the Common Labelling and the Median Graph",
        "summary": "  In structural pattern recognition, given a set of graphs, the computation of\na Generalized Median Graph is a well known problem. Some methods approach the\nproblem by assuming a relation between the Generalized Median Graph and the\nCommon Labelling problem. However, this relation has still not been formally\nproved. In this paper, we analyse such relation between both problems. The main\nresult proves that the cost of the common labelling upper-bounds the cost of\nthe median with respect to the given set. In addition, we show that the two\nproblems are equivalent in some cases.\n",
        "published": "2012-10-31T08:29:58Z",
        "pdf_link": "http://arxiv.org/pdf/1210.8262v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.0055v1",
        "title": "Dimensionality Reduction and Classification Feature Using Mutual\n  Information Applied to Hyperspectral Images: A Wrapper Strategy Algorithm\n  Based on Minimizing the Error Probability Using the Inequality of Fano",
        "summary": "  In the feature classification domain, the choice of data affects widely the\nresults. For the Hyperspectral image, the bands dont all contain the\ninformation; some bands are irrelevant like those affected by various\natmospheric effects, see Figure.4, and decrease the classification accuracy.\nAnd there exist redundant bands to complicate the learning system and product\nincorrect prediction [14]. Even the bands contain enough information about the\nscene they may can't predict the classes correctly if the dimension of space\nimages, see Figure.3, is so large that needs many cases to detect the\nrelationship between the bands and the scene (Hughes phenomenon) [10]. We can\nreduce the dimensionality of hyperspectral images by selecting only the\nrelevant bands (feature selection or subset selection methodology), or\nextracting, from the original bands, new bands containing the maximal\ninformation about the classes, using any functions, logical or numerical\n(feature extraction methodology) [11][9]. Here we focus on the feature\nselection using mutual information. Hyperspectral images have three advantages\nregarding the multispectral images [6],\n",
        "published": "2012-10-31T23:30:59Z",
        "pdf_link": "http://arxiv.org/pdf/1211.0055v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.0191v1",
        "title": "Performance Evaluation of Random Set Based Pedestrian Tracking\n  Algorithms",
        "summary": "  The paper evaluates the error performance of three random finite set based\nmulti-object trackers in the context of pedestrian video tracking. The\nevaluation is carried out using a publicly available video dataset of 4500\nframes (town centre street) for which the ground truth is available. The input\nto all pedestrian tracking algorithms is an identical set of head and body\ndetections, obtained using the Histogram of Oriented Gradients (HOG) detector.\nThe tracking error is measured using the recently proposed OSPA metric for\ntracks, adopted as the only known mathematically rigorous metric for measuring\nthe distance between two sets of tracks. A comparative analysis is presented\nunder various conditions.\n",
        "published": "2012-10-25T23:21:46Z",
        "pdf_link": "http://arxiv.org/pdf/1211.0191v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.0602v1",
        "title": "Segmentation of ultrasound images of thyroid nodule for assisting fine\n  needle aspiration cytology",
        "summary": "  The incidence of thyroid nodule is very high and generally increases with the\nage. Thyroid nodule may presage the emergence of thyroid cancer. The thyroid\nnodule can be completely cured if detected early. Fine needle aspiration\ncytology is a recognized early diagnosis method of thyroid nodule. There are\nstill some limitations in the fine needle aspiration cytology, and the\nultrasound diagnosis of thyroid nodule has become the first choice for\nauxiliary examination of thyroid nodular disease. If we could combine medical\nimaging technology and fine needle aspiration cytology, the diagnostic rate of\nthyroid nodule would be improved significantly. The properties of ultrasound\nwill degrade the image quality, which makes it difficult to recognize the edges\nfor physicians. Image segmentation technique based on graph theory has become a\nresearch hotspot at present. Normalized cut (Ncut) is a representative one,\nwhich is suitable for segmentation of feature parts of medical image. However,\nhow to solve the normalized cut has become a problem, which needs large memory\ncapacity and heavy calculation of weight matrix. It always generates over\nsegmentation or less segmentation which leads to inaccurate in the\nsegmentation. The speckle noise in B ultrasound image of thyroid tumor makes\nthe quality of the image deteriorate. In the light of this characteristic, we\ncombine the anisotropic diffusion model with the normalized cut in this paper.\nAfter the enhancement of anisotropic diffusion model, it removes the noise in\nthe B ultrasound image while preserves the important edges and local details.\nThis reduces the amount of computation in constructing the weight matrix of the\nimproved normalized cut and improves the accuracy of the final segmentation\nresults. The feasibility of the method is proved by the experimental results.\n",
        "published": "2012-11-03T06:55:03Z",
        "pdf_link": "http://arxiv.org/pdf/1211.0602v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.0613v2",
        "title": "Application of Symmetric Uncertainty and Mutual Information to\n  Dimensionality Reduction and Classification of Hyperspectral Images",
        "summary": "  Remote sensing is a technology to acquire data for disatant substances,\nnecessary to construct a model knowledge for applications as classification.\nRecently Hyperspectral Images (HSI) becomes a high technical tool that the main\ngoal is to classify the point of a region. The HIS is more than a hundred\nbidirectional measures, called bands (or simply images), of the same region\ncalled Ground Truth Map (GT). But some bands are not relevant because they are\naffected by different atmospheric effects; others contain redundant\ninformation; and high dimensionality of HSI features make the accuracy of\nclassification lower. All these bands can be important for some applications;\nbut for the classification a small subset of these is relevant. The problematic\nrelated to HSI is the dimensionality reduction. Many studies use mutual\ninformation (MI) to select the relevant bands. Others studies use the MI\nnormalized forms, like Symmetric Uncertainty, in medical imagery applications.\nIn this paper we introduce an algorithm based also on MI to select relevant\nbands and it apply the Symmetric Uncertainty coefficient to control redundancy\nand increase the accuracy of classification. This algorithm is feature\nselection tool and a Filter strategy. We establish this study on HSI AVIRIS\n92AV3C. This is an effectiveness, and fast scheme to control redundancy.\n",
        "published": "2012-11-03T14:01:29Z",
        "pdf_link": "http://arxiv.org/pdf/1211.0613v2"
    },
    {
        "id": "http://arxiv.org/abs/1211.1252v1",
        "title": "Implementation of Radon Transformation for Electrical Impedance\n  Tomography (EIT)",
        "summary": "  Radon Transformation is generally used to construct optical image (like CT\nimage) from the projection data in biomedical imaging. In this paper, the\nconcept of Radon Transformation is implemented to reconstruct Electrical\nImpedance Topographic Image (conductivity or resistivity distribution) of a\ncircular subject. A parallel resistance model of a subject is proposed for\nElectrical Impedance Topography(EIT) or Magnetic Induction Tomography(MIT). A\ncircular subject with embedded circular objects is segmented into equal width\nslices from different angles. For each angle, Conductance and Conductivity of\neach slice is calculated and stored in an array. A back projection method is\nused to generate a two-dimensional image from one-dimensional projections. As a\nback projection method, Inverse Radon Transformation is applied on the\ncalculated conductance and conductivity to reconstruct two dimensional images.\nThese images are compared to the target image. In the time of image\nreconstruction, different filters are used and these images are compared with\neach other and target image.\n",
        "published": "2012-10-16T09:46:12Z",
        "pdf_link": "http://arxiv.org/pdf/1211.1252v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.1482v4",
        "title": "Gender Recognition in Walk Gait through 3D Motion by Quadratic Bezier\n  Curve and Statistical Techniques",
        "summary": "  Motion capture is the process of recording the movement of objects or people.\nIt is used in military, entertainment, sports, and medical applications, and\nfor validation of computer vision[2] and robotics. In filmmaking and video game\ndevelopment, it refers to recording actions of human actors, and using that\ninformation to animate digital character models in 2D or 3D computer animation.\nWhen it includes face and fingers or captures subtle\n",
        "published": "2012-11-07T08:19:04Z",
        "pdf_link": "http://arxiv.org/pdf/1211.1482v4"
    },
    {
        "id": "http://arxiv.org/abs/1211.1650v1",
        "title": "Different Operating Systems Compatible for Image Prepress Process in\n  Color Management: Analysis and Performance Testing",
        "summary": "  Image computing has become a real catchphrase over the past few years and the\ninterpretations of the meaning of the term vary greatly. The Imagecomputing\nmarket is currently rapidly evolving with high growth prospects and almost\ndaily announcements of new devices and application platforms, which results in\nan increasing diversification of devices, operating system and development\nplatforms. Compared to more traditional information technology markets like the\none of desktop computing, mobile computing is much less consolidated and\nneither standards nor even industry standards have yet been established. There\nare various platforms and interfaces which may be used to perform the desired\ntasks through the device. We have tried to compare the various mobile operating\nsystems and their trade-offs.\n",
        "published": "2012-11-07T19:52:50Z",
        "pdf_link": "http://arxiv.org/pdf/1211.1650v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.1656v1",
        "title": "James-Stein Type Center Pixel Weights for Non-Local Means Image\n  Denoising",
        "summary": "  Non-Local Means (NLM) and variants have been proven to be effective and\nrobust in many image denoising tasks. In this letter, we study the parameter\nselection problem of center pixel weights (CPW) in NLM. Our key contributions\nare: 1) we give a novel formulation of the CPW problem from the statistical\nshrinkage perspective; 2) we introduce the James-Stein type CPWs for NLM; and\n3) we propose a new adaptive CPW that is locally tuned for each image pixel.\nOur experimental results showed that compared to existing CPW solutions, the\nnew proposed CPWs are more robust and effective under various noise levels. In\nparticular, the NLM with the James-Stein type CPWs attain higher means with\nsmaller variances in terms of the peak signal and noise ratio, implying they\nimprove the NLM robustness and make it less sensitive to parameter selection.\n",
        "published": "2012-11-07T20:10:24Z",
        "pdf_link": "http://arxiv.org/pdf/1211.1656v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.1752v1",
        "title": "3D Scene Grammar for Parsing RGB-D Pointclouds",
        "summary": "  We pose 3D scene-understanding as a problem of parsing in a grammar. A\ngrammar helps us capture the compositional structure of real-word objects,\ne.g., a chair is composed of a seat, a back-rest and some legs. Having multiple\nrules for an object helps us capture structural variations in objects, e.g., a\nchair can optionally also have arm-rests. Finally, having rules to capture\ncomposition at different levels helps us formulate the entire scene-processing\npipeline as a single problem of finding most likely parse-tree---small segments\ncombine to form parts of objects, parts to objects and objects to a scene. We\nattach a generative probability model to our grammar by having a\nfeature-dependent probability function for every rule. We evaluated it by\nextracting labels for every segment and comparing the results with the\nstate-of-the-art segment-labeling algorithm. Our algorithm was outperformed by\nthe state-or-the-art method. But, Our model can be trained very efficiently\n(within seconds), and it scales only linearly in with the number of rules in\nthe grammar. Also, we think that this is an important problem for the 3D vision\ncommunity. So, we are releasing our dataset and related code.\n",
        "published": "2012-11-08T03:11:53Z",
        "pdf_link": "http://arxiv.org/pdf/1211.1752v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.1800v1",
        "title": "A Comparative study of Arabic handwritten characters invariant feature",
        "summary": "  This paper is practically interested in the unchangeable feature of Arabic\nhandwritten character. It presents results of comparative study achieved on\ncertain features extraction techniques of handwritten character, based on Hough\ntransform, Fourier transform, Wavelet transform and Gabor Filter. Obtained\nresults show that Hough Transform and Gabor filter are insensible to the\nrotation and translation, Fourier Transform is sensible to the rotation but\ninsensible to the translation, in contrast to Hough Transform and Gabor filter,\nWavelets Transform is sensitive to the rotation as well as to the translation.\n",
        "published": "2012-11-08T09:24:21Z",
        "pdf_link": "http://arxiv.org/pdf/1211.1800v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.1968v2",
        "title": "Fourier-Bessel rotational invariant eigenimages",
        "summary": "  We present an efficient and accurate algorithm for principal component\nanalysis (PCA) of a large set of two dimensional images, and, for each image,\nthe set of its uniform rotations in the plane and its reflection. The algorithm\nstarts by expanding each image, originally given on a Cartesian grid, in the\nFourier-Bessel basis for the disk. Because the images are bandlimited in the\nFourier domain, we use a sampling criterion to truncate the Fourier-Bessel\nexpansion such that the maximum amount of information is preserved without the\neffect of aliasing. The constructed covariance matrix is invariant to rotation\nand reflection and has a special block diagonal structure. PCA is efficiently\ndone for each block separately. This Fourier-Bessel based PCA detects more\nmeaningful eigenimages and has improved denoising capability compared to\ntraditional PCA for a finite number of noisy images.\n",
        "published": "2012-11-08T20:59:49Z",
        "pdf_link": "http://arxiv.org/pdf/1211.1968v2"
    },
    {
        "id": "http://arxiv.org/abs/1211.2007v1",
        "title": "Multi-input Multi-output Beta Wavelet Network: Modeling of Acoustic\n  Units for Speech Recognition",
        "summary": "  In this paper, we propose a novel architecture of wavelet network called\nMulti-input Multi-output Wavelet Network MIMOWN as a generalization of the old\narchitecture of wavelet network. This newel prototype was applied to speech\nrecognition application especially to model acoustic unit of speech. The\noriginality of our work is the proposal of MIMOWN to model acoustic unit of\nspeech. This approach was proposed to overcome limitation of old wavelet\nnetwork model. The use of the multi-input multi-output architecture will allows\ntraining wavelet network on various examples of acoustic units.\n",
        "published": "2012-11-08T22:23:54Z",
        "pdf_link": "http://arxiv.org/pdf/1211.2007v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.2037v1",
        "title": "Time Complexity Analysis of Binary Space Partitioning Scheme for Image\n  Compression",
        "summary": "  Segmentation-based image coding methods provide high compression ratios when\ncompared with traditional image coding approaches like the transform and sub\nband coding for low bit-rate compression applications. In this paper, a\nsegmentation-based image coding method, namely the Binary Space Partition\nscheme, that divides the desired image using a recursive procedure for coding\nis presented. The BSP approach partitions the desired image recursively by\nusing bisecting lines, selected from a collection of discrete optional lines,\nin a hierarchical manner. This partitioning procedure generates a binary tree,\nwhich is referred to as the BSP-tree representation of the desired image. The\nalgorithm is extremely complex in computation and has high execution time. The\ntime complexity of the BSP scheme is explored in this work.\n",
        "published": "2012-11-09T03:59:48Z",
        "pdf_link": "http://arxiv.org/pdf/1211.2037v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.2082v1",
        "title": "3D Surface Reconstruction of Underwater Objects",
        "summary": "  In this paper, we propose a novel technique to reconstruct 3D surface of an\nunderwater object using stereo images. Reconstructing the 3D surface of an\nunderwater object is really a challenging task due to degraded quality of\nunderwater images. There are various reason of quality degradation of\nunderwater images i.e., non-uniform illumination of light on the surface of\nobjects, scattering and absorption effects. Floating particles present in\nunderwater produces Gaussian noise on the captured underwater images which\ndegrades the quality of images. The degraded underwater images are preprocessed\nby applying homomorphic, wavelet denoising and anisotropic filtering\nsequentially. The uncalibrated rectification technique is applied to\npreprocessed images to rectify the left and right images. The rectified left\nand right image lies on a common plane. To find the correspondence points in a\nleft and right images, we have applied dense stereo matching technique i.e.,\ngraph cut method. Finally, we estimate the depth of images using triangulation\ntechnique. The experimental result shows that the proposed method reconstruct\n3D surface of underwater objects accurately using captured underwater stereo\nimages.\n",
        "published": "2012-11-09T09:17:26Z",
        "pdf_link": "http://arxiv.org/pdf/1211.2082v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.2116v1",
        "title": "Localisation of Numerical Date Field in an Indian Handwritten Document",
        "summary": "  This paper describes a method to localise all those areas which may\nconstitute the date field in an Indian handwritten document. Spatial patterns\nof the date field are studied from various handwritten documents and an\nalgorithm is developed through statistical analysis to identify those sets of\nconnected components which may constitute the date. Common date patterns\nfollowed in India are considered to classify the date formats in different\nclasses. Reported results demonstrate promising performance of the proposed\napproach\n",
        "published": "2012-11-09T12:59:11Z",
        "pdf_link": "http://arxiv.org/pdf/1211.2116v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.2150v1",
        "title": "NF-SAVO: Neuro-Fuzzy system for Arabic Video OCR",
        "summary": "  In this paper we propose a robust approach for text extraction and\nrecognition from video clips which is called Neuro-Fuzzy system for Arabic\nVideo OCR. In Arabic video text recognition, a number of noise components\nprovide the text relatively more complicated to separate from the background.\nFurther, the characters can be moving or presented in a diversity of colors,\nsizes and fonts that are not uniform. Added to this, is the fact that the\nbackground is usually moving making text extraction a more intricate process.\nVideo include two kinds of text, scene text and artificial text. Scene text is\nusually text that becomes part of the scene itself as it is recorded at the\ntime of filming the scene. But artificial text is produced separately and away\nfrom the scene and is laid over it at a later stage or during the post\nprocessing time. The emergence of artificial text is consequently vigilantly\ndirected. This type of text carries with it important information that helps in\nvideo referencing, indexing and retrieval.\n",
        "published": "2012-11-09T14:57:53Z",
        "pdf_link": "http://arxiv.org/pdf/1211.2150v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.2500v1",
        "title": "A New Algorithm Based Entropic Threshold for Edge Detection in Images",
        "summary": "  Edge detection is one of the most critical tasks in automatic image analysis.\nThere exists no universal edge detection method which works well under all\nconditions. This paper shows the new approach based on the one of the most\nefficient techniques for edge detection, which is entropy-based thresholding.\nThe main advantages of the proposed method are its robustness and its\nflexibility. We present experimental results for this method, and compare\nresults of the algorithm against several leading edge detection methods, such\nas Canny, LOG, and Sobel. Experimental results demonstrate that the proposed\nmethod achieves better result than some classic methods and the quality of the\nedge detector of the output images is robust and decrease the computation time.\n",
        "published": "2012-11-12T02:56:08Z",
        "pdf_link": "http://arxiv.org/pdf/1211.2500v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.2502v1",
        "title": "New Edge Detection Technique based on the Shannon Entropy in Gray Level\n  Images",
        "summary": "  Edge detection is an important field in image processing. Edges characterize\nobject boundaries and are therefore useful for segmentation, registration,\nfeature extraction, and identification of objects in a scene. In this paper, an\napproach utilizing an improvement of Baljit and Amar method which uses Shannon\nentropy other than the evaluation of derivatives of the image in detecting\nedges in gray level images has been proposed. The proposed method can reduce\nthe CPU time required for the edge detection process and the quality of the\nedge detector of the output images is robust. A standard test images, the\nreal-world and synthetic images are used to compare the results of the proposed\nedge detector with the Baljit and Amar edge detector method. In order to\nvalidate the results, the run time of the proposed method and the pervious\nmethod are presented. It has been observed that the proposed edge detector\nworks effectively for different gray scale digital images. The performance\nevaluation of the proposed technique in terms of the measured CPU time and the\nquality of edge detector method are presented. Experimental results demonstrate\nthat the proposed method achieve better result than the relevant classic\nmethod.\n",
        "published": "2012-11-12T03:06:18Z",
        "pdf_link": "http://arxiv.org/pdf/1211.2502v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.2863v1",
        "title": "Multi-Sensor Fusion via Reduction of Dimensionality",
        "summary": "  Large high-dimensional datasets are becoming more and more popular in an\nincreasing number of research areas. Processing the high dimensional data\nincurs a high computational cost and is inherently inefficient since many of\nthe values that describe a data object are redundant due to noise and inner\ncorrelations. Consequently, the dimensionality, i.e. the number of values that\nare used to describe a data object, needs to be reduced prior to any other\nprocessing of the data. The dimensionality reduction removes, in most cases,\nnoise from the data and reduces substantially the computational cost of\nalgorithms that are applied to the data.\n  In this thesis, a novel coherent integrated methodology is introduced\n(theory, algorithm and applications) to reduce the dimensionality of\nhigh-dimensional datasets. The method constructs a diffusion process among the\ndata coordinates via a random walk. The dimensionality reduction is obtained\nbased on the eigen-decomposition of the Markov matrix that is associated with\nthe random walk. The proposed method is utilized for: (a) segmentation and\ndetection of anomalies in hyper-spectral images; (b) segmentation of\nmulti-contrast MRI images; and (c) segmentation of video sequences.\n  We also present algorithms for: (a) the characterization of materials using\ntheir spectral signatures to enable their identification; (b) detection of\nvehicles according to their acoustic signatures; and (c) classification of\nvascular vessels recordings to detect hyper-tension and cardio-vascular\ndiseases.\n  The proposed methodology and algorithms produce excellent results that\nsuccessfully compete with current state-of-the-art algorithms.\n",
        "published": "2012-11-13T01:05:42Z",
        "pdf_link": "http://arxiv.org/pdf/1211.2863v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.3901v1",
        "title": "Visual Recognition of Isolated Swedish Sign Language Signs",
        "summary": "  We present a method for recognition of isolated Swedish Sign Language signs.\nThe method will be used in a game intended to help children training signing at\nhome, as a complement to training with a teacher. The target group is not\nprimarily deaf children, but children with language disorders. Using sign\nlanguage as a support in conversation has been shown to greatly stimulate the\nspeech development of such children. The signer is captured with an RGB-D\n(Kinect) sensor, which has three advantages over a regular RGB camera. Firstly,\nit allows complex backgrounds to be removed easily. We segment the hands and\nface based on skin color and depth information. Secondly, it helps with the\nresolution of hand over face occlusion. Thirdly, signs take place in 3D; some\naspects of the signs are defined by hand motion vertically to the image plane.\nThis motion can be estimated if the depth is observable. The 3D motion of the\nhands relative to the torso are used as a cue together with the hand shape, and\nHMMs trained with this input are used for classification. To obtain higher\nrobustness towards differences across signers, Fisher Linear Discriminant\nAnalysis is used to find the combinations of features that are most descriptive\nfor each sign, regardless of signer. Experiments show that the system can\ndistinguish signs from a challenging 94 word vocabulary with a precision of up\nto 94% in the signer dependent case and up to 47% in the signer independent\ncase.\n",
        "published": "2012-11-16T14:29:31Z",
        "pdf_link": "http://arxiv.org/pdf/1211.3901v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.4264v1",
        "title": "Non-Local Patch Regression: Robust Image Denoising in Patch Space",
        "summary": "  It was recently demonstrated in [Chaudhury et al.,Non-Local Euclidean\nMedians,2012] that the denoising performance of Non-Local Means (NLM) can be\nimproved at large noise levels by replacing the mean by the robust Euclidean\nmedian. Numerical experiments on synthetic and natural images showed that the\nlatter consistently performed better than NLM beyond a certain noise level, and\nsignificantly so for images with sharp edges. The Euclidean mean and median can\nbe put into a common regression (on the patch space) framework, in which the\nl_2 norm of the residuals is considered in the former, while the l_1 norm is\nconsidered in the latter. The natural question then is what happens if we\nconsider l_p (0<p<1) regression? We investigate this possibility in this paper.\n",
        "published": "2012-11-18T22:36:43Z",
        "pdf_link": "http://arxiv.org/pdf/1211.4264v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.4307v1",
        "title": "Efficient Superimposition Recovering Algorithm",
        "summary": "  In this article, we address the issue of recovering latent transparent layers\nfrom superimposition images. Here, we assume we have the estimated\ntransformations and extracted gradients of latent layers. To rapidly recover\nhigh-quality image layers, we propose an Efficient Superimposition Recovering\nAlgorithm (ESRA) by extending the framework of accelerated gradient method. In\naddition, a key building block (in each iteration) in our proposed method is\nthe proximal operator calculating. Here we propose to employ a dual approach\nand present our Parallel Algorithm with Constrained Total Variation (PACTV)\nmethod. Our recovering method not only reconstructs high-quality layers without\ncolor-bias problem, but also theoretically guarantees good convergence\nperformance.\n",
        "published": "2012-11-19T05:44:24Z",
        "pdf_link": "http://arxiv.org/pdf/1211.4307v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.4499v1",
        "title": "Rate-Distortion Analysis of Multiview Coding in a DIBR Framework",
        "summary": "  Depth image based rendering techniques for multiview applications have been\nrecently introduced for efficient view generation at arbitrary camera\npositions. Encoding rate control has thus to consider both texture and depth\ndata. Due to different structures of depth and texture images and their\ndifferent roles on the rendered views, distributing the available bit budget\nbetween them however requires a careful analysis. Information loss due to\ntexture coding affects the value of pixels in synthesized views while errors in\ndepth information lead to shift in objects or unexpected patterns at their\nboundaries. In this paper, we address the problem of efficient bit allocation\nbetween textures and depth data of multiview video sequences. We adopt a\nrate-distortion framework based on a simplified model of depth and texture\nimages. Our model preserves the main features of depth and texture images.\nUnlike most recent solutions, our method permits to avoid rendering at encoding\ntime for distortion estimation so that the encoding complexity is not\naugmented. In addition to this, our model is independent of the underlying\ninpainting method that is used at decoder. Experiments confirm our theoretical\nresults and the efficiency of our rate allocation strategy.\n",
        "published": "2012-11-19T17:09:56Z",
        "pdf_link": "http://arxiv.org/pdf/1211.4499v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.4771v1",
        "title": "Matching Through Features and Features Through Matching",
        "summary": "  This paper addresses how to construct features for the problem of image\ncorrespondence, in particular, the paper addresses how to construct features so\nas to maintain the right level of invariance versus discriminability. We show\nthat without additional prior knowledge of the 3D scene, the right tradeoff\ncannot be established in a pre-processing step of the images as is typically\ndone in most feature-based matching methods. However, given knowledge of the\nsecond image to match, the tradeoff between invariance and discriminability of\nfeatures in the first image is less ambiguous. This suggests to setup the\nproblem of feature extraction and matching as a joint estimation problem. We\ndevelop a possible mathematical framework, a possible computational algorithm,\nand we give example demonstration on finding correspondence on images related\nby a scene that undergoes large 3D deformation of non-planar objects and camera\nviewpoint change.\n",
        "published": "2012-11-20T15:15:56Z",
        "pdf_link": "http://arxiv.org/pdf/1211.4771v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.5355v1",
        "title": "Cobb Angle Measurement of Scoliosis with Reduced Variability",
        "summary": "  Cobb angle, which is a measure of spinal curvature is the standard method for\nquantifying the magnitude of Scoliosis related to spinal deformity in\northopedics. Determining the Cobb angle through manual process is subject to\nhuman errors. In this work, we propose a methodology to measure the magnitude\nof Cobb angle, which appreciably reduces the variability related to its\nmeasurement compared to the related works. The proposed methodology is\nfacilitated by using a suitable new improved version of Non-Local Means for\nimage denoisation and Otsus automatic threshold selection for Canny edge\ndetection. We have selected NLM for preprocessing of the image as it is one of\nthe fine states of art for image denoisation and helps in retaining the image\nquality. Trimmedmean, median are more robust to outliners than mean and\nfollowing this concept we observed that NLM denoising quality performance can\nbe enhanced by using Euclidean trimmed-mean replacing the mean. To prove the\nbetter performance of the Non-Local Euclidean Trimmed-mean denoising filter, we\nhave provided some comparative study results of the proposed denoising\ntechnique with traditional NLM and NonLocal Euclidean Medians. The experimental\nresults for Cobb angle measurement over intra observer and inter observer\nexperimental data reveals the better performance and superiority of the\nproposed approach compared to the related works. MATLAB2009b image processing\ntoolbox was used for the purpose of simulation and verification of the proposed\nmethodology.\n",
        "published": "2012-11-22T19:09:29Z",
        "pdf_link": "http://arxiv.org/pdf/1211.5355v1"
    },
    {
        "id": "http://arxiv.org/abs/1211.5712v1",
        "title": "Detection of elliptical shapes via cross-entropy clustering",
        "summary": "  The problem of finding elliptical shapes in an image will be considered. We\ndiscuss the solution which uses cross-entropy clustering. The proposed method\nallows the search for ellipses with predefined sizes and position in the space.\nMoreover, it works well for search of ellipsoids in higher dimensions.\n",
        "published": "2012-11-24T23:08:15Z",
        "pdf_link": "http://arxiv.org/pdf/1211.5712v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.0030v1",
        "title": "Viewpoint Invariant Object Detector",
        "summary": "  Object Detection is the task of identifying the existence of an object class\ninstance and locating it within an image. Difficulties in handling high\nintra-class variations constitute major obstacles to achieving high performance\non standard benchmark datasets (scale, viewpoint, lighting conditions and\norientation variations provide good examples). Suggested model aims at\nproviding more robustness to detecting objects suffering severe distortion due\nto < 60{\\deg} viewpoint changes. In addition, several model computational\nbottlenecks have been resolved leading to a significant increase in the model\nperformance (speed and space) without compromising the resulting accuracy.\nFinally, we produced two illustrative applications showing the potential of the\nobject detection technology being deployed in real life applications; namely\ncontent-based image search and content-based video search.\n",
        "published": "2012-11-30T22:35:19Z",
        "pdf_link": "http://arxiv.org/pdf/1212.0030v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.0134v1",
        "title": "Fingertip Detection: A Fast Method with Natural Hand",
        "summary": "  Many vision based applications have used fingertips to track or manipulate\ngestures in their applications. Gesture identification is a natural way to pass\nthe signals to the machine, as the human express its feelings most of the time\nwith hand expressions. Here a novel time efficient algorithm has been described\nfor fingertip detection. This method is invariant to hand direction and in\npreprocessing it cuts only hand part from the full image, hence further\ncomputation would be much faster than processing full image. Binary silhouette\nof the input image is generated using HSV color space based skin filter and\nhand cropping done based on intensity histogram of the hand image\n",
        "published": "2012-12-01T16:59:07Z",
        "pdf_link": "http://arxiv.org/pdf/1212.0134v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.0291v1",
        "title": "An Image Based Technique for Enhancement of Underwater Images",
        "summary": "  The underwater images usually suffers from non-uniform lighting, low\ncontrast, blur and diminished colors. In this paper, we proposed an image based\npreprocessing technique to enhance the quality of the underwater images. The\nproposed technique comprises a combination of four filters such as homomorphic\nfiltering, wavelet denoising, bilateral filter and contrast equalization. These\nfilters are applied sequentially on degraded underwater images. The literature\nsurvey reveals that image based preprocessing algorithms uses standard filter\ntechniques with various combinations. For smoothing the image, the image based\npreprocessing algorithms uses the anisotropic filter. The main drawback of the\nanisotropic filter is that iterative in nature and computation time is high\ncompared to bilateral filter. In the proposed technique, in addition to other\nthree filters, we employ a bilateral filter for smoothing the image. The\nexperimentation is carried out in two stages. In the first stage, we have\nconducted various experiments on captured images and estimated optimal\nparameters for bilateral filter. Similarly, optimal filter bank and optimal\nwavelet shrinkage function are estimated for wavelet denoising. In the second\nstage, we conducted the experiments using estimated optimal parameters, optimal\nfilter bank and optimal wavelet shrinkage function for evaluating the proposed\ntechnique. We evaluated the technique using quantitative based criteria such as\na gradient magnitude histogram and Peak Signal to Noise Ratio (PSNR). Further,\nthe results are qualitatively evaluated based on edge detection results. The\nproposed technique enhances the quality of the underwater images and can be\nemployed prior to apply computer vision techniques.\n",
        "published": "2012-12-03T05:57:46Z",
        "pdf_link": "http://arxiv.org/pdf/1212.0291v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.0318v1",
        "title": "Comparison of Fuzzy and Neuro Fuzzy Image Fusion Techniques and its\n  Applications",
        "summary": "  Image fusion is the process of integrating multiple images of the same scene\ninto a single fused image to reduce uncertainty and minimizing redundancy while\nextracting all the useful information from the source images. Image fusion\nprocess is required for different applications like medical imaging, remote\nsensing, medical imaging, machine vision, biometrics and military applications\nwhere quality and critical information is required. In this paper, image fusion\nusing fuzzy and neuro fuzzy logic approaches utilized to fuse images from\ndifferent sensors, in order to enhance visualization. The proposed work further\nexplores comparison between fuzzy based image fusion and neuro fuzzy fusion\ntechnique along with quality evaluation indices for image fusion like image\nquality index, mutual information measure, fusion factor, fusion symmetry,\nfusion index, root mean square error, peak signal to noise ratio, entropy,\ncorrelation coefficient and spatial frequency. Experimental results obtained\nfrom fusion process prove that the use of the neuro fuzzy based image fusion\napproach shows better performance in first two test cases while in the third\ntest case fuzzy based image fusion technique gives better results.\n",
        "published": "2012-12-03T08:55:52Z",
        "pdf_link": "http://arxiv.org/pdf/1212.0318v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.0383v1",
        "title": "GLCM-based chi-square histogram distance for automatic detection of\n  defects on patterned textures",
        "summary": "  Chi-square histogram distance is one of the distance measures that can be\nused to find dissimilarity between two histograms. Motivated by the fact that\ntexture discrimination by human vision system is based on second-order\nstatistics, we make use of histogram of gray-level co-occurrence matrix (GLCM)\nthat is based on second-order statistics and propose a new machine vision\nalgorithm for automatic defect detection on patterned textures. Input defective\nimages are split into several periodic blocks and GLCMs are computed after\nquantizing the gray levels from 0-255 to 0-63 to keep the size of GLCM compact\nand to reduce computation time. Dissimilarity matrix derived from chi-square\ndistances of the GLCMs is subjected to hierarchical clustering to automatically\nidentify defective and defect-free blocks. Effectiveness of the proposed method\nis demonstrated through experiments on defective real-fabric images of 2 major\nwallpaper groups (pmm and p4m groups).\n",
        "published": "2012-12-03T13:40:41Z",
        "pdf_link": "http://arxiv.org/pdf/1212.0383v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.0402v1",
        "title": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild",
        "summary": "  We introduce UCF101 which is currently the largest dataset of human actions.\nIt consists of 101 action classes, over 13k clips and 27 hours of video data.\nThe database consists of realistic user uploaded videos containing camera\nmotion and cluttered background. Additionally, we provide baseline action\nrecognition results on this new dataset using standard bag of words approach\nwith overall performance of 44.5%. To the best of our knowledge, UCF101 is\ncurrently the most challenging dataset of actions due to its large number of\nclasses, large number of clips and also unconstrained nature of such clips.\n",
        "published": "2012-12-03T14:45:31Z",
        "pdf_link": "http://arxiv.org/pdf/1212.0402v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.0433v1",
        "title": "Compressive Schlieren Deflectometry",
        "summary": "  Schlieren deflectometry aims at characterizing the deflections undergone by\nrefracted incident light rays at any surface point of a transparent object. For\nsmooth surfaces, each surface location is actually associated with a sparse\ndeflection map (or spectrum). This paper presents a novel method to\ncompressively acquire and reconstruct such spectra. This is achieved by\naltering the way deflection information is captured in a common Schlieren\nDeflectometer, i.e., the deflection spectra are indirectly observed by the\nprinciple of spread spectrum compressed sensing. These observations are\nrealized optically using a 2-D Spatial Light Modulator (SLM) adjusted to the\ncorresponding sensing basis and whose modulations encode the light deviation\nsubsequently recorded by a CCD camera. The efficiency of this approach is\ndemonstrated experimentally on the observation of few test objects. Further,\nusing a simple parametrization of the deflection spectra we show that relevant\nkey parameters can be directly computed using the measurements, avoiding full\nreconstruction.\n",
        "published": "2012-12-03T16:21:07Z",
        "pdf_link": "http://arxiv.org/pdf/1212.0433v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.0888v1",
        "title": "Unmixing of Hyperspectral Data Using Robust Statistics-based NMF",
        "summary": "  Mixed pixels are presented in hyperspectral images due to low spatial\nresolution of hyperspectral sensors. Spectral unmixing decomposes mixed pixels\nspectra into endmembers spectra and abundance fractions. In this paper using of\nrobust statistics-based nonnegative matrix factorization (RNMF) for spectral\nunmixing of hyperspectral data is investigated. RNMF uses a robust cost\nfunction and iterative updating procedure, so is not sensitive to outliers.\nThis method has been applied to simulated data using USGS spectral library,\nAVIRIS and ROSIS datasets. Unmixing results are compared to traditional NMF\nmethod based on SAD and AAD measures. Results demonstrate that this method can\nbe used efficiently for hyperspectral unmixing purposes.\n",
        "published": "2012-12-04T21:59:35Z",
        "pdf_link": "http://arxiv.org/pdf/1212.0888v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.1073v2",
        "title": "Kernel Estimation from Salient Structure for Robust Motion Deblurring",
        "summary": "  Blind image deblurring algorithms have been improving steadily in the past\nyears. Most state-of-the-art algorithms, however, still cannot perform\nperfectly in challenging cases, especially in large blur setting. In this\npaper, we focus on how to estimate a good kernel estimate from a single blurred\nimage based on the image structure. We found that image details caused by\nblurring could adversely affect the kernel estimation, especially when the blur\nkernel is large. One effective way to eliminate these details is to apply image\ndenoising model based on the Total Variation (TV). First, we developed a novel\nmethod for computing image structures based on TV model, such that the\nstructures undermining the kernel estimation will be removed. Second, to\nmitigate the possible adverse effect of salient edges and improve the\nrobustness of kernel estimation, we applied a gradient selection method. Third,\nwe proposed a novel kernel estimation method, which is capable of preserving\nthe continuity and sparsity of the kernel and reducing the noises. Finally, we\ndeveloped an adaptive weighted spatial prior, for the purpose of preserving\nsharp edges in latent image restoration. The effectiveness of our method is\ndemonstrated by experiments on various kinds of challenging examples.\n",
        "published": "2012-12-05T16:02:43Z",
        "pdf_link": "http://arxiv.org/pdf/1212.1073v2"
    },
    {
        "id": "http://arxiv.org/abs/1212.1329v1",
        "title": "Automatic Detection of Texture Defects Using Texture-Periodicity and\n  Gabor Wavelets",
        "summary": "  In this paper, we propose a machine vision algorithm for automatically\ndetecting defects in textures belonging to 16 out of 17 wallpaper groups using\ntexture-periodicity and a family of Gabor wavelets. Input defective images are\nsubjected to Gabor wavelet transformation in multi-scales and\nmulti-orientations and a resultant image is obtained in L2 norm. The resultant\nimage is split into several periodic blocks and energy of each block is used as\na feature space to automatically identify defective and defect-free blocks\nusing Ward's hierarchical clustering. Experiments on defective fabric images of\nthree major wallpaper groups, namely, pmm, p2 and p4m, show that the proposed\nmethod is robust in finding fabric defects without human intervention and can\nbe used for automatic defect detection in fabric industries.\n",
        "published": "2012-12-06T14:17:21Z",
        "pdf_link": "http://arxiv.org/pdf/1212.1329v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.1819v2",
        "title": "A fair comparison of many max-tree computation algorithms (Extended\n  version of the paper submitted to ISMM 2013",
        "summary": "  With the development of connected filters for the last decade, many\nalgorithms have been proposed to compute the max-tree. Max-tree allows to\ncompute the most advanced connected operators in a simple way. However, no fair\ncomparison of algorithms has been proposed yet and the choice of an algorithm\nover an other depends on many parameters. Since the need of fast algorithms is\nobvious for production code, we present an in depth comparison of five\nalgorithms and some variations of them in a unique framework. Finally, a\ndecision tree will be proposed to help user in choosing the right algorithm\nwith respect to their data.\n",
        "published": "2012-12-08T17:38:40Z",
        "pdf_link": "http://arxiv.org/pdf/1212.1819v2"
    },
    {
        "id": "http://arxiv.org/abs/1212.2245v1",
        "title": "Fast and Robust Linear Motion Deblurring",
        "summary": "  We investigate efficient algorithmic realisations for robust deconvolution of\ngrey-value images with known space-invariant point-spread function, with\nemphasis on 1D motion blur scenarios. The goal is to make deconvolution\nsuitable as preprocessing step in automated image processing environments with\ntight time constraints. Candidate deconvolution methods are selected for their\nrestoration quality, robustness and efficiency. Evaluation of restoration\nquality and robustness on synthetic and real-world test images leads us to\nfocus on a combination of Wiener filtering with few iterations of robust and\nregularised Richardson-Lucy deconvolution. We discuss algorithmic optimisations\nfor specific scenarios. In the case of uniform linear motion blur in coordinate\ndirection, it is possible to achieve real-time performance (less than 50 ms) in\nsingle-threaded CPU computation on images of $256\\times256$ pixels. For more\ngeneral space-invariant blur settings, still favourable computation times are\nobtained. Exemplary parallel implementations demonstrate that the proposed\nmethod also achieves real-time performance for general 1D motion blurs in a\nmulti-threaded CPU setting, and for general 2D blurs on a GPU.\n",
        "published": "2012-12-10T23:00:10Z",
        "pdf_link": "http://arxiv.org/pdf/1212.2245v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.2278v2",
        "title": "Inverting and Visualizing Features for Object Detection",
        "summary": "  We introduce algorithms to visualize feature spaces used by object detectors.\nThe tools in this paper allow a human to put on `HOG goggles' and perceive the\nvisual world as a HOG based object detector sees it. We found that these\nvisualizations allow us to analyze object detection systems in new ways and\ngain new insight into the detector's failures. For example, when we visualize\nthe features for high scoring false alarms, we discovered that, although they\nare clearly wrong in image space, they do look deceptively similar to true\npositives in feature space. This result suggests that many of these false\nalarms are caused by our choice of feature space, and indicates that creating a\nbetter learning algorithm or building bigger datasets is unlikely to correct\nthese errors. By visualizing feature spaces, we can gain a more intuitive\nunderstanding of our detection systems.\n",
        "published": "2012-12-11T01:59:51Z",
        "pdf_link": "http://arxiv.org/pdf/1212.2278v2"
    },
    {
        "id": "http://arxiv.org/abs/1212.2546v1",
        "title": "A Learning Framework for Morphological Operators using Counter-Harmonic\n  Mean",
        "summary": "  We present a novel framework for learning morphological operators using\ncounter-harmonic mean. It combines concepts from morphology and convolutional\nneural networks. A thorough experimental validation analyzes basic\nmorphological operators dilation and erosion, opening and closing, as well as\nthe much more complex top-hat transform, for which we report a real-world\napplication from the steel industry. Using online learning and stochastic\ngradient descent, our system learns both the structuring element and the\ncomposition of operators. It scales well to large datasets and online settings.\n",
        "published": "2012-12-11T17:29:04Z",
        "pdf_link": "http://arxiv.org/pdf/1212.2546v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.2692v1",
        "title": "Enhanced skin colour classifier using RGB Ratio model",
        "summary": "  Skin colour detection is frequently been used for searching people, face\ndetection, pornographic filtering and hand tracking. The presence of skin or\nnon-skin in digital image can be determined by manipulating pixels colour or\npixels texture. The main problem in skin colour detection is to represent the\nskin colour distribution model that is invariant or least sensitive to changes\nin illumination condition. Another problem comes from the fact that many\nobjects in the real world may possess almost similar skin-tone colour such as\nwood, leather, skin-coloured clothing, hair and sand. Moreover, skin colour is\ndifferent between races and can be different from a person to another, even\nwith people of the same ethnicity. Finally, skin colour will appear a little\ndifferent when different types of camera are used to capture the object or\nscene. The objective in this study is to develop a skin colour classifier based\non pixel-based using RGB ratio model. The RGB ratio model is a newly proposed\nmethod that belongs under the category of an explicitly defined skin region\nmodel. This skin classifier was tested with SIdb dataset and two benchmark\ndatasets; UChile and TDSD datasets to measure classifier performance. The\nperformance of skin classifier was measured based on true positive (TF) and\nfalse positive (FP) indicator. This newly proposed model was compared with\nKovac, Saleh and Swift models. The experimental results showed that the RGB\nratio model outperformed all the other models in term of detection rate. The\nRGB ratio model is able to reduce FP detection that caused by reddish objects\ncolour as well as be able to detect darkened skin and skin covered by shadow.\n",
        "published": "2012-12-12T03:01:00Z",
        "pdf_link": "http://arxiv.org/pdf/1212.2692v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.2823v1",
        "title": "Tracking Revisited using RGBD Camera: Baseline and Benchmark",
        "summary": "  Although there has been significant progress in the past decade,tracking is\nstill a very challenging computer vision task, due to problems such as\nocclusion and model drift.Recently, the increased popularity of depth sensors\ne.g. Microsoft Kinect has made it easy to obtain depth data at low cost.This\nmay be a game changer for tracking, since depth information can be used to\nprevent model drift and handle occlusion.In this paper, we construct a\nbenchmark dataset of 100 RGBD videos with high diversity, including deformable\nobjects, various occlusion conditions and moving cameras. We propose a very\nsimple but strong baseline model for RGBD tracking, and present a quantitative\ncomparison of several state-of-the-art tracking algorithms.Experimental results\nshow that including depth information and reasoning about occlusion\nsignificantly improves tracking performance. The datasets, evaluation details,\nsource code for the baseline algorithm, and instructions for submitting new\nmodels will be made available online after acceptance.\n",
        "published": "2012-12-12T14:02:41Z",
        "pdf_link": "http://arxiv.org/pdf/1212.2823v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.2860v1",
        "title": "Pituitary Adenoma Volumetry with 3D Slicer",
        "summary": "  In this study, we present pituitary adenoma volumetry using the free and open\nsource medical image computing platform for biomedical research: (3D) Slicer.\nVolumetric changes in cerebral pathologies like pituitary adenomas are a\ncritical factor in treatment decisions by physicians and in general the volume\nis acquired manually. Therefore, manual slice-by-slice segmentations in\nmagnetic resonance imaging (MRI) data, which have been obtained at regular\nintervals, are performed. In contrast to this manual time consuming\nslice-by-slice segmentation process Slicer is an alternative which can be\nsignificantly faster and less user intensive. In this contribution, we compare\npure manual segmentations of ten pituitary adenomas with semi-automatic\nsegmentations under Slicer. Thus, physicians drew the boundaries completely\nmanually on a slice-by-slice basis and performed a Slicer-enhanced segmentation\nusing the competitive region-growing based module of Slicer named GrowCut.\nResults showed that the time and user effort required for GrowCut-based\nsegmentations were on average about thirty percent less than the pure manual\nsegmentations. Furthermore, we calculated the Dice Similarity Coefficient (DSC)\nbetween the manual and the Slicer-based segmentations to proof that the two are\ncomparable yielding an average DSC of 81.97\\pm3.39%.\n",
        "published": "2012-12-12T16:12:32Z",
        "pdf_link": "http://arxiv.org/pdf/1212.2860v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.3268v3",
        "title": "Robust image reconstruction from multi-view measurements",
        "summary": "  We propose a novel method to accurately reconstruct a set of images\nrepresenting a single scene from few linear multi-view measurements. Each\nobserved image is modeled as the sum of a background image and a foreground\none. The background image is common to all observed images but undergoes\ngeometric transformations, as the scene is observed from different viewpoints.\nIn this paper, we assume that these geometric transformations are represented\nby a few parameters, e.g., translations, rotations, affine transformations,\netc.. The foreground images differ from one observed image to another, and are\nused to model possible occlusions of the scene. The proposed reconstruction\nalgorithm estimates jointly the images and the transformation parameters from\nthe available multi-view measurements. The ideal solution of this multi-view\nimaging problem minimizes a non-convex functional, and the reconstruction\ntechnique is an alternating descent method built to minimize this functional.\nThe convergence of the proposed algorithm is studied, and conditions under\nwhich the sequence of estimated images and parameters converges to a critical\npoint of the non-convex functional are provided. Finally, the efficiency of the\nalgorithm is demonstrated using numerical simulations for applications such as\ncompressed sensing or super-resolution.\n",
        "published": "2012-12-13T19:00:17Z",
        "pdf_link": "http://arxiv.org/pdf/1212.3268v3"
    },
    {
        "id": "http://arxiv.org/abs/1212.3373v1",
        "title": "A Novel Directional Weighted Minimum Deviation (DWMD) Based Filter for\n  Removal of Random Valued Impulse Noise",
        "summary": "  The most median-based de noising methods works fine for restoring the images\ncorrupted by Randomn Valued Impulse Noise with low noise level but very poor\nwith highly corrupted images. In this paper a directional weighted minimum\ndeviation (DWMD) based filter has been proposed for removal of high random\nvalued impulse noise (RVIN). The proposed approach based on Standard Deviation\n(SD) works in two phases. The first phase detects the contaminated pixels by\ndifferencing between the test pixel and its neighbor pixels aligned with four\nmain directions. The second phase filters only those pixels keeping others\nintact. The filtering scheme is based on minimum standard deviation of the four\ndirectional pixels. Extensive simulations show that the proposed filter not\nonly provide better performance of de noising RVIN but can preserve more\ndetails features even thin lines or dots. This technique shows better\nperformance in terms of PSNR, Image Fidelity and Computational Cost compared to\nthe existing filters.\n",
        "published": "2012-12-14T00:13:11Z",
        "pdf_link": "http://arxiv.org/pdf/1212.3373v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.3530v5",
        "title": "A Multi-Orientation Analysis Approach to Retinal Vessel Tracking",
        "summary": "  This paper presents a method for retinal vasculature extraction based on\nbiologically inspired multi-orientation analysis. We apply multi-orientation\nanalysis via so-called invertible orientation scores, modeling the cortical\ncolumns in the visual system of higher mammals. This allows us to generically\ndeal with many hitherto complex problems inherent to vessel tracking, such as\ncrossings, bifurcations, parallel vessels, vessels of varying widths and\nvessels with high curvature. Our approach applies tracking in invertible\norientation scores via a novel geometrical principle for curve optimization in\nthe Euclidean motion group SE(2). The method runs fully automatically and\nprovides a detailed model of the retinal vasculature, which is crucial as a\nsound basis for further quantitative analysis of the retina, especially in\nscreening applications.\n",
        "published": "2012-12-14T17:04:03Z",
        "pdf_link": "http://arxiv.org/pdf/1212.3530v5"
    },
    {
        "id": "http://arxiv.org/abs/1212.3767v2",
        "title": "Visual Objects Classification with Sliding Spatial Pyramid Matching",
        "summary": "  We present a method for visual object classification using only a single\nfeature, transformed color SIFT with a variant of Spatial Pyramid Matching\n(SPM) that we called Sliding Spatial Pyramid Matching (SSPM), trained with an\nensemble of linear regression (provided by LINEAR) to obtained state of the art\nresult on Caltech-101 of 83.46%. SSPM is a special version of SPM where instead\nof dividing an image into K number of regions, a subwindow of fixed size is\nslide around the image with a fixed step size. For each subwindow, a histogram\nof visual words is generated. To obtained the visual vocabulary, instead of\nperforming K-means clustering, we randomly pick N exemplars from the training\nset and encode them with a soft non-linear mapping method. We then trained 15\nmodels, each with a different visual word size with linear regression. All 15\nmodels are then averaged together to form a single strong model.\n",
        "published": "2012-12-16T09:10:54Z",
        "pdf_link": "http://arxiv.org/pdf/1212.3767v2"
    },
    {
        "id": "http://arxiv.org/abs/1212.4527v1",
        "title": "GMM-Based Hidden Markov Random Field for Color Image and 3D Volume\n  Segmentation",
        "summary": "  In this project, we first study the Gaussian-based hidden Markov random field\n(HMRF) model and its expectation-maximization (EM) algorithm. Then we\ngeneralize it to Gaussian mixture model-based hidden Markov random field. The\nalgorithm is implemented in MATLAB. We also apply this algorithm to color image\nsegmentation problems and 3D volume segmentation problems.\n",
        "published": "2012-12-18T22:30:23Z",
        "pdf_link": "http://arxiv.org/pdf/1212.4527v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.4608v1",
        "title": "Perceptually Motivated Shape Context Which Uses Shape Interiors",
        "summary": "  In this paper, we identify some of the limitations of current-day shape\nmatching techniques. We provide examples of how contour-based shape matching\ntechniques cannot provide a good match for certain visually similar shapes. To\novercome this limitation, we propose a perceptually motivated variant of the\nwell-known shape context descriptor. We identify that the interior properties\nof the shape play an important role in object recognition and develop a\ndescriptor that captures these interior properties. We show that our method can\neasily be augmented with any other shape matching algorithm. We also show from\nour experiments that the use of our descriptor can significantly improve the\nretrieval rates.\n",
        "published": "2012-12-19T09:40:09Z",
        "pdf_link": "http://arxiv.org/pdf/1212.4608v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.5352v1",
        "title": "On the Adaptability of Neural Network Image Super-Resolution",
        "summary": "  In this paper, we described and developed a framework for Multilayer\nPerceptron (MLP) to work on low level image processing, where MLP will be used\nto perform image super-resolution. Meanwhile, MLP are trained with different\ntypes of images from various categories, hence analyse the behaviour and\nperformance of the neural network. The tests are carried out using qualitative\ntest, in which Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR) and\nStructural Similarity Index (SSIM). The results showed that MLP trained with\nsingle image category can perform reasonably well compared to methods proposed\nby other researchers.\n",
        "published": "2012-12-21T07:30:38Z",
        "pdf_link": "http://arxiv.org/pdf/1212.5352v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.5656v1",
        "title": "High-precision camera distortion measurements with a \"calibration harp\"",
        "summary": "  This paper addresses the high precision measurement of the distortion of a\ndigital camera from photographs. Traditionally, this distortion is measured\nfrom photographs of a flat pattern which contains aligned elements.\nNevertheless, it is nearly impossible to fabricate a very flat pattern and to\nvalidate its flatness. This fact limits the attainable measurable precisions.\nIn contrast, it is much easier to obtain physically very precise straight lines\nby tightly stretching good quality strings on a frame. Taking literally\n\"plumb-line methods\", we built a \"calibration harp\" instead of the classic flat\npatterns to obtain a high precision measurement tool, demonstrably reaching\n2/100 pixel precisions. The harp is complemented with the algorithms computing\nautomatically from harp photographs two different and complementary lens\ndistortion measurements. The precision of the method is evaluated on images\ncorrected by state-of-the-art distortion correction algorithms, and by popular\nsoftware. Three applications are shown: first an objective and reliable\nmeasurement of the result of any distortion correction. Second, the harp\npermits to control state-of-the art global camera calibration algorithms: It\npermits to select the right distortion model, thus avoiding internal\ncompensation errors inherent to these methods. Third, the method replaces\nmanual procedures in other distortion correction methods, makes them fully\nautomatic, and increases their reliability and precision.\n",
        "published": "2012-12-22T05:00:01Z",
        "pdf_link": "http://arxiv.org/pdf/1212.5656v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.5720v2",
        "title": "Hierarchical Graphical Models for Multigroup Shape Analysis using\n  Expectation Maximization with Sampling in Kendall's Shape Space",
        "summary": "  This paper proposes a novel framework for multi-group shape analysis relying\non a hierarchical graphical statistical model on shapes within a population.The\nframework represents individual shapes as point setsmodulo translation,\nrotation, and scale, following the notion in Kendall shape space.While\nindividual shapes are derived from their group shape model, each group shape\nmodel is derived from a single population shape model. The hierarchical model\nfollows the natural organization of population data and the top level in the\nhierarchy provides a common frame of reference for multigroup shape analysis,\ne.g. classification and hypothesis testing. Unlike typical shape-modeling\napproaches, the proposed model is a generative model that defines a joint\ndistribution of object-boundary data and the shape-model variables.\nFurthermore, it naturally enforces optimal correspondences during the process\nof model fitting and thereby subsumes the so-called correspondence problem. The\nproposed inference scheme employs an expectation maximization (EM) algorithm\nthat treats the individual and group shape variables as hidden random variables\nand integrates them out before estimating the parameters (population mean and\nvariance and the group variances). The underpinning of the EM algorithm is the\nsampling of pointsets, in Kendall shape space, from their posterior\ndistribution, for which we exploit a highly-efficient scheme based on\nHamiltonian Monte Carlo simulation. Experiments in this paper use the fitted\nhierarchical model to perform (1) hypothesis testing for comparison between\npairs of groups using permutation testing and (2) classification for image\nretrieval. The paper validates the proposed framework on simulated data and\ndemonstrates results on real data.\n",
        "published": "2012-12-22T20:27:22Z",
        "pdf_link": "http://arxiv.org/pdf/1212.5720v2"
    },
    {
        "id": "http://arxiv.org/abs/1212.6094v1",
        "title": "Large Scale Strongly Supervised Ensemble Metric Learning, with\n  Applications to Face Verification and Retrieval",
        "summary": "  Learning Mahanalobis distance metrics in a high- dimensional feature space is\nvery difficult especially when structural sparsity and low rank are enforced to\nimprove com- putational efficiency in testing phase. This paper addresses both\naspects by an ensemble metric learning approach that consists of sparse block\ndiagonal metric ensembling and join- t metric learning as two consecutive\nsteps. The former step pursues a highly sparse block diagonal metric by\nselecting effective feature groups while the latter one further exploits\ncorrelations between selected feature groups to obtain an accurate and low rank\nmetric. Our algorithm considers all pairwise or triplet constraints generated\nfrom training samples with explicit class labels, and possesses good scala-\nbility with respect to increasing feature dimensionality and growing data\nvolumes. Its applications to face verification and retrieval outperform\nexisting state-of-the-art methods in accuracy while retaining high efficiency.\n",
        "published": "2012-12-25T22:49:31Z",
        "pdf_link": "http://arxiv.org/pdf/1212.6094v1"
    },
    {
        "id": "http://arxiv.org/abs/1212.6933v3",
        "title": "On Automation and Medical Image Interpretation, With Applications for\n  Laryngeal Imaging",
        "summary": "  Indeed, these are exciting times. We are in the heart of a digital\nrenaissance. Automation and computer technology allow engineers and scientists\nto fabricate processes that amalgamate quality of life. We anticipate much\ngrowth in medical image interpretation and understanding, due to the influx of\ncomputer technologies. This work should serve as a guide to introduce the\nreader to core themes in theoretical computer science, as well as imaging\napplications for understanding vocal-fold vibrations. In this work, we motivate\nthe use of automation, review some mathematical models of computation. We\npresent a proof of a classical problem in image analysis that cannot be\nautomated by means of algorithms. Furthermore, discuss some applications for\nprocessing medical images of the vocal folds, and discuss some of the\nexhilarating directions the art of automation will take vocal-fold image\ninterpretation and quite possibly other areas of biomedical image analysis.\n",
        "published": "2012-12-31T17:38:02Z",
        "pdf_link": "http://arxiv.org/pdf/1212.6933v3"
    },
    {
        "id": "http://arxiv.org/abs/1301.0127v3",
        "title": "A Semi-automated Statistical Algorithm for Object Separation",
        "summary": "  We explicate a semi-automated statistical algorithm for object identification\nand segregation in both gray scale and color images. The algorithm makes\noptimal use of the observation that definite objects in an image are typically\nrepresented by pixel values having narrow Gaussian distributions about\ncharacteristic mean values. Furthermore, for visually distinct objects, the\ncorresponding Gaussian distributions have negligible overlap with each other\nand hence the Mahalanobis distance between these distributions are large. These\nstatistical facts enable one to sub-divide images into multiple thresholds of\nvariable sizes, each segregating similar objects. The procedure incorporates\nthe sensitivity of human eye to the gray pixel values into the variable\nthreshold size, while mapping the Gaussian distributions into localized\n\\delta-functions, for object separation. The effectiveness of this recursive\nstatistical algorithm is demonstrated using a wide variety of images.\n",
        "published": "2013-01-01T19:51:28Z",
        "pdf_link": "http://arxiv.org/pdf/1301.0127v3"
    },
    {
        "id": "http://arxiv.org/abs/1301.0167v1",
        "title": "Classifier Fusion Method to Recognize Handwritten Kannada Numerals",
        "summary": "  Optical Character Recognition (OCR) is one of the important fields in image\nprocessing and pattern recognition domain. Handwritten character recognition\nhas always been a challenging task. Only a little work can be traced towards\nthe recognition of handwritten characters for the south Indian languages.\nKannada is one such south Indian language which is also one of the official\nlanguage of India. Accurate recognition of Kannada characters is a challenging\ntask because of the high degree of similarity between the characters. Hence,\ngood quality features are to be extracted and better classifiers are needed to\nimprove the accuracy of the OCR for Kannada characters. This paper explores the\neffectiveness of feature extraction method like run length count (RLC) and\ndirectional chain code (DCC) for the recognition of handwritten Kannada\nnumerals. In this paper, a classifier fusion method is implemented to improve\nthe recognition rate. For the classifier fusion, we have considered K-nearest\nneighbour (KNN) and Linear classifier (LC). The novelty of this method is to\nachieve better accuracy with few features using classifier fusion approach.\nProposed method achieves an average recognition rate of 96%.\n",
        "published": "2013-01-02T04:45:44Z",
        "pdf_link": "http://arxiv.org/pdf/1301.0167v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.0432v1",
        "title": "A Self-Organizing Neural Scheme for Door Detection in Different\n  Environments",
        "summary": "  Doors are important landmarks for indoor mobile robot navigation and also\nassist blind people to independently access unfamiliar buildings. Most existing\nalgorithms of door detection are limited to work for familiar environments\nbecause of restricted assumptions about color, texture and shape. In this paper\nwe propose a novel approach which employs feature based classification and uses\nthe Kohonen Self-Organizing Map (SOM) for the purpose of door detection.\nGeneric and stable features are used for the training of SOM that increase the\nperformance significantly: concavity, bottom-edge intensity profile and door\nedges. To validate the robustness and generalizability of our method, we\ncollected a large dataset of real world door images from a variety of\nenvironments and different lighting conditions. The algorithm achieves more\nthan 95% detection which demonstrates that our door detection method is generic\nand robust with variations of color, texture, occlusions, lighting condition,\nscales, and viewpoints.\n",
        "published": "2013-01-03T12:04:28Z",
        "pdf_link": "http://arxiv.org/pdf/1301.0432v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.0612v1",
        "title": "Adaptive Foreground and Shadow Detection inImage Sequences",
        "summary": "  This paper presents a novel method of foreground segmentation that\ndistinguishes moving objects from their moving cast shadows in monocular image\nsequences. The models of background, edge information, and shadow are set up\nand adaptively updated. A Bayesian belief network is proposed to describe the\nrelationships among the segmentation label, background, intensity, and edge\ninformation. The notion of Markov random field is used to encourage the spatial\nconnectivity of the segmented regions. The solution is obtained by maximizing\nthe posterior possibility density of the segmentation field.\n",
        "published": "2012-12-12T15:59:10Z",
        "pdf_link": "http://arxiv.org/pdf/1301.0612v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.0998v1",
        "title": "Stratified SIFT Matching for Human Iris Recognition",
        "summary": "  This paper proposes an efficient three fold stratified SIFT matching for iris\nrecognition. The objective is to filter wrongly paired conventional SIFT\nmatches. In Strata I, the keypoints from gallery and probe iris images are\npaired using traditional SIFT approach. Due to high image similarity at\ndifferent regions of iris there may be some impairments. These are detected and\nfiltered by finding gradient of paired keypoints in Strata II. Further, the\nscaling factor of paired keypoints is used to remove impairments in Strata III.\nThe pairs retained after Strata III are likely to be potential matches for iris\nrecognition. The proposed system performs with an accuracy of 96.08% and 97.15%\non publicly available CASIAV3 and BATH databases respectively. This marks\nsignificant improvement of accuracy and FAR over the existing SIFT matching for\niris.\n",
        "published": "2013-01-06T12:05:28Z",
        "pdf_link": "http://arxiv.org/pdf/1301.0998v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.1374v1",
        "title": "PaFiMoCS: Particle Filtered Modified-CS and Applications in Visual\n  Tracking across Illumination Change",
        "summary": "  We study the problem of tracking (causally estimating) a time sequence of\nsparse spatial signals with changing sparsity patterns, as well as other\nunknown states, from a sequence of nonlinear observations corrupted by\n(possibly) non-Gaussian noise. In many applications, particularly those in\nvisual tracking, the unknown state can be split into a small dimensional part,\ne.g. global motion, and a spatial signal, e.g. illumination or shape\ndeformation. The spatial signal is often well modeled as being sparse in some\ndomain. For a long sequence, its sparsity pattern can change over time,\nalthough the changes are usually slow. To address the above problem, we propose\na novel solution approach called Particle Filtered Modified-CS (PaFiMoCS). The\nkey idea of PaFiMoCS is to importance sample for the small dimensional state\nvector, while replacing importance sampling by slow sparsity pattern change\nconstrained posterior mode tracking for recovering the sparse spatial signal.\nWe show that the problem of tracking moving objects across spatially varying\nillumination change is an example of the above problem and explain how to\ndesign PaFiMoCS for it. Experiments on both simulated data as well as on real\nvideos with significant illumination changes demonstrate the superiority of the\nproposed algorithm as compared with existing particle filter based tracking\nalgorithms.\n",
        "published": "2013-01-08T01:18:21Z",
        "pdf_link": "http://arxiv.org/pdf/1301.1374v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.1551v1",
        "title": "A novel processing pipeline for optical multi-touch surfaces",
        "summary": "  In this thesis a new approach for touch detection on optical multi-touch\ndevices is proposed that exploits the fact that the camera images reveal not\nonly the actual touch points but also objects above the screen such as the hand\nor arm of a user. The touch processing relies on the Maximally Stable Extremal\nRegions algorithm for finding the users' fingertips in the camera image. The\nhierarchical structure of the generated extremal regions serves as a starting\npoint for agglomerative clustering of the fingertips into hands. Furthermore, a\nheuristic is suggested that supports the identification of individual fingers\nas well as the distinction between left hands and right hands if all five\nfingers of a hand are in contact with the touch surface.\n  The evaluation confirmed that the system is robust against detection errors\nresulting from non-uniform illumination and reliably assigns touch points to\nindividual hands based on the implicitly tracked context information. The\nefficient multi-threaded implementation handles two-handed input from multiple\nusers in real-time.\n",
        "published": "2013-01-08T14:48:23Z",
        "pdf_link": "http://arxiv.org/pdf/1301.1551v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.1671v1",
        "title": "Causal graph-based video segmentation",
        "summary": "  Numerous approaches in image processing and computer vision are making use of\nsuper-pixels as a pre-processing step. Among the different methods producing\nsuch over-segmentation of an image, the graph-based approach of Felzenszwalb\nand Huttenlocher is broadly employed. One of its interesting properties is that\nthe regions are computed in a greedy manner in quasi-linear time. The algorithm\nmay be trivially extended to video segmentation by considering a video as a 3D\nvolume, however, this can not be the case for causal segmentation, when\nsubsequent frames are unknown. We propose an efficient video segmentation\napproach that computes temporally consistent pixels in a causal manner, filling\nthe need for causal and real time applications.\n",
        "published": "2013-01-08T20:56:17Z",
        "pdf_link": "http://arxiv.org/pdf/1301.1671v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.2252v1",
        "title": "A Factorized Variational Technique for Phase Unwrapping in Markov Random\n  Fields",
        "summary": "  Some types of medical and topographic imaging device produce images in which\nthe pixel values are \"phase-wrapped\", i.e. measured modulus a known scalar.\nPhase unwrapping can be viewed as the problem of inferring the number of shifts\nbetween each and every pair of neighboring pixels, subject to an a priori\npreference for smooth surfaces, and subject to a zero curl constraint, which\nrequires that the shifts must sum to 0 around every loop. We formulate phase\nunwrapping as a mean field inference problem in a Markov network, where the\nprior favors the zero curl constraint. We compare our mean field technique with\nthe least squares method on a synthetic 100x100 image, and give results on a\n512x512 synthetic aperture radar image from Sandia National Laboratories.<Long\nText>\n",
        "published": "2013-01-10T16:22:19Z",
        "pdf_link": "http://arxiv.org/pdf/1301.2252v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.2820v3",
        "title": "Clustering Learning for Robotic Vision",
        "summary": "  We present the clustering learning technique applied to multi-layer\nfeedforward deep neural networks. We show that this unsupervised learning\ntechnique can compute network filters with only a few minutes and a much\nreduced set of parameters. The goal of this paper is to promote the technique\nfor general-purpose robotic vision systems. We report its use in static image\ndatasets and object tracking datasets. We show that networks trained with\nclustering learning can outperform large networks trained for many hours on\ncomplex datasets.\n",
        "published": "2013-01-13T20:49:30Z",
        "pdf_link": "http://arxiv.org/pdf/1301.2820v3"
    },
    {
        "id": "http://arxiv.org/abs/1301.2884v1",
        "title": "Wavelet-based Scale Saliency",
        "summary": "  Both pixel-based scale saliency (PSS) and basis project methods focus on\nmultiscale analysis of data content and structure. Their theoretical relations\nand practical combination are previously discussed. However, no models have\never been proposed for calculating scale saliency on basis-projected\ndescriptors since then. This paper extend those ideas into mathematical models\nand implement them in the wavelet-based scale saliency (WSS). While PSS uses\npixel-value descriptors, WSS treats wavelet sub-bands as basis descriptors. The\npaper discusses different wavelet descriptors: discrete wavelet transform\n(DWT), wavelet packet transform (DWPT), quaternion wavelet transform (QWT) and\nbest basis quaternion wavelet packet transform (QWPTBB). WSS saliency maps of\ndifferent descriptors are generated and compared against other saliency methods\nby both quantitative and quanlitative methods. Quantitative results, ROC\ncurves, AUC values and NSS values are collected from simulations on Bruce and\nKootstra image databases with human eye-tracking data as ground-truth.\nFurthermore, qualitative visual results of saliency maps are analyzed and\ncompared against each other as well as eye-tracking data inclusive in the\ndatabases.\n",
        "published": "2013-01-14T08:36:00Z",
        "pdf_link": "http://arxiv.org/pdf/1301.2884v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.3385v2",
        "title": "Recurrent Online Clustering as a Spatio-Temporal Feature Extractor in\n  DeSTIN",
        "summary": "  This paper presents a basic enhancement to the DeSTIN deep learning\narchitecture by replacing the explicitly calculated transition tables that are\nused to capture temporal features with a simpler, more scalable mechanism. This\nmechanism uses feedback of state information to cluster over a space comprised\nof both the spatial input and the current state. The resulting architecture\nachieves state-of-the-art results on the MNIST classification benchmark.\n",
        "published": "2013-01-15T15:34:07Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3385v2"
    },
    {
        "id": "http://arxiv.org/abs/1301.3457v2",
        "title": "A Geometric Descriptor for Cell-Division Detection",
        "summary": "  We describe a method for cell-division detection based on a geometric-driven\ndescriptor that can be represented as a 5-layers processing network, based\nmainly on wavelet filtering and a test for mirror symmetry between pairs of\npixels. After the centroids of the descriptors are computed for a sequence of\nframes, the two-steps piecewise constant function that best fits the sequence\nof centroids determines the frame where the division occurs.\n",
        "published": "2013-01-15T19:18:52Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3457v2"
    },
    {
        "id": "http://arxiv.org/abs/1301.3560v1",
        "title": "Complexity of Representation and Inference in Compositional Models with\n  Part Sharing",
        "summary": "  This paper describes serial and parallel compositional models of multiple\nobjects with part sharing. Objects are built by part-subpart compositions and\nexpressed in terms of a hierarchical dictionary of object parts. These parts\nare represented on lattices of decreasing sizes which yield an executive\nsummary description. We describe inference and learning algorithms for these\nmodels. We analyze the complexity of this model in terms of computation time\n(for serial computers) and numbers of nodes (e.g., \"neurons\") for parallel\ncomputers. In particular, we compute the complexity gains by part sharing and\nits dependence on how the dictionary scales with the level of the hierarchy. We\nexplore three regimes of scaling behavior where the dictionary size (i)\nincreases exponentially with the level, (ii) is determined by an unsupervised\ncompositional learning algorithm applied to real data, (iii) decreases\nexponentially with scale. This analysis shows that in some regimes the use of\nshared parts enables algorithms which can perform inference in time linear in\nthe number of levels for an exponential number of objects. In other regimes\npart sharing has little advantage for serial computers but can give linear\nprocessing on parallel computers.\n",
        "published": "2013-01-16T02:29:15Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3560v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.3572v2",
        "title": "Indoor Semantic Segmentation using depth information",
        "summary": "  This work addresses multi-class segmentation of indoor scenes with RGB-D\ninputs. While this area of research has gained much attention recently, most\nworks still rely on hand-crafted features. In contrast, we apply a multiscale\nconvolutional network to learn features directly from the images and the depth\ninformation. We obtain state-of-the-art on the NYU-v2 depth dataset with an\naccuracy of 64.5%. We illustrate the labeling of indoor scenes in videos\nsequences that could be processed in real-time using appropriate hardware such\nas an FPGA.\n",
        "published": "2013-01-16T03:31:30Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3572v2"
    },
    {
        "id": "http://arxiv.org/abs/1301.3755v1",
        "title": "Gradient Driven Learning for Pooling in Visual Pipeline Feature\n  Extraction Models",
        "summary": "  Hyper-parameter selection remains a daunting task when building a pattern\nrecognition architecture which performs well, particularly in recently\nconstructed visual pipeline models for feature extraction. We re-formulate\npooling in an existing pipeline as a function of adjustable pooling map weight\nparameters and propose the use of supervised error signals from gradient\ndescent to tune the established maps within the model. This technique allows us\nto learn what would otherwise be a design choice within the model and\nspecialize the maps to aggregate areas of invariance for the task presented.\nPreliminary results show moderate potential gains in classification accuracy\nand highlight areas of importance within the intermediate feature\nrepresentation space.\n",
        "published": "2013-01-16T17:05:57Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3755v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.3964v1",
        "title": "Multiscale Discriminant Saliency for Visual Attention",
        "summary": "  The bottom-up saliency, an early stage of humans' visual attention, can be\nconsidered as a binary classification problem between center and surround\nclasses. Discriminant power of features for the classification is measured as\nmutual information between features and two classes distribution. The estimated\ndiscrepancy of two feature classes very much depends on considered scale\nlevels; then, multi-scale structure and discriminant power are integrated by\nemploying discrete wavelet features and Hidden markov tree (HMT). With wavelet\ncoefficients and Hidden Markov Tree parameters, quad-tree like label structures\nare constructed and utilized in maximum a posterior probability (MAP) of hidden\nclass variables at corresponding dyadic sub-squares. Then, saliency value for\neach dyadic square at each scale level is computed with discriminant power\nprinciple and the MAP. Finally, across multiple scales is integrated the final\nsaliency map by an information maximization rule. Both standard quantitative\ntools such as NSS, LCC, AUC and qualitative assessments are used for evaluating\nthe proposed multiscale discriminant saliency method (MDIS) against the\nwell-know information-based saliency method AIM on its Bruce Database wity\neye-tracking data. Simulation results are presented and analyzed to verify the\nvalidity of MDIS as well as point out its disadvantages for further research\ndirection.\n",
        "published": "2013-01-17T02:12:48Z",
        "pdf_link": "http://arxiv.org/pdf/1301.3964v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.4377v1",
        "title": "Multiple models of Bayesian networks applied to offline recognition of\n  Arabic handwritten city names",
        "summary": "  In this paper we address the problem of offline Arabic handwriting word\nrecognition. Off-line recognition of handwritten words is a difficult task due\nto the high variability and uncertainty of human writing. The majority of the\nrecent systems are constrained by the size of the lexicon to deal with and the\nnumber of writers. In this paper, we propose an approach for multi-writers\nArabic handwritten words recognition using multiple Bayesian networks. First,\nwe cut the image in several blocks. For each block, we compute a vector of\ndescriptors. Then, we use K-means to cluster the low-level features including\nZernik and Hu moments. Finally, we apply four variants of Bayesian networks\nclassifiers (Na\\\"ive Bayes, Tree Augmented Na\\\"ive Bayes (TAN), Forest\nAugmented Na\\\"ive Bayes (FAN) and DBN (dynamic bayesian network) to classify\nthe whole image of tunisian city name. The results demonstrate FAN and DBN\noutperform good recognition rates\n",
        "published": "2013-01-18T13:26:55Z",
        "pdf_link": "http://arxiv.org/pdf/1301.4377v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.4558v1",
        "title": "Lip Localization and Viseme Classification for Visual Speech Recognition",
        "summary": "  The need for an automatic lip-reading system is ever increasing. Infact,\ntoday, extraction and reliable analysis of facial movements make up an\nimportant part in many multimedia systems such as videoconference, low\ncommunication systems, lip-reading systems. In addition, visual information is\nimperative among people with special needs. We can imagine, for example, a\ndependent person ordering a machine with an easy lip movement or by a simple\nsyllable pronunciation. Moreover, people with hearing problems compensate for\ntheir special needs by lip-reading as well as listening to the person with\nwhome they are talking.\n",
        "published": "2013-01-19T11:36:53Z",
        "pdf_link": "http://arxiv.org/pdf/1301.4558v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.5356v3",
        "title": "Efficient MRF Energy Propagation for Video Segmentation via Bilateral\n  Filters",
        "summary": "  Segmentation of an object from a video is a challenging task in multimedia\napplications. Depending on the application, automatic or interactive methods\nare desired; however, regardless of the application type, efficient computation\nof video object segmentation is crucial for time-critical applications;\nspecifically, mobile and interactive applications require near real-time\nefficiencies. In this paper, we address the problem of video segmentation from\nthe perspective of efficiency. We initially redefine the problem of video\nobject segmentation as the propagation of MRF energies along the temporal\ndomain. For this purpose, a novel and efficient method is proposed to propagate\nMRF energies throughout the frames via bilateral filters without using any\nglobal texture, color or shape model. Recently presented bi-exponential filter\nis utilized for efficiency, whereas a novel technique is also developed to\ndynamically solve graph-cuts for varying, non-lattice graphs in general linear\nfiltering scenario. These improvements are experimented for both automatic and\ninteractive video segmentation scenarios. Moreover, in addition to the\nefficiency, segmentation quality is also tested both quantitatively and\nqualitatively. Indeed, for some challenging examples, significant time\nefficiency is observed without loss of segmentation quality.\n",
        "published": "2013-01-22T22:26:33Z",
        "pdf_link": "http://arxiv.org/pdf/1301.5356v3"
    },
    {
        "id": "http://arxiv.org/abs/1301.5491v1",
        "title": "ChESS - Quick and Robust Detection of Chess-board Features",
        "summary": "  Localization of chess-board vertices is a common task in computer vision,\nunderpinning many applications, but relatively little work focusses on\ndesigning a specific feature detector that is fast, accurate and robust. In\nthis paper the `Chess-board Extraction by Subtraction and Summation' (ChESS)\nfeature detector, designed to exclusively respond to chess-board vertices, is\npresented. The method proposed is robust against noise, poor lighting and poor\ncontrast, requires no prior knowledge of the extent of the chess-board pattern,\nis computationally very efficient, and provides a strength measure of detected\nfeatures. Such a detector has significant application both in the key field of\ncamera calibration, as well as in Structured Light 3D reconstruction. Evidence\nis presented showing its robustness, accuracy, and efficiency in comparison to\nother commonly used detectors both under simulation and in experimental 3D\nreconstruction of flat plate and cylindrical objects\n",
        "published": "2013-01-23T13:10:21Z",
        "pdf_link": "http://arxiv.org/pdf/1301.5491v1"
    },
    {
        "id": "http://arxiv.org/abs/1301.6646v2",
        "title": "Image registration with sparse approximations in parametric dictionaries",
        "summary": "  We examine in this paper the problem of image registration from the new\nperspective where images are given by sparse approximations in parametric\ndictionaries of geometric functions. We propose a registration algorithm that\nlooks for an estimate of the global transformation between sparse images by\nexamining the set of relative geometrical transformations between the\nrespective features. We propose a theoretical analysis of our registration\nalgorithm and we derive performance guarantees based on two novel important\nproperties of redundant dictionaries, namely the robust linear independence and\nthe transformation inconsistency. We propose several illustrations and insights\nabout the importance of these dictionary properties and show that common\nproperties such as coherence or restricted isometry property fail to provide\nsufficient information in registration problems. We finally show with\nillustrative experiments on simple visual objects and handwritten digits images\nthat our algorithm outperforms baseline competitor methods in terms of\ntransformation-invariant distance computation and classification.\n",
        "published": "2013-01-28T19:06:44Z",
        "pdf_link": "http://arxiv.org/pdf/1301.6646v2"
    },
    {
        "id": "http://arxiv.org/abs/1301.6847v2",
        "title": "Robust Face Recognition via Block Sparse Bayesian Learning",
        "summary": "  Face recognition (FR) is an important task in pattern recognition and\ncomputer vision. Sparse representation (SR) has been demonstrated to be a\npowerful framework for FR. In general, an SR algorithm treats each face in a\ntraining dataset as a basis function, and tries to find a sparse representation\nof a test face under these basis functions. The sparse representation\ncoefficients then provide a recognition hint. Early SR algorithms are based on\na basic sparse model. Recently, it has been found that algorithms based on a\nblock sparse model can achieve better recognition rates. Based on this model,\nin this study we use block sparse Bayesian learning (BSBL) to find a sparse\nrepresentation of a test face for recognition. BSBL is a recently proposed\nframework, which has many advantages over existing block-sparse-model based\nalgorithms. Experimental results on the Extended Yale B, the AR and the CMU PIE\nface databases show that using BSBL can achieve better recognition rates and\nhigher robustness than state-of-the-art algorithms in most cases.\n",
        "published": "2013-01-29T07:23:00Z",
        "pdf_link": "http://arxiv.org/pdf/1301.6847v2"
    },
    {
        "id": "http://arxiv.org/abs/1301.7641v2",
        "title": "Multi-scale Discriminant Saliency with Wavelet-based Hidden Markov Tree\n  Modelling",
        "summary": "  The bottom-up saliency, an early stage of humans' visual attention, can be\nconsidered as a binary classification problem between centre and surround\nclasses. Discriminant power of features for the classification is measured as\nmutual information between distributions of image features and corresponding\nclasses . As the estimated discrepancy very much depends on considered scale\nlevel, multi-scale structure and discriminant power are integrated by employing\ndiscrete wavelet features and Hidden Markov Tree (HMT). With wavelet\ncoefficients and Hidden Markov Tree parameters, quad-tree like label structures\nare constructed and utilized in maximum a posterior probability (MAP) of hidden\nclass variables at corresponding dyadic sub-squares. Then, a saliency value for\neach square block at each scale level is computed with discriminant power\nprinciple. Finally, across multiple scales is integrated the final saliency map\nby an information maximization rule. Both standard quantitative tools such as\nNSS, LCC, AUC and qualitative assessments are used for evaluating the proposed\nmulti-scale discriminant saliency (MDIS) method against the well-know\ninformation based approach AIM on its released image collection with\neye-tracking data. Simulation results are presented and analysed to verify the\nvalidity of MDIS as well as point out its limitation for further research\ndirection.\n",
        "published": "2013-01-31T15:20:17Z",
        "pdf_link": "http://arxiv.org/pdf/1301.7641v2"
    },
    {
        "id": "http://arxiv.org/abs/1301.7661v1",
        "title": "Fast non parametric entropy estimation for spatial-temporal saliency\n  method",
        "summary": "  This paper formulates bottom-up visual saliency as center surround\nconditional entropy and presents a fast and efficient technique for the\ncomputation of such a saliency map. It is shown that the new saliency\nformulation is consistent with self-information based saliency,\ndecision-theoretic saliency and Bayesian definition of surprises but also faces\nthe same significant computational challenge of estimating probability density\nin very high dimensional spaces with limited samples. We have developed a fast\nand efficient nonparametric method to make the practical implementation of\nthese types of saliency maps possible. By aligning pixels from the center and\nsurround regions and treating their location coordinates as random variables,\nwe use a k-d partitioning method to efficiently estimating the center surround\nconditional entropy. We present experimental results on two publicly available\neye tracking still image databases and show that the new technique is\ncompetitive with state of the art bottom-up saliency computational methods. We\nhave also extended the technique to compute spatiotemporal visual saliency of\nvideo and evaluate the bottom-up spatiotemporal saliency against eye tracking\ndata on a video taken onboard a moving vehicle with the driver's eye being\ntracked by a head mounted eye-tracker.\n",
        "published": "2013-01-31T16:05:26Z",
        "pdf_link": "http://arxiv.org/pdf/1301.7661v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.0446v1",
        "title": "Sparse Camera Network for Visual Surveillance -- A Comprehensive Survey",
        "summary": "  Technological advances in sensor manufacture, communication, and computing\nare stimulating the development of new applications that are transforming\ntraditional vision systems into pervasive intelligent camera networks. The\nanalysis of visual cues in multi-camera networks enables a wide range of\napplications, from smart home and office automation to large area surveillance\nand traffic surveillance. While dense camera networks - in which most cameras\nhave large overlapping fields of view - are well studied, we are mainly\nconcerned with sparse camera networks. A sparse camera network undertakes large\narea surveillance using as few cameras as possible, and most cameras have\nnon-overlapping fields of view with one another. The task is challenging due to\nthe lack of knowledge about the topological structure of the network,\nvariations in the appearance and motion of specific tracking targets in\ndifferent views, and the difficulties of understanding composite events in the\nnetwork. In this review paper, we present a comprehensive survey of recent\nresearch results to address the problems of intra-camera tracking, topological\nstructure learning, target appearance modeling, and global activity\nunderstanding in sparse camera networks. A number of current open research\nissues are discussed.\n",
        "published": "2013-02-03T02:40:29Z",
        "pdf_link": "http://arxiv.org/pdf/1302.0446v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.0494v4",
        "title": "Local Structure Matching Driven by Joint-Saliency-Structure Adaptive\n  Kernel Regression",
        "summary": "  For nonrigid image registration, matching the particular structures (or the\noutliers) that have missing correspondence and/or local large deformations, can\nbe more difficult than matching the common structures with small deformations\nin the two images. Most existing works depend heavily on the outlier\nsegmentation to remove the outlier effect in the registration. Moreover, these\nworks do not handle simultaneously the missing correspondences and local large\ndeformations. In this paper, we defined the nonrigid image registration as a\nlocal adaptive kernel regression which locally reconstruct the moving image's\ndense deformation vectors from the sparse deformation vectors in the\nmulti-resolution block matching. The kernel function of the kernel regression\nadapts its shape and orientation to the reference image's structure to gather\nmore deformation vector samples of the same structure for the iterative\nregression computation, whereby the moving image's local deformations could be\ncompliant with the reference image's local structures. To estimate the local\ndeformations around the outliers, we use joint saliency map that highlights the\ncorresponding saliency structures (called Joint Saliency Structures, JSSs) in\nthe two images to guide the dense deformation reconstruction by emphasizing\nthose JSSs' sparse deformation vectors in the kernel regression. The\nexperimental results demonstrate that by using local JSS adaptive kernel\nregression, the proposed method achieves almost the best performance in\nalignment of all challenging image pairs with outlier structures compared with\nother five state-of-the-art nonrigid registration algorithms.\n",
        "published": "2013-02-03T14:14:27Z",
        "pdf_link": "http://arxiv.org/pdf/1302.0494v4"
    },
    {
        "id": "http://arxiv.org/abs/1302.0689v1",
        "title": "Multi-scale Visual Attention & Saliency Modelling with Decision Theory",
        "summary": "  Bottom-up saliency, an early human visual processing, behaves like binary\nclassification of interest and null hypothesis. Its discriminant power, mutual\ninformation of image features and class distribution, is closely related to\nsaliency value by the well-known centre-surround theory. As classification\naccuracy very much depends on window sizes, the discriminant saliency (power)\nvaries according to sampling scales. Discriminating power estimation in\nmulti-scales framework needs integrating with wavelet transformation and then\nestimating statistical discrepancy of two consecutive scales (centre-surround\nwindows) by Hidden Markov Tree (HMT) model. Finally, multi-scale discriminant\nsaliency (MDIS) maps are combined by the maximum information rule to synthesize\na final saliency map. All MDIS maps are evaluated with standard quantitative\ntools (NSS,LCC,AUC) on N.Bruce's database with ground truth data as\neye-tracking locations ; as well assessed qualitatively by visual examination\nof individual cases. For evaluating MDIS against well-known AIM saliency\nmethod, simulations are needed and described in details with several\ninteresting conclusions, drawn for further research directions.\n",
        "published": "2013-02-04T14:00:52Z",
        "pdf_link": "http://arxiv.org/pdf/1302.0689v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.1007v1",
        "title": "Image Denoising Using Interquartile Range Filter with Local Averaging",
        "summary": "  Image denoising is one of the fundamental problems in image processing. In\nthis paper, a novel approach to suppress noise from the image is conducted by\napplying the interquartile range (IQR) which is one of the statistical methods\nused to detect outlier effect from a dataset. A window of size kXk was\nimplemented to support IQR filter. Each pixel outside the IQR range of the kXk\nwindow is treated as noisy pixel. The estimation of the noisy pixels was\nobtained by local averaging. The essential advantage of applying IQR filter is\nto preserve edge sharpness better of the original image. A variety of test\nimages have been used to support the proposed filter and PSNR was calculated\nand compared with median filter. The experimental results on standard test\nimages demonstrate this filter is simpler and better performing than median\nfilter.\n",
        "published": "2013-02-05T12:02:53Z",
        "pdf_link": "http://arxiv.org/pdf/1302.1007v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.1294v1",
        "title": "Image Interpolation Using Kriging Technique for Spatial Data",
        "summary": "  Image interpolation has been used spaciously by customary interpolation\ntechniques. Recently, Kriging technique has been widely implemented in\nsimulation area and geostatistics for prediction. In this article, Kriging\ntechnique was used instead of the classical interpolation methods to predict\nthe unknown points in the digital image array. The efficiency of the proposed\ntechnique was proven using the PSNR and compared with the traditional\ninterpolation techniques. The results showed that Kriging technique is almost\naccurate as cubic interpolation and in some images Kriging has higher accuracy.\nA miscellaneous test images have been used to consolidate the proposed\ntechnique.\n",
        "published": "2013-02-06T09:22:58Z",
        "pdf_link": "http://arxiv.org/pdf/1302.1294v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.1296v1",
        "title": "Hybrid Image Segmentation using Discerner Cluster in FCM and Histogram\n  Thresholding",
        "summary": "  Image thresholding has played an important role in image segmentation. This\npaper presents a hybrid approach for image segmentation based on the\nthresholding by fuzzy c-means (THFCM) algorithm for image segmentation. The\ngoal of the proposed approach is to find a discerner cluster able to find an\nautomatic threshold. The algorithm is formulated by applying the standard FCM\nclustering algorithm to the frequencies (y-values) on the smoothed histogram.\nHence, the frequencies of an image can be used instead of the conventional\nwhole data of image. The cluster that has the highest peak which represents the\nmaximum frequency in the image histogram will play as an excellent role in\ndetermining a discerner cluster to the grey level image. Then, the pixels\nbelong to the discerner cluster represent an object in the gray level histogram\nwhile the other clusters represent a background. Experimental results with\nstandard test images have been obtained through the proposed approach (THFCM).\n",
        "published": "2013-02-06T09:31:59Z",
        "pdf_link": "http://arxiv.org/pdf/1302.1296v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.1300v1",
        "title": "Kriging Interpolation Filter to Reduce High Density Salt and Pepper\n  Noise",
        "summary": "  Image denoising is a critical issue in the field of digital image processing.\nThis paper proposes a novel Salt & Pepper noise suppression by developing a\nKriging Interpolation Filter (KIF) for image denoising. Gray-level images\ndegraded with Salt & Pepper noise have been considered. A sequential search for\nnoise detection was made using kXk window size to determine non-noisy pixels\nonly. The non-noisy pixels are passed into Kriging interpolation method to\npredict their absent neighbor pixels that were noisy pixels at the first phase.\nThe utilization of Kriging interpolation filter proves that it is very\nimpressive to suppress high noise density. It has been found that Kriging\nInterpolation filter achieves noise reduction without loss of edges and\ndetailed information. Comparisons with existing algorithms are done using\nquality metrics like PSNR and MSE to assess the proposed filter.\n",
        "published": "2013-02-06T09:45:18Z",
        "pdf_link": "http://arxiv.org/pdf/1302.1300v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.1690v1",
        "title": "A Fast Learning Algorithm for Image Segmentation with Max-Pooling\n  Convolutional Networks",
        "summary": "  We present a fast algorithm for training MaxPooling Convolutional Networks to\nsegment images. This type of network yields record-breaking performance in a\nvariety of tasks, but is normally trained on a computationally expensive\npatch-by-patch basis. Our new method processes each training image in a single\npass, which is vastly more efficient.\n  We validate the approach in different scenarios and report a 1500-fold\nspeed-up. In an application to automated steel defect detection and\nsegmentation, we obtain excellent performance with short training times.\n",
        "published": "2013-02-07T10:17:07Z",
        "pdf_link": "http://arxiv.org/pdf/1302.1690v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.2073v2",
        "title": "pROST : A Smoothed Lp-norm Robust Online Subspace Tracking Method for\n  Realtime Background Subtraction in Video",
        "summary": "  An increasing number of methods for background subtraction use Robust PCA to\nidentify sparse foreground objects. While many algorithms use the L1-norm as a\nconvex relaxation of the ideal sparsifying function, we approach the problem\nwith a smoothed Lp-norm and present pROST, a method for robust online subspace\ntracking. The algorithm is based on alternating minimization on manifolds.\nImplemented on a graphics processing unit it achieves realtime performance.\nExperimental results on a state-of-the-art benchmark for background subtraction\non real-world video data indicate that the method succeeds at a broad variety\nof background subtraction scenarios, and it outperforms competing approaches\nwhen video quality is deteriorated by camera jitter.\n",
        "published": "2013-02-08T16:14:14Z",
        "pdf_link": "http://arxiv.org/pdf/1302.2073v2"
    },
    {
        "id": "http://arxiv.org/abs/1302.3155v1",
        "title": "Morphological Analusis Of The Left Ventricular Eendocardial Surface\n  Using A Bag-Of-Features Descriptor",
        "summary": "  The limitations of conventional imaging techniques have hitherto precluded a\nthorough and formal investigation of the complex morphology of the left\nventricular (LV) endocardial surface and its relation to the severity of\nCoronary Artery Disease (CAD). Recent developments in high-resolution\nMultirow-Detector Computed Tomography (MDCT) scanner technology have enabled\nthe imaging of LV endocardial surface morphology in a single heart beat.\nAnalysis of high-resolution Computed Tomography (CT) images from a 320-MDCT\nscanner allows the study of the relationship between percent Diameter Stenosis\n(DS) of the major coronary arteries and localization of the cardiac segments\naffected by coronary arterial stenosis. In this paper a novel approach for the\nanalysis using a combination of rigid transformation-invariant shape\ndescriptors and a more generalized isometry-invariant Bag-of-Features (BoF)\ndescriptor, is proposed and implemented. The proposed approach is shown to be\nsuccessful in identifying, localizing and quantifying the incidence and extent\nof CAD and thus, is seen to have a potentially significant clinical impact.\nSpecifically, the association between the incidence and extent of CAD,\ndetermined via the percent DS measurements of the major coronary arteries, and\nthe alterations in the endocardial surface morphology is formally quantified. A\nmultivariate regression test performed on a strict leave-one-out basis are\nshown to exhibit a distinct pattern in terms of the correlation coefficient\nwithin the cardiac segments where the incidence of coronary arterial stenosis\nis localized.\n",
        "published": "2013-02-13T16:25:19Z",
        "pdf_link": "http://arxiv.org/pdf/1302.3155v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.3785v2",
        "title": "Analysis of Descent-Based Image Registration",
        "summary": "  We present a performance analysis for image registration with gradient\ndescent methods. We consider a typical multiscale registration setting where\nthe global 2-D translation between a pair of images is estimated by smoothing\nthe images and minimizing the distance between them with gradient descent. Our\nstudy particularly concentrates on the effect of noise and low-pass filtering\non the alignment accuracy. We adopt an analytic representation for images and\nanalyze the well-behavedness of the image distance function by estimating the\nneighborhood of translations for which it is free of undesired local minima.\nThis corresponds to the neighborhood of translation vectors that are correctly\ncomputable with a simple gradient descent minimization. We show that the area\nof this neighborhood increases at least quadratically with the smoothing filter\nsize, which justifies the use of a smoothing step in image registration with\nlocal optimizers such as gradient descent. We then examine the effect of noise\non the alignment accuracy and derive an upper bound for the alignment error in\nterms of the noise properties and filter size. Our main finding is that the\nerror increases at a rate that is at least linear with respect to the filter\nsize. Therefore, smoothing improves the well-behavedness of the distance\nfunction; however, this comes at the cost of amplifying the alignment error in\nnoisy settings. Our results provide a mathematical insight about why\nhierarchical techniques are effective in image registration, suggesting that\nthe multiscale coarse-to-fine alignment strategy of these techniques is very\nsuitable from the perspective of the trade-off between the well-behavedness of\nthe objective function and the registration accuracy. To the best of our\nknowledge, this is the first such study for descent-based image registration.\n",
        "published": "2013-02-15T15:45:32Z",
        "pdf_link": "http://arxiv.org/pdf/1302.3785v2"
    },
    {
        "id": "http://arxiv.org/abs/1302.3900v1",
        "title": "Robust Image Segmentation in Low Depth Of Field Images",
        "summary": "  In photography, low depth of field (DOF) is an important technique to\nemphasize the object of interest (OOI) within an image. Thus, low DOF images\nare widely used in the application area of macro, portrait or sports\nphotography. When viewing a low DOF image, the viewer implicitly concentrates\non the regions that are sharper regions of the image and thus segments the\nimage into regions of interest and non regions of interest which has a major\nimpact on the perception of the image. Thus, a robust algorithm for the fully\nautomatic detection of the OOI in low DOF images provides valuable information\nfor subsequent image processing and image retrieval. In this paper we propose a\nrobust and parameterless algorithm for the fully automatic segmentation of low\nDOF images. We compare our method with three similar methods and show the\nsuperior robustness even though our algorithm does not require any parameters\nto be set by hand. The experiments are conducted on a real world data set with\nhigh and low DOF images.\n",
        "published": "2013-02-15T21:49:26Z",
        "pdf_link": "http://arxiv.org/pdf/1302.3900v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.4043v1",
        "title": "A new scheme of signature extraction for iris authentication",
        "summary": "  Iris recognition, a relatively new biometric technology, has great\nadvantages, such as variability, stability and security, thus is the most\npromising for high security environment. Iris recognition is proposed in this\nreport. We describe some methods, the first one is based on grey level\nhistogram to extract the pupil, the second is based on elliptic and parabolic\nHOUGH transformation to determinate the edge of iris, upper and lower eyelids,\nthe third we used 2D Gabor Wavelets to encode the iris and finally we used the\nHamming distance for authentication.\n",
        "published": "2013-02-17T08:11:58Z",
        "pdf_link": "http://arxiv.org/pdf/1302.4043v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.4673v1",
        "title": "Good Recognition is Non-Metric",
        "summary": "  Recognition is the fundamental task of visual cognition, yet how to formalize\nthe general recognition problem for computer vision remains an open issue. The\nproblem is sometimes reduced to the simplest case of recognizing matching\npairs, often structured to allow for metric constraints. However, visual\nrecognition is broader than just pair matching -- especially when we consider\nmulti-class training data and large sets of features in a learning context.\nWhat we learn and how we learn it has important implications for effective\nalgorithms. In this paper, we reconsider the assumption of recognition as a\npair matching test, and introduce a new formal definition that captures the\nbroader context of the problem. Through a meta-analysis and an experimental\nassessment of the top algorithms on popular data sets, we gain a sense of how\noften metric properties are violated by good recognition algorithms. By\nstudying these violations, useful insights come to light: we make the case that\nlocally metric algorithms should leverage outside information to solve the\ngeneral recognition problem.\n",
        "published": "2013-02-19T17:02:34Z",
        "pdf_link": "http://arxiv.org/pdf/1302.4673v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.5189v1",
        "title": "Object Detection in Real Images",
        "summary": "  Object detection and recognition are important problems in computer vision.\nSince these problems are meta-heuristic, despite a lot of research, practically\nusable, intelligent, real-time, and dynamic object detection/recognition\nmethods are still unavailable. We propose a new object detection/recognition\nmethod, which improves over the existing methods in every stage of the object\ndetection/recognition process. In addition to the usual features, we propose to\nuse geometric shapes, like linear cues, ellipses and quadrangles, as additional\nfeatures. The full potential of geometric cues is exploited by using them to\nextract other features in a robust, computationally efficient, and less\nmeta-heuristic manner. We also propose a new hierarchical codebook, which\nprovides good generalization and discriminative properties. The codebook\nenables fast multi-path inference mechanisms based on propagation of\nconditional likelihoods, that make it robust to occlusion and noise. It has the\ncapability of dynamic learning. We also propose a new learning method that has\ngenerative and discriminative learning capabilities, does not need large and\nfully supervised training dataset, and is capable of online learning. The\npreliminary work of detecting geometric shapes in real images has been\ncompleted. This preliminary work is the focus of this report. Future path for\nrealizing the proposed object detection/recognition method is also discussed in\nbrief.\n",
        "published": "2013-02-21T06:06:47Z",
        "pdf_link": "http://arxiv.org/pdf/1302.5189v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.5894v1",
        "title": "Four Side Distance: A New Fourier Shape Signature",
        "summary": "  Shape is one of the main features in content based image retrieval (CBIR).\nThis paper proposes a new shape signature. In this technique, features of each\nshape are extracted based on four sides of the rectangle that covers the shape.\nThe proposed technique is Fourier based and it is invariant to translation,\nscaling and rotation. The retrieval performance between some commonly used\nFourier based signatures and the proposed four sides distance (FSD) signature\nhas been tested using MPEG-7 database. Experimental results are shown that the\nFSD signature has better performance compared with those signatures.\n",
        "published": "2013-02-24T10:49:39Z",
        "pdf_link": "http://arxiv.org/pdf/1302.5894v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.5957v1",
        "title": "Shape Characterization via Boundary Distortion",
        "summary": "  In this paper, we derive new shape descriptors based on a directional\ncharacterization. The main idea is to study the behavior of the shape\nneighborhood under family of transformations. We obtain a description invariant\nwith respect to rotation, reflection, translation and scaling. A well-defined\nmetric is then proposed on the associated feature space. We show the continuity\nof this metric. Some results on shape retrieval are provided on two databases\nto show the accuracy of the proposed shape metric.\n",
        "published": "2013-02-24T21:38:20Z",
        "pdf_link": "http://arxiv.org/pdf/1302.5957v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.5985v1",
        "title": "A Meta-Theory of Boundary Detection Benchmarks",
        "summary": "  Human labeled datasets, along with their corresponding evaluation algorithms,\nplay an important role in boundary detection. We here present a psychophysical\nexperiment that addresses the reliability of such benchmarks. To find better\nremedies to evaluate the performance of any boundary detection algorithm, we\npropose a computational framework to remove inappropriate human labels and\nestimate the intrinsic properties of boundaries.\n",
        "published": "2013-02-25T03:12:12Z",
        "pdf_link": "http://arxiv.org/pdf/1302.5985v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.6379v1",
        "title": "Image-based Face Detection and Recognition: \"State of the Art\"",
        "summary": "  Face recognition from image or video is a popular topic in biometrics\nresearch. Many public places usually have surveillance cameras for video\ncapture and these cameras have their significant value for security purpose. It\nis widely acknowledged that the face recognition have played an important role\nin surveillance system as it doesn't need the object's cooperation. The actual\nadvantages of face based identification over other biometrics are uniqueness\nand acceptance. As human face is a dynamic object having high degree of\nvariability in its appearance, that makes face detection a difficult problem in\ncomputer vision. In this field, accuracy and speed of identification is a main\nissue.\n  The goal of this paper is to evaluate various face detection and recognition\nmethods, provide complete solution for image based face detection and\nrecognition with higher accuracy, better response rate as an initial step for\nvideo surveillance. Solution is proposed based on performed tests on various\nface rich databases in terms of subjects, pose, emotions, race and light.\n",
        "published": "2013-02-26T10:12:30Z",
        "pdf_link": "http://arxiv.org/pdf/1302.6379v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.6957v1",
        "title": "Ensemble Sparse Models for Image Analysis",
        "summary": "  Sparse representations with learned dictionaries have been successful in\nseveral image analysis applications. In this paper, we propose and analyze the\nframework of ensemble sparse models, and demonstrate their utility in image\nrestoration and unsupervised clustering. The proposed ensemble model\napproximates the data as a linear combination of approximations from multiple\n\\textit{weak} sparse models. Theoretical analysis of the ensemble model reveals\nthat even in the worst-case, the ensemble can perform better than any of its\nconstituent individual models. The dictionaries corresponding to the individual\nsparse models are obtained using either random example selection or boosted\napproaches. Boosted approaches learn one dictionary per round such that the\ndictionary learned in a particular round is optimized for the training examples\nhaving high reconstruction error in the previous round. Results with compressed\nrecovery show that the ensemble representations lead to a better performance\ncompared to using a single dictionary obtained with the conventional\nalternating minimization approach. The proposed ensemble models are also used\nfor single image superresolution, and we show that they perform comparably to\nthe recent approaches. In unsupervised clustering, experiments show that the\nproposed model performs better than baseline approaches in several standard\ndatasets.\n",
        "published": "2013-02-27T18:58:36Z",
        "pdf_link": "http://arxiv.org/pdf/1302.6957v1"
    },
    {
        "id": "http://arxiv.org/abs/1302.7180v1",
        "title": "Fast Matching by 2 Lines of Code for Large Scale Face Recognition\n  Systems",
        "summary": "  In this paper, we propose a method to apply the popular cascade classifier\ninto face recognition to improve the computational efficiency while keeping\nhigh recognition rate. In large scale face recognition systems, because the\nprobability of feature templates coming from different subjects is very high,\nmost of the matching pairs will be rejected by the early stages of the cascade.\nTherefore, the cascade can improve the matching speed significantly. On the\nother hand, using the nested structure of the cascade, we could drop some\nstages at the end of feature to reduce the memory and bandwidth usage in some\nresources intensive system while not sacrificing the performance too much. The\ncascade is learned by two steps. Firstly, some kind of prepared features are\ngrouped into several nested stages. And then, the threshold of each stage is\nlearned to achieve user defined verification rate (VR). In the paper, we take a\nlandmark based Gabor+LDA face recognition system as baseline to illustrate the\nprocess and advantages of the proposed method. However, the use of this method\nis very generic and not limited in face recognition, which can be easily\ngeneralized to other biometrics as a post-processing module. Experiments on the\nFERET database show the good performance of our baseline and an experiment on a\nself-collected large scale database illustrates that the cascade can improve\nthe matching speed significantly.\n",
        "published": "2013-02-28T12:59:41Z",
        "pdf_link": "http://arxiv.org/pdf/1302.7180v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.0479v2",
        "title": "Scale Selection of Adaptive Kernel Regression by Joint Saliency Map for\n  Nonrigid Image Registration",
        "summary": "  Joint saliency map (JSM) [1] was developed to assign high joint saliency\nvalues to the corresponding saliency structures (called Joint Saliency\nStructures, JSSs) but zero or low joint saliency values to the outliers (or\nmismatches) that are introduced by missing correspondence or local large\ndeformations between the reference and moving images to be registered. JSM\nguides the local structure matching in nonrigid registration by emphasizing\nthese JSSs' sparse deformation vectors in adaptive kernel regression of\nhierarchical sparse deformation vectors for iterative dense deformation\nreconstruction. By designing an effective superpixel-based local structure\nscale estimator to compute the reference structure's structure scale, we\nfurther propose to determine the scale (the width) of kernels in the adaptive\nkernel regression through combining the structure scales to JSM-based scales of\nmismatch between the local saliency structures. Therefore, we can adaptively\nselect the sample size of sparse deformation vectors to reconstruct the dense\ndeformation vectors for accurately matching the every local structures in the\ntwo images. The experimental results demonstrate better accuracy of our method\nin aligning two images with missing correspondence and local large deformation\nthan the state-of-the-art methods.\n",
        "published": "2013-03-03T09:15:25Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0479v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.0582v2",
        "title": "Multiple Kernel Sparse Representations for Supervised and Unsupervised\n  Learning",
        "summary": "  In complex visual recognition tasks it is typical to adopt multiple\ndescriptors, that describe different aspects of the images, for obtaining an\nimproved recognition performance. Descriptors that have diverse forms can be\nfused into a unified feature space in a principled manner using kernel methods.\nSparse models that generalize well to the test data can be learned in the\nunified kernel space, and appropriate constraints can be incorporated for\napplication in supervised and unsupervised learning. In this paper, we propose\nto perform sparse coding and dictionary learning in the multiple kernel space,\nwhere the weights of the ensemble kernel are tuned based on graph-embedding\nprinciples such that class discrimination is maximized. In our proposed\nalgorithm, dictionaries are inferred using multiple levels of 1-D subspace\nclustering in the kernel space, and the sparse codes are obtained using a\nsimple levelwise pursuit scheme. Empirical results for object recognition and\nimage clustering show that our algorithm outperforms existing sparse coding\nbased approaches, and compares favorably to other state-of-the-art methods.\n",
        "published": "2013-03-03T23:41:34Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0582v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.0633v1",
        "title": "Omega Model for Human Detection and Counting for application in Smart\n  Surveillance System",
        "summary": "  Driven by the significant advancements in technology and social issues such\nas security management, there is a strong need for Smart Surveillance System in\nour society today. One of the key features of a Smart Surveillance System is\nefficient human detection and counting such that the system can decide and\nlabel events on its own. In this paper we propose a new, novel and robust\nmodel, The Omega Model, for detecting and counting human beings present in the\nscene. The proposed model employs a set of four distinct descriptors for\nidentifying the unique features of the head, neck and shoulder regions of a\nperson. This unique head neck shoulder signature given by the Omega Model\nexploits the challenges such as inter person variations in size and shape of\npeoples head, neck and shoulder regions to achieve robust detection of human\nbeings even under partial occlusion, dynamically changing background and\nvarying illumination conditions. After experimentation we observe and analyze\nthe influences of each of the four descriptors on the system performance and\ncomputation speed and conclude that a weight based decision making system\nproduces the best results. Evaluation results on a number of images indicate\nthe validation of our method in actual situation.\n",
        "published": "2013-03-04T08:01:36Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0633v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.0634v1",
        "title": "Indian Sign Language Recognition Using Eigen Value Weighted Euclidean\n  Distance Based Classification Technique",
        "summary": "  Sign Language Recognition is one of the most growing fields of research\ntoday. Many new techniques have been developed recently in these fields. Here\nin this paper, we have proposed a system using Eigen value weighted Euclidean\ndistance as a classification technique for recognition of various Sign\nLanguages of India. The system comprises of four parts: Skin Filtering, Hand\nCropping, Feature Extraction and Classification. Twenty four signs were\nconsidered in this paper, each having ten samples, thus a total of two hundred\nforty images was considered for which recognition rate obtained was 97 percent.\n",
        "published": "2013-03-04T08:06:07Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0634v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.0635v1",
        "title": "Recognition of Facial Expression Using Eigenvector Based Distributed\n  Features and Euclidean Distance Based Decision Making Technique",
        "summary": "  In this paper, an Eigenvector based system has been presented to recognize\nfacial expressions from digital facial images. In the approach, firstly the\nimages were acquired and cropping of five significant portions from the image\nwas performed to extract and store the Eigenvectors specific to the\nexpressions. The Eigenvectors for the test images were also computed, and\nfinally the input facial image was recognized when similarity was obtained by\ncalculating the minimum Euclidean distance between the test image and the\ndifferent expressions.\n",
        "published": "2013-03-04T08:09:22Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0635v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.0644v1",
        "title": "Automatic symmetry based cluster approach for anomalous brain\n  identification in PET scan image : An Analysis",
        "summary": "  Medical image segmentation is referred to the segmentation of known anatomic\nstructures from different medical images. Normally, the medical data researches\nare more complicated and an exclusive structures. This computer aided diagnosis\nis used for assisting doctors in evaluating medical imagery or in recognizing\nabnormal findings in a medical image. To integrate the specialized knowledge\nfor medical data processing is helpful to form a real useful healthcare\ndecision making system. This paper studies the different symmetry based\ndistances applied in clustering algorithms and analyzes symmetry approach for\nPositron Emission Tomography (PET) scan image segmentation. Unlike CT and MRI,\nthe PET scan identifies the structure of blood flow to and from organs. PET\nscan also helps in early diagnosis of cancer and heart, brain and gastro\nintestinal ailments and to detect the progress of treatment. In this paper, the\nscope diagnostic task expands for PET image in various brain functions.\n",
        "published": "2013-03-04T08:52:45Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0644v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.0645v1",
        "title": "Symmetry Based Cluster Approach for Automatic Recognition of the\n  Epileptic Focus in Brain Using PET Scan Image : An Analysis",
        "summary": "  Recognition of epileptic focal point is the important diagnosis when\nscreening the epilepsy patients for latent surgical cures. The accurate\nlocalization is challenging one because of the low spatial resolution images\nwith more noisy data. Positron Emission Tomography (PET) has now replaced the\nissues and caring a high resolution. This paper focuses the research of\nautomated localization of epileptic seizures in brain functional images using\nsymmetry based cluster approach. This approach presents a fully automated\nsymmetry based brain abnormality detection method for PET sequences. PET images\nare spatially normalized to Digital Imaging and Communications in Medicine\n(DICOM) standard and then it has been trained using symmetry based cluster\napproach using Medical Image Processing, Analysis & Visualization (MIPAV) tool.\nThe performance evolution is considered by the metric like accuracy of\ndiagnosis. The obtained result is surely assists the surgeon for the automated\nidentification of seizures focus.\n",
        "published": "2013-03-04T09:00:23Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0645v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.0647v1",
        "title": "Spatial Fuzzy C Means PET Image Segmentation of Neurodegenerative\n  Disorder",
        "summary": "  Nuclear image has emerged as a promising research work in medical field.\nImages from different modality meet its own challenge. Positron Emission\nTomography (PET) image may help to precisely localize disease to assist in\nplanning the right treatment for each case and saving valuable time. In this\npaper, a novel approach of Spatial Fuzzy C Means (PET SFCM) clustering\nalgorithm is introduced on PET scan image datasets. The proposed algorithm is\nincorporated the spatial neighborhood information with traditional FCM and\nupdating the objective function of each cluster. This algorithm is implemented\nand tested on huge data collection of patients with brain neuro degenerative\ndisorder such as Alzheimers disease. It has demonstrated its effectiveness by\ntesting it for real world patient data sets. Experimental results are compared\nwith conventional FCM and K Means clustering algorithm. The performance of the\nPET SFCM provides satisfactory results compared with other two algorithms\n",
        "published": "2013-03-04T09:08:34Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0647v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.0964v1",
        "title": "GBM Volumetry using the 3D Slicer Medical Image Computing Platform",
        "summary": "  Volumetric change in glioblastoma multiforme (GBM) over time is a critical\nfactor in treatment decisions. Typically, the tumor volume is computed on a\nslice-by-slice basis using MRI scans obtained at regular intervals. (3D)Slicer\n- a free platform for biomedical research - provides an alternative to this\nmanual slice-by-slice segmentation process, which is significantly faster and\nrequires less user interaction. In this study, 4 physicians segmented GBMs in\n10 patients, once using the competitive region-growing based GrowCut\nsegmentation module of Slicer, and once purely by drawing boundaries completely\nmanually on a slice-by-slice basis. Furthermore, we provide a variability\nanalysis for three physicians for 12 GBMs. The time required for GrowCut\nsegmentation was on an average 61% of the time required for a pure manual\nsegmentation. A comparison of Slicer-based segmentation with manual\nslice-by-slice segmentation resulted in a Dice Similarity Coefficient of 88.43\n+/- 5.23% and a Hausdorff Distance of 2.32 +/- 5.23 mm.\n",
        "published": "2013-03-05T09:40:46Z",
        "pdf_link": "http://arxiv.org/pdf/1303.0964v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.1624v1",
        "title": "On Robust Face Recognition via Sparse Encoding: the Good, the Bad, and\n  the Ugly",
        "summary": "  In the field of face recognition, Sparse Representation (SR) has received\nconsiderable attention during the past few years. Most of the relevant\nliterature focuses on holistic descriptors in closed-set identification\napplications. The underlying assumption in SR-based methods is that each class\nin the gallery has sufficient samples and the query lies on the subspace\nspanned by the gallery of the same class. Unfortunately, such assumption is\neasily violated in the more challenging face verification scenario, where an\nalgorithm is required to determine if two faces (where one or both have not\nbeen seen before) belong to the same person. In this paper, we first discuss\nwhy previous attempts with SR might not be applicable to verification problems.\nWe then propose an alternative approach to face verification via SR.\nSpecifically, we propose to use explicit SR encoding on local image patches\nrather than the entire face. The obtained sparse signals are pooled via\naveraging to form multiple region descriptors, which are then concatenated to\nform an overall face descriptor. Due to the deliberate loss spatial relations\nwithin each region (caused by averaging), the resulting descriptor is robust to\nmisalignment & various image deformations. Within the proposed framework, we\nevaluate several SR encoding techniques: l1-minimisation, Sparse Autoencoder\nNeural Network (SANN), and an implicit probabilistic technique based on\nGaussian Mixture Models. Thorough experiments on AR, FERET, exYaleB, BANCA and\nChokePoint datasets show that the proposed local SR approach obtains\nconsiderably better and more robust performance than several previous\nstate-of-the-art holistic SR methods, in both verification and closed-set\nidentification problems. The experiments also show that l1-minimisation based\nencoding has a considerably higher computational than the other techniques, but\nleads to higher recognition rates.\n",
        "published": "2013-03-07T09:30:10Z",
        "pdf_link": "http://arxiv.org/pdf/1303.1624v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.1667v1",
        "title": "ALPRS - A New Approach for License Plate Recognition using the Sift\n  Algorithm",
        "summary": "  This paper presents a new approach for the automatic license plate\nrecognition, which includes the SIFT algorithm in step to locate the plate in\nthe input image. In this new approach, besides the comparison of the features\nobtained with the SIFT algorithm, the correspondence between the spatial\norientations and the positioning associated with the keypoints is also\nobserved. Afterwards, an algorithm is used for the character recognition of the\nplates, very fast, which makes it possible its application in real time. The\nresults obtained with the proposed approach presented very good success rates,\nso much for locating the characters in the input image, as for their\nrecognition.\n",
        "published": "2013-03-07T12:49:49Z",
        "pdf_link": "http://arxiv.org/pdf/1303.1667v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.1749v2",
        "title": "Simplifying Energy Optimization using Partial Enumeration",
        "summary": "  Energies with high-order non-submodular interactions have been shown to be\nvery useful in vision due to their high modeling power. Optimization of such\nenergies, however, is generally NP-hard. A naive approach that works for small\nproblem instances is exhaustive search, that is, enumeration of all possible\nlabelings of the underlying graph. We propose a general minimization approach\nfor large graphs based on enumeration of labelings of certain small patches.\nThis partial enumeration technique reduces complex high-order energy\nformulations to pairwise Constraint Satisfaction Problems with unary costs\n(uCSP), which can be efficiently solved using standard methods like TRW-S. Our\napproach outperforms a number of existing state-of-the-art algorithms on well\nknown difficult problems (e.g. curvature regularization, stereo,\ndeconvolution); it gives near global minimum and better speed.\n  Our main application of interest is curvature regularization. In the context\nof segmentation, our partial enumeration technique allows to evaluate curvature\ndirectly on small patches using a novel integral geometry approach.\n",
        "published": "2013-03-07T16:59:11Z",
        "pdf_link": "http://arxiv.org/pdf/1303.1749v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.1761v1",
        "title": "Improving Automatic Emotion Recognition from speech using Rhythm and\n  Temporal feature",
        "summary": "  This paper is devoted to improve automatic emotion recognition from speech by\nincorporating rhythm and temporal features. Research on automatic emotion\nrecognition so far has mostly been based on applying features like MFCCs, pitch\nand energy or intensity. The idea focuses on borrowing rhythm features from\nlinguistic and phonetic analysis and applying them to the speech signal on the\nbasis of acoustic knowledge only. In addition to this we exploit a set of\ntemporal and loudness features. A segmentation unit is employed in starting to\nseparate the voiced/unvoiced and silence parts and features are explored on\ndifferent segments. Thereafter different classifiers are used for\nclassification. After selecting the top features using an IGR filter we are\nable to achieve a recognition rate of 80.60 % on the Berlin Emotion Database\nfor the speaker dependent framework.\n",
        "published": "2013-03-07T17:33:06Z",
        "pdf_link": "http://arxiv.org/pdf/1303.1761v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.1829v1",
        "title": "Watersheds on edge or node weighted graphs \"par l'exemple\"",
        "summary": "  Watersheds have been defined both for node and edge weighted graphs. We show\nthat they are identical: for each edge (resp.\\ node) weighted graph exists a\nnode (resp. edge) weighted graph with the same minima and catchment basin.\n",
        "published": "2013-03-07T21:15:29Z",
        "pdf_link": "http://arxiv.org/pdf/1303.1829v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.2437v1",
        "title": "Least-Squares FIR Models of Low-Resolution MR data for Efficient\n  Phase-Error Compensation with Simultaneous Artefact Removal",
        "summary": "  Signal space models in both phase-encode, and frequency-encode directions are\npresented for extrapolation of 2D partial kspace. Using the boxcar\nrepresentation of low-resolution spatial data, and a geometrical representation\nof signal space vectors in both positive and negative phase-encode directions,\na robust predictor is constructed using a series of signal space projections.\nCompared to some of the existing phase-correction methods that require\nacquisition of a pre-determined set of fractional kspace lines, the proposed\npredictor is found to be more efficient, due to its capability of exhibiting an\nequivalent degree of performance using only half the number of fractional\nlines. Robust filtering of noisy data is achieved using a second signal space\nmodel in the frequency-encode direction, bypassing the requirement of a prior\nhighpass filtering operation. The signal space is constructed from Fourier\nTransformed samples of each row in the low-resolution image. A set of FIR\nfilters are estimated by fitting a least squares model to this signal space.\nPartial kspace extrapolation using the FIR filters is shown to result in\nartifact-free reconstruction, particularly in respect of Gibbs ringing and\nstreaking type artifacts.\n",
        "published": "2013-03-11T06:40:02Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2437v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.2439v1",
        "title": "Voxel-wise Weighted MR Image Enhancement using an Extended Neighborhood\n  Filter",
        "summary": "  We present an edge preserving and denoising filter for enhancing the features\nin images, which contain an ROI having a narrow spatial extent. Typical\nexamples include angiograms, or ROI spatially distributed in multiple locations\nand contained within an outlying region, such as in multiple-sclerosis. The\nfiltering involves determination of multiplicative weights in the spatial\ndomain using an extended set of neighborhood directions. Equivalently, the\nfiltering operation may be interpreted as a combination of directional filters\nin the frequency domain, with selective weighting for spatial frequencies\ncontained within each direction. The advantages of the proposed filter in\ncomparison to specialized non-linear filters, which operate on diffusion\nprinciple, are illustrated using numerical phantom data. The performance\nevaluation is carried out on simulated images from BrainWeb database for\nmultiple-sclerosis, acute ischemic stroke using clinically acquired FLAIR\nimages and MR angiograms.\n",
        "published": "2013-03-11T06:54:26Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2439v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.2465v1",
        "title": "A Low-Complexity Algorithm for Static Background Estimation from\n  Cluttered Image Sequences in Surveillance Contexts",
        "summary": "  For the purposes of foreground estimation, the true background model is\nunavailable in many practical circumstances and needs to be estimated from\ncluttered image sequences. We propose a sequential technique for static\nbackground estimation in such conditions, with low computational and memory\nrequirements. Image sequences are analysed on a block-by-block basis. For each\nblock location a representative set is maintained which contains distinct\nblocks obtained along its temporal line. The background estimation is carried\nout in a Markov Random Field framework, where the optimal labelling solution is\ncomputed using iterated conditional modes. The clique potentials are computed\nbased on the combined frequency response of the candidate block and its\nneighbourhood. It is assumed that the most appropriate block results in the\nsmoothest response, indirectly enforcing the spatial continuity of structures\nwithin a scene. Experiments on real-life surveillance videos demonstrate that\nthe proposed method obtains considerably better background estimates (both\nqualitatively and quantitatively) than median filtering and the recently\nproposed \"intervals of stable intensity\" method. Further experiments on the\nWallflower dataset suggest that the combination of the proposed method with a\nforeground segmentation algorithm results in improved foreground segmentation.\n",
        "published": "2013-03-11T09:57:49Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2465v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.2607v2",
        "title": "Joint optimization of fitting & matching in multi-view reconstruction",
        "summary": "  Many standard approaches for geometric model fitting are based on pre-matched\nimage features. Typically, such pre-matching uses only feature appearances\n(e.g. SIFT) and a large number of non-unique features must be discarded in\norder to control the false positive rate. In contrast, we solve feature\nmatching and multi-model fitting problems in a joint optimization framework.\nThis paper proposes several fit-&-match energy formulations based on a\ngeneralization of the assignment problem. We developed an efficient solver\nbased on min-cost-max-flow algorithm that finds near optimal solutions. Our\napproach significantly increases the number of detected matches. In practice,\nenergy-based joint fitting & matching allows to increase the distance between\nview-points previously restricted by robustness of local SIFT-matching and to\nimprove the model fitting accuracy when compared to state-of-the-art\nmulti-model fitting techniques.\n",
        "published": "2013-03-11T18:14:42Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2607v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.2610v1",
        "title": "Kernel Sparse Models for Automated Tumor Segmentation",
        "summary": "  In this paper, we propose sparse coding-based approaches for segmentation of\ntumor regions from MR images. Sparse coding with data-adapted dictionaries has\nbeen successfully employed in several image recovery and vision problems. The\nproposed approaches obtain sparse codes for each pixel in brain magnetic\nresonance images considering their intensity values and location information.\nSince it is trivial to obtain pixel-wise sparse codes, and combining multiple\nfeatures in the sparse coding setup is not straightforward, we propose to\nperform sparse coding in a high-dimensional feature space where non-linear\nsimilarities can be effectively modeled. We use the training data from\nexpert-segmented images to obtain kernel dictionaries with the kernel K-lines\nclustering procedure. For a test image, sparse codes are computed with these\nkernel dictionaries, and they are used to identify the tumor regions. This\napproach is completely automated, and does not require user intervention to\ninitialize the tumor regions in a test image. Furthermore, a low complexity\nsegmentation approach based on kernel sparse codes, which allows the user to\ninitialize the tumor region, is also presented. Results obtained with both the\nproposed approaches are validated against manual segmentation by an expert\nradiologist, and the proposed methods lead to accurate tumor identification.\n",
        "published": "2013-03-11T18:33:01Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2610v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.2685v1",
        "title": "Bilateral Filter: Graph Spectral Interpretation and Extensions",
        "summary": "  In this paper we study the bilateral filter proposed by Tomasi and Manduchi,\nas a spectral domain transform defined on a weighted graph. The nodes of this\ngraph represent the pixels in the image and a graph signal defined on the nodes\nrepresents the intensity values. Edge weights in the graph correspond to the\nbilateral filter coefficients and hence are data adaptive. Spectrum of a graph\nis defined in terms of the eigenvalues and eigenvectors of the graph Laplacian\nmatrix. We use this spectral interpretation to generalize the bilateral filter\nand propose more flexible and application specific spectral designs of\nbilateral-like filters. We show that these spectral filters can be implemented\nwith k-iterative bilateral filtering operations and do not require expensive\ndiagonalization of the Laplacian matrix.\n",
        "published": "2013-03-11T20:52:57Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2685v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.2751v1",
        "title": "Gaussian Mixture Model for Handwritten Script Identification",
        "summary": "  This paper presents a Gaussian Mixture Model (GMM) to identify the script of\nhandwritten words of Roman, Devanagari, Kannada and Telugu scripts. It\nemphasizes the significance of directional energies for identification of\nscript of the word. It is robust to varied image sizes and different styles of\nwriting. A GMM is modeled using a set of six novel features derived from\ndirectional energy distributions of the underlying image. The standard\ndeviation of directional energy distributions are computed by decomposing an\nimage matrix into right and left diagonals. Furthermore, deviation of\nhorizontal and vertical distributions of energies is also built-in to GMM. A\ndataset of 400 images out of 800 (200 of each script) are used for training GMM\nand the remaining is for testing. An exhaustive experimentation is carried out\nat bi-script, tri-script and multi-script level and achieved script\nidentification accuracies in percentage as 98.7, 98.16 and 96.91 respectively.\n",
        "published": "2013-03-12T02:32:02Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2751v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.2783v1",
        "title": "Combined Learning of Salient Local Descriptors and Distance Metrics for\n  Image Set Face Verification",
        "summary": "  In contrast to comparing faces via single exemplars, matching sets of face\nimages increases robustness and discrimination performance. Recent image set\nmatching approaches typically measure similarities between subspaces or\nmanifolds, while representing faces in a rigid and holistic manner. Such\nrepresentations are easily affected by variations in terms of alignment,\nillumination, pose and expression. While local feature based representations\nare considerably more robust to such variations, they have received little\nattention within the image set matching area. We propose a novel image set\nmatching technique, comprised of three aspects: (i) robust descriptors of face\nregions based on local features, partly inspired by the hierarchy in the human\nvisual system, (ii) use of several subspace and exemplar metrics to compare\ncorresponding face regions, (iii) jointly learning which regions are the most\ndiscriminative while finding the optimal mixing weights for combining metrics.\nFace recognition experiments on LFW, PIE and MOBIO face datasets show that the\nproposed algorithm obtains considerably better performance than several recent\nstate-of-the-art techniques, such as Local Principal Angle and the Kernel\nAffine Hull Method.\n",
        "published": "2013-03-12T06:12:59Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2783v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.2844v1",
        "title": "A Stochastic Grammar for Natural Shapes",
        "summary": "  We consider object detection using a generic model for natural shapes. A\ncommon approach for object recognition involves matching object models directly\nto images. Another approach involves building intermediate representations via\na generic grouping processes. We argue that these two processes (model-based\nrecognition and grouping) may use similar computational mechanisms. By defining\na generic model for shapes we can use model-based techniques to implement a\nmid-level vision grouping process.\n",
        "published": "2013-03-12T11:23:47Z",
        "pdf_link": "http://arxiv.org/pdf/1303.2844v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.3087v1",
        "title": "Statistical Texture Features based Handwritten and Printed Text\n  Classification in South Indian Documents",
        "summary": "  In this paper, we use statistical texture features for handwritten and\nprinted text classification. We primarily aim for word level classification in\nsouth Indian scripts. Words are first extracted from the scanned document. For\neach extracted word, statistical texture features are computed such as mean,\nstandard deviation, smoothness, moment, uniformity, entropy and local range\nincluding local entropy. These feature vectors are then used to classify words\nvia k-NN classifier. We have validated the approach over several different\ndatasets. Scripts like Kannada, Telugu, Malayalam and Hindi i.e., Devanagari\nare primarily employed where an average classification rate of 99.26% is\nachieved. In addition, to provide an extensibility of the approach, we address\nRoman script by using publicly available dataset and interesting results are\nreported.\n",
        "published": "2013-03-13T04:51:22Z",
        "pdf_link": "http://arxiv.org/pdf/1303.3087v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.3152v1",
        "title": "Material quality assessment of silk nanofibers based on swarm\n  intelligence",
        "summary": "  In this paper, we propose a novel approach for texture analysis based on\nartificial crawler model. Our method assumes that each agent can interact with\nthe environment and each other. The evolution process converges to an\nequilibrium state according to the set of rules. For each textured image, the\nfeature vector is composed by signatures of the live agents curve at each time.\nExperimental results revealed that combining the minimum and maximum signatures\ninto one increase the classification rate. In addition, we pioneer the use of\nautonomous agents for characterizing silk fibroin scaffolds. The results\nstrongly suggest that our approach can be successfully employed for texture\nanalysis.\n",
        "published": "2013-03-13T13:23:21Z",
        "pdf_link": "http://arxiv.org/pdf/1303.3152v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.4160v1",
        "title": "Improved Foreground Detection via Block-based Classifier Cascade with\n  Probabilistic Decision Integration",
        "summary": "  Background subtraction is a fundamental low-level processing task in numerous\ncomputer vision applications. The vast majority of algorithms process images on\na pixel-by-pixel basis, where an independent decision is made for each pixel. A\ngeneral limitation of such processing is that rich contextual information is\nnot taken into account. We propose a block-based method capable of dealing with\nnoise, illumination variations and dynamic backgrounds, while still obtaining\nsmooth contours of foreground objects. Specifically, image sequences are\nanalysed on an overlapping block-by-block basis. A low-dimensional texture\ndescriptor obtained from each block is passed through an adaptive classifier\ncascade, where each stage handles a distinct problem. A probabilistic\nforeground mask generation approach then exploits block overlaps to integrate\ninterim block-level decisions into final pixel-level foreground segmentation.\nUnlike many pixel-based methods, ad-hoc post-processing of foreground masks is\nnot required. Experiments on the difficult Wallflower and I2R datasets show\nthat the proposed approach obtains on average better results (both\nqualitatively and quantitatively) than several prominent methods. We\nfurthermore propose the use of tracking performance as an unbiased approach for\nassessing the practical usefulness of foreground segmentation methods, and show\nthat the proposed approach leads to considerable improvements in tracking\naccuracy on the CAVIAR dataset.\n",
        "published": "2013-03-18T05:48:40Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4160v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.4614v1",
        "title": "Handwritten and Printed Text Separation in Real Document",
        "summary": "  The aim of the paper is to separate handwritten and printed text from a real\ndocument embedded with noise, graphics including annotations. Relying on\nrun-length smoothing algorithm (RLSA), the extracted pseudo-lines and\npseudo-words are used as basic blocks for classification. To handle this, a\nmulti-class support vector machine (SVM) with Gaussian kernel performs a first\nlabelling of each pseudo-word including the study of local neighbourhood. It\nthen propagates the context between neighbours so that we can correct possible\nlabelling errors. Considering running time complexity issue, we propose linear\ncomplexity methods where we use k-NN with constraint. When using a kd-tree, it\nis almost linearly proportional to the number of pseudo-words. The performance\nof our system is close to 90%, even when very small learning dataset where\nsamples are basically composed of complex administrative documents.\n",
        "published": "2013-03-19T14:23:24Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4614v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.4803v1",
        "title": "A Survey of Appearance Models in Visual Object Tracking",
        "summary": "  Visual object tracking is a significant computer vision task which can be\napplied to many domains such as visual surveillance, human computer\ninteraction, and video compression. In the literature, researchers have\nproposed a variety of 2D appearance models. To help readers swiftly learn the\nrecent advances in 2D appearance models for visual object tracking, we\ncontribute this survey, which provides a detailed review of the existing 2D\nappearance models. In particular, this survey takes a module-based architecture\nthat enables readers to easily grasp the key points of visual object tracking.\nIn this survey, we first decompose the problem of appearance modeling into two\ndifferent processing stages: visual representation and statistical modeling.\nThen, different 2D appearance models are categorized and discussed with respect\nto their composition modules. Finally, we address several issues of interest as\nwell as the remaining challenges for future research on this topic. The\ncontributions of this survey are four-fold. First, we review the literature of\nvisual representations according to their feature-construction mechanisms\n(i.e., local and global). Second, the existing statistical modeling schemes for\ntracking-by-detection are reviewed according to their model-construction\nmechanisms: generative, discriminative, and hybrid generative-discriminative.\nThird, each type of visual representations or statistical modeling techniques\nis analyzed and discussed from a theoretical or practical viewpoint. Fourth,\nthe existing benchmark resources (e.g., source code and video datasets) are\nexamined in this survey.\n",
        "published": "2013-03-20T01:08:33Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4803v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.4839v1",
        "title": "The State of the Art Recognize in Arabic Script through Combination of\n  Online and Offline",
        "summary": "  Handwriting recognition refers to the identification of written characters.\nHandwriting recognition has become an acute research area in recent years for\nthe ease of access of computer science. In this paper primarily discussed\nOn-line and Off-line handwriting recognition methods for Arabic words which are\noften used among then across the Middle East and North Africa People. Arabic\nword online handwriting recognition is a very challenging task due to its\ncursive nature. Because of the characteristic of the whole body of the Arabic\nscript, namely connectivity between the characters, thereby the segmentation of\nAn Arabic script is very difficult. In this paper we introduced an Arabic\nscript multiple classifier system for recognizing notes written on a Starboard.\nThis Arabic script multiple classifier system combines one off-line and on-line\nhandwriting recognition systems. The Arabic script recognizers are all based on\nHidden Markov Models but vary in the way of preprocessing and normalization. To\ncombine the Arabic script output sequences of the recognizers, we incrementally\nalign the word sequences using a norm string matching algorithm. The Arabic\nscript combination we could increase the system performance over the excellent\ncharacter recognizer by about 3%. The proposed technique is also the necessary\nstep towards character recognition, person identification, personality\ndetermination where input data is processed from all perspectives.\n",
        "published": "2013-03-20T04:54:44Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4839v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.4840v1",
        "title": "Asynchronous Cellular Operations on Gray Images Extracting Topographic\n  Shape Features and Their Relations",
        "summary": "  A variety of operations of cellular automata on gray images is presented. All\noperations are of a wave-front nature finishing in a stable state. They are\nused to extract shape descripting gray objects robust to a variety of pattern\ndistortions. Topographic terms are used: \"lakes\", \"dales\", \"dales of dales\". It\nis shown how mutual object relations like \"above\" can be presented in terms of\ngray image analysis and how it can be used for character classification and for\ngray pattern decomposition. Algorithms can be realized with a parallel\nasynchronous architecture. Keywords: Pattern Recognition, Mathematical\nMorphology, Cellular Automata, Wave-front Algorithms, Gray Image Analysis,\nTopographical Shape Descriptors, Asynchronous Parallel Processors, Holes,\nCavities, Concavities, Graphs.\n",
        "published": "2013-03-20T04:59:08Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4840v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.4845v2",
        "title": "On Constructing the Value Function for Optimal Trajectory Problem and\n  its Application to Image Processing",
        "summary": "  We proposed an algorithm for solving Hamilton-Jacobi equation associated to\nan optimal trajectory problem for a vehicle moving inside the pre-specified\ndomain with the speed depending upon the direction of the motion and current\nposition of the vehicle. The dynamics of the vehicle is defined by an ordinary\ndifferential equation, the right hand of which is given by product of control(a\ntime dependent fuction) and a function dependent on trajectory and control. At\nsome unspecified terminal time, the vehicle reaches the boundary of the\npre-specified domain and incurs a terminal cost. We also associate the\ntraveling cost with a type of integral to the trajectory followed by vehicle.\nWe are interested in a numerical method for finding a trajectory that minimizes\nthe sum of the traveling cost and terminal cost. We developed an algorithm\nsolving the value function for general trajectory optimization problem. Our\nalgorithm is closely related to the Tsitsiklis's Fast Marching Method and J. A.\nSethian's OUM and SLF-LLL[1-4] and is a generalization of them. On the basis of\nthese results, We applied our algorithm to the image processing such as\nfingerprint verification.\n",
        "published": "2013-03-20T06:16:55Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4845v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.4866v1",
        "title": "A Robust Rapid Approach to Image Segmentation with Optimal Thresholding\n  and Watershed Transform",
        "summary": "  This paper describes a novel method for partitioning image into meaningful\nsegments. The proposed method employs watershed transform, a well-known image\nsegmentation technique. Along with that, it uses various auxiliary schemes such\nas Binary Gradient Masking, dilation which segment the image in proper way. The\nalgorithm proposed in this paper considers all these methods in effective way\nand takes little time. It is organized in such a manner so that it operates on\ninput image adaptively. Its robustness and efficiency makes it more convenient\nand suitable for all types of images.\n",
        "published": "2013-03-20T08:15:07Z",
        "pdf_link": "http://arxiv.org/pdf/1303.4866v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.5691v1",
        "title": "Cortical Surface Co-Registration based on MRI Images and Photos",
        "summary": "  Brain shift, i.e. the change in configuration of the brain after opening the\ndura mater, is a key problem in neuronavigation. We present an approach to\nco-register intra-operative microscope images with pre-operative MRI to adapt\nand optimize intra-operative neuronavigation. The tools are a robust\nclassification of sulci on MRI extracted cortical surfaces, guided user marking\nof most prominent sulci on a microscope image, and the actual variational\nregistration method with a fidelity energy for 3D deformations of the cortical\nsurface combined with a higher order, linear elastica type prior energy.\nFurthermore, the actual registration is validated on an artificial testbed with\nknown ground truth deformation and on real data of a neuro clinical patient.\n",
        "published": "2013-03-22T19:07:13Z",
        "pdf_link": "http://arxiv.org/pdf/1303.5691v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.6066v2",
        "title": "Asymmetric Pruning for Learning Cascade Detectors",
        "summary": "  Cascade classifiers are one of the most important contributions to real-time\nobject detection. Nonetheless, there are many challenging problems arising in\ntraining cascade detectors. One common issue is that the node classifier is\ntrained with a symmetric classifier. Having a low misclassification error rate\ndoes not guarantee an optimal node learning goal in cascade classifiers, i.e.,\nan extremely high detection rate with a moderate false positive rate. In this\nwork, we present a new approach to train an effective node classifier in a\ncascade detector. The algorithm is based on two key observations: 1) Redundant\nweak classifiers can be safely discarded; 2) The final detector should satisfy\nthe asymmetric learning objective of the cascade architecture. To achieve this,\nwe separate the classifier training into two steps: finding a pool of\ndiscriminative weak classifiers/features and training the final classifier by\npruning weak classifiers which contribute little to the asymmetric learning\ncriterion (asymmetric classifier construction). Our model reduction approach\nhelps accelerate the learning time while achieving the pre-determined learning\nobjective. Experimental results on both face and car data sets verify the\neffectiveness of the proposed algorithm. On the FDDB face data sets, our\napproach achieves the state-of-the-art performance, which demonstrates the\nadvantage of our approach.\n",
        "published": "2013-03-25T10:01:19Z",
        "pdf_link": "http://arxiv.org/pdf/1303.6066v2"
    },
    {
        "id": "http://arxiv.org/abs/1303.6455v1",
        "title": "Performance Evaluation of Edge-Directed Interpolation Methods for Images",
        "summary": "  Many interpolation methods have been developed for high visual quality, but\nfail for inability to preserve image structures. Edges carry heavy structural\ninformation for detection, determination and classification. Edge-adaptive\ninterpolation approaches become a center of focus. In this paper, performance\nof four edge-directed interpolation methods comparing with two traditional\nmethods is evaluated on two groups of images. These methods include new\nedge-directed interpolation (NEDI), edge-guided image interpolation (EGII),\niterative curvature-based interpolation (ICBI), directional cubic convolution\ninterpolation (DCCI) and two traditional approaches, bi-linear and bi-cubic.\nMeanwhile, no parameters are mentioned to measure edge-preserving ability of\nedge-adaptive interpolation approaches and we proposed two. One evaluates\naccuracy and the other measures robustness of edge-preservation ability.\nPerformance evaluation is based on six parameters. Objective assessment and\nvisual analysis are illustrated and conclusions are drawn from theoretical\nbackgrounds and practical results.\n",
        "published": "2013-03-26T12:35:46Z",
        "pdf_link": "http://arxiv.org/pdf/1303.6455v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.6619v1",
        "title": "An N-dimensional approach towards object based classification of\n  remotely sensed imagery",
        "summary": "  Remote sensing techniques are widely used for land cover classification and\nurban analysis. The availability of high resolution remote sensing imagery\nlimits the level of classification accuracy attainable from pixel-based\napproach. In this paper object-based classification scheme based on a\nhierarchical support vector machine is introduced. By combining spatial and\nspectral information, the amount of overlap between classes can be decreased;\nthereby yielding higher classification accuracy and more accurate land cover\nmaps. We have adopted certain automatic approaches based on the advanced\ntechniques as Cellular automata and Genetic Algorithm for kernel and tuning\nparameter selection. Performance evaluation of the proposed methodology in\ncomparison with the existing approaches is performed with reference to the\nBhopal city study area.\n",
        "published": "2013-03-26T19:39:20Z",
        "pdf_link": "http://arxiv.org/pdf/1303.6619v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.6711v1",
        "title": "An intelligent approach towards automatic shape modeling and object\n  extraction from satellite images using cellular automata based algorithm",
        "summary": "  Automatic feature extraction domain has witnessed the application of many\nintelligent methodologies over past decade; however detection accuracy of these\napproaches were limited as object geometry and contextual knowledge were not\ngiven enough consideration. In this paper, we propose a frame work for accurate\ndetection of features along with automatic interpolation, and interpretation by\nmodeling feature shape as well as contextual knowledge using advanced\ntechniques such as SVRF, Cellular Neural Network, Core set, and MACA. Developed\nmethodology has been compared with contemporary methods using different\nstatistical measures. Investigations over various satellite images revealed\nthat considerable success was achieved with the CNN approach. CNN has been\neffective in modeling different complex features effectively and complexity of\nthe approach has been considerably reduced using corset optimization. The\nsystem has dynamically used spectral and spatial information for representing\ncontextual knowledge using CNN-prolog approach. System has been also proved to\nbe effective in providing intelligent interpolation and interpretation of\nrandom features.\n",
        "published": "2013-03-27T00:33:52Z",
        "pdf_link": "http://arxiv.org/pdf/1303.6711v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.6926v1",
        "title": "A Comparative Analysis on the Applicability of Entropy in remote sensing",
        "summary": "  Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.\nMethodologies were implemented in Matlab and were enhanced with entropy\nvariations. Evaluation of various implementations was based on different\nstatistical parameters with reference to the study area The popular available\nversions like Tsalli's, Shanon's, and Renyi's entropies were analysed in\ncontext of various remote sensing operations namely thresholding, clustering\nand registration.\n",
        "published": "2013-03-27T18:57:12Z",
        "pdf_link": "http://arxiv.org/pdf/1303.6926v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.6927v1",
        "title": "An investigation towards wavelet based optimization of automatic image\n  registration techniques",
        "summary": "  Image registration is the process of transforming different sets of data into\none coordinate system and is required for various remote sensing applications\nlike change detection, image fusion, and other related areas. The effect of\nincreased relief displacement, requirement of more control points, and\nincreased data volume are the challenges associated with the registration of\nhigh resolution image data. The objective of this research work is to study the\nmost efficient techniques and to investigate the extent of improvement\nachievable by enhancing them with Wavelet transform. The SIFT feature based\nmethod uses the Eigen value for extracting thousands of key points based on\nscale invariant features and these feature points when further enhanced by the\nwavelet transform yields the best results.\n",
        "published": "2013-03-27T19:02:02Z",
        "pdf_link": "http://arxiv.org/pdf/1303.6927v1"
    },
    {
        "id": "http://arxiv.org/abs/1303.7390v2",
        "title": "Geometric tree kernels: Classification of COPD from airway tree geometry",
        "summary": "  Methodological contributions: This paper introduces a family of kernels for\nanalyzing (anatomical) trees endowed with vector valued measurements made along\nthe tree. While state-of-the-art graph and tree kernels use combinatorial\ntree/graph structure with discrete node and edge labels, the kernels presented\nin this paper can include geometric information such as branch shape, branch\nradius or other vector valued properties. In addition to being flexible in\ntheir ability to model different types of attributes, the presented kernels are\ncomputationally efficient and some of them can easily be computed for large\ndatasets (N of the order 10.000) of trees with 30-600 branches. Combining the\nkernels with standard machine learning tools enables us to analyze the relation\nbetween disease and anatomical tree structure and geometry. Experimental\nresults: The kernels are used to compare airway trees segmented from low-dose\nCT, endowed with branch shape descriptors and airway wall area percentage\nmeasurements made along the tree. Using kernelized hypothesis testing we show\nthat the geometric airway trees are significantly differently distributed in\npatients with Chronic Obstructive Pulmonary Disease (COPD) than in healthy\nindividuals. The geometric tree kernels also give a significant increase in the\nclassification accuracy of COPD from geometric tree structure endowed with\nairway wall thickness measurements in comparison with state-of-the-art methods,\ngiving further insight into the relationship between airway wall thickness and\nCOPD. Software: Software for computing kernels and statistical tests is\navailable at http://image.diku.dk/aasa/software.php.\n",
        "published": "2013-03-29T13:25:17Z",
        "pdf_link": "http://arxiv.org/pdf/1303.7390v2"
    },
    {
        "id": "http://arxiv.org/abs/1304.0019v1",
        "title": "Age group and gender recognition from human facial images",
        "summary": "  This work presents an automatic human gender and age group recognition system\nbased on human facial images. It makes an extensive experiment with row pixel\nintensity valued features and Discrete Cosine Transform (DCT) coefficient\nfeatures with Principal Component Analysis and k-Nearest Neighbor\nclassification to identify the best recognition approach. The final results\nshow approaches using DCT coefficient outperform their counter parts resulting\nin a 99% correct gender recognition rate and 68% correct age group recognition\nrate (considering four distinct age groups) in unseen test images. Detailed\nexperimental settings and obtained results are clearly presented and explained\nin this report.\n",
        "published": "2013-03-29T20:32:04Z",
        "pdf_link": "http://arxiv.org/pdf/1304.0019v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.0023v4",
        "title": "The two-dimensional Gabor function adapted to natural image statistics:\n  A model of simple-cell receptive fields and sparse structure in images",
        "summary": "  The two-dimensional Gabor function is adapted to natural image statistics,\nleading to a tractable probabilistic generative model that can be used to model\nsimple-cell receptive-field profiles, or generate basis functions for sparse\ncoding applications. Learning is found to be most pronounced in three\nGabor-function parameters representing the size and spatial frequency of the\ntwo-dimensional Gabor function, and characterized by a non-uniform probability\ndistribution with heavy tails. All three parameters are found to be strongly\ncorrelated: resulting in a basis of multiscale Gabor functions with similar\naspect ratios, and size-dependent spatial frequencies. A key finding is that\nthe distribution of receptive-field sizes is scale-invariant over a wide range\nof values, so there is no characteristic receptive-field size selected by\nnatural image statistics. The Gabor-function aspect ratio is found to be\napproximately conserved by the learning rules and is therefore not\nwell-determined by natural image statistics. This allows for three distinct\nsolutions: a basis of Gabor functions with sharp orientation resolution at the\nexpense of spatial-frequency resolution; a basis of Gabor functions with sharp\nspatial-frequency resolution at the expense of orientation resolution; or a\nbasis with unit aspect ratio. Arbitrary mixtures of all three cases are also\npossible. Two parameters controlling the shape of the marginal distributions in\na probabilistic generative model fully account for all three solutions. The\nbest-performing probabilistic generative model for sparse coding applications\nis found to be a Gaussian copula with Pareto marginal probability density\nfunctions.\n",
        "published": "2013-03-29T20:39:53Z",
        "pdf_link": "http://arxiv.org/pdf/1304.0023v4"
    },
    {
        "id": "http://arxiv.org/abs/1304.0421v1",
        "title": "Stroke-Based Cursive Character Recognition",
        "summary": "  Human eye can see and read what is written or displayed either in natural\nhandwriting or in printed format. The same work in case the machine does is\ncalled handwriting recognition. Handwriting recognition can be broken down into\ntwo categories: off-line and on-line. ...\n",
        "published": "2013-04-01T19:14:27Z",
        "pdf_link": "http://arxiv.org/pdf/1304.0421v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.0823v2",
        "title": "Lie Algebrized Gaussians for Image Representation",
        "summary": "  We present an image representation method which is derived from analyzing\nGaussian probability density function (\\emph{pdf}) space using Lie group\ntheory. In our proposed method, images are modeled by Gaussian mixture models\n(GMMs) which are adapted from a globally trained GMM called universal\nbackground model (UBM). Then we vectorize the GMMs based on two facts: (1)\ncomponents of image-specific GMMs are closely grouped together around their\ncorresponding component of the UBM due to the characteristic of the UBM\nadaption procedure; (2) Gaussian \\emph{pdf}s form a Lie group, which is a\ndifferentiable manifold rather than a vector space. We map each Gaussian\ncomponent to the tangent vector space (named Lie algebra) of Lie group at the\nmanifold position of UBM. The final feature vector, named Lie algebrized\nGaussians (LAG) is then constructed by combining the Lie algebrized Gaussian\ncomponents with mixture weights. We apply LAG features to scene category\nrecognition problem and observe state-of-the-art performance on 15Scenes\nbenchmark.\n",
        "published": "2013-04-03T02:38:01Z",
        "pdf_link": "http://arxiv.org/pdf/1304.0823v2"
    },
    {
        "id": "http://arxiv.org/abs/1304.0839v1",
        "title": "Multiscale Hybrid Non-local Means Filtering Using Modified Similarity\n  Measure",
        "summary": "  A new multiscale implementation of non-local means filtering for image\ndenoising is proposed. The proposed algorithm also introduces a modification of\nsimilarity measure for patch comparison. The standard Euclidean norm is\nreplaced by weighted Euclidean norm for patch based comparison. Assuming the\npatch as an oriented surface, notion of normal vector patch is being associated\nwith each patch. The inner product of these normal vector patches is then used\nin weighted Euclidean distance of photometric patches as the weight factor. The\nalgorithm involves two steps: The first step is multiscale implementation of an\naccelerated non-local means filtering in the stationary wavelet domain to\nobtain a refined version of the noisy patches for later comparison. This step\nis inspired by a preselection phase of finding similar patches in various\nnon-local means approaches. The next step is to apply the modified non-local\nmeans filtering to the noisy image using the reference patches obtained in the\nfirst step. These refined patches contain less noise, and consequently the\ncomputation of normal vectors and partial derivatives is more accurate.\nExperimental results indicate equivalent or better performance of proposed\nalgorithm as compared to various state of the art algorithms.\n",
        "published": "2013-04-03T04:24:21Z",
        "pdf_link": "http://arxiv.org/pdf/1304.0839v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.0886v1",
        "title": "Improved Anomaly Detection in Crowded Scenes via Cell-based Analysis of\n  Foreground Speed, Size and Texture",
        "summary": "  A robust and efficient anomaly detection technique is proposed, capable of\ndealing with crowded scenes where traditional tracking based approaches tend to\nfail. Initial foreground segmentation of the input frames confines the analysis\nto foreground objects and effectively ignores irrelevant background dynamics.\nInput frames are split into non-overlapping cells, followed by extracting\nfeatures based on motion, size and texture from each cell. Each feature type is\nindependently analysed for the presence of an anomaly. Unlike most methods, a\nrefined estimate of object motion is achieved by computing the optical flow of\nonly the foreground pixels. The motion and size features are modelled by an\napproximated version of kernel density estimation, which is computationally\nefficient even for large training datasets. Texture features are modelled by an\nadaptively grown codebook, with the number of entries in the codebook selected\nin an online fashion. Experiments on the recently published UCSD Anomaly\nDetection dataset show that the proposed method obtains considerably better\nresults than three recent approaches: MPPCA, social force, and mixture of\ndynamic textures (MDT). The proposed method is also several orders of magnitude\nfaster than MDT, the next best performing method.\n",
        "published": "2013-04-03T09:31:27Z",
        "pdf_link": "http://arxiv.org/pdf/1304.0886v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.1022v1",
        "title": "A software for aging faces applied to ancient marble busts",
        "summary": "  The study and development of software able to show the effect of aging of\nfaces is one of the tasks of face recognition technologies. Some software\nsolutions are used for investigations, some others to show the effects of drugs\non healthy appearance, however some other applications can be proposed for the\nanalysis of visual arts. Here we use a freely available software, which is\nproviding interesting results, for the comparison of ancient marble busts. An\nanalysis of Augustus busts is proposed.\n",
        "published": "2013-04-03T17:34:20Z",
        "pdf_link": "http://arxiv.org/pdf/1304.1022v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.1419v1",
        "title": "Integration of spatio-temporal contrast sensitivity with a multi-slice\n  channelized Hotelling observer",
        "summary": "  Barten's model of spatio-temporal contrast sensitivity function of human\nvisual system is embedded in a multi-slice channelized Hotelling observer. This\nis done by 3D filtering of the stack of images with the spatio-temporal\ncontrast sensitivity function and feeding the result (i.e., the perceived image\nstack) to the multi-slice channelized Hotelling observer. The proposed\nprocedure of considering spatio-temporal contrast sensitivity function is\ngeneric in the sense that it can be used with observers other than multi-slice\nchannelized Hotelling observer. Detection performance of the new observer in\ndigital breast tomosynthesis is measured in a variety of browsing speeds, at\ntwo spatial sampling rates, using computer simulations. Our results show a peak\nin detection performance in mid browsing speeds. We compare our results to\nthose of a human observer study reported earlier (I. Diaz et al. SPIE MI 2011).\nThe effects of display luminance, contrast and spatial sampling rate, with and\nwithout considering foveal vision, are also studied. Reported simulations are\nconducted with real digital breast tomosynthesis image stacks, as well as\nstacks from an anthropomorphic software breast phantom (P. Bakic et al. Med\nPhys. 2011). Lesion cases are simulated by inserting single\nmicro-calcifications or masses. Limitations of our methods and ways to improve\nthem are discussed.\n",
        "published": "2013-04-04T16:24:16Z",
        "pdf_link": "http://arxiv.org/pdf/1304.1419v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.1568v1",
        "title": "Multiscale Fractal Descriptors Applied to Texture Classification",
        "summary": "  This work proposes the combination of multiscale transform with fractal\ndescriptors employed in the classification of gray-level texture images. We\napply the space-scale transform (derivative + Gaussian filter) over the\nBouligand-Minkowski fractal descriptors, followed by a threshold over the\nfilter response, aiming at attenuating noise effects caused by the final part\nof this response. The method is tested in the classification of a well-known\ndata set (Brodatz) and compared with other classical texture descriptor\ntechniques. The results demonstrate the advantage of the proposed approach,\nachieving a higher success rate with a reduced amount of descriptors.\n",
        "published": "2013-04-04T22:07:27Z",
        "pdf_link": "http://arxiv.org/pdf/1304.1568v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.1572v5",
        "title": "Stable and Informative Spectral Signatures for Graph Matching",
        "summary": "  In this paper, we consider the approximate weighted graph matching problem\nand introduce stable and informative first and second order compatibility terms\nsuitable for inclusion into the popular integer quadratic program formulation.\nOur approach relies on a rigorous analysis of stability of spectral signatures\nbased on the graph Laplacian. In the case of the first order term, we derive an\nobjective function that measures both the stability and informativeness of a\ngiven spectral signature. By optimizing this objective, we design new spectral\nnode signatures tuned to a specific graph to be matched. We also introduce the\npairwise heat kernel distance as a stable second order compatibility term; we\njustify its plausibility by showing that in a certain limiting case it\nconverges to the classical adjacency matrix-based second order compatibility\nfunction. We have tested our approach on a set of synthetic graphs, the\nwidely-used CMU house sequence, and a set of real images. These experiments\nshow the superior performance of our first and second order compatibility terms\nas compared with the commonly used ones.\n",
        "published": "2013-04-04T22:19:49Z",
        "pdf_link": "http://arxiv.org/pdf/1304.1572v5"
    },
    {
        "id": "http://arxiv.org/abs/1304.1876v3",
        "title": "Proceedings of the 37th Annual Workshop of the Austrian Association for\n  Pattern Recognition (AGM/AAPR), 2013",
        "summary": "  This volume represents the proceedings of the 37th Annual Workshop of the\nAustrian Association for Pattern Recognition (\\\"OAGM/AAPR), held May 23-24,\n2013, in Innsbruck, Austria.\n",
        "published": "2013-04-06T10:36:25Z",
        "pdf_link": "http://arxiv.org/pdf/1304.1876v3"
    },
    {
        "id": "http://arxiv.org/abs/1304.1972v1",
        "title": "Facial transformations of ancient portraits: the face of Caesar",
        "summary": "  Some software solutions used to obtain the facial transformations can help\ninvestigating the artistic metamorphosis of the ancient portraits of the same\nperson. An analysis with a freely available software of portraitures of Julius\nCaesar is proposed, showing his several \"morphs\". The software helps enhancing\nthe mood the artist added to a portrait.\n",
        "published": "2013-04-07T09:43:47Z",
        "pdf_link": "http://arxiv.org/pdf/1304.1972v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.2109v1",
        "title": "Automatic Fingerprint Recognition Using Minutiae Matching Technique for\n  the Large Fingerprint Database",
        "summary": "  Extracting minutiae from fingerprint images is one of the most important\nsteps in automatic fingerprint identification system. Because minutiae matching\nare certainly the most well-known and widely used method for fingerprint\nmatching, minutiae are local discontinuities in the fingerprint pattern. In\nthis paper a fingerprint matching algorithm is proposed using some specific\nfeature of the minutiae points, also the acquired fingerprint image is\nconsidered by minimizing its size by generating a corresponding fingerprint\ntemplate for a large fingerprint database. The results achieved are compared\nwith those obtained through some other methods also shows some improvement in\nthe minutiae detection process in terms of memory and time required.\n",
        "published": "2013-04-08T06:14:48Z",
        "pdf_link": "http://arxiv.org/pdf/1304.2109v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.2683v1",
        "title": "Image Classification by Feature Dimension Reduction and Graph based\n  Ranking",
        "summary": "  Dimensionality reduction (DR) of image features plays an important role in\nimage retrieval and classification tasks. Recently, two types of methods have\nbeen proposed to improve the both the accuracy and efficiency for the\ndimensionality reduction problem. One uses Non-negative matrix factorization\n(NMF) to describe the image distribution on the space of base matrix. Another\none for dimension reduction trains a subspace projection matrix to project\noriginal data space into some low-dimensional subspaces which have deep\narchitecture, so that the low-dimensional codes would be learned. At the same\ntime, the graph based similarity learning algorithm which tries to exploit\ncontextual information for improving the effectiveness of image rankings is\nalso proposed for image class and retrieval problem. In this paper, after above\ntwo methods mentioned are utilized to reduce the high-dimensional features of\nimages respectively, we learn the graph based similarity for the image\nclassification problem. This paper compares the proposed approach with other\napproaches on an image database.\n",
        "published": "2013-04-09T18:11:08Z",
        "pdf_link": "http://arxiv.org/pdf/1304.2683v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.2999v2",
        "title": "A New Approach To Two-View Motion Segmentation Using Global Dimension\n  Minimization",
        "summary": "  We present a new approach to rigid-body motion segmentation from two views.\nWe use a previously developed nonlinear embedding of two-view point\ncorrespondences into a 9-dimensional space and identify the different motions\nby segmenting lower-dimensional subspaces. In order to overcome nonuniform\ndistributions along the subspaces, whose dimensions are unknown, we suggest the\nnovel concept of global dimension and its minimization for clustering subspaces\nwith some theoretical motivation. We propose a fast projected gradient\nalgorithm for minimizing global dimension and thus segmenting motions from\n2-views. We develop an outlier detection framework around the proposed method,\nand we present state-of-the-art results on outlier-free and outlier-corrupted\ntwo-view data for segmenting motion.\n",
        "published": "2013-04-10T15:34:08Z",
        "pdf_link": "http://arxiv.org/pdf/1304.2999v2"
    },
    {
        "id": "http://arxiv.org/abs/1304.3192v1",
        "title": "Rotational Projection Statistics for 3D Local Surface Description and\n  Object Recognition",
        "summary": "  Recognizing 3D objects in the presence of noise, varying mesh resolution,\nocclusion and clutter is a very challenging task. This paper presents a novel\nmethod named Rotational Projection Statistics (RoPS). It has three major\nmodules: Local Reference Frame (LRF) definition, RoPS feature description and\n3D object recognition. We propose a novel technique to define the LRF by\ncalculating the scatter matrix of all points lying on the local surface. RoPS\nfeature descriptors are obtained by rotationally projecting the neighboring\npoints of a feature point onto 2D planes and calculating a set of statistics\n(including low-order central moments and entropy) of the distribution of these\nprojected points. Using the proposed LRF and RoPS descriptor, we present a\nhierarchical 3D object recognition algorithm. The performance of the proposed\nLRF, RoPS descriptor and object recognition algorithm was rigorously tested on\na number of popular and publicly available datasets. Our proposed techniques\nexhibited superior performance compared to existing techniques. We also showed\nthat our method is robust with respect to noise and varying mesh resolution.\nOur RoPS based algorithm achieved recognition rates of 100%, 98.9%, 95.4% and\n96.0% respectively when tested on the Bologna, UWA, Queen's and Ca' Foscari\nVenezia Datasets.\n",
        "published": "2013-04-11T04:26:52Z",
        "pdf_link": "http://arxiv.org/pdf/1304.3192v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.3447v1",
        "title": "Developing and Analyzing Boundary Detection Operators Using\n  Probabilistic Models",
        "summary": "  Most feature detectors such as edge detectors or circle finders are\nstatistical, in the sense that they decide at each point in an image about the\npresence of a feature, this paper describes the use of Bayesian feature\ndetectors.\n",
        "published": "2013-03-27T19:58:23Z",
        "pdf_link": "http://arxiv.org/pdf/1304.3447v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.3915v1",
        "title": "Single View Depth Estimation from Examples",
        "summary": "  We describe a non-parametric, \"example-based\" method for estimating the depth\nof an object, viewed in a single photo. Our method consults a database of\nexample 3D geometries, searching for those which look similar to the object in\nthe photo. The known depths of the selected database objects act as shape\npriors which constrain the process of estimating the object's depth. We show\nhow this process can be performed by optimizing a well defined target\nlikelihood function, via a hard-EM procedure. We address the problem of\nrepresenting the (possibly infinite) variability of viewing conditions with a\nfinite (and often very small) example set, by proposing an on-the-fly example\nupdate scheme. We further demonstrate the importance of non-stationarity in\navoiding misleading examples when estimating structured shapes. We evaluate our\nmethod and present both qualitative as well as quantitative results for\nchallenging object classes. Finally, we show how this same technique may be\nreadily applied to a number of related problems. These include the novel task\nof estimating the occluded depth of an object's backside and the task of\ntailoring custom fitting image-maps for input depths.\n",
        "published": "2013-04-14T13:56:14Z",
        "pdf_link": "http://arxiv.org/pdf/1304.3915v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.4041v1",
        "title": "Multispectral Spatial Characterization: Application to Mitosis Detection\n  in Breast Cancer Histopathology",
        "summary": "  Accurate detection of mitosis plays a critical role in breast cancer\nhistopathology. Manual detection and counting of mitosis is tedious and subject\nto considerable inter- and intra-reader variations. Multispectral imaging is a\nrecent medical imaging technology, proven successful in increasing the\nsegmentation accuracy in other fields. This study aims at improving the\naccuracy of mitosis detection by developing a specific solution using\nmultispectral and multifocal imaging of breast cancer histopathological data.\nWe propose to enable clinical routine-compliant quality of mitosis\ndiscrimination from other objects. The proposed framework includes\ncomprehensive analysis of spectral bands and z-stack focus planes, detection of\nexpected mitotic regions (candidates) in selected focus planes and spectral\nbands, computation of multispectral spatial features for each candidate,\nselection of multispectral spatial features and a study of different\nstate-of-the-art classification methods for candidates classification as\nmitotic or non mitotic figures. This framework has been evaluated on MITOS\nmultispectral medical dataset and achieved 60% detection rate and 57%\nF-Measure. Our results indicate that multispectral spatial features have more\ninformation for mitosis classification in comparison with white spectral band\nfeatures, being therefore a very promising exploration area to improve the\nquality of the diagnosis assistance in histopathology.\n",
        "published": "2013-04-15T10:11:34Z",
        "pdf_link": "http://arxiv.org/pdf/1304.4041v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.4112v1",
        "title": "Shadow Estimation Method for \"The Episolar Constraint: Monocular Shape\n  from Shadow Correspondence\"",
        "summary": "  Recovering shadows is an important step for many vision algorithms. Current\napproaches that work with time-lapse sequences are limited to simple\nthresholding heuristics. We show these approaches only work with very careful\ntuning of parameters, and do not work well for long-term time-lapse sequences\ntaken over the span of many months. We introduce a parameter-free expectation\nmaximization approach which simultaneously estimates shadows, albedo, surface\nnormals, and skylight. This approach is more accurate than previous methods,\nworks over both very short and very long sequences, and is robust to the\neffects of nonlinear camera response. Finally, we demonstrate that the shadow\nmasks derived through this algorithm substantially improve the performance of\nsun-based photometric stereo compared to earlier shadow mask estimation.\n",
        "published": "2013-04-15T14:31:21Z",
        "pdf_link": "http://arxiv.org/pdf/1304.4112v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.4535v1",
        "title": "Heterogeneous patterns enhancing static and dynamic texture\n  classification",
        "summary": "  Some mixtures, such as colloids like milk, blood, and gelatin, have\nhomogeneous appearance when viewed with the naked eye, however, to observe them\nat the nanoscale is possible to understand the heterogeneity of its components.\nThe same phenomenon can occur in pattern recognition in which it is possible to\nsee heterogeneous patterns in texture images. However, current methods of\ntexture analysis can not adequately describe such heterogeneous patterns.\nCommon methods used by researchers analyse the image information in a global\nway, taking all its features in an integrated manner. Furthermore, multi-scale\nanalysis verifies the patterns at different scales, but still preserving the\nhomogeneous analysis. On the other hand various methods use textons to\nrepresent the texture, breaking texture down into its smallest unit. To tackle\nthis problem, we propose a method to identify texture patterns not small as\ntextons at distinct scales enhancing the separability among different types of\ntexture. We find sub patterns of texture according to the scale and then group\nsimilar patterns for a more refined analysis. Tests were performed in four\nstatic texture databases and one dynamic one. Results show that our method\nprovides better classification rate compared with conventional approaches both\nin static and in dynamic texture.\n",
        "published": "2013-04-16T17:53:16Z",
        "pdf_link": "http://arxiv.org/pdf/1304.4535v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.4662v1",
        "title": "Tracking of Fingertips and Centres of Palm using KINECT",
        "summary": "  Hand Gesture is a popular way to interact or control machines and it has been\nimplemented in many applications. The geometry of hand is such that it is hard\nto construct in virtual environment and control the joints but the\nfunctionality and DOF encourage researchers to make a hand like instrument.\nThis paper presents a novel method for fingertips detection and centres of\npalms detection distinctly for both hands using MS KINECT in 3D from the input\nimage. KINECT facilitates us by providing the depth information of foreground\nobjects. The hands were segmented using the depth vector and centres of palms\nwere detected using distance transformation on inverse image. This result would\nbe used to feed the inputs to the robotic hands to emulate human hands\noperation.\n",
        "published": "2013-04-17T01:20:10Z",
        "pdf_link": "http://arxiv.org/pdf/1304.4662v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.4711v1",
        "title": "Automated Switching System for Skin Pixel Segmentation in Varied\n  Lighting",
        "summary": "  In Computer Vision, colour-based spatial techniquesoften assume a static skin\ncolour model. However, skin colour perceived by a camera can change when\nlighting changes. In common real environment multiple light sources impinge on\nthe skin. Moreover, detection techniques may vary when the image under study is\ntaken under different lighting condition than the one that was earlier under\nconsideration. Therefore, for robust skin pixel detection, a dynamic skin\ncolour model that can cope with the changes must be employed. This paper shows\nthat skin pixel detection in a digital colour image can be significantly\nimproved by employing automated colour space switching methods. In the root of\nthe switching technique which is employed in this study, lies the statistical\nmean of value of the skin pixels in the image which in turn has been derived\nfrom the Value, measures as a third component of the HSV. The study is based on\nexperimentations on a set of images where capture time conditions varying from\nhighly illuminated to almost dark.\n",
        "published": "2013-04-17T07:07:52Z",
        "pdf_link": "http://arxiv.org/pdf/1304.4711v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.4765v1",
        "title": "Robust Noise Filtering in Image Sequences",
        "summary": "  Image sequences filtering have recently become a very important technical\nproblem especially with the advent of new technology in multimedia and video\nsystems applications. Often image sequences are corrupted by some amount of\nnoise introduced by the image sensor and therefore inherently present in the\nimaging process. The main problem in the image sequences is how to deal with\nspatio-temporal and non stationary signals. In this paper, we propose a robust\nmethod for noise removal of image sequence based on coupled spatial and\ntemporal anisotropic diffusion. The idea is to achieve an adaptive smoothing in\nboth spatial and temporal directions, by solving a nonlinear diffusion\nequation. This allows removing noise while preserving all spatial and temporal\ndiscontinuities\n",
        "published": "2013-04-17T10:55:43Z",
        "pdf_link": "http://arxiv.org/pdf/1304.4765v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.4994v1",
        "title": "Polygon Matching and Indexing Under Affine Transformations",
        "summary": "  Given a collection $\\{Z_1,Z_2,\\ldots,Z_m\\}$ of $n$-sided polygons in the\nplane and a query polygon $W$ we give algorithms to find all $Z_\\ell$ such that\n$W=f(Z_\\ell)$ with $f$ an unknown similarity transformation in time independent\nof the size of the collection. If $f$ is a known affine transformation, we show\nhow to find all $Z_\\ell$ such that $W=f(Z_\\ell)$ in $O(n+\\log(m))$ time.\n  For a pair $W,W^\\prime$ of polygons we can find all the pairs\n$Z_\\ell,Z_{\\ell^\\prime}$ such that $W=f(Z_\\ell)$ and\n$W^\\prime=f(Z_{\\ell^\\prime})$ for an unknown affine transformation $f$ in\n$O(m+n)$ time.\n  For the case of triangles we also give bounds for the problem of matching\ntriangles with variable vertices, which is equivalent to affine matching\ntriangles in noisy conditions.\n",
        "published": "2013-04-18T00:40:22Z",
        "pdf_link": "http://arxiv.org/pdf/1304.4994v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.5212v1",
        "title": "Object Tracking in Videos: Approaches and Issues",
        "summary": "  Mobile object tracking has an important role in the computer vision\napplications. In this paper, we use a tracked target-based taxonomy to present\nthe object tracking algorithms. The tracked targets are divided into three\ncategories: points of interest, appearance and silhouette of mobile objects.\nAdvantages and limitations of the tracking approaches are also analyzed to find\nthe future directions in the object tracking domain.\n",
        "published": "2013-04-18T18:41:47Z",
        "pdf_link": "http://arxiv.org/pdf/1304.5212v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.5319v1",
        "title": "A Joint Intensity and Depth Co-Sparse Analysis Model for Depth Map\n  Super-Resolution",
        "summary": "  High-resolution depth maps can be inferred from low-resolution depth\nmeasurements and an additional high-resolution intensity image of the same\nscene. To that end, we introduce a bimodal co-sparse analysis model, which is\nable to capture the interdependency of registered intensity and depth\ninformation. This model is based on the assumption that the co-supports of\ncorresponding bimodal image structures are aligned when computed by a suitable\npair of analysis operators. No analytic form of such operators exist and we\npropose a method for learning them from a set of registered training signals.\nThis learning process is done offline and returns a bimodal analysis operator\nthat is universally applicable to natural scenes. We use this to exploit the\nbimodal co-sparse analysis model as a prior for solving inverse problems, which\nleads to an efficient algorithm for depth map super-resolution.\n",
        "published": "2013-04-19T06:35:33Z",
        "pdf_link": "http://arxiv.org/pdf/1304.5319v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.5587v2",
        "title": "Color image denoising by chromatic edges based vector valued diffusion",
        "summary": "  In this letter we propose to denoise digital color images via an improved\ngeometric diffusion scheme. By introducing edges detected from all three color\nchannels into the diffusion the proposed scheme avoids color smearing\nartifacts. Vector valued diffusion is used to control the smoothing and the\ngeometry of color images are taken into consideration. Color edge strength\nfunction computed from different planes is introduced and it stops the\ndiffusion spread across chromatic edges. Experimental results indicate that the\nscheme achieves good denoising with edge preservation when compared to other\nrelated schemes.\n",
        "published": "2013-04-20T05:05:53Z",
        "pdf_link": "http://arxiv.org/pdf/1304.5587v2"
    },
    {
        "id": "http://arxiv.org/abs/1304.6192v1",
        "title": "A Bag of Visual Words Approach for Symbols-Based Coarse-Grained Ancient\n  Coin Classification",
        "summary": "  The field of Numismatics provides the names and descriptions of the symbols\nminted on the ancient coins. Classification of the ancient coins aims at\nassigning a given coin to its issuer. Various issuers used various symbols for\ntheir coins. We propose to use these symbols for a framework that will coarsely\nclassify the ancient coins. Bag of visual words (BoVWs) is a well established\nvisual recognition technique applied to various problems in computer vision\nlike object and scene recognition. Improvements have been made by incorporating\nthe spatial information to this technique. We apply the BoVWs technique to our\nproblem and use three symbols for coarse-grained classification. We use\nrectangular tiling, log-polar tiling and circular tiling to incorporate spatial\ninformation to BoVWs. Experimental results show that the circular tiling proves\nsuperior to the rest of the methods for our problem.\n",
        "published": "2013-04-23T07:46:11Z",
        "pdf_link": "http://arxiv.org/pdf/1304.6192v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.6213v1",
        "title": "Counting people from above: Airborne video based crowd analysis",
        "summary": "  Crowd monitoring and analysis in mass events are highly important\ntechnologies to support the security of attending persons. Proposed methods\nbased on terrestrial or airborne image/video data often fail in achieving\nsufficiently accurate results to guarantee a robust service. We present a novel\nframework for estimating human count, density and motion from video data based\non custom tailored object detection techniques, a regression based density\nestimate and a total variation based optical flow extraction. From the gathered\nfeatures we present a detailed accuracy analysis versus ground truth\nmeasurements. In addition, all information is projected into world coordinates\nto enable a direct integration with existing geo-information systems. The\nresulting human counts demonstrate a mean error of 4% to 9% and thus represent\na most efficient measure that can be robustly applied in security critical\nservices.\n",
        "published": "2013-04-23T09:51:02Z",
        "pdf_link": "http://arxiv.org/pdf/1304.6213v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.6291v1",
        "title": "Learning Visual Symbols for Parsing Human Poses in Images",
        "summary": "  Parsing human poses in images is fundamental in extracting critical visual\ninformation for artificial intelligent agents. Our goal is to learn\nself-contained body part representations from images, which we call visual\nsymbols, and their symbol-wise geometric contexts in this parsing process. Each\nsymbol is individually learned by categorizing visual features leveraged by\ngeometric information. In the categorization, we use Latent Support Vector\nMachine followed by an efficient cross validation procedure to learn visual\nsymbols. Then, these symbols naturally define geometric contexts of body parts\nin a fine granularity. When the structure of the compositional parts is a tree,\nwe derive an efficient approach to estimating human poses in images.\nExperiments on two large datasets suggest our approach outperforms state of the\nart methods.\n",
        "published": "2013-04-23T14:07:19Z",
        "pdf_link": "http://arxiv.org/pdf/1304.6291v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.6379v1",
        "title": "Semi-Optimal Edge Detector based on Simple Standard Deviation with\n  Adjusted Thresholding",
        "summary": "  This paper proposes a novel method which combines both median filter and\nsimple standard deviation to accomplish an excellent edge detector for image\nprocessing. First of all, a denoising process must be applied on the grey scale\nimage using median filter to identify pixels which are likely to be\ncontaminated by noise. The benefit of this step is to smooth the image and get\nrid of the noisy pixels. After that, the simple statistical standard deviation\ncould be computed for each 2X2 window size. If the value of the standard\ndeviation inside the 2X2 window size is greater than a predefined threshold,\nthen the upper left pixel in the 2?2 window represents an edge. The visual\ndifferences between the proposed edge detector and the standard known edge\ndetectors have been shown to support the contribution in this paper.\n",
        "published": "2013-04-23T18:53:58Z",
        "pdf_link": "http://arxiv.org/pdf/1304.6379v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.6759v1",
        "title": "k-Modulus Method for Image Transformation",
        "summary": "  In this paper, we propose a new algorithm to make a novel spatial image\ntransformation. The proposed approach aims to reduce the bit depth used for\nimage storage. The basic technique for the proposed transformation is based of\nthe modulus operator. The goal is to transform the whole image into multiples\nof predefined integer. The division of the whole image by that integer will\nguarantee that the new image surely less in size from the original image. The\nk-Modulus Method could not be used as a stand alone transform for image\ncompression because of its high compression ratio. It could be used as a scheme\nembedded in other image processing fields especially compression. According to\nits high PSNR value, it could be amalgamated with other methods to facilitate\nthe redundancy criterion.\n",
        "published": "2013-04-24T21:34:30Z",
        "pdf_link": "http://arxiv.org/pdf/1304.6759v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.6933v2",
        "title": "Digit Recognition in Handwritten Weather Records",
        "summary": "  This paper addresses the automatic recognition of handwritten temperature\nvalues in weather records. The localization of table cells is based on line\ndetection using projection profiles. Further, a stroke-preserving line removal\nmethod which is based on gradient images is proposed. The presented digit\nrecognition utilizes features which are extracted using a set of filters and a\nSupport Vector Machine classifier. It was evaluated on the MNIST and the USPS\ndataset and our own database with about 17,000 RGB digit images. An accuracy of\n99.36% per digit is achieved for the entire system using a set of 84 weather\nrecords.\n",
        "published": "2013-04-25T15:14:42Z",
        "pdf_link": "http://arxiv.org/pdf/1304.6933v2"
    },
    {
        "id": "http://arxiv.org/abs/1304.6990v1",
        "title": "Euclidean Upgrade from a Minimal Number of Segments",
        "summary": "  In this paper, we propose an algebraic approach to upgrade a projective\nreconstruction to a Euclidean one, and aim at computing the rectifying\nhomography from a minimal number of 9 segments of known length. Constraints are\nderived from these segments which yield a set of polynomial equations that we\nsolve by means of Gr\\\"obner bases. We explain how a solver for such a system of\nequations can be constructed from simplified template data. Moreover, we\npresent experiments that demonstrate that the given problem can be solved in\nthis way.\n",
        "published": "2013-04-25T19:44:26Z",
        "pdf_link": "http://arxiv.org/pdf/1304.6990v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.7153v1",
        "title": "A Convex Approach for Image Hallucination",
        "summary": "  In this paper we propose a global convex approach for image hallucination.\nAltering the idea of classical multi image super resolution (SU) systems to\nsingle image SU, we incorporate aligned images to hallucinate the output. Our\nwork is based on the paper of Tappen et al. where they use a non-convex model\nfor image hallucination. In comparison we formulate a convex primal\noptimization problem and derive a fast converging primal-dual algorithm with a\nglobal optimal solution. We use a database with face images to incorporate\nhigh-frequency details to the high-resolution output. We show that we can\nachieve state-of-the-art results by using a convex approach.\n",
        "published": "2013-04-26T13:10:22Z",
        "pdf_link": "http://arxiv.org/pdf/1304.7153v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.7184v1",
        "title": "Reading Ancient Coin Legends: Object Recognition vs. OCR",
        "summary": "  Standard OCR is a well-researched topic of computer vision and can be\nconsidered solved for machine-printed text. However, when applied to\nunconstrained images, the recognition rates drop drastically. Therefore, the\nemployment of object recognition-based techniques has become state of the art\nin scene text recognition applications. This paper presents a scene text\nrecognition method tailored to ancient coin legends and compares the results\nachieved in character and word recognition experiments to a standard OCR\nengine. The conducted experiments show that the proposed method outperforms the\nstandard OCR engine on a set of 180 cropped coin legend words.\n",
        "published": "2013-04-26T14:33:52Z",
        "pdf_link": "http://arxiv.org/pdf/1304.7184v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.7211v1",
        "title": "Algorithmic Optimisations for Iterative Deconvolution Methods",
        "summary": "  We investigate possibilities to speed up iterative algorithms for non-blind\nimage deconvolution. We focus on algorithms in which convolution with the\npoint-spread function to be deconvolved is used in each iteration, and aim at\naccelerating these convolution operations as they are typically the most\nexpensive part of the computation. We follow two approaches: First, for some\npractically important specific point-spread functions, algorithmically\nefficient sliding window or list processing techniques can be used. In some\nconstellations this allows faster computation than via the Fourier domain.\nSecond, as iterations progress, computation of convolutions can be restricted\nto subsets of pixels. For moderate thinning rates this can be done with almost\nno impact on the reconstruction quality. Both approaches are demonstrated in\nthe context of Richardson-Lucy deconvolution but are not restricted to this\nmethod.\n",
        "published": "2013-04-26T16:02:40Z",
        "pdf_link": "http://arxiv.org/pdf/1304.7211v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.7236v1",
        "title": "In the sight of my wearable camera: Classifying my visual experience",
        "summary": "  We introduce and we analyze a new dataset which resembles the input to\nbiological vision systems much more than most previously published ones. Our\nanalysis leaded to several important conclusions. First, it is possible to\ndisambiguate over dozens of visual scenes (locations) encountered over the\ncourse of several weeks of a human life with accuracy of over 80%, and this\nopens up possibility for numerous novel vision applications, from early\ndetection of dementia to everyday use of wearable camera streams for automatic\nreminders, and visual stream exchange. Second, our experimental results\nindicate that, generative models such as Latent Dirichlet Allocation or\nCounting Grids, are more suitable to such types of data, as they are more\nrobust to overtraining and comfortable with images at low resolution, blurred\nand characterized by relatively random clutter and a mix of objects.\n",
        "published": "2013-04-26T17:28:13Z",
        "pdf_link": "http://arxiv.org/pdf/1304.7236v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.7948v2",
        "title": "Convolutional Neural Networks learn compact local image descriptors",
        "summary": "  A standard deep convolutional neural network paired with a suitable loss\nfunction learns compact local image descriptors that perform comparably to\nstate-of-the art approaches.\n",
        "published": "2013-04-30T10:41:26Z",
        "pdf_link": "http://arxiv.org/pdf/1304.7948v2"
    },
    {
        "id": "http://arxiv.org/abs/1304.8052v1",
        "title": "Registration of Images with Outliers Using Joint Saliency Map",
        "summary": "  Mutual information (MI) is a popular similarity measure for image\nregistration, whereby good registration can be achieved by maximizing the\ncompactness of the clusters in the joint histogram. However, MI is sensitive to\nthe \"outlier\" objects that appear in one image but not the other, and also\nsuffers from local and biased maxima. We propose a novel joint saliency map\n(JSM) to highlight the corresponding salient structures in the two images, and\nemphatically group those salient structures into the smoothed compact clusters\nin the weighted joint histogram. This strategy could solve both the outlier and\nthe local maxima problems. Experimental results show that the JSM-MI based\nalgorithm is not only accurate but also robust for registration of challenging\nimage pairs with outliers.\n",
        "published": "2013-03-29T22:30:09Z",
        "pdf_link": "http://arxiv.org/pdf/1304.8052v1"
    },
    {
        "id": "http://arxiv.org/abs/1304.8092v1",
        "title": "Fractal-Based Detection of Microcalcification Clusters in Digital\n  Mammograms",
        "summary": "  In this paper, a novel method for edge detection of microcalcification\nclusters in mammogram images is presented using the concept of Fractal\nDimension and Hurst co-efficient that enables to locate the microcalcifications\nin the mammograms. This technique detects the edges accurately than the ones\nobtained by the conventional Sobel method. Generally, Sobel method detects the\nedges of the regions/objects in an image using the Fudge factor that assumes\nits value as 0.5, by default. In this proposed technique, the Fudge factor is\nsuitably replaced with Hurst Co-efficient, which is computed as the difference\nof Fractal dimension and the topological dimension of a given input image.\nThese two dimensions are image-dependent, and hence the respective Hurst\nco-efficient too varies with respect to images. Hence, the image-dependent\nHurst co-efficient based Sobel method is proved to produce better results than\nthe Fudge factor based Sobel method. The results of the proposed method\nsubstantiate the merit of the proposed technique.\n",
        "published": "2013-04-30T17:51:27Z",
        "pdf_link": "http://arxiv.org/pdf/1304.8092v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.0311v1",
        "title": "An Adaptive Descriptor Design for Object Recognition in the Wild",
        "summary": "  Digital images nowadays have various styles of appearance, in the aspects of\ncolor tones, contrast, vignetting, and etc. These 'picture styles' are directly\nrelated to the scene radiance, image pipeline of the camera, and post\nprocessing functions. Due to the complexity and nonlinearity of these causes,\npopular gradient-based image descriptors won't be invariant to different\npicture styles, which will decline the performance of object recognition. Given\nthat images shared online or created by individual users are taken with a wide\nrange of devices and may be processed by various post processing functions, to\nfind a robust object recognition system is useful and challenging. In this\npaper, we present the first study on the influence of picture styles for object\nrecognition, and propose an adaptive approach based on the kernel view of\ngradient descriptors and multiple kernel learning, without estimating or\nspecifying the styles of images used in training and testing. We conduct\nexperiments on Domain Adaptation data set and Oxford Flower data set. The\nexperiments also include several variants of the flower data set by processing\nthe images with popular photo effects. The results demonstrate that our\nproposed method improve from standard descriptors in all cases.\n",
        "published": "2013-05-01T23:11:36Z",
        "pdf_link": "http://arxiv.org/pdf/1305.0311v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.0871v2",
        "title": "Dictionary learning based image enhancement for rarity detection",
        "summary": "  Image enhancement is an important image processing technique that processes\nimages suitably for a specific application e.g. image editing. The conventional\nsolutions of image enhancement are grouped into two categories which are\nspatial domain processing method and transform domain processing method such as\ncontrast manipulation, histogram equalization, homomorphic filtering. This\npaper proposes a new image enhance method based on dictionary learning.\nParticularly, the proposed method adjusts the image by manipulating the rarity\nof dictionary atoms. Firstly, learn the dictionary through sparse coding\nalgorithms on divided sub-image blocks. Secondly, compute the rarity of\ndictionary atoms on statistics of the corresponding sparse coefficients.\nThirdly, adjust the rarity according to specific application and form a new\ndictionary. Finally, reconstruct the image using the updated dictionary and\nsparse coefficients. Compared with the traditional techniques, the proposed\nmethod enhances image based on the image content not on distribution of pixel\ngrey value or frequency. The advantages of the proposed method lie in that it\nis in better correspondence with the response of the human visual system and\nmore suitable for salient objects extraction. The experimental results\ndemonstrate the effectiveness of the proposed image enhance method.\n",
        "published": "2013-05-04T03:14:46Z",
        "pdf_link": "http://arxiv.org/pdf/1305.0871v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.1052v1",
        "title": "Hybridization of Otsu Method and Median Filter for Color Image\n  Segmentation",
        "summary": "  In this article a novel algorithm for color image segmentation has been\ndeveloped. The proposed algorithm based on combining two existing methods in\nsuch a novel way to obtain a significant method to partition the color image\ninto significant regions. On the first phase, the traditional Otsu method for\ngray channel image segmentation were applied for each of the R,G, and B\nchannels separately to determine the suitable automatic threshold for each\nchannel. After that, the new modified channels are integrated again to\nformulate a new color image. The resulted image suffers from some kind of\ndistortion. To get rid of this distortion, the second phase is arise which is\nthe median filter to smooth the image and increase the segmented regions. This\nprocess looks very significant by the ocular eye. Experimental results were\npresented on a variety of test images to support the proposed algorithm.\n",
        "published": "2013-05-05T20:49:54Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1052v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.1163v1",
        "title": "A Computer Vision System for Attention Mapping in SLAM based 3D Models",
        "summary": "  The study of human factors in the frame of interaction studies has been\nrelevant for usability engi-neering and ergonomics for decades. Today, with the\nadvent of wearable eye-tracking and Google glasses, monitoring of human factors\nwill soon become ubiquitous. This work describes a computer vision system that\nenables pervasive mapping and monitoring of human attention. The key\ncontribu-tion is that our methodology enables full 3D recovery of the gaze\npointer, human view frustum and associated human centred measurements directly\ninto an automatically computed 3D model in real-time. We apply RGB-D SLAM and\ndescriptor matching methodologies for the 3D modelling, locali-zation and fully\nautomated annotation of ROIs (regions of interest) within the acquired 3D\nmodel. This innovative methodology will open new avenues for attention studies\nin real world environments, bringing new potential into automated processing\nfor human factors technologies.\n",
        "published": "2013-05-06T12:35:52Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1163v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.1199v4",
        "title": "How to find real-world applications for compressive sensing",
        "summary": "  The potential of compressive sensing (CS) has spurred great interest in the\nresearch community and is a fast growing area of research. However, research\ntranslating CS theory into practical hardware and demonstrating clear and\nsignificant benefits with this hardware over current, conventional imaging\ntechniques has been limited. This article helps researchers to find those niche\napplications where the CS approach provides substantial gain over conventional\napproaches by articulating lessons learned in finding one such application; sea\nskimming missile detection. As a proof of concept, it is demonstrated that a\nsimplified CS missile detection architecture and algorithm provides comparable\nresults to the conventional imaging approach but using a smaller FPA. The\nprimary message is that all of the excitement surrounding CS is necessary and\nappropriate for encouraging our creativity but we all must also take off our\n\"rose colored glasses\" and critically judge our ideas, methods and results\nrelative to conventional imaging approaches.\n",
        "published": "2013-05-06T14:00:07Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1199v4"
    },
    {
        "id": "http://arxiv.org/abs/1305.1206v1",
        "title": "A Contrario Selection of Optimal Partitions for Image Segmentation",
        "summary": "  We present a novel segmentation algorithm based on a hierarchical\nrepresentation of images. The main contribution of this work is to explore the\ncapabilities of the A Contrario reasoning when applied to the segmentation\nproblem, and to overcome the limitations of current algorithms within that\nframework. This exploratory approach has three main goals.\n  Our first goal is to extend the search space of greedy merging algorithms to\nthe set of all partitions spanned by a certain hierarchy, and to cast the\nsegmentation as a selection problem within this space. In this way we increase\nthe number of tested partitions and thus we potentially improve the\nsegmentation results. In addition, this space is considerably smaller than the\nspace of all possible partitions, thus we still keep the complexity controlled.\n  Our second goal aims to improve the locality of region merging algorithms,\nwhich usually merge pairs of neighboring regions. In this work, we overcome\nthis limitation by introducing a validation procedure for complete partitions,\nrather than for pairs of regions.\n  The third goal is to perform an exhaustive experimental evaluation\nmethodology in order to provide reproducible results.\n  Finally, we embed the selection process on a statistical A Contrario\nframework which allows us to have only one free parameter related to the\ndesired scale.\n",
        "published": "2013-05-06T14:17:11Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1206v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.1344v1",
        "title": "Speckle Noise Reduction in Medical Ultrasound Images",
        "summary": "  Ultrasound imaging is an incontestable vital tool for diagnosis, it provides\nin non-invasive manner the internal structure of the body to detect eventually\ndiseases or abnormalities tissues. Unfortunately, the presence of speckle noise\nin these images affects edges and fine details which limit the contrast\nresolution and make diagnostic more difficult. In this paper, we propose a\ndenoising approach which combines logarithmic transformation and a non linear\ndiffusion tensor. Since speckle noise is multiplicative and nonwhite process,\nthe logarithmic transformation is a reasonable choice to convert\nsignaldependent or pure multiplicative noise to an additive one. The key idea\nfrom using diffusion tensor is to adapt the flow diffusion towards the local\norientation by applying anisotropic diffusion along the coherent structure\ndirection of interesting features in the image. To illustrate the effective\nperformance of our algorithm, we present some experimental results on\nsynthetically and real echographic images.\n",
        "published": "2013-05-06T22:25:52Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1344v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.1443v2",
        "title": "Standard Fingerprint Databases: Manual Minutiae Labeling and Matcher\n  Performance Analyses",
        "summary": "  Fingerprint verification and identification algorithms based on minutiae\nfeatures are used in many biometric systems today (e.g., governmental e-ID\nprograms, border control, AFIS, personal authentication for portable devices).\nResearchers in industry/academia are now able to utilize many publicly\navailable fingerprint databases (e.g., Fingerprint Verification Competition\n(FVC) & NIST databases) to compare/evaluate their feature extraction and/or\nmatching algorithm performances against those of others. The results from these\nevaluations are typically utilized by decision makers responsible for\nimplementing the cited biometric systems, in selecting/tuning specific sensors,\nfeature extractors and matchers. In this study, for a subset of the cited\npublic fingerprint databases, we report fingerprint minutiae matching results,\nwhich are based on (i) minutiae extracted automatically from fingerprint\nimages, and (ii) minutiae extracted manually by human subjects. By doing so, we\nare able to (i) quantitatively judge the performance differences between these\ntwo cases, (ii) elaborate on performance upper bounds of minutiae matching,\nutilizing what can be termed as \"ground truth\" minutiae features, (iii) analyze\nminutiae matching performance, without coupling it with the minutiae extraction\nperformance beforehand. Further, as we will freely distribute the minutiae\ntemplates, originating from this manual labeling study, in a standard minutiae\ntemplate exchange format (ISO 19794-2), we believe that other researchers in\nthe biometrics community will be able to utilize the associated results &\ntemplates to create their own evaluations pertaining to their fingerprint\nminutiae extractors/matchers.\n",
        "published": "2013-05-07T09:03:38Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1443v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.1520v1",
        "title": "A Method for Visuo-Spatial Classification of Freehand Shapes Freely\n  Sketched",
        "summary": "  We present the principle and the main steps of a new method for the\nvisuo-spatial analysis of geometrical sketches recorded online. Visuo-spatial\nanalysis is a necessary step for multi-level analysis. Multi-level analysis\nsimultaneously allows classification, comparison or clustering of the\nconstituent parts of a pattern according to their visuo-spatial properties,\ntheir procedural strategies, their structural or temporal parameters, or any\ncombination of two or more of those parameters. The first results provided by\nthis method concern the comparison of sketches to some perfect patterns of\nsimple geometrical figures and the measure of dissimilarity between real\nsketches. The mean rates of good decision higher than 95% obtained are\npromising in both cases.\n",
        "published": "2013-05-07T14:02:46Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1520v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.1912v4",
        "title": "Automated polyp detection in colon capsule endoscopy",
        "summary": "  Colorectal polyps are important precursors to colon cancer, a major health\nproblem. Colon capsule endoscopy (CCE) is a safe and minimally invasive\nexamination procedure, in which the images of the intestine are obtained via\ndigital cameras on board of a small capsule ingested by a patient. The video\nsequence is then analyzed for the presence of polyps. We propose an algorithm\nthat relieves the labor of a human operator analyzing the frames in the video\nsequence. The algorithm acts as a binary classifier, which labels the frame as\neither containing polyps or not, based on the geometrical analysis and the\ntexture content of the frame. The geometrical analysis is based on a\nsegmentation of an image with the help of a mid-pass filter. The features\nextracted by the segmentation procedure are classified according to an\nassumption that the polyps are characterized as protrusions that are mostly\nround in shape. Thus, we use a best fit ball radius as a decision parameter of\na binary classifier. We present a statistical study of the performance of our\napproach on a data set containing over 18,900 frames from the endoscopic video\nsequences of five adult patients. The algorithm demonstrates a solid\nperformance, achieving 47% sensitivity per frame and over 81% sensitivity per\npolyp at a specificity level of 90%. On average, with a video sequence length\nof 3747 frames, only 367 false positive frames need to be inspected by a human\noperator.\n",
        "published": "2013-05-08T18:33:28Z",
        "pdf_link": "http://arxiv.org/pdf/1305.1912v4"
    },
    {
        "id": "http://arxiv.org/abs/1305.2221v1",
        "title": "Repairing and Inpainting Damaged Images using Diffusion Tensor",
        "summary": "  Removing or repairing the imperfections of a digital images or videos is a\nvery active and attractive field of research belonging to the image inpainting\ntechnique. This later has a wide range of applications, such as removing\nscratches in old photographic image, removing text and logos or creating\ncartoon and artistic effects. In this paper, we propose an efficient method to\nrepair a damaged image based on a non linear diffusion tensor. The idea is to\ntrack perfectly the local geometry of the damaged image and allowing diffusion\nonly in the isophotes curves direction. To illustrate the effective performance\nof our method, we present some experimental results on test and real\nphotographic color images\n",
        "published": "2013-05-09T22:10:36Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2221v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.2269v1",
        "title": "Beyond Physical Connections: Tree Models in Human Pose Estimation",
        "summary": "  Simple tree models for articulated objects prevails in the last decade.\nHowever, it is also believed that these simple tree models are not capable of\ncapturing large variations in many scenarios, such as human pose estimation.\nThis paper attempts to address three questions: 1) are simple tree models\nsufficient? more specifically, 2) how to use tree models effectively in human\npose estimation? and 3) how shall we use combined parts together with single\nparts efficiently?\n  Assuming we have a set of single parts and combined parts, and the goal is to\nestimate a joint distribution of their locations. We surprisingly find that no\nlatent variables are introduced in the Leeds Sport Dataset (LSP) during\nlearning latent trees for deformable model, which aims at approximating the\njoint distributions of body part locations using minimal tree structure. This\nsuggests one can straightforwardly use a mixed representation of single and\ncombined parts to approximate their joint distribution in a simple tree model.\nAs such, one only needs to build Visual Categories of the combined parts, and\nthen perform inference on the learned latent tree. Our method outperformed the\nstate of the art on the LSP, both in the scenarios when the training images are\nfrom the same dataset and from the PARSE dataset. Experiments on animal images\nfrom the VOC challenge further support our findings.\n",
        "published": "2013-05-10T07:09:14Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2269v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.2395v1",
        "title": "Shape Reconstruction and Recognition with Isolated Non-directional Cues",
        "summary": "  The paper investigates a hypothesis that our visual system groups visual cues\nbased on how they form a surface, or more specifically triangulation derived\nfrom the visual cues. To test our hypothesis, we compare shape recognition with\nthree different representations of visual cues: a set of isolated dots\ndelineating the outline of the shape, a set of triangles obtained from Delaunay\ntriangulation of the set of dots, and a subset of Delaunay triangles excluding\nthose outside of the shape. Each participant was assigned to one particular\nrepresentation type and increased the number of dots (and consequentially\ntriangles) until the underlying shape could be identified. We compare the\naverage number of dots needed for identification among three types of\nrepresentations. Our hypothesis predicts that the results from the three\nrepresentations will be similar. However, they show statistically significant\ndifferences. The paper also presents triangulation based algorithms for\nreconstruction and recognition of a shape from a set of isolated dots.\nExperiments showed that the algorithms were more effective and perceptually\nagreeable than similar contour based ones. From these experiments, we conclude\nthat triangulation does affect our shape recognition. However, the surface\nbased approach presents a number of computational advantages over the contour\nbased one and should be studied further.\n",
        "published": "2013-05-10T17:35:02Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2395v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.2687v1",
        "title": "Automatic Parameter Adaptation for Multi-object Tracking",
        "summary": "  Object tracking quality usually depends on video context (e.g. object\nocclusion level, object density). In order to decrease this dependency, this\npaper presents a learning approach to adapt the tracker parameters to the\ncontext variations. In an offline phase, satisfactory tracking parameters are\nlearned for video context clusters. In the online control phase, once a context\nchange is detected, the tracking parameters are tuned using the learned values.\nThe experimental results show that the proposed approach outperforms the recent\ntrackers in state of the art. This paper brings two contributions: (1) a\nclassification method of video sequences to learn offline tracking parameters,\n(2) a new method to tune online tracking parameters using tracking context.\n",
        "published": "2013-05-13T07:14:07Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2687v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.2827v1",
        "title": "Human Mood Detection For Human Computer Interaction",
        "summary": "  In this paper we propose an easiest approach for facial expression\nrecognition. Here we are using concept of SVM for Expression Classification.\nMain problem is sub divided in three main modules. First one is Face detection\nin which we are using skin filter and Face segmentation. We are given more\nstress on feature Extraction. This method is effective enough for application\nwhere fast execution is required. Second, Facial Feature Extraction which is\nessential part for expression recognition. In this module we used Edge\nProjection Analysis. Finally extracted features vector is passed towards SVM\nclassifier for Expression Recognition. We are considering six basic Expressions\n(Anger, Fear, Disgust, Joy, Sadness, and Surprise)\n",
        "published": "2013-05-10T08:58:01Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2827v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.2828v1",
        "title": "Image Optimization and Prediction",
        "summary": "  Image Processing, Optimization and Prediction of an Image play a key role in\nComputer Science. Image processing provides a way to analyze and identify an\nimage .Many areas like medical image processing, Satellite images, natural\nimages and artificial images requires lots of analysis and research on\noptimization. In Image Optimization and Prediction we are combining the\nfeatures of Query Optimization, Image Processing and Prediction . Image\noptimization is used in Pattern analysis, object recognition, in medical Image\nprocessing to predict the type of diseases, in satellite images for predicting\nweather forecast, availability of water or mineral etc. Image Processing,\nOptimization and analysis is a wide open area for research .Lots of research\nhas been conducted in the area of Image analysis and many techniques are\navailable for image analysis but, a single technique is not yet identified for\nimage analysis and prediction .our research is focused on identifying a global\ntechnique for image analysis and Prediction.\n",
        "published": "2013-05-10T08:43:59Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2828v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.2949v2",
        "title": "Unsupervised ensemble of experts (EoE) framework for automatic\n  binarization of document images",
        "summary": "  In recent years, a large number of binarization methods have been developed,\nwith varying performance generalization and strength against different\nbenchmarks. In this work, to leverage on these methods, an ensemble of experts\n(EoE) framework is introduced, to efficiently combine the outputs of various\nmethods. The proposed framework offers a new selection process of the\nbinarization methods, which are actually the experts in the ensemble, by\nintroducing three concepts: confidentness, endorsement and schools of experts.\nThe framework, which is highly objective, is built based on two general\nprinciples: (i) consolidation of saturated opinions and (ii) identification of\nschools of experts. After building the endorsement graph of the ensemble for an\ninput document image based on the confidentness of the experts, the saturated\nopinions are consolidated, and then the schools of experts are identified by\nthresholding the consolidated endorsement graph. A variation of the framework,\nin which no selection is made, is also introduced that combines the outputs of\nall experts using endorsement-dependent weights. The EoE framework is evaluated\non the set of participating methods in the H-DIBCO'12 contest and also on an\nensemble generated from various instances of grid-based Sauvola method with\npromising performance.\n",
        "published": "2013-05-13T20:37:29Z",
        "pdf_link": "http://arxiv.org/pdf/1305.2949v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.3013v1",
        "title": "Novel variational model for inpainting in the wavelet domain",
        "summary": "  Wavelet domain inpainting refers to the process of recovering the missing\ncoefficients during the image compression or transmission stage. Recently, an\nefficient algorithm framework which is called Bregmanized operator splitting\n(BOS) was proposed for solving the classical variational model of wavelet\ninpainting. However, it is still time-consuming to some extent due to the inner\niteration. In this paper, a novel variational model is established to formulate\nthis reconstruction problem from the view of image decomposition. Then an\nefficient iterative algorithm based on the split-Bregman method is adopted to\ncalculate an optimal solution, and it is also proved to be convergent. Compared\nwith the BOS algorithm the proposed algorithm avoids the inner iteration and\nhence is more simple. Numerical experiments demonstrate that the proposed\nmethod is very efficient and outperforms the current state-of-the-art methods,\nespecially in the computational time.\n",
        "published": "2013-05-14T03:45:09Z",
        "pdf_link": "http://arxiv.org/pdf/1305.3013v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.3189v1",
        "title": "A Bag of Words Approach for Semantic Segmentation of Monitored Scenes",
        "summary": "  This paper proposes a semantic segmentation method for outdoor scenes\ncaptured by a surveillance camera. Our algorithm classifies each perceptually\nhomogenous region as one of the predefined classes learned from a collection of\nmanually labelled images. The proposed approach combines two different types of\ninformation. First, color segmentation is performed to divide the scene into\nperceptually similar regions. Then, the second step is based on SIFT keypoints\nand uses the bag of words representation of the regions for the classification.\nThe prediction is done using a Na\\\"ive Bayesian Network as a generative\nclassifier. Compared to existing techniques, our method provides more compact\nrepresentations of scene contents and the segmentation result is more\nconsistent with human perception due to the combination of the color\ninformation with the image keypoints. The experiments conducted on a publicly\navailable data set demonstrate the validity of the proposed method.\n",
        "published": "2013-05-14T15:58:38Z",
        "pdf_link": "http://arxiv.org/pdf/1305.3189v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.3250v3",
        "title": "Bioacoustical Periodic Pulse Train Signal Detection and Classification\n  using Spectrogram Intensity Binarization and Energy Projection",
        "summary": "  The following work outlines an approach for automatic detection and\nrecognition of periodic pulse train signals using a multi-stage process based\non spectrogram edge detection, energy projection and classification. The method\nhas been implemented to automatically detect and recognize pulse train songs of\nminke whales. While the long term goal of this work is to properly identify and\ndetect minke songs from large multi-year datasets, this effort was developed\nusing sounds off the coast of Massachusetts, in the Stellwagen Bank National\nMarine Sanctuary. The detection methodology is presented and evaluated on 232\ncontinuous hours of acoustic recordings and a qualitative analysis of machine\nlearning classifiers and their performance is described. The trained automatic\ndetection and classification system is applied to 120 continuous hours,\ncomprised of various challenges such as broadband and narrowband noises, low\nSNR, and other pulse train signatures. This automatic system achieves a TPR of\n63% for FPR of 0.6% (or 0.87 FP/h), at a Precision (PPV) of 84% and an F1 score\nof 71%.\n",
        "published": "2013-05-14T18:49:52Z",
        "pdf_link": "http://arxiv.org/pdf/1305.3250v3"
    },
    {
        "id": "http://arxiv.org/abs/1305.3633v2",
        "title": "Classification for Big Dataset of Bioacoustic Signals Based on Human\n  Scoring System and Artificial Neural Network",
        "summary": "  In this paper, we propose a method to improve sound classification\nperformance by combining signal features, derived from the time-frequency\nspectrogram, with human perception. The method presented herein exploits an\nartificial neural network (ANN) and learns the signal features based on the\nhuman perception knowledge. The proposed method is applied to a large acoustic\ndataset containing 24 months of nearly continuous recordings. The results show\na significant improvement in performance of the detection-classification\nsystem; yielding as much as 20% improvement in true positive rate for a given\nfalse positive rate.\n",
        "published": "2013-05-15T20:53:39Z",
        "pdf_link": "http://arxiv.org/pdf/1305.3633v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.3635v2",
        "title": "Bioacoustic Signal Classification Based on Continuous Region Processing,\n  Grid Masking and Artificial Neural Network",
        "summary": "  In this paper, we develop a novel method based on machine-learning and image\nprocessing to identify North Atlantic right whale (NARW) up-calls in the\npresence of high levels of ambient and interfering noise. We apply a continuous\nregion algorithm on the spectrogram to extract the regions of interest, and\nthen use grid masking techniques to generate a small feature set that is then\nused in an artificial neural network classifier to identify the NARW up-calls.\nIt is shown that the proposed technique is effective in detecting and capturing\neven very faint up-calls, in the presence of ambient and interfering noises.\nThe method is evaluated on a dataset recorded in Massachusetts Bay, United\nStates. The dataset includes 20000 sound clips for training, and 10000 sound\nclips for testing. The results show that the proposed technique can achieve an\nerror rate of less than FPR = 4.5% for a 90% true positive rate.\n",
        "published": "2013-05-15T20:59:03Z",
        "pdf_link": "http://arxiv.org/pdf/1305.3635v2"
    },
    {
        "id": "http://arxiv.org/abs/1305.3939v1",
        "title": "Analysis Of Interest Points Of Curvelet Coefficients Contributions Of\n  Microscopic Images And Improvement Of Edges",
        "summary": "  This paper focuses on improved edge model based on Curvelet coefficients\nanalysis. Curvelet transform is a powerful tool for multiresolution\nrepresentation of object with anisotropic edge. Curvelet coefficients\ncontributions have been analyzed using Scale Invariant Feature Transform\n(SIFT), commonly used to study local structure in images. The permutation of\nCurvelet coefficients from original image and edges image obtained from\ngradient operator is used to improve original edges. Experimental results show\nthat this method brings out details on edges when the decomposition scale\nincreases.\n",
        "published": "2013-05-16T21:25:54Z",
        "pdf_link": "http://arxiv.org/pdf/1305.3939v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.4064v1",
        "title": "Font Acknowledgment and Character Extraction of Digital and Scanned\n  Images",
        "summary": "  The font recognition and character extraction is of immense importance as\nthese are many scenarios where data are in such a form, which cannot be\nprocessed like in image form or as a hard copy. So the procedure developed in\nthis paper is basically related to identifying the font (Times New Roman, Arial\nand Comic Sans MS) and afterwards recovering the text using simple correlation\nbased method where the binary templates are correlated to the input image text\ncharacters. All of this extraction is done in the presence of a little noise as\nimages may have noisy patterns due to photocopying. The significance of this\nmethod exists in extraction of data from various monitoring (Surveillance)\ncamera footages or even more. The method is developed on Matlab\\c{opyright}\nwhich takes input image and recovers text and font information from it in a\ntext file.\n",
        "published": "2013-05-17T13:05:31Z",
        "pdf_link": "http://arxiv.org/pdf/1305.4064v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.4298v1",
        "title": "Blockwise SURE Shrinkage for Non-Local Means",
        "summary": "  In this letter, we investigate the shrinkage problem for the non-local means\n(NLM) image denoising. In particular, we derive the closed-form of the optimal\nblockwise shrinkage for NLM that minimizes the Stein's unbiased risk estimator\n(SURE). We also propose a constant complexity algorithm allowing fast blockwise\nshrinkage. Simulation results show that the proposed blockwise shrinkage method\nimproves NLM performance in attaining higher peak signal noise ratio (PSNR) and\nstructural similarity index (SSIM), and makes NLM more robust against parameter\nchanges. Similar ideas can be applicable to other patchwise image denoising\ntechniques.\n",
        "published": "2013-05-18T20:45:40Z",
        "pdf_link": "http://arxiv.org/pdf/1305.4298v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.4537v5",
        "title": "Object Detection with Pixel Intensity Comparisons Organized in Decision\n  Trees",
        "summary": "  We describe a method for visual object detection based on an ensemble of\noptimized decision trees organized in a cascade of rejectors. The trees use\npixel intensity comparisons in their internal nodes and this makes them able to\nprocess image regions very fast. Experimental analysis is provided through a\nface detection problem. The obtained results are encouraging and demonstrate\nthat the method has practical value. Additionally, we analyse its sensitivity\nto noise and show how to perform fast rotation invariant object detection.\nComplete source code is provided at https://github.com/nenadmarkus/pico.\n",
        "published": "2013-05-20T14:35:47Z",
        "pdf_link": "http://arxiv.org/pdf/1305.4537v5"
    },
    {
        "id": "http://arxiv.org/abs/1305.4544v1",
        "title": "Efficient Image Retargeting for High Dynamic Range Scenes",
        "summary": "  Most of the real world scenes have a very high dynamic range (HDR). The\nmobile phone cameras and the digital cameras available in markets are limited\nin their capability in both the range and spatial resolution. Same argument can\nbe posed about the limited dynamic range display devices which also differ in\nthe spatial resolution and aspect ratios.\n  In this paper, we address the problem of displaying the high contrast low\ndynamic range (LDR) image of a HDR scene in a display device which has\ndifferent spatial resolution compared to that of the capturing digital camera.\nThe optimal solution proposed in this work can be employed with any camera\nwhich has the ability to shoot multiple differently exposed images of a scene.\nFurther, the proposed solutions provide the flexibility in the depiction of\nentire contrast of the HDR scene as a LDR image with an user specified spatial\nresolution. This task is achieved through an optimized content aware\nretargeting framework which preserves salient features along with the algorithm\nto combine multi-exposure images. We show the proposed approach performs\nexceedingly well in the generation of high contrast LDR image of varying\nspatial resolution compared to an alternate approach.\n",
        "published": "2013-05-20T14:54:56Z",
        "pdf_link": "http://arxiv.org/pdf/1305.4544v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.5160v1",
        "title": "A novel automatic thresholding segmentation method with local adaptive\n  thresholds",
        "summary": "  A novel method for segmenting bright objects from dark background for\ngrayscale image is proposed. The concept of this method can be stated simply\nas: to pick out the local-thinnest bands on the grayscale grade-map. It turns\nout to be a threshold-based method with local adaptive thresholds, where each\nlocal threshold is determined by requiring the average normal-direction\ngradient on the object boundary to be local minimal. The method is highly\nautomatic and the segmentation mimics a man's natural expectation even the\nobject boundaries are fuzzy.\n",
        "published": "2013-05-22T15:00:43Z",
        "pdf_link": "http://arxiv.org/pdf/1305.5160v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.5728v1",
        "title": "Edge Detection in Radar Images Using Weibull Distribution",
        "summary": "  Radar images can reveal information about the shape of the surface terrain as\nwell as its physical and biophysical properties. Radar images have long been\nused in geological studies to map structural features that are revealed by the\nshape of the landscape. Radar imagery also has applications in vegetation and\ncrop type mapping, landscape ecology, hydrology, and volcanology. Image\nprocessing is using for detecting for objects in radar images. Edge detection;\nwhich is a method of determining the discontinuities in gray level images; is a\nvery important initial step in Image processing. Many classical edge detectors\nhave been developed over time. Some of the well-known edge detection operators\nbased on the first derivative of the image are Roberts, Prewitt, Sobel which is\ntraditionally implemented by convolving the image with masks. Also Gaussian\ndistribution has been used to build masks for the first and second derivative.\nHowever, this distribution has limit to only symmetric shape. This paper will\nuse to construct the masks, the Weibull distribution which was more general\nthan Gaussian because it has symmetric and asymmetric shape. The constructed\nmasks are applied to images and we obtained good results.\n",
        "published": "2013-05-24T13:39:18Z",
        "pdf_link": "http://arxiv.org/pdf/1305.5728v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.5756v1",
        "title": "Flooding edge or node weighted graphs",
        "summary": "  Reconstruction closings have all properties of a physical flooding of a\ntopographic surface. They are precious for simplifying gradient images or,\nfilling unwanted catchment basins, on which a subsequent watershed transform\nextracts the targeted objects. Flooding a topographic surface may be modeled as\nflooding a node weighted graph (TG), with unweighted edges, the node weights\nrepresenting the ground level. The progression of a flooding may also be\nmodeled on the region adjacency graph (RAG) of a topographic surface. On a RAG\neach node represents a catchment basin and edges connect neighboring nodes. The\nedges are weighted by the altitude of the pass point between both adjacent\nregions. The graph is flooded from sources placed at the marker positions and\neach node is assigned to the source by which it has been flooded. The level of\nthe flood is represented on the nodes on each type of graphs. The same flooding\nmay thus be modeled on a TG or on a RAG. We characterize all valid floodings on\nboth types of graphs, as they should verify the laws of hydrostatics. We then\nshow that each flooding of a node weighted graph also is a flooding of an edge\nweighted graph with appropriate edge weights. The highest flooding under a\nceiling function may be interpreted as the shortest distance to the root for\nthe ultrametric flooding distance in an augmented graph. The ultrametric\ndistance between two nodes is the minimal altitude of a flooding for which both\nnodes are flooded. This remark permits to flood edge or node weighted graphs by\nusing shortest path algorithms. It appears that the collection of all lakes of\na RAG has the structure of a dendrogram, on which the highest flooding under a\nceiling function may be rapidly found.\n",
        "published": "2013-05-24T14:47:40Z",
        "pdf_link": "http://arxiv.org/pdf/1305.5756v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.5905v1",
        "title": "AGM/AAPR 2013 - The 37th Annual Workshop of the Austrian Association\n  for Pattern Recognition",
        "summary": "  In this editorial, the organizers summarize facts and background about the\nevent.\n",
        "published": "2013-05-25T09:30:49Z",
        "pdf_link": "http://arxiv.org/pdf/1305.5905v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.6387v3",
        "title": "Higher-order Segmentation via Multicuts",
        "summary": "  Multicuts enable to conveniently represent discrete graphical models for\nunsupervised and supervised image segmentation, in the case of local energy\nfunctions that exhibit symmetries. The basic Potts model and natural extensions\nthereof to higher-order models provide a prominent class of such objectives,\nthat cover a broad range of segmentation problems relevant to image analysis\nand computer vision. We exhibit a way to systematically take into account such\nhigher-order terms for computational inference. Furthermore, we present results\nof a comprehensive and competitive numerical evaluation of a variety of\ndedicated cutting-plane algorithms. Our approach enables the globally optimal\nevaluation of a significant subset of these models, without compromising\nruntime. Polynomially solvable relaxations are studied as well, along with\nadvanced rounding schemes for post-processing.\n",
        "published": "2013-05-28T07:23:39Z",
        "pdf_link": "http://arxiv.org/pdf/1305.6387v3"
    },
    {
        "id": "http://arxiv.org/abs/1305.6918v1",
        "title": "Video Human Segmentation using Fuzzy Object Models and its Application\n  to Body Pose Estimation of Toddlers for Behavior Studies",
        "summary": "  Video object segmentation is a challenging problem due to the presence of\ndeformable, connected, and articulated objects, intra- and inter-object\nocclusions, object motion, and poor lighting. Some of these challenges call for\nobject models that can locate a desired object and separate it from its\nsurrounding background, even when both share similar colors and textures. In\nthis work, we extend a fuzzy object model, named cloud system model (CSM), to\nhandle video segmentation, and evaluate it for body pose estimation of toddlers\nat risk of autism. CSM has been successfully used to model the parts of the\nbrain (cerebrum, left and right brain hemispheres, and cerebellum) in order to\nautomatically locate and separate them from each other, the connected brain\nstem, and the background in 3D MR-images. In our case, the objects are\narticulated parts (2D projections) of the human body, which can deform, cause\nself-occlusions, and move along the video. The proposed CSM extension handles\narticulation by connecting the individual clouds, body parts, of the system\nusing a 2D stickman model. The stickman representation naturally allows us to\nextract 2D body pose measures of arm asymmetry patterns during unsupported gait\nof toddlers, a possible behavioral marker of autism. The results show that our\nmethod can provide insightful knowledge to assist the specialist's observations\nduring real in-clinic assessments.\n",
        "published": "2013-05-29T19:46:19Z",
        "pdf_link": "http://arxiv.org/pdf/1305.6918v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.7053v1",
        "title": "A Local Active Contour Model for Image Segmentation with Intensity\n  Inhomogeneity",
        "summary": "  A novel locally statistical active contour model (ACM) for image segmentation\nin the presence of intensity inhomogeneity is presented in this paper. The\ninhomogeneous objects are modeled as Gaussian distributions of different means\nand variances, and a moving window is used to map the original image into\nanother domain, where the intensity distributions of inhomogeneous objects are\nstill Gaussian but are better separated. The means of the Gaussian\ndistributions in the transformed domain can be adaptively estimated by\nmultiplying a bias field with the original signal within the window. A\nstatistical energy functional is then defined for each local region, which\ncombines the bias field, the level set function, and the constant approximating\nthe true signal of the corresponding object. Experiments on both synthetic and\nreal images demonstrate the superiority of our proposed algorithm to\nstate-of-the-art and representative methods.\n",
        "published": "2013-05-30T10:14:14Z",
        "pdf_link": "http://arxiv.org/pdf/1305.7053v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.7181v1",
        "title": "Lensless Imaging by Compressive Sensing",
        "summary": "  In this paper, we propose a lensless compressive imaging architecture. The\narchitecture consists of two components, an aperture assembly and a sensor. No\nlens is used. The aperture assembly consists of a two dimensional array of\naperture elements. The transmittance of each aperture element is independently\ncontrollable. The sensor is a single detection element. A compressive sensing\nmatrix is implemented by adjusting the transmittance of the individual aperture\nelements according to the values of the sensing matrix. The proposed\narchitecture is simple and reliable because no lens is used. The architecture\ncan be used for capturing images of visible and other spectra such as infrared,\nor millimeter waves, in surveillance applications for detecting anomalies or\nextracting features such as speed of moving objects. Multiple sensors may be\nused with a single aperture assembly to capture multi-view images\nsimultaneously. A prototype was built by using a LCD panel and a photoelectric\nsensor for capturing images of visible spectrum.\n",
        "published": "2013-05-30T17:56:03Z",
        "pdf_link": "http://arxiv.org/pdf/1305.7181v1"
    },
    {
        "id": "http://arxiv.org/abs/1305.7311v1",
        "title": "Robust Hyperspectral Unmixing with Correntropy based Metric",
        "summary": "  Hyperspectral unmixing is one of the crucial steps for many hyperspectral\napplications. The problem of hyperspectral unmixing has proven to be a\ndifficult task in unsupervised work settings where the endmembers and\nabundances are both unknown. What is more, this task becomes more challenging\nin the case that the spectral bands are degraded with noise. This paper\npresents a robust model for unsupervised hyperspectral unmixing. Specifically,\nour model is developed with the correntropy based metric where the non-negative\nconstraints on both endmembers and abundances are imposed to keep physical\nsignificance. In addition, a sparsity prior is explicitly formulated to\nconstrain the distribution of the abundances of each endmember. To solve our\nmodel, a half-quadratic optimization technique is developed to convert the\noriginal complex optimization problem into an iteratively re-weighted NMF with\nsparsity constraints. As a result, the optimization of our model can adaptively\nassign small weights to noisy bands and give more emphasis on noise-free bands.\nIn addition, with sparsity constraints, our model can naturally generate sparse\nabundances. Experiments on synthetic and real data demonstrate the\neffectiveness of our model in comparison to the related state-of-the-art\nunmixing models.\n",
        "published": "2013-05-31T06:43:31Z",
        "pdf_link": "http://arxiv.org/pdf/1305.7311v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.0139v1",
        "title": "Image Inpainting by Kriging Interpolation Technique",
        "summary": "  Image inpainting is the art of predicting damaged regions of an image. The\nmanual way of image inpainting is a time consuming. Therefore, there must be an\nautomatic digital method for image inpainting that recovers the image from the\ndamaged regions. In this paper, a novel statistical image inpainting algorithm\nbased on Kriging interpolation technique was proposed. Kriging technique\nautomatically fills the damaged region in an image using the information\navailable from its surrounding regions in such away that it uses the spatial\ncorrelation structure of points inside the k-by-k block. Kriging has the\nability to face the challenge of keeping the structure and texture information\nas the size of damaged region heighten. Experimental results showed that,\nKriging has a high PSNR value when recovering a variety of test images from\nscratches and text as damaged regions.\n",
        "published": "2013-06-01T19:16:43Z",
        "pdf_link": "http://arxiv.org/pdf/1306.0139v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.0152v1",
        "title": "An Analysis of the Connections Between Layers of Deep Neural Networks",
        "summary": "  We present an analysis of different techniques for selecting the connection\nbe- tween layers of deep neural networks. Traditional deep neural networks use\nran- dom connection tables between layers to keep the number of connections\nsmall and tune to different image features. This kind of connection performs\nadequately in supervised deep networks because their values are refined during\nthe training. On the other hand, in unsupervised learning, one cannot rely on\nback-propagation techniques to learn the connections between layers. In this\nwork, we tested four different techniques for connecting the first layer of the\nnetwork to the second layer on the CIFAR and SVHN datasets and showed that the\naccuracy can be im- proved up to 3% depending on the technique used. We also\nshowed that learning the connections based on the co-occurrences of the\nfeatures does not confer an advantage over a random connection table in small\nnetworks. This work is helpful to improve the efficiency of connections between\nthe layers of unsupervised deep neural networks.\n",
        "published": "2013-06-01T21:37:25Z",
        "pdf_link": "http://arxiv.org/pdf/1306.0152v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.0974v1",
        "title": "Distributed Bayesian inference for consistent labeling of tracked\n  objects in non-overlapping camera networks",
        "summary": "  One of the fundamental requirements for visual surveillance using\nnon-overlapping camera networks is the correct labeling of tracked objects on\neach camera in a consistent way,in the sense that the captured tracklets, or\nobservations in this paper, of the same object at different cameras should be\nassigned with the same label. In this paper, we formulate this task as a\nBayesian inference problem and propose a distributed inference framework in\nwhich the posterior distribution of labeling variable corresponding to each\nobservation, conditioned on all history appearance and spatio-temporal evidence\nmade in the whole networks, is calculated based solely on local information\nprocessing on each camera and mutual information exchanging between neighboring\ncameras. In our framework, the number of objects presenting in the monitored\nregion, i.e. the sampling space of labeling variables, does not need to be\nspecified beforehand. Instead, it can be determined automatically on the fly.\nIn addition, we make no assumption about the appearance distribution of a\nsingle object, but use similarity scores between appearance pairs, given by\nadvanced object re-identification algorithm, as appearance likelihood for\ninference. This feature makes our method very flexible and competitive when\nobserving condition undergoes large changes across camera views. To cope with\nthe problem of missing detection, which is critical for distributed inference,\nwe consider an enlarged neighborhood of each camera during inference and use a\nmixture model to describe the higher order spatio-temporal constraints. The\nrobustness of the algorithm against missing detection is improved at the cost\nof slightly increased computation and communication burden at each camera node.\nFinally, we demonstrate the effectiveness of our method through experiments on\nan indoor Office Building dataset and an outdoor Campus Garden dataset.\n",
        "published": "2013-06-05T03:50:58Z",
        "pdf_link": "http://arxiv.org/pdf/1306.0974v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.1301v1",
        "title": "Recognition of Indian Sign Language in Live Video",
        "summary": "  Sign Language Recognition has emerged as one of the important area of\nresearch in Computer Vision. The difficulty faced by the researchers is that\nthe instances of signs vary with both motion and appearance. Thus, in this\npaper a novel approach for recognizing various alphabets of Indian Sign\nLanguage is proposed where continuous video sequences of the signs have been\nconsidered. The proposed system comprises of three stages: Preprocessing stage,\nFeature Extraction and Classification. Preprocessing stage includes skin\nfiltering, histogram matching. Eigen values and Eigen Vectors were considered\nfor feature extraction stage and finally Eigen value weighted Euclidean\ndistance is used to recognize the sign. It deals with bare hands, thus allowing\nthe user to interact with the system in natural way. We have considered 24\ndifferent alphabets in the video sequences and attained a success rate of\n96.25%.\n",
        "published": "2013-06-06T05:40:06Z",
        "pdf_link": "http://arxiv.org/pdf/1306.1301v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.1462v1",
        "title": "K-Algorithm A Modified Technique for Noise Removal in Handwritten\n  Documents",
        "summary": "  OCR has been an active research area since last few decades. OCR performs the\nrecognition of the text in the scanned document image and converts it into\neditable form. The OCR process can have several stages like pre-processing,\nsegmentation, recognition and post processing. The pre-processing stage is a\ncrucial stage for the success of OCR, which mainly deals with noise removal. In\nthe present paper, a modified technique for noise removal named as K-Algorithm\nhas been proposed, which has two stages as filtering and binarization. The\nproposed technique shows improvised results in comparison to median filtering\ntechnique.\n",
        "published": "2013-06-06T16:30:57Z",
        "pdf_link": "http://arxiv.org/pdf/1306.1462v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.1603v1",
        "title": "Infrared face recognition: a literature review",
        "summary": "  Automatic face recognition (AFR) is an area with immense practical potential\nwhich includes a wide range of commercial and law enforcement applications, and\nit continues to be one of the most active research areas of computer vision.\nEven after over three decades of intense research, the state-of-the-art in AFR\ncontinues to improve, benefiting from advances in a range of different fields\nincluding image processing, pattern recognition, computer graphics and\nphysiology. However, systems based on visible spectrum images continue to face\nchallenges in the presence of illumination, pose and expression changes, as\nwell as facial disguises, all of which can significantly decrease their\naccuracy. Amongst various approaches which have been proposed in an attempt to\novercome these limitations, the use of infrared (IR) imaging has emerged as a\nparticularly promising research direction. This paper presents a comprehensive\nand timely review of the literature on this subject.\n",
        "published": "2013-06-07T03:57:53Z",
        "pdf_link": "http://arxiv.org/pdf/1306.1603v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.1609v1",
        "title": "Vesselness features and the inverse compositional AAM for robust face\n  recognition using thermal IR",
        "summary": "  Over the course of the last decade, infrared (IR) and particularly thermal IR\nimaging based face recognition has emerged as a promising complement to\nconventional, visible spectrum based approaches which continue to struggle when\napplied in the real world. While inherently insensitive to visible spectrum\nillumination changes, IR images introduce specific challenges of their own,\nmost notably sensitivity to factors which affect facial heat emission patterns,\ne.g. emotional state, ambient temperature, and alcohol intake. In addition,\nfacial expression and pose changes are more difficult to correct in IR images\nbecause they are less rich in high frequency detail which is an important cue\nfor fitting any deformable model. We describe a novel method which addresses\nthese challenges. To normalize for pose and facial expression changes we\ngenerate a synthetic frontal image of a face in a canonical, neutral facial\nexpression from an image of the face in an arbitrary pose and facial\nexpression. This is achieved by piecewise affine warping which follows active\nappearance model (AAM) fitting. This is the first publication which explores\nthe use of an AAM on thermal IR images; we propose a pre-processing step which\nenhances detail in thermal images, making AAM convergence faster and more\naccurate. To overcome the problem of thermal IR image sensitivity to the\npattern of facial temperature emissions we describe a representation based on\nreliable anatomical features. In contrast to previous approaches, our\nrepresentation is not binary; rather, our method accounts for the reliability\nof the extracted features. This makes the proposed representation much more\nrobust both to pose and scale changes. The effectiveness of the proposed\napproach is demonstrated on the largest public database of thermal IR images of\nfaces on which it achieved 100% identification, significantly outperforming\nprevious methods.\n",
        "published": "2013-06-07T05:03:16Z",
        "pdf_link": "http://arxiv.org/pdf/1306.1609v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.1619v1",
        "title": "Statistical Denoising for single molecule fluorescence microscopic\n  images",
        "summary": "  Single molecule fluorescence microscopy is a powerful technique for\nuncovering detailed information about biological systems, both in vitro and in\nvivo. In such experiments, the inherently low signal to noise ratios mean that\naccurate algorithms to separate true signal and background noise are essential\nto generate meaningful results. To this end, we have developed a new and robust\nmethod to reduce noise in single molecule fluorescence images by using a\nGaussian Markov Random Field (GMRF) prior in a Bayesian framework. Two\ndifferent strategies are proposed to build the prior - an intrinsic GMRF, with\na stationary relationship between pixels and a heterogeneous intrinsic GMRF,\nwith a differently weighted relationship between pixels classified as molecules\nand background. Testing with synthetic and real experimental fluorescence\nimages demonstrates that the heterogeneous intrinsic GMRF is superior to other\nconventional de-noising approaches.\n",
        "published": "2013-06-07T05:39:48Z",
        "pdf_link": "http://arxiv.org/pdf/1306.1619v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.1822v1",
        "title": "Illumination-invariant face recognition from a single image across\n  extreme pose using a dual dimension AAM ensemble in the thermal infrared\n  spectrum",
        "summary": "  Over the course of the last decade, infrared (IR) and particularly thermal IR\nimaging based face recognition has emerged as a promising complement to\nconventional, visible spectrum based approaches which continue to struggle when\napplied in practice. While inherently insensitive to visible spectrum\nillumination changes, IR data introduces specific challenges of its own, most\nnotably sensitivity to factors which affect facial heat emission patterns, e.g.\nemotional state, ambient temperature, and alcohol intake. In addition, facial\nexpression and pose changes are more difficult to correct in IR images because\nthey are less rich in high frequency detail which is an important cue for\nfitting any deformable model. In this paper we describe a novel method which\naddresses these major challenges. Specifically, when comparing two thermal IR\nimages of faces, we mutually normalize their poses and facial expressions by\nusing an active appearance model (AAM) to generate synthetic images of the two\nfaces with a neutral facial expression and in the same view (the average of the\ntwo input views). This is achieved by piecewise affine warping which follows\nAAM fitting. A major contribution of our work is the use of an AAM ensemble in\nwhich each AAM is specialized to a particular range of poses and a particular\nregion of the thermal IR face space. Combined with the contributions from our\nprevious work which addressed the problem of reliable AAM fitting in the\nthermal IR spectrum, and the development of a person-specific representation\nrobust to transient changes in the pattern of facial temperature emissions, the\nproposed ensemble framework accurately matches faces across the full range of\nyaw from frontal to profile, even in the presence of scale variation (e.g. due\nto the varying distance of a subject from the camera).\n",
        "published": "2013-06-07T04:17:25Z",
        "pdf_link": "http://arxiv.org/pdf/1306.1822v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.1894v1",
        "title": "Speckle Reduction with Adaptive Stack Filters",
        "summary": "  Stack filters are a special case of non-linear filters. They have a good\nperformance for filtering images with different types of noise while preserving\nedges and details. A stack filter decomposes an input image into stacks of\nbinary images according to a set of thresholds. Each binary image is then\nfiltered by a Boolean function, which characterizes the filter. Adaptive stack\nfilters can be computed by training using a prototype (ideal) image and its\ncorrupted version, leading to optimized filters with respect to a loss\nfunction. In this work we propose the use of training with selected samples for\nthe estimation of the optimal Boolean function. We study the performance of\nadaptive stack filters when they are applied to speckled imagery, in particular\nto Synthetic Aperture Radar (SAR) images. This is done by evaluating the\nquality of the filtered images through the use of suitable image quality\nindexes and by measuring the classification accuracy of the resulting images.\nWe used SAR images as input, since they are affected by speckle noise that\nmakes classification a difficult task.\n",
        "published": "2013-06-08T08:21:06Z",
        "pdf_link": "http://arxiv.org/pdf/1306.1894v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.2100v1",
        "title": "Discriminative extended canonical correlation analysis for pattern set\n  matching",
        "summary": "  In this paper we address the problem of matching sets of vectors embedded in\nthe same input space. We propose an approach which is motivated by canonical\ncorrelation analysis (CCA), a statistical technique which has proven successful\nin a wide variety of pattern recognition problems. Like CCA when applied to the\nmatching of sets, our extended canonical correlation analysis (E-CCA) aims to\nextract the most similar modes of variability within two sets. Our first major\ncontribution is the formulation of a principled framework for robust inference\nof such modes from data in the presence of uncertainty associated with noise\nand sampling randomness. E-CCA retains the efficiency and closed form\ncomputability of CCA, but unlike it, does not possess free parameters which\ncannot be inferred directly from data (inherent data dimensionality, and the\nnumber of canonical correlations used for set similarity computation). Our\nsecond major contribution is to show that in contrast to CCA, E-CCA is readily\nadapted to match sets in a discriminative learning scheme which we call\ndiscriminative extended canonical correlation analysis (DE-CCA). Theoretical\ncontributions of this paper are followed by an empirical evaluation of its\npremises on the task of face recognition from sets of rasterized appearance\nimages. The results demonstrate that our approach, E-CCA, already outperforms\nboth CCA and its quasi-discriminative counterpart constrained CCA (C-CCA), for\nall values of their free parameters. An even greater improvement is achieved\nwith the discriminative variant, DE-CCA.\n",
        "published": "2013-06-10T04:41:37Z",
        "pdf_link": "http://arxiv.org/pdf/1306.2100v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.2102v1",
        "title": "Discriminative k-means clustering",
        "summary": "  The k-means algorithm is a partitional clustering method. Over 60 years old,\nit has been successfully used for a variety of problems. The popularity of\nk-means is in large part a consequence of its simplicity and efficiency. In\nthis paper we are inspired by these appealing properties of k-means in the\ndevelopment of a clustering algorithm which accepts the notion of \"positively\"\nand \"negatively\" labelled data. The goal is to discover the cluster structure\nof both positive and negative data in a manner which allows for the\ndiscrimination between the two sets. The usefulness of this idea is\ndemonstrated practically on the problem of face recognition, where the task of\nlearning the scope of a person's appearance should be done in a manner which\nallows this face to be differentiated from others.\n",
        "published": "2013-06-10T04:59:05Z",
        "pdf_link": "http://arxiv.org/pdf/1306.2102v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.2159v1",
        "title": "Image segmentation by optimal and hierarchical piecewise constant\n  approximations",
        "summary": "  Piecewise constant image approximations of sequential number of segments or\nclusters of disconnected pixels are treated. The method of majorizing of\noptimal approximation sequence by hierarchical sequence of image approximations\nis proposed. A generalization for multidimensional case of color and\nmultispectral images is foreseen.\n",
        "published": "2013-06-10T10:35:26Z",
        "pdf_link": "http://arxiv.org/pdf/1306.2159v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.2599v1",
        "title": "Hand Gesture Recognition Based on Karhunen-Loeve Transform",
        "summary": "  In this paper, we have proposed a system based on K-L Transform to recognize\ndifferent hand gestures. The system consists of five steps: skin filtering,\npalm cropping, edge detection, feature extraction, and classification. Firstly\nthe hand is detected using skin filtering and palm cropping was performed to\nextract out only the palm portion of the hand. The extracted image was then\nprocessed using the Canny Edge Detection technique to extract the outline\nimages of palm. After palm extraction, the features of hand were extracted\nusing K-L Transform technique and finally the input gesture was recognized\nusing proper classifier. In our system, we have tested for 10 different hand\ngestures, and recognizing rate obtained was 96%. Hence we propose an easy\napproach to recognize different hand gestures.\n",
        "published": "2013-06-11T18:03:06Z",
        "pdf_link": "http://arxiv.org/pdf/1306.2599v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.2795v1",
        "title": "Recurrent Convolutional Neural Networks for Scene Parsing",
        "summary": "  Scene parsing is a technique that consist on giving a label to all pixels in\nan image according to the class they belong to. To ensure a good visual\ncoherence and a high class accuracy, it is essential for a scene parser to\ncapture image long range dependencies. In a feed-forward architecture, this can\nbe simply achieved by considering a sufficiently large input context patch,\naround each pixel to be labeled. We propose an approach consisting of a\nrecurrent convolutional neural network which allows us to consider a large\ninput context, while limiting the capacity of the model. Contrary to most\nstandard approaches, our method does not rely on any segmentation methods, nor\nany task-specific features. The system is trained in an end-to-end manner over\nraw pixels, and models complex spatial dependencies with low inference cost. As\nthe context size increases with the built-in recurrence, the system identifies\nand corrects its own errors. Our approach yields state-of-the-art performance\non both the Stanford Background Dataset and the SIFT Flow Dataset, while\nremaining very fast at test time.\n",
        "published": "2013-06-12T11:56:57Z",
        "pdf_link": "http://arxiv.org/pdf/1306.2795v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.2967v3",
        "title": "Optimization of Clustering for Clustering-based Image Denoising",
        "summary": "  In this paper, the problem of de-noising of an image contaminated with\nadditive white Gaussian noise (AWGN) is studied. This subject has been\ncontinued to be an open problem in signal processing for more than 50 years. In\nthe present paper, we suggest a method based on global clustering of image\nconstructing blocks. Noting that the type of clustering plays an important role\nin clustering-based de-noising methods, we address two questions about the\nclustering. First, which parts of data should be considered for clustering?\nSecond, what data clustering method is suitable for de-noising? Clustering is\nexploited to learn an over complete dictionary. By obtaining sparse\ndecomposition of the noisy image blocks in terms of the dictionary atoms, the\nde-noised version is achieved. Experimental results show that our dictionary\nlearning framework outperforms traditional dictionary learning methods such as\nK-SVD.\n",
        "published": "2013-06-12T20:23:07Z",
        "pdf_link": "http://arxiv.org/pdf/1306.2967v3"
    },
    {
        "id": "http://arxiv.org/abs/1306.3032v1",
        "title": "A Face-like Structure Detection on Planet and Satellite Surfaces using\n  Image Processing",
        "summary": "  This paper demonstrates that face-like structures are everywhere, and can be\nde-tected automatically even with computers. Huge amount of satellite images of\nthe Earth, the Moon, the Mars are explored and many interesting face-like\nstructure are detected. Throughout this fact, we believe that science and\ntechnologies can alert people not to easily become an occultist.\n",
        "published": "2013-06-13T06:28:07Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3032v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.3084v1",
        "title": "Segmentation et Interprtation de Nuages de Points pour la\n  Modlisation d'Environnements Urbains",
        "summary": "  Dans cet article, nous pr\\'esentons une m\\'ethode pour la d\\'etection et la\nclassification d'artefacts au niveau du sol, comme phase de filtrage\npr\\'ealable \\`a la mod\\'elisation d'environnements urbains. La m\\'ethode de\nd\\'etection est r\\'ealis\\'ee sur l'image profondeur, une projection de nuage de\npoints sur un plan image o\\`u la valeur du pixel correspond \\`a la distance du\npoint au plan. En faisant l'hypoth\\`ese que les artefacts sont situ\\'es au sol,\nils sont d\\'etect\\'es par une transformation de chapeau haut de forme par\nremplissage de trous sur l'image de profondeur. Les composantes connexes ainsi\nobtenues, sont ensuite caract\\'eris\\'ees et une analyse des variables est\nutilis\\'ee pour la s\\'election des caract\\'eristiques les plus discriminantes.\nLes composantes connexes sont donc classifi\\'ees en quatre cat\\'egories\n(lampadaires, pi\\'etons, voitures et \"Reste\") \\`a l'aide d'un algorithme\nd'apprentissage supervis\\'e. La m\\'ethode a \\'et\\'e test\\'ee sur des nuages de\npoints de la ville de Paris, en montrant de bons r\\'esultats de d\\'etection et\nde classification dans l'ensemble de donn\\'ees.---In this article, we present a\nmethod for detection and classification of artifacts at the street level, in\norder to filter cloud point, facilitating the urban modeling process. Our\napproach exploits 3D information by using range image, a projection of 3D\npoints onto an image plane where the pixel intensity is a function of the\nmeasured distance between 3D points and the plane. By assuming that the\nartifacts are on the ground, they are detected using a Top-Hat of the hole\nfilling algorithm of range images. Then, several features are extracted from\nthe detected connected components and a stepwise forward variable/model\nselection by using the Wilk's Lambda criterion is performed. Afterward, CCs are\nclassified in four categories (lampposts, pedestrians, cars and others) by\nusing a supervised machine learning method. The proposed method was tested on\ncloud points of Paris, and have shown satisfactory results on the whole\ndataset.\n",
        "published": "2013-06-13T11:27:58Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3084v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.3294v1",
        "title": "Feature Learning by Multidimensional Scaling and its Applications in\n  Object Recognition",
        "summary": "  We present the MDS feature learning framework, in which multidimensional\nscaling (MDS) is applied on high-level pairwise image distances to learn\nfixed-length vector representations of images. The aspects of the images that\nare captured by the learned features, which we call MDS features, completely\ndepend on what kind of image distance measurement is employed. With properly\nselected semantics-sensitive image distances, the MDS features provide rich\nsemantic information about the images that is not captured by other feature\nextraction techniques. In our work, we introduce the iterated\nLevenberg-Marquardt algorithm for solving MDS, and study the MDS feature\nlearning with IMage Euclidean Distance (IMED) and Spatial Pyramid Matching\n(SPM) distance. We present experiments on both synthetic data and real images\n--- the publicly accessible UIUC car image dataset. The MDS features based on\nSPM distance achieve exceptional performance for the car recognition task.\n",
        "published": "2013-06-14T04:43:40Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3294v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.3297v1",
        "title": "Matching objects across the textured-smooth continuum",
        "summary": "  The problem of 3D object recognition is of immense practical importance, with\nthe last decade witnessing a number of breakthroughs in the state of the art.\nMost of the previous work has focused on the matching of textured objects using\nlocal appearance descriptors extracted around salient image points. The\nrecently proposed bag of boundaries method was the first to address directly\nthe problem of matching smooth objects using boundary features. However, no\nprevious work has attempted to achieve a holistic treatment of the problem by\njointly using textural and shape features which is what we describe herein. Due\nto the complementarity of the two modalities, we fuse the corresponding\nmatching scores and learn their relative weighting in a data specific manner by\noptimizing discriminative performance on synthetically distorted data. For the\ntextural description of an object we adopt a representation in the form of a\nhistogram of SIFT based visual words. Similarly the apparent shape of an object\nis represented by a histogram of discretized features capturing local shape. On\na large public database of a diverse set of objects, the proposed method is\nshown to outperform significantly both purely textural and purely shape based\napproaches for matching across viewpoint variation.\n",
        "published": "2013-06-14T05:52:58Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3297v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.3415v1",
        "title": "Live-wire 3D medical images segmentation",
        "summary": "  This report describes the design, implementation, evaluation and original\nenhancements to the Live-Wire method for 2D and 3D image segmentation.\nLive-Wire 2D employs a semi-automatic paradigm; the user is asked to select a\nfew boundary points of the object to segment, to steer the process in the right\ndirection, while the result is displayed in real time. In our implementation\nsegmentation is extended to three dimensions by performing this process on a\nslice-by-slice basis. User's time and involvement is further reduced by\nallowing him to specify object contours in planes orthogonal to the slices. If\nthese planes are chosen strategically, Live-Wire 3D can perform 2D segmentation\nin the plane of each slice automatically. This report also proposes two\nimprovements to the original method, path heating and a new graph edge feature\nfunction based on variance of path properties along the boundary. We show that\nthese improvements lead up to a 33% reduction in interaction with the user, and\nimproved delineation in presence of strong interfering edges.\n",
        "published": "2013-06-14T14:52:10Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3415v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.3560v1",
        "title": "iCub World: Friendly Robots Help Building Good Vision Data-Sets",
        "summary": "  In this paper we present and start analyzing the iCub World data-set, an\nobject recognition data-set, we acquired using a Human-Robot Interaction (HRI)\nscheme and the iCub humanoid robot platform. Our set up allows for rapid\nacquisition and annotation of data with corresponding ground truth. While more\nconstrained in its scopes -- the iCub world is essentially a robotics research\nlab -- we demonstrate how the proposed data-set poses challenges to current\nrecognition systems. The iCubWorld data-set is publicly available. The data-set\ncan be downloaded from: http://www.iit.it/en/projects/data-sets.html.\n",
        "published": "2013-06-15T09:27:17Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3560v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.3828v1",
        "title": "Non-Uniform Blind Deblurring with a Spatially-Adaptive Sparse Prior",
        "summary": "  Typical blur from camera shake often deviates from the standard uniform\nconvolutional script, in part because of problematic rotations which create\ngreater blurring away from some unknown center point. Consequently, successful\nblind deconvolution requires the estimation of a spatially-varying or\nnon-uniform blur operator. Using ideas from Bayesian inference and convex\nanalysis, this paper derives a non-uniform blind deblurring algorithm with\nseveral desirable, yet previously-unexplored attributes. The underlying\nobjective function includes a spatially adaptive penalty which couples the\nlatent sharp image, non-uniform blur operator, and noise level together. This\ncoupling allows the penalty to automatically adjust its shape based on the\nestimated degree of local blur and image structure such that regions with large\nblur or few prominent edges are discounted. Remaining regions with modest blur\nand revealing edges therefore dominate the overall estimation process without\nexplicitly incorporating structure-selection heuristics. The algorithm can be\nimplemented using a majorization-minimization strategy that is virtually\nparameter free. Detailed theoretical analysis and empirical validation on real\nimages serve to validate the proposed method.\n",
        "published": "2013-06-17T12:12:22Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3828v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.3855v2",
        "title": "Two-View Matching with View Synthesis Revisited",
        "summary": "  Wide-baseline matching focussing on problems with extreme viewpoint change is\nconsidered. We introduce the use of view synthesis with affine-covariant\ndetectors to solve such problems and show that matching with the Hessian-Affine\nor MSER detectors outperforms the state-of-the-art ASIFT.\n  To minimise the loss of speed caused by view synthesis, we propose the\nMatching On Demand with view Synthesis algorithm (MODS) that uses progressively\nmore synthesized images and more (time-consuming) detectors until reliable\nestimation of geometry is possible. We show experimentally that the MODS\nalgorithm solves problems beyond the state-of-the-art and yet is comparable in\nspeed to standard wide-baseline matchers on simpler problems.\n  Minor contributions include an improved method for tentative correspondence\nselection, applicable both with and without view synthesis and a view synthesis\nsetup greatly improving MSER robustness to blur and scale change that increase\nits running time by 10% only.\n",
        "published": "2013-06-17T13:44:25Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3855v2"
    },
    {
        "id": "http://arxiv.org/abs/1306.3874v2",
        "title": "Classifying and Visualizing Motion Capture Sequences using Deep Neural\n  Networks",
        "summary": "  The gesture recognition using motion capture data and depth sensors has\nrecently drawn more attention in vision recognition. Currently most systems\nonly classify dataset with a couple of dozens different actions. Moreover,\nfeature extraction from the data is often computational complex. In this paper,\nwe propose a novel system to recognize the actions from skeleton data with\nsimple, but effective, features using deep neural networks. Features are\nextracted for each frame based on the relative positions of joints (PO),\ntemporal differences (TD), and normalized trajectories of motion (NT). Given\nthese features a hybrid multi-layer perceptron is trained, which simultaneously\nclassifies and reconstructs input data. We use deep autoencoder to visualize\nlearnt features, and the experiments show that deep neural networks can capture\nmore discriminative information than, for instance, principal component\nanalysis can. We test our system on a public database with 65 classes and more\nthan 2,000 motion sequences. We obtain an accuracy above 95% which is, to our\nknowledge, the state of the art result for such a large dataset.\n",
        "published": "2013-06-17T14:26:52Z",
        "pdf_link": "http://arxiv.org/pdf/1306.3874v2"
    },
    {
        "id": "http://arxiv.org/abs/1306.4079v1",
        "title": "A Novel Block-DCT and PCA Based Image Perceptual Hashing Algorithm",
        "summary": "  Image perceptual hashing finds applications in content indexing, large-scale\nimage database management, certification and authentication and digital\nwatermarking. We propose a Block-DCT and PCA based image perceptual hash in\nthis article and explore the algorithm in the application of tamper detection.\nThe main idea of the algorithm is to integrate color histogram and DCT\ncoefficients of image blocks as perceptual feature, then to compress perceptual\nfeatures as inter-feature with PCA, and to threshold to create a robust hash.\nThe robustness and discrimination properties of the proposed algorithm are\nevaluated in detail. Our algorithms first construct a secondary image, derived\nfrom input image by pseudo-randomly extracting features that approximately\ncapture semi-global geometric characteristics. From the secondary image (which\ndoes not perceptually resemble the input), we further extract the final\nfeatures which can be used as a hash value (and can be further suitably\nquantized). In this paper, we use spectral matrix invariants as embodied by\nSingular Value Decomposition. Surprisingly, formation of the secondary image\nturns out be quite important since it not only introduces further robustness,\nbut also enhances the security properties. Indeed, our experiments reveal that\nour hashing algorithms extract most of the geometric information from the\nimages and hence are robust to severe perturbations (e.g. up to %50 cropping by\narea with 20 degree rotations) on images while avoiding misclassification.\nExperimental results show that the proposed image perceptual hash algorithm can\neffectively address the tamper detection problem with advantageous robustness\nand discrimination.\n",
        "published": "2013-06-18T06:58:58Z",
        "pdf_link": "http://arxiv.org/pdf/1306.4079v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.4345v1",
        "title": "An Overview of the Research on Texture Based Plant Leaf Classification",
        "summary": "  Plant classification has a broad application prospective in agriculture and\nmedicine, and is especially significant to the biology diversity research. As\nplants are vitally important for environmental protection, it is more important\nto identify and classify them accurately. Plant leaf classification is a\ntechnique where leaf is classified based on its different morphological\nfeatures. The goal of this paper is to provide an overview of different aspects\nof texture based plant leaf classification and related things. At last we will\nbe concluding about the efficient method i.e. the method that gives better\nperformance compared to the other methods.\n",
        "published": "2013-06-18T20:38:07Z",
        "pdf_link": "http://arxiv.org/pdf/1306.4345v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.4746v1",
        "title": "Felzenszwalb-Baum-Welch: Event Detection by Changing Appearance",
        "summary": "  We propose a method which can detect events in videos by modeling the change\nin appearance of the event participants over time. This method makes it\npossible to detect events which are characterized not by motion, but by the\nchanging state of the people or objects involved. This is accomplished by using\nobject detectors as output models for the states of a hidden Markov model\n(HMM). The method allows an HMM to model the sequence of poses of the event\nparticipants over time, and is effective for poses of humans and inanimate\nobjects. The ability to use existing object-detection methods as part of an\nevent model makes it possible to leverage ongoing work in the object-detection\ncommunity. A novel training method uses an EM loop to simultaneously learn the\ntemporal structure and object models automatically, without the need to specify\neither the individual poses to be modeled or the frames in which they occur.\nThe E-step estimates the latent assignment of video frames to HMM states, while\nthe M-step estimates both the HMM transition probabilities and state output\nmodels, including the object detectors, which are trained on the weighted\nsubset of frames assigned to their state. A new dataset was gathered because\nlittle work has been done on events characterized by changing object pose, and\nsuitable datasets are not available. Our method produced results superior to\nthat of comparison systems on this dataset.\n",
        "published": "2013-06-20T03:22:19Z",
        "pdf_link": "http://arxiv.org/pdf/1306.4746v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.5096v1",
        "title": "Computer Aided ECG Analysis - State of the Art and Upcoming Challenges",
        "summary": "  In this paper we present current achievements in computer aided ECG analysis\nand their applicability in real world medical diagnosis process. Most of the\ncurrent work is covering problems of removing noise, detecting heartbeats and\nrhythm-based analysis. There are some advancements in particular ECG segments\ndetection and beat classifications but with limited evaluations and without\nclinical approvals. This paper presents state of the art advancements in those\nareas till present day. Besides this short computer science and signal\nprocessing literature review, paper covers future challenges regarding the ECG\nsignal morphology analysis deriving from the medical literature review. Paper\nis concluded with identified gaps in current advancements and testing, upcoming\nchallenges for future research and a bullseye test is suggested for morphology\nanalysis evaluation.\n",
        "published": "2013-06-21T11:09:18Z",
        "pdf_link": "http://arxiv.org/pdf/1306.5096v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.5151v1",
        "title": "Fine-Grained Visual Classification of Aircraft",
        "summary": "  This paper introduces FGVC-Aircraft, a new dataset containing 10,000 images\nof aircraft spanning 100 aircraft models, organised in a three-level hierarchy.\nAt the finer level, differences between models are often subtle but always\nvisually measurable, making visual recognition challenging but possible. A\nbenchmark is obtained by defining corresponding classification tasks and\nevaluation protocols, and baseline results are presented. The construction of\nthis dataset was made possible by the work of aircraft enthusiasts, a strategy\nthat can extend to the study of number of other object classes. Compared to the\ndomains usually considered in fine-grained visual classification (FGVC), for\nexample animals, aircraft are rigid and hence less deformable. They, however,\npresent other interesting modes of variation, including purpose, size,\ndesignation, structure, historical style, and branding.\n",
        "published": "2013-06-21T14:31:57Z",
        "pdf_link": "http://arxiv.org/pdf/1306.5151v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.5293v1",
        "title": "New Approach of Estimating PSNR-B For De-blocked Images",
        "summary": "  Measurement of image quality is very crucial to many image processing\napplications. Quality metrics are used to measure the quality of improvement in\nthe images after they are processed and compared with the original images.\nCompression is one of the applications where it is required to monitor the\nquality of decompressed or decoded image. JPEG compression is the lossy\ncompression which is most prevalent technique for image codecs. But it suffers\nfrom blocking artifacts. Various deblocking filters are used to reduce blocking\nartifacts. The efficiency of deblocking filters which improves visual signals\ndegraded by blocking artifacts from compression will also be studied. Objective\nquality metrics like PSNR, SSIM, and PSNRB for analyzing the quality of\ndeblocked images will be studied. We introduce a new approach of PSNR-B for\nanalyzing quality of deblocked images. Simulation results show that new\napproach of PSNR-B called modified PSNR-B. it gives even better results\ncompared to existing well known blockiness specific indices\n",
        "published": "2013-06-22T06:12:26Z",
        "pdf_link": "http://arxiv.org/pdf/1306.5293v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.6058v2",
        "title": "A maximal-information color to gray conversion method for document\n  images: Toward an optimal grayscale representation for document image\n  binarization",
        "summary": "  A novel method to convert color/multi-spectral images to gray-level images is\nintroduced to increase the performance of document binarization methods. The\nmethod uses the distribution of the pixel data of the input document image in a\ncolor space to find a transformation, called the dual transform, which balances\nthe amount of information on all color channels. Furthermore, in order to\nreduce the intensity variations on the gray output, a color reduction\npreprocessing step is applied. Then, a channel is selected as the gray value\nrepresentation of the document image based on the homogeneity criterion on the\ntext regions. In this way, the proposed method can provide a\nluminance-independent contrast enhancement. The performance of the method is\nevaluated against various images from two databases, the ICDAR'03 Robust\nReading, the KAIST and the DIBCO'09 datasets, subjectively and objectively with\npromising results. The ground truth images for the images from the ICDAR'03\nRobust Reading dataset have been created manually by the authors.\n",
        "published": "2013-06-25T18:41:04Z",
        "pdf_link": "http://arxiv.org/pdf/1306.6058v2"
    },
    {
        "id": "http://arxiv.org/abs/1306.6263v2",
        "title": "Persian Heritage Image Binarization Competition (PHIBC 2012)",
        "summary": "  The first competition on the binarization of historical Persian documents and\nmanuscripts (PHIBC 2012) has been organized in conjunction with the first\nIranian conference on pattern recognition and image analysis (PRIA 2013). The\nmain objective of PHIBC 2012 is to evaluate performance of the binarization\nmethodologies, when applied on the Persian heritage images. This paper provides\na report on the methodology and performance of the three submitted algorithms\nbased on evaluation measures has been used.\n",
        "published": "2013-06-26T14:56:00Z",
        "pdf_link": "http://arxiv.org/pdf/1306.6263v2"
    },
    {
        "id": "http://arxiv.org/abs/1306.6269v2",
        "title": "Active Contour Models for Manifold Valued Image Segmentation",
        "summary": "  Image segmentation is the process of partitioning a image into different\nregions or groups based on some characteristics like color, texture, motion or\nshape etc. Active contours is a popular variational method for object\nsegmentation in images, in which the user initializes a contour which evolves\nin order to optimize an objective function designed such that the desired\nobject boundary is the optimal solution. Recently, imaging modalities that\nproduce Manifold valued images have come up, for example, DT-MRI images, vector\nfields. The traditional active contour model does not work on such images. In\nthis paper, we generalize the active contour model to work on Manifold valued\nimages. As expected, our algorithm detects regions with similar Manifold values\nin the image. Our algorithm also produces expected results on usual gray-scale\nimages, since these are nothing but trivial examples of Manifold valued images.\nAs another application of our general active contour model, we perform texture\nsegmentation on gray-scale images by first creating an appropriate Manifold\nvalued image. We demonstrate segmentation results for manifold valued images\nand texture images.\n",
        "published": "2013-06-26T15:16:54Z",
        "pdf_link": "http://arxiv.org/pdf/1306.6269v2"
    },
    {
        "id": "http://arxiv.org/abs/1306.6726v1",
        "title": "A Novel Active Contour Model for Texture Segmentation",
        "summary": "  Texture is intuitively defined as a repeated arrangement of a basic pattern\nor object in an image. There is no mathematical definition of a texture though.\nThe human visual system is able to identify and segment different textures in a\ngiven image. Automating this task for a computer is far from trivial. There are\nthree major components of any texture segmentation algorithm: (a) The features\nused to represent a texture, (b) the metric induced on this representation\nspace and (c) the clustering algorithm that runs over these features in order\nto segment a given image into different textures. In this paper, we propose an\nactive contour based novel unsupervised algorithm for texture segmentation. We\nuse intensity covariance matrices of regions as the defining feature of\ntextures and find regions that have the most inter-region dissimilar covariance\nmatrices using active contours. Since covariance matrices are symmetric\npositive definite, we use geodesic distance defined on the manifold of\nsymmetric positive definite matrices PD(n) as a measure of dissimlarity between\nsuch matrices. We demonstrate performance of our algorithm on both artificial\nand real texture images.\n",
        "published": "2013-06-28T06:32:42Z",
        "pdf_link": "http://arxiv.org/pdf/1306.6726v1"
    },
    {
        "id": "http://arxiv.org/abs/1306.6842v1",
        "title": "New Mathematical and Algorithmic Schemes for Pattern Classification with\n  Application to the Identification of Writers of Important Ancient Documents",
        "summary": "  In this paper, a novel approach is introduced for classifying curves into\nproper families, according to their similarity. First, a mathematical quantity\nwe call plane curvature is introduced and a number of propositions are stated\nand proved. Proper similarity measures of two curves are introduced and a\nsubsequent statistical analysis is applied. First, the efficiency of the curve\nfitting process has been tested on 2 shapes datasets of reference. Next, the\nmethodology has been applied to the very important problem of classifying 23\nByzantine codices and 46 Ancient inscriptions to their writers, thus achieving\ncorrect dating of their content. The inscriptions have been attributed to ten\nindividual hands and the Byzantine codices to four writers.\n",
        "published": "2013-06-28T13:51:18Z",
        "pdf_link": "http://arxiv.org/pdf/1306.6842v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.0271v2",
        "title": "Compositional Dictionaries for Domain Adaptive Face Recognition",
        "summary": "  We present a dictionary learning approach to compensate for the\ntransformation of faces due to changes in view point, illumination, resolution,\netc. The key idea of our approach is to force domain-invariant sparse coding,\ni.e., design a consistent sparse representation of the same face in different\ndomains. In this way, classifiers trained on the sparse codes in the source\ndomain consisting of frontal faces for example can be applied to the target\ndomain (consisting of faces in different poses, illumination conditions, etc)\nwithout much loss in recognition accuracy. The approach is to first learn a\ndomain base dictionary, and then describe each domain shift (identity, pose,\nillumination) using a sparse representation over the base dictionary. The\ndictionary adapted to each domain is expressed as sparse linear combinations of\nthe base dictionary. In the context of face recognition, with the proposed\ncompositional dictionary approach, a face image can be decomposed into sparse\nrepresentations for a given subject, pose and illumination respectively. This\napproach has three advantages: first, the extracted sparse representation for a\nsubject is consistent across domains and enables pose and illumination\ninsensitive face recognition. Second, sparse representations for pose and\nillumination can subsequently be used to estimate the pose and illumination\ncondition of a face image. Finally, by composing sparse representations for\nsubject and the different domains, we can also perform pose alignment and\nillumination normalization. Extensive experiments using two public face\ndatasets are presented to demonstrate the effectiveness of our approach for\nface recognition.\n",
        "published": "2013-08-01T17:27:31Z",
        "pdf_link": "http://arxiv.org/pdf/1308.0271v2"
    },
    {
        "id": "http://arxiv.org/abs/1308.0273v1",
        "title": "Learning Robust Subspace Clustering",
        "summary": "  We propose a low-rank transformation-learning framework to robustify subspace\nclustering. Many high-dimensional data, such as face images and motion\nsequences, lie in a union of low-dimensional subspaces. The subspace clustering\nproblem has been extensively studied in the literature to partition such\nhigh-dimensional data into clusters corresponding to their underlying\nlow-dimensional subspaces. However, low-dimensional intrinsic structures are\noften violated for real-world observations, as they can be corrupted by errors\nor deviate from ideal models. We propose to address this by learning a linear\ntransformation on subspaces using matrix rank, via its convex surrogate nuclear\nnorm, as the optimization criteria. The learned linear transformation restores\na low-rank structure for data from the same subspace, and, at the same time,\nforces a high-rank structure for data from different subspaces. In this way, we\nreduce variations within the subspaces, and increase separations between the\nsubspaces for more accurate subspace clustering. This proposed learned robust\nsubspace clustering framework significantly enhances the performance of\nexisting subspace clustering methods. To exploit the low-rank structures of the\ntransformed subspaces, we further introduce a subspace clustering technique,\ncalled Robust Sparse Subspace Clustering, which efficiently combines robust PCA\nwith sparse modeling. We also discuss the online learning of the\ntransformation, and learning of the transformation while simultaneously\nreducing the data dimensionality. Extensive experiments using public datasets\nare presented, showing that the proposed approach significantly outperforms\nstate-of-the-art subspace clustering methods.\n",
        "published": "2013-08-01T17:31:37Z",
        "pdf_link": "http://arxiv.org/pdf/1308.0273v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.0275v1",
        "title": "Domain-invariant Face Recognition using Learned Low-rank Transformation",
        "summary": "  We present a low-rank transformation approach to compensate for face\nvariations due to changes in visual domains, such as pose and illumination. The\nkey idea is to learn discriminative linear transformations for face images\nusing matrix rank as the optimization criteria. The learned linear\ntransformations restore a shared low-rank structure for faces from the same\nsubject, and, at the same time, force a high-rank structure for faces from\ndifferent subjects. In this way, among the transformed faces, we reduce\nvariations caused by domain changes within the classes, and increase\nseparations between the classes for better face recognition across domains.\nExtensive experiments using public datasets are presented to demonstrate the\neffectiveness of our approach for face recognition across domains. The\npotential of the approach for feature extraction in generic object recognition\nand coded aperture design are discussed as well.\n",
        "published": "2013-08-01T17:34:36Z",
        "pdf_link": "http://arxiv.org/pdf/1308.0275v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.0290v1",
        "title": "Sparse Dictionary-based Attributes for Action Recognition and\n  Summarization",
        "summary": "  We present an approach for dictionary learning of action attributes via\ninformation maximization. We unify the class distribution and appearance\ninformation into an objective function for learning a sparse dictionary of\naction attributes. The objective function maximizes the mutual information\nbetween what has been learned and what remains to be learned in terms of\nappearance information and class distribution for each dictionary atom. We\npropose a Gaussian Process (GP) model for sparse representation to optimize the\ndictionary objective function. The sparse coding property allows a kernel with\ncompact support in GP to realize a very efficient dictionary learning process.\nHence we can describe an action video by a set of compact and discriminative\naction attributes. More importantly, we can recognize modeled action categories\nin a sparse feature space, which can be generalized to unseen and unmodeled\naction categories. Experimental results demonstrate the effectiveness of our\napproach in action recognition and summarization.\n",
        "published": "2013-08-01T18:25:16Z",
        "pdf_link": "http://arxiv.org/pdf/1308.0290v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.0365v1",
        "title": "Hybrid Focal Stereo Networks for Pattern Analysis in Homogeneous Scenes",
        "summary": "  In this paper we address the problem of multiple camera calibration in the\npresence of a homogeneous scene, and without the possibility of employing\ncalibration object based methods. The proposed solution exploits salient\nfeatures present in a larger field of view, but instead of employing active\nvision we replace the cameras with stereo rigs featuring a long focal analysis\ncamera, as well as a short focal registration camera. Thus, we are able to\npropose an accurate solution which does not require intrinsic variation models\nas in the case of zooming cameras. Moreover, the availability of the two views\nsimultaneously in each rig allows for pose re-estimation between rigs as often\nas necessary. The algorithm has been successfully validated in an indoor\nsetting, as well as on a difficult scene featuring a highly dense pilgrim crowd\nin Makkah.\n",
        "published": "2013-08-01T21:58:33Z",
        "pdf_link": "http://arxiv.org/pdf/1308.0365v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.0890v1",
        "title": "Head Gesture Recognition using Optical Flow based Classification with\n  Reinforcement of GMM based Background Subtraction",
        "summary": "  This paper describes a technique of real time head gesture recognition\nsystem. The method includes Gaussian mixture model (GMM) accompanied by optical\nflow algorithm which provided us the required information regarding head\nmovement. The proposed model can be implemented in various control system. We\nare also presenting the result and implementation of both mentioned method.\n",
        "published": "2013-08-05T05:17:26Z",
        "pdf_link": "http://arxiv.org/pdf/1308.0890v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.1126v1",
        "title": "Image interpolation using Shearlet based iterative refinement",
        "summary": "  This paper proposes an image interpolation algorithm exploiting sparse\nrepresentation for natural images. It involves three main steps: (a) obtaining\nan initial estimate of the high resolution image using linear methods like FIR\nfiltering, (b) promoting sparsity in a selected dictionary through iterative\nthresholding, and (c) extracting high frequency information from the\napproximation to refine the initial estimate. For the sparse modeling, a\nshearlet dictionary is chosen to yield a multiscale directional representation.\nThe proposed algorithm is compared to several state-of-the-art methods to\nassess its objective as well as subjective performance. Compared to the cubic\nspline interpolation method, an average PSNR gain of around 0.8 dB is observed\nover a dataset of 200 images.\n",
        "published": "2013-08-05T21:33:06Z",
        "pdf_link": "http://arxiv.org/pdf/1308.1126v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.1374v1",
        "title": "Bayesian ensemble learning for image denoising",
        "summary": "  Natural images are often affected by random noise and image denoising has\nlong been a central topic in Computer Vision. Many algorithms have been\nintroduced to remove the noise from the natural images, such as Gaussian,\nWiener filtering and wavelet thresholding. However, many of these algorithms\nremove the fine edges and make them blur. Recently, many promising denoising\nalgorithms have been introduced such as Non-local Means, Fields of Experts, and\nBM3D. In this paper, we explore Bayesian method of ensemble learning for image\ndenoising. Ensemble methods seek to combine multiple different algorithms to\nretain the strengths of all methods and the weaknesses of none. Bayesian\nensemble models are Non-local Means and Fields of Experts, the very successful\nrecent algorithms. The Non-local Means presumes that the image contains an\nextensive amount of self-similarity. The approach of the Fields of Experts\nmodel extends traditional Markov Random Field model by learning potential\nfunctions over extended pixel neighborhoods. The two models are implemented and\nimage denoising is performed on natural images. The experimental results\nobtained are used to compare with the single algorithm and discuss the ensemble\nlearning and their approaches. Comparing to the results of Non-local Means and\nFields of Experts, Ensemble learning showed improvement nearly 1dB.\n",
        "published": "2013-08-06T18:46:18Z",
        "pdf_link": "http://arxiv.org/pdf/1308.1374v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.1981v3",
        "title": "A Framework for the Analysis of Computational Imaging Systems with\n  Practical Applications",
        "summary": "  Over the last decade, a number of Computational Imaging (CI) systems have\nbeen proposed for tasks such as motion deblurring, defocus deblurring and\nmultispectral imaging. These techniques increase the amount of light reaching\nthe sensor via multiplexing and then undo the deleterious effects of\nmultiplexing by appropriate reconstruction algorithms. Given the widespread\nappeal and the considerable enthusiasm generated by these techniques, a\ndetailed performance analysis of the benefits conferred by this approach is\nimportant.\n  Unfortunately, a detailed analysis of CI has proven to be a challenging\nproblem because performance depends equally on three components: (1) the\noptical multiplexing, (2) the noise characteristics of the sensor, and (3) the\nreconstruction algorithm. A few recent papers have performed analysis taking\nmultiplexing and noise characteristics into account. However, analysis of CI\nsystems under state-of-the-art reconstruction algorithms, most of which exploit\nsignal prior models, has proven to be unwieldy. In this paper, we present a\ncomprehensive analysis framework incorporating all three components.\n  In order to perform this analysis, we model the signal priors using a\nGaussian Mixture Model (GMM). A GMM prior confers two unique characteristics.\nFirstly, GMM satisfies the universal approximation property which says that any\nprior density function can be approximated to any fidelity using a GMM with\nappropriate number of mixtures. Secondly, a GMM prior lends itself to\nanalytical tractability allowing us to derive simple expressions for the\n`minimum mean square error' (MMSE), which we use as a metric to characterize\nthe performance of CI systems. We use our framework to analyze several\npreviously proposed CI techniques, giving conclusive answer to the question:\n`How much performance gain is due to use of a signal prior and how much is due\nto multiplexing?\n",
        "published": "2013-08-08T21:21:54Z",
        "pdf_link": "http://arxiv.org/pdf/1308.1981v3"
    },
    {
        "id": "http://arxiv.org/abs/1308.2654v1",
        "title": "Local image registration a comparison for bilateral registration\n  mammography",
        "summary": "  Early tumor detection is key in reducing the number of breast cancer death\nand screening mammography is one of the most widely available and reliable\nmethod for early detection. However, it is difficult for the radiologist to\nprocess with the same attention each case, due the large amount of images to be\nread. Computer aided detection (CADe) systems improve tumor detection rate; but\nthe current efficiency of these systems is not yet adequate and the correct\ninterpretation of CADe outputs requires expert human intervention. Computer\naided diagnosis systems (CADx) are being designed to improve cancer diagnosis\naccuracy, but they have not been efficiently applied in breast cancer. CADx\nefficiency can be enhanced by considering the natural mirror symmetry between\nthe right and left breast. The objective of this work is to evaluate\nco-registration algorithms for the accurate alignment of the left to right\nbreast for CADx enhancement. A set of mammograms were artificially altered to\ncreate a ground truth set to evaluate the registration efficiency of DEMONs,\nand SPLINE deformable registration algorithms. The registration accuracy was\nevaluated using mean square errors, mutual information and correlation. The\nresults on the 132 images proved that the SPLINE deformable registration\nover-perform the DEMONS on mammography images.\n",
        "published": "2013-08-12T19:29:49Z",
        "pdf_link": "http://arxiv.org/pdf/1308.2654v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.3052v2",
        "title": "Gradient Magnitude Similarity Deviation: A Highly Efficient Perceptual\n  Image Quality Index",
        "summary": "  It is an important task to faithfully evaluate the perceptual quality of\noutput images in many applications such as image compression, image restoration\nand multimedia streaming. A good image quality assessment (IQA) model should\nnot only deliver high quality prediction accuracy but also be computationally\nefficient. The efficiency of IQA metrics is becoming particularly important due\nto the increasing proliferation of high-volume visual data in high-speed\nnetworks. We present a new effective and efficient IQA model, called gradient\nmagnitude similarity deviation (GMSD). The image gradients are sensitive to\nimage distortions, while different local structures in a distorted image suffer\ndifferent degrees of degradations. This motivates us to explore the use of\nglobal variation of gradient based local quality map for overall image quality\nprediction. We find that the pixel-wise gradient magnitude similarity (GMS)\nbetween the reference and distorted images combined with a novel pooling\nstrategy the standard deviation of the GMS map can predict accurately\nperceptual image quality. The resulting GMSD algorithm is much faster than most\nstate-of-the-art IQA methods, and delivers highly competitive prediction\naccuracy.\n",
        "published": "2013-08-14T07:25:10Z",
        "pdf_link": "http://arxiv.org/pdf/1308.3052v2"
    },
    {
        "id": "http://arxiv.org/abs/1308.4440v1",
        "title": "Influences Combination of Multi-Sensor Images on Classification Accuracy",
        "summary": "  This paper focuses on two main issues; first one is the impact of combination\nof multi-sensor images on the supervised learning classification accuracy using\nsegment Fusion (SF). The second issue attempts to undertake the study of\nsupervised machine learning classification technique of remote sensing images\nby using four classifiers like Parallelepiped (Pp), Mahalanobis Distance (MD),\nMaximum-Likelihood (ML) and Euclidean Distance(ED) classifiers, and their\naccuracies have been evaluated on their respected classification to choose the\nbest technique for classification of remote sensing images. QuickBird\nmultispectral data (MS) and panchromatic data (PAN) have been used in this\nstudy to demonstrate the enhancement and accuracy assessment of fused image\nover the original images using ALwassaiProcess software. According to\nexperimental result of this study, is that the test results indicate the\nsupervised classification results of fusion image, which generated better than\nthe MS did. As well as the result with Euclidean classifier is robust and\nprovides better results than the other classifiers do, despite of the popular\nbelief that the maximum-likelihood classifier is the most accurate classifier.\n",
        "published": "2013-08-20T21:34:47Z",
        "pdf_link": "http://arxiv.org/pdf/1308.4440v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.4902v1",
        "title": "A review on handwritten character and numeral recognition for Roman,\n  Arabic, Chinese and Indian scripts",
        "summary": "  There are a lot of intensive researches on handwritten character recognition\n(HCR) for almost past four decades. The research has been done on some of\npopular scripts such as Roman, Arabic, Chinese and Indian. In this paper we\npresent a review on HCR work on the four popular scripts. We have summarized\nmost of the published paper from 2005 to recent and also analyzed the various\nmethods in creating a robust HCR system. We also added some future direction of\nresearch on HCR.\n",
        "published": "2013-08-22T15:38:15Z",
        "pdf_link": "http://arxiv.org/pdf/1308.4902v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.5063v1",
        "title": "Suspicious Object Recognition Method in Video Stream Based on Visual\n  Attention",
        "summary": "  We propose a state of the art method for intelligent object recognition and\nvideo surveillance based on human visual attention. Bottom up and top down\nattention are applied respectively in the process of acquiring interested\nobject(saliency map) and object recognition. The revision of 4 channel PFT\nmethod is proposed for bottom up attention and enhances the speed and accuracy.\nInhibit of return (IOR) is applied in judging the sequence of saliency object\npop out. Euclidean distance of color distribution, object center coordinates\nand speed are considered in judging whether the target is match and suspicious.\nThe extensive tests on videos and images show that our method in video analysis\nhas high accuracy and fast speed compared with traditional method. The method\ncan be applied into many fields such as video surveillance and security.\n",
        "published": "2013-08-23T07:26:56Z",
        "pdf_link": "http://arxiv.org/pdf/1308.5063v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.5315v1",
        "title": "Edge-detection applied to moving sand dunes on Mars",
        "summary": "  Here we discuss the application of an edge detection filter, the Sobel filter\nof GIMP, to the recently discovered motion of some sand dunes on Mars. The\nfilter allows a good comparison of an image HiRISE of 2007 and an image of 1999\nrecorded by the Mars Global Surveyor of the dunes in the Nili Patera caldera,\nmeasuring therefore the motion of the dunes on a longer period of time than\nthat previously investigated.\n",
        "published": "2013-08-24T11:07:05Z",
        "pdf_link": "http://arxiv.org/pdf/1308.5315v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.5876v1",
        "title": "Hierarchized block wise image approximation by greedy pursuit strategies",
        "summary": "  An approach for effective implementation of greedy selection methodologies,\nto approximate an image partitioned into blocks, is proposed. The method is\nspecially designed for approximating partitions on a transformed image. It\nevolves by selecting, at each iteration step, i) the elements for approximating\neach of the blocks partitioning the image and ii) the hierarchized sequence in\nwhich the blocks are approximated to reach the required global condition on\nsparsity.\n",
        "published": "2013-08-27T13:57:16Z",
        "pdf_link": "http://arxiv.org/pdf/1308.5876v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.6056v1",
        "title": "Brain MRI Segmentation with Fast and Globally Convex Multiphase Active\n  Contours",
        "summary": "  Multiphase active contour based models are useful in identifying multiple\nregions with different characteristics such as the mean values of regions. This\nis relevant in brain magnetic resonance images (MRIs), allowing the\ndifferentiation of white matter against gray matter. We consider a well defined\nglobally convex formulation of Vese and Chan multiphase active contour model\nfor segmenting brain MRI images. A well-established theory and an efficient\ndual minimization scheme are thoroughly described which guarantees optimal\nsolutions and provides stable segmentations. Moreover, under the dual\nminimization implementation our model perfectly describes disjoint regions by\navoiding local minima solutions. Experimental results indicate that the\nproposed approach provides better accuracy than other related multiphase active\ncontour algorithms even under severe noise, intensity inhomogeneities, and\npartial volume effects.\n",
        "published": "2013-08-28T04:48:00Z",
        "pdf_link": "http://arxiv.org/pdf/1308.6056v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.6309v1",
        "title": "Text recognition in both ancient and cartographic documents",
        "summary": "  This paper deals with the recognition and matching of text in both\ncartographic maps and ancient documents. The purpose of this work is to find\nsimilar text regions based on statistical and global features. A phase of\nnormalization is done first, in object to well categorize the same quantity of\ninformation. A phase of wordspotting is done next by combining local and global\nfeatures. We make different experiments by combining the different techniques\nof extracting features in order to obtain better results in recognition phase.\nWe applied fontspotting on both ancient documents and cartographic ones. We\nalso applied the wordspotting in which we adopted a new technique which tries\nto compare the images of character and not the entire images words. We present\nthe precision and recall values obtained with three methods for the new method\nof wordspotting applied on characters only.\n",
        "published": "2013-08-28T20:59:55Z",
        "pdf_link": "http://arxiv.org/pdf/1308.6309v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.6311v1",
        "title": "Categorizing ancient documents",
        "summary": "  The analysis of historical documents is still a topical issue given the\nimportance of information that can be extracted and also the importance given\nby the institutions to preserve their heritage. The main idea in order to\ncharacterize the content of the images of ancient documents after attempting to\nclean the image is segmented blocks texts from the same image and tries to find\nsimilar blocks in either the same image or the entire image database. Most\napproaches of offline handwriting recognition proceed by segmenting words into\nsmaller pieces (usually characters) which are recognized separately.\nRecognition of a word then requires the recognition of all characters (OCR)\nthat compose it. Our work focuses mainly on the characterization of classes in\nimages of old documents. We use Som toolbox for finding classes in documents.\nWe applied also fractal dimensions and points of interest to categorize and\nmatch ancient documents.\n",
        "published": "2013-08-28T21:09:35Z",
        "pdf_link": "http://arxiv.org/pdf/1308.6311v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.6319v1",
        "title": "A proposition of a robust system for historical document images\n  indexation",
        "summary": "  Characterizing noisy or ancient documents is a challenging problem up to now.\nMany techniques have been done in order to effectuate feature extraction and\nimage indexation for such documents. Global approaches are in general less\nrobust and exact than local approaches. That's why, we propose in this paper, a\nhybrid system based on global approach(fractal dimension), and a local one\nbased on SIFT descriptor. The Scale Invariant Feature Transform seems to do\nwell with our application since it's rotation invariant and relatively robust\nto changing illumination.In the first step the calculation of fractal dimension\nis applied to images in order to eliminate images which have distant features\nthan image request characteristics. Next, the SIFT is applied to show which\nimages match well the request. However the average matching time using the\nhybrid approach is better than \"fractal dimension\" and \"SIFT descriptor\" if\nthey are used alone.\n",
        "published": "2013-08-28T21:37:08Z",
        "pdf_link": "http://arxiv.org/pdf/1308.6319v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.6388v1",
        "title": "GNCGCP - Graduated NonConvexity and Graduated Concavity Procedure",
        "summary": "  In this paper we propose the Graduated NonConvexity and Graduated Concavity\nProcedure (GNCGCP) as a general optimization framework to approximately solve\nthe combinatorial optimization problems on the set of partial permutation\nmatrices. GNCGCP comprises two sub-procedures, graduated nonconvexity (GNC)\nwhich realizes a convex relaxation and graduated concavity (GC) which realizes\na concave relaxation. It is proved that GNCGCP realizes exactly a type of\nconvex-concave relaxation procedure (CCRP), but with a much simpler formulation\nwithout needing convex or concave relaxation in an explicit way. Actually,\nGNCGCP involves only the gradient of the objective function and is therefore\nvery easy to use in practical applications. Two typical NP-hard problems,\n(sub)graph matching and quadratic assignment problem (QAP), are employed to\ndemonstrate its simplicity and state-of-the-art performance.\n",
        "published": "2013-08-29T08:00:20Z",
        "pdf_link": "http://arxiv.org/pdf/1308.6388v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.6401v1",
        "title": "A Synergistic Approach for Recovering Occlusion-Free Textured 3D Maps of\n  Urban Facades from Heterogeneous Cartographic Data",
        "summary": "  In this paper we present a practical approach for generating an\nocclusion-free textured 3D map of urban facades by the synergistic use of\nterrestrial images, 3D point clouds and area-based information. Particularly in\ndense urban environments, the high presence of urban objects in front of the\nfacades causes significant difficulties for several stages in computational\nbuilding modeling. Major challenges lie on the one hand in extracting complete\n3D facade quadrilateral delimitations and on the other hand in generating\nocclusion-free facade textures. For these reasons, we describe a\nstraightforward approach for completing and recovering facade geometry and\ntextures by exploiting the data complementarity of terrestrial multi-source\nimagery and area-based information.\n",
        "published": "2013-08-29T08:47:09Z",
        "pdf_link": "http://arxiv.org/pdf/1308.6401v1"
    },
    {
        "id": "http://arxiv.org/abs/1308.6687v1",
        "title": "Image Set based Collaborative Representation for Face Recognition",
        "summary": "  With the rapid development of digital imaging and communication technologies,\nimage set based face recognition (ISFR) is becoming increasingly important. One\nkey issue of ISFR is how to effectively and efficiently represent the query\nface image set by using the gallery face image sets. The set-to-set distance\nbased methods ignore the relationship between gallery sets, while representing\nthe query set images individually over the gallery sets ignores the correlation\nbetween query set images. In this paper, we propose a novel image set based\ncollaborative representation and classification method for ISFR. By modeling\nthe query set as a convex or regularized hull, we represent this hull\ncollaboratively over all the gallery sets. With the resolved representation\ncoefficients, the distance between the query set and each gallery set can then\nbe calculated for classification. The proposed model naturally and effectively\nextends the image based collaborative representation to an image set based one,\nand our extensive experiments on benchmark ISFR databases show the superiority\nof the proposed method to state-of-the-art ISFR methods under different set\nsizes in terms of both recognition rate and efficiency.\n",
        "published": "2013-08-30T09:08:56Z",
        "pdf_link": "http://arxiv.org/pdf/1308.6687v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.0123v2",
        "title": "A Robust Alternating Direction Method for Constrained Hybrid Variational\n  Deblurring Model",
        "summary": "  In this work, a new constrained hybrid variational deblurring model is\ndeveloped by combining the non-convex first- and second-order total variation\nregularizers. Moreover, a box constraint is imposed on the proposed model to\nguarantee high deblurring performance. The developed constrained hybrid\nvariational model could achieve a good balance between preserving image details\nand alleviating ringing artifacts. In what follows, we present the\ncorresponding numerical solution by employing an iteratively reweighted\nalgorithm based on alternating direction method of multipliers. The\nexperimental results demonstrate the superior performance of the proposed\nmethod in terms of quantitative and qualitative image quality assessments.\n",
        "published": "2013-08-31T14:29:52Z",
        "pdf_link": "http://arxiv.org/pdf/1309.0123v2"
    },
    {
        "id": "http://arxiv.org/abs/1309.0213v3",
        "title": "Learning to Rank for Blind Image Quality Assessment",
        "summary": "  Blind image quality assessment (BIQA) aims to predict perceptual image\nquality scores without access to reference images. State-of-the-art BIQA\nmethods typically require subjects to score a large number of images to train a\nrobust model. However, subjective quality scores are imprecise, biased, and\ninconsistent, and it is challenging to obtain a large scale database, or to\nextend existing databases, because of the inconvenience of collecting images,\ntraining the subjects, conducting subjective experiments, and realigning human\nquality evaluations. To combat these limitations, this paper explores and\nexploits preference image pairs (PIPs) such as \"the quality of image $I_a$ is\nbetter than that of image $I_b$\" for training a robust BIQA model. The\npreference label, representing the relative quality of two images, is generally\nprecise and consistent, and is not sensitive to image content, distortion type,\nor subject identity; such PIPs can be generated at very low cost. The proposed\nBIQA method is one of learning to rank. We first formulate the problem of\nlearning the mapping from the image features to the preference label as one of\nclassification. In particular, we investigate the utilization of a multiple\nkernel learning algorithm based on group lasso (MKLGL) to provide a solution. A\nsimple but effective strategy to estimate perceptual image quality scores is\nthen presented. Experiments show that the proposed BIQA method is highly\neffective and achieves comparable performance to state-of-the-art BIQA\nalgorithms. Moreover, the proposed method can be easily extended to new\ndistortion categories.\n",
        "published": "2013-09-01T12:26:53Z",
        "pdf_link": "http://arxiv.org/pdf/1309.0213v3"
    },
    {
        "id": "http://arxiv.org/abs/1309.0261v1",
        "title": "Multi-Column Deep Neural Networks for Offline Handwritten Chinese\n  Character Classification",
        "summary": "  Our Multi-Column Deep Neural Networks achieve best known recognition rates on\nChinese characters from the ICDAR 2011 and 2013 offline handwriting\ncompetitions, approaching human performance.\n",
        "published": "2013-09-01T20:35:17Z",
        "pdf_link": "http://arxiv.org/pdf/1309.0261v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.0309v1",
        "title": "A Study on Unsupervised Dictionary Learning and Feature Encoding for\n  Action Classification",
        "summary": "  Many efforts have been devoted to develop alternative methods to traditional\nvector quantization in image domain such as sparse coding and soft-assignment.\nThese approaches can be split into a dictionary learning phase and a feature\nencoding phase which are often closely connected. In this paper, we investigate\nthe effects of these phases by separating them for video-based action\nclassification. We compare several dictionary learning methods and feature\nencoding schemes through extensive experiments on KTH and HMDB51 datasets.\nExperimental results indicate that sparse coding performs consistently better\nthan the other encoding methods in large complex dataset (i.e., HMDB51), and it\nis robust to different dictionaries. For small simple dataset (i.e., KTH) with\nless variation, however, all the encoding strategies perform competitively. In\naddition, we note that the strength of sophisticated encoding approaches comes\nnot from their corresponding dictionaries but the encoding mechanisms, and we\ncan just use randomly selected exemplars as dictionaries for video-based action\nclassification.\n",
        "published": "2013-09-02T07:06:05Z",
        "pdf_link": "http://arxiv.org/pdf/1309.0309v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.0999v1",
        "title": "Minutiae Based Thermal Face Recognition using Blood Perfusion Data",
        "summary": "  This paper describes an efficient approach for human face recognition based\non blood perfusion data from infra-red face images. Blood perfusion data are\ncharacterized by the regional blood flow in human tissue and therefore do not\ndepend entirely on surrounding temperature. These data bear a great potential\nfor deriving discriminating facial thermogram for better classification and\nrecognition of face images in comparison to optical image data. Blood perfusion\ndata are related to distribution of blood vessels under the face skin. A\ndistribution of blood vessels are unique for each person and as a set of\nextracted minutiae points from a blood perfusion data of a human face should be\nunique for that face. There may be several such minutiae point sets for a\nsingle face but all of these correspond to that particular face only. Entire\nface image is partitioned into equal blocks and the total number of minutiae\npoints from each block is computed to construct final vector. Therefore, the\nsize of the feature vectors is found to be same as total number of blocks\nconsidered. For classification, a five layer feed-forward backpropagation\nneural network has been used. A number of experiments were conducted to\nevaluate the performance of the proposed face recognition system with varying\nblock sizes. Experiments have been performed on the database created at our own\nlaboratory. The maximum success of 91.47% recognition has been achieved with\nblock size 8X8.\n",
        "published": "2013-09-04T12:18:55Z",
        "pdf_link": "http://arxiv.org/pdf/1309.0999v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.1000v1",
        "title": "Automated Thermal Face recognition based on Minutiae Extraction",
        "summary": "  In this paper an efficient approach for human face recognition based on the\nuse of minutiae points in thermal face image is proposed. The thermogram of\nhuman face is captured by thermal infra-red camera. Image processing methods\nare used to pre-process the captured thermogram, from which different\nphysiological features based on blood perfusion data are extracted. Blood\nperfusion data are related to distribution of blood vessels under the face\nskin. In the present work, three different methods have been used to get the\nblood perfusion image, namely bit-plane slicing and medial axis transform,\nmorphological erosion and medial axis transform, sobel edge operators.\nDistribution of blood vessels is unique for each person and a set of extracted\nminutiae points from a blood perfusion data of a human face should be unique\nfor that face. Two different methods are discussed for extracting minutiae\npoints from blood perfusion data. For extraction of features entire face image\nis partitioned into equal size blocks and the total number of minutiae points\nfrom each block is computed to construct final feature vector. Therefore, the\nsize of the feature vectors is found to be same as total number of blocks\nconsidered. A five layer feed-forward back propagation neural network is used\nas the classification tool. A number of experiments were conducted to evaluate\nthe performance of the proposed face recognition methodologies with varying\nblock size on the database created at our own laboratory. It has been found\nthat the first method supercedes the other two producing an accuracy of 97.62%\nwith block size 16X16 for bit-plane 4.\n",
        "published": "2013-09-04T12:26:50Z",
        "pdf_link": "http://arxiv.org/pdf/1309.1000v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.1009v1",
        "title": "A Comparative Study of Human thermal face recognition based on Haar\n  wavelet transform (HWT) and Local Binary Pattern (LBP)",
        "summary": "  Thermal infra-red (IR) images focus on changes of temperature distribution on\nfacial muscles and blood vessels. These temperature changes can be regarded as\ntexture features of images. A comparative study of face recognition methods\nworking in thermal spectrum is carried out in this paper. In these study two\nlocal-matching methods based on Haar wavelet transform and Local Binary Pattern\n(LBP) are analyzed. Wavelet transform is a good tool to analyze multi-scale,\nmulti-direction changes of texture. Local binary patterns (LBP) are a type of\nfeature used for classification in computer vision. Firstly, human thermal IR\nface image is preprocessed and cropped the face region only from the entire\nimage. Secondly, two different approaches are used to extract the features from\nthe cropped face region. In the first approach, the training images and the\ntest images are processed with Haar wavelet transform and the LL band and the\naverage of LH/HL/HH bands sub-images are created for each face image. Then a\ntotal confidence matrix is formed for each face image by taking a weighted sum\nof the corresponding pixel values of the LL band and average band. For LBP\nfeature extraction, each of the face images in training and test datasets is\ndivided into 161 numbers of sub images, each of size 8X8 pixels. For each such\nsub images, LBP features are extracted which are concatenated in row wise\nmanner. PCA is performed separately on the individual feature set for\ndimensionality reeducation. Finally two different classifiers are used to\nclassify face images. One such classifier multi-layer feed forward neural\nnetwork and another classifier is minimum distance classifier. The Experiments\nhave been performed on the database created at our own laboratory and Terravic\nFacial IR Database.\n",
        "published": "2013-09-04T12:41:48Z",
        "pdf_link": "http://arxiv.org/pdf/1309.1009v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.1080v1",
        "title": "Boosting in Location Space",
        "summary": "  The goal of object detection is to find objects in an image. An object\ndetector accepts an image and produces a list of locations as $(x,y)$ pairs.\nHere we introduce a new concept: {\\bf location-based boosting}. Location-based\nboosting differs from previous boosting algorithms because it optimizes a new\nspatial loss function to combine object detectors, each of which may have\nmarginal performance, into a single, more accurate object detector. A\nstructured representation of object locations as a list of $(x,y)$ pairs is a\nmore natural domain for object detection than the spatially unstructured\nrepresentation produced by classifiers. Furthermore, this formulation allows us\nto take advantage of the intuition that large areas of the background are\nuninteresting and it is not worth expending computational effort on them. This\nresults in a more scalable algorithm because it does not need to take measures\nto prevent the background data from swamping the foreground data such as\nsubsampling or applying an ad-hoc weighting to the pixels. We first present the\ntheory of location-based boosting, and then motivate it with empirical results\non a challenging data set.\n",
        "published": "2013-09-04T15:49:09Z",
        "pdf_link": "http://arxiv.org/pdf/1309.1080v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.1155v1",
        "title": "Minutiae Based Thermal Human Face Recognition using Label Connected\n  Component Algorithm",
        "summary": "  In this paper, a thermal infra red face recognition system for human\nidentification and verification using blood perfusion data and back propagation\nfeed forward neural network is proposed. The system consists of three steps. At\nthe very first step face region is cropped from the colour 24-bit input images.\nSecondly face features are extracted from the croped region, which will be\ntaken as the input of the back propagation feed forward neural network in the\nthird step and classification and recognition is carried out. The proposed\napproaches are tested on a number of human thermal infra red face images\ncreated at our own laboratory. Experimental results reveal the higher degree\nperformance\n",
        "published": "2013-09-04T13:32:28Z",
        "pdf_link": "http://arxiv.org/pdf/1309.1155v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.1156v1",
        "title": "Thermal Human face recognition based on Haar wavelet transform and\n  series matching technique",
        "summary": "  Thermal infrared (IR) images represent the heat patterns emitted from hot\nobject and they do not consider the energies reflected from an object. Objects\nliving or non-living emit different amounts of IR energy according to their\nbody temperature and characteristics. Humans are homoeothermic and hence\ncapable of maintaining constant temperature under different surrounding\ntemperature. Face recognition from thermal (IR) images should focus on changes\nof temperature on facial blood vessels. These temperature changes can be\nregarded as texture features of images and wavelet transform is a very good\ntool to analyze multi-scale and multi-directional texture. Wavelet transform is\nalso used for image dimensionality reduction, by removing redundancies and\npreserving original features of the image. The sizes of the facial images are\nnormally large. So, the wavelet transform is used before image similarity is\nmeasured. Therefore this paper describes an efficient approach of human face\nrecognition based on wavelet transform from thermal IR images. The system\nconsists of three steps. At the very first step, human thermal IR face image is\npreprocessed and the face region is only cropped from the entire image.\nSecondly, Haar wavelet is used to extract low frequency band from the cropped\nface region. Lastly, the image classification between the training images and\nthe test images is done, which is based on low-frequency components. The\nproposed approach is tested on a number of human thermal infrared face images\ncreated at our own laboratory and Terravic Facial IR Database. Experimental\nresults indicated that the thermal infra red face images can be recognized by\nthe proposed system effectively. The maximum success of 95% recognition has\nbeen achieved.\n",
        "published": "2013-09-04T13:45:25Z",
        "pdf_link": "http://arxiv.org/pdf/1309.1156v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.1539v2",
        "title": "Practical Matrix Completion and Corruption Recovery using Proximal\n  Alternating Robust Subspace Minimization",
        "summary": "  Low-rank matrix completion is a problem of immense practical importance.\nRecent works on the subject often use nuclear norm as a convex surrogate of the\nrank function. Despite its solid theoretical foundation, the convex version of\nthe problem often fails to work satisfactorily in real-life applications. Real\ndata often suffer from very few observations, with support not meeting the\nrandom requirements, ubiquitous presence of noise and potentially gross\ncorruptions, sometimes with these simultaneously occurring.\n  This paper proposes a Proximal Alternating Robust Subspace Minimization\n(PARSuMi) method to tackle the three problems. The proximal alternating scheme\nexplicitly exploits the rank constraint on the completed matrix and uses the\n$\\ell_0$ pseudo-norm directly in the corruption recovery step. We show that the\nproposed method for the non-convex and non-smooth model converges to a\nstationary point. Although it is not guaranteed to find the global optimal\nsolution, in practice we find that our algorithm can typically arrive at a good\nlocal minimizer when it is supplied with a reasonably good starting point based\non convex optimization. Extensive experiments with challenging synthetic and\nreal data demonstrate that our algorithm succeeds in a much larger range of\npractical problems where convex optimization fails, and it also outperforms\nvarious state-of-the-art algorithms.\n",
        "published": "2013-09-06T05:38:32Z",
        "pdf_link": "http://arxiv.org/pdf/1309.1539v2"
    },
    {
        "id": "http://arxiv.org/abs/1309.1628v2",
        "title": "Topology preserving thinning for cell complexes",
        "summary": "  A topology preserving skeleton is a synthetic representation of an object\nthat retains its topology and many of its significant morphological properties.\nThe process of obtaining the skeleton, referred to as skeletonization or\nthinning, is a very active research area. It plays a central role in reducing\nthe amount of information to be processed during image analysis and\nvisualization, computer-aided diagnosis or by pattern recognition algorithms.\n  This paper introduces a novel topology preserving thinning algorithm which\nremoves \\textit{simple cells}---a generalization of simple points---of a given\ncell complex. The test for simple cells is based on \\textit{acyclicity tables}\nautomatically produced in advance with homology computations. Using acyclicity\ntables render the implementation of thinning algorithms straightforward.\nMoreover, the fact that tables are automatically filled for all possible\nconfigurations allows to rigorously prove the generality of the algorithm and\nto obtain fool-proof implementations. The novel approach enables, for the first\ntime, according to our knowledge, to thin a general unstructured simplicial\ncomplex. Acyclicity tables for cubical and simplicial complexes and an open\nsource implementation of the thinning algorithm are provided as additional\nmaterial to allow their immediate use in the vast number of practical\napplications arising in medical imaging and beyond.\n",
        "published": "2013-09-06T13:11:48Z",
        "pdf_link": "http://arxiv.org/pdf/1309.1628v2"
    },
    {
        "id": "http://arxiv.org/abs/1309.1830v1",
        "title": "Radar shadow detection in SAR images using DEM and projections",
        "summary": "  Synthetic aperture radar (SAR) images are widely used in target recognition\ntasks nowadays. In this letter, we propose an automatic approach for radar\nshadow detection and extraction from SAR images utilizing geometric projections\nalong with the digital elevation model (DEM) which corresponds to the given\ngeo-referenced SAR image. First, the DEM is rotated into the radar geometry so\nthat each row would match that of a radar line of sight. Next, we extract the\nshadow regions by processing row by row until the image is covered fully. We\ntest the proposed shadow detection approach on different DEMs and a simulated\n1D signals and 2D hills and volleys modeled by various variance based Gaussian\nfunctions. Experimental results indicate the proposed algorithm produces good\nresults in detecting shadows in SAR images with high resolution.\n",
        "published": "2013-09-07T07:14:42Z",
        "pdf_link": "http://arxiv.org/pdf/1309.1830v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.2057v1",
        "title": "Single image super resolution in spatial and wavelet domain",
        "summary": "  Recently single image super resolution is very important research area to\ngenerate high resolution image from given low resolution image. Algorithms of\nsingle image resolution are mainly based on wavelet domain and spatial domain.\nFilters support to model the regularity of natural images is exploited in\nwavelet domain while edges of images get sharp during up sampling in spatial\ndomain. Here single image super resolution algorithm is presented which based\non both spatial and wavelet domain and take the advantage of both. Algorithm is\niterative and use back projection to minimize reconstruction error. Wavelet\nbased denoising method is also introduced to remove noise.\n",
        "published": "2013-09-09T07:33:50Z",
        "pdf_link": "http://arxiv.org/pdf/1309.2057v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.2506v1",
        "title": "A multi-stream hmm approach to offline handwritten arabic word\n  recognition",
        "summary": "  In This paper we presented new approach for cursive Arabic text recognition\nsystem. The objective is to propose methodology analytical offline recognition\nof handwritten Arabic for rapid implementation. The first part in the writing\nrecognition system is the preprocessing phase is the preprocessing phase to\nprepare the data was introduces and extracts a set of simple statistical\nfeatures by two methods : from a window which is sliding long that text line\nthe right to left and the approach VH2D (consists in projecting every character\non the abscissa, on the ordinate and the diagonals 45{\\deg} and 135{\\deg}) . It\nthen injects the resulting feature vectors to Hidden Markov Model (HMM) and\ncombined the two HMM by multi-stream approach.\n",
        "published": "2013-09-10T13:40:30Z",
        "pdf_link": "http://arxiv.org/pdf/1309.2506v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.2752v1",
        "title": "Robust Periocular Recognition By Fusing Sparse Representations of Color\n  and Geometry Information",
        "summary": "  In this paper, we propose a re-weighted elastic net (REN) model for biometric\nrecognition. The new model is applied to data separated into geometric and\ncolor spatial components. The geometric information is extracted using a fast\ncartoon - texture decomposition model based on a dual formulation of the total\nvariation norm allowing us to carry information about the overall geometry of\nimages. Color components are defined using linear and nonlinear color spaces,\nnamely the red-green-blue (RGB), chromaticity-brightness (CB) and\nhue-saturation-value (HSV). Next, according to a Bayesian fusion-scheme, sparse\nrepresentations for classification purposes are obtained. The scheme is\nnumerically solved using a gradient projection (GP) algorithm. In the empirical\nvalidation of the proposed model, we have chosen the periocular region, which\nis an emerging trait known for its robustness against low quality data. Our\nresults were obtained in the publicly available UBIRIS.v2 data set and show\nconsistent improvements in recognition effectiveness when compared to related\nstate-of-the-art techniques.\n",
        "published": "2013-09-11T08:11:14Z",
        "pdf_link": "http://arxiv.org/pdf/1309.2752v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.3006v2",
        "title": "The Classification Accuracy of Multiple-Metric Learning Algorithm on\n  Multi-Sensor Fusion",
        "summary": "  This paper focuses on two main issues; first one is the impact of Similarity\nSearch to learning the training sample in metric space, and searching based on\nsupervised learning classi-fication. In particular, four metrics space\nsearching are based on spatial information that are introduced as the\nfollowing; Cheby-shev Distance (CD); Bray Curtis Distance (BCD); Manhattan\nDistance (MD) and Euclidean Distance(ED) classifiers. The second issue\ninvestigates the performance of combination of mul-ti-sensor images on the\nsupervised learning classification accura-cy. QuickBird multispectral data (MS)\nand panchromatic data (PAN) have been used in this study to demonstrate the\nenhance-ment and accuracy assessment of fused image over the original images.\nThe supervised classification results of fusion image generated better than the\nMS did. QuickBird and the best results with ED classifier than the other did.\n",
        "published": "2013-09-11T23:58:23Z",
        "pdf_link": "http://arxiv.org/pdf/1309.3006v2"
    },
    {
        "id": "http://arxiv.org/abs/1309.3418v1",
        "title": "A Novel Approach in detecting pose orientation of a 3D face required for\n  face",
        "summary": "  In this paper we present a novel approach that takes as input a 3D image and\ngives as output its pose i.e. it tells whether the face is oriented with\nrespect the X, Y or Z axes with angles of rotation up to 40 degree. All the\nexperiments have been performed on the FRAV3D Database. After applying the\nproposed algorithm to the 3D facial surface we have obtained i.e. on 848 3D\nface images our method detected the pose correctly for 566 face images,thus\ngiving an approximately 67 % of correct pose detection.\n",
        "published": "2013-09-13T10:12:22Z",
        "pdf_link": "http://arxiv.org/pdf/1309.3418v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.3425v1",
        "title": "A method for nose-tip based 3D face registration using maximum intensity\n  algorithm",
        "summary": "  In this paper we present a novel technique of registering 3D images across\npose. In this context, we have taken into account the images which are aligned\nacross X, Y and Z axes. We have first determined the angle across which the\nimage is rotated with respect to X, Y and Z axes and then translation is\nperformed on the images. After testing the proposed method on 472 images from\nthe FRAV3D database, the method correctly registers 358 images thus giving a\nperformance rate of 75.84%.\n",
        "published": "2013-09-13T11:28:29Z",
        "pdf_link": "http://arxiv.org/pdf/1309.3425v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.3848v1",
        "title": "SEEDS: Superpixels Extracted via Energy-Driven Sampling",
        "summary": "  Superpixel algorithms aim to over-segment the image by grouping pixels that\nbelong to the same object. Many state-of-the-art superpixel algorithms rely on\nminimizing objective functions to enforce color ho- mogeneity. The optimization\nis accomplished by sophis- ticated methods that progressively build the\nsuperpix- els, typically by adding cuts or growing superpixels. As a result,\nthey are computationally too expensive for real-time applications. We introduce\na new approach based on a simple hill-climbing optimization. Starting from an\ninitial superpixel partitioning, it continuously refines the superpixels by\nmodifying the boundaries. We define a robust and fast to evaluate energy\nfunction, based on enforcing color similarity between the bound- aries and the\nsuperpixel color histogram. In a series of experiments, we show that we achieve\nan excellent com- promise between accuracy and efficiency. We are able to\nachieve a performance comparable to the state-of- the-art, but in real-time on\na single Intel i7 CPU at 2.8GHz.\n",
        "published": "2013-09-16T08:23:10Z",
        "pdf_link": "http://arxiv.org/pdf/1309.3848v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.4426v1",
        "title": "GRED: Graph-Regularized 3D Shape Reconstruction from Highly Anisotropic\n  and Noisy Images",
        "summary": "  Analysis of microscopy images can provide insight into many biological\nprocesses. One particularly challenging problem is cell nuclear segmentation in\nhighly anisotropic and noisy 3D image data. Manually localizing and segmenting\neach and every cell nuclei is very time consuming, which remains a bottleneck\nin large scale biological experiments. In this work we present a tool for\nautomated segmentation of cell nuclei from 3D fluorescent microscopic data. Our\ntool is based on state-of-the-art image processing and machine learning\ntechniques and supports a friendly graphical user interface (GUI). We show that\nour tool is as accurate as manual annotation but greatly reduces the time for\nthe registration.\n",
        "published": "2013-09-17T18:55:37Z",
        "pdf_link": "http://arxiv.org/pdf/1309.4426v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.4573v1",
        "title": "A novel approach for nose tip detection using smoothing by weighted\n  median filtering applied to 3D face images in variant poses",
        "summary": "  This paper is based on an application of smoothing of 3D face images followed\nby feature detection i.e. detecting the nose tip. The present method uses a\nweighted mesh median filtering technique for smoothing. In this present\nsmoothing technique we have built the neighborhood surrounding a particular\npoint in 3D face and replaced that with the weighted value of the surrounding\npoints in 3D face image. After applying the smoothing technique to the 3D face\nimages our experimental results show that we have obtained considerable\nimprovement as compared to the algorithm without smoothing. We have used here\nthe maximum intensity algorithm for detecting the nose-tip and this method\ncorrectly detects the nose-tip in case of any pose i.e. along X, Y, and Z axes.\nThe present technique gave us worked successfully on 535 out of 542 3D face\nimages as compared to the method without smoothing which worked only on 521 3D\nface images out of 542 face images. Thus we have obtained a 98.70% performance\nrate over 96.12% performance rate of the algorithm without smoothing. All the\nexperiments have been performed on the FRAV3D database.\n",
        "published": "2013-09-18T08:40:21Z",
        "pdf_link": "http://arxiv.org/pdf/1309.4573v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.4577v1",
        "title": "Detection of pose orientation across single and multiple axes in case of\n  3D face images",
        "summary": "  In this paper, we propose a new approach that takes as input a 3D face image\nacross X, Y and Z axes as well as both Y and X axes and gives output as its\npose i.e. it tells whether the face is oriented with respect the X, Y or Z axes\nor is it oriented across multiple axes with angles of rotation up to 42 degree.\nAll the experiments have been performed on the FRAV3D, GAVADB and Bosphorus\ndatabase which has two figures of each individual across multiple axes. After\napplying the proposed algorithm to the 3D facial surface from FRAV3D on 848 3D\nfaces, 566 3D faces were correctly recognized for pose thus giving 67% of\ncorrect identification rate. We had experimented on 420 images from the GAVADB\ndatabase, and only 336 images were detected for correct pose identification\nrate i.e. 80% and from Bosphorus database on 560 images only 448 images were\ndetected for correct pose identification i.e. 80%.abstract goes here.\n",
        "published": "2013-09-18T08:47:34Z",
        "pdf_link": "http://arxiv.org/pdf/1309.4577v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.4582v1",
        "title": "A novel approach to nose-tip and eye corners detection using H-K\n  Curvature Analysis in case of 3D images",
        "summary": "  In this paper we present a novel method that combines a HK curvature-based\napproach for three-dimensional (3D) face detection in different poses (X-axis,\nY-axis and Z-axis). Salient face features, such as the eyes and nose, are\ndetected through an analysis of the curvature of the entire facial surface. All\nthe experiments have been performed on the FRAV3D Database. After applying the\nproposed algorithm to the 3D facial surface we have obtained considerably good\nresults i.e. on 752 3D face images our method detected the eye corners for 543\nface images, thus giving a 72.20% of eye corners detection and 743 face images\nfor nose-tip detection thus giving a 98.80% of good nose tip localization\n",
        "published": "2013-09-18T09:02:56Z",
        "pdf_link": "http://arxiv.org/pdf/1309.4582v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.5004v1",
        "title": "Blind Deconvolution via Maximum Kurtosis Adaptive Filtering",
        "summary": "  In this paper, we present an algorithm for identifying a parametrically\ndescribed destructive unknown system based on a non-gaussianity measure. It is\nknown that under certain conditions the output of a linear system is more\ngaussian than the input. Hence, an inverse filter is searched, such that its\noutput is minimally gaussian. We use the kurtosis as a measure of the\nnon-gaussianity of the signal. A maximum of the kurtosis as a function of the\ndeconvolving filter coefficients is searched. The search is done iteratively\nusing the gradient ascent algorithm, and the coefficients at the maximum point\ncorrespond to the inverse filter coefficients. This filter may be applied to\nthe distorted signal to obtain the original undistorted signal. While a similar\napproach has been used before, it was always directed at a particular kind of a\nsignal, commonly of impulsive characteristics. In this paper a successful\nattempt has been made to apply the algorithm to a wider range of signals, such\nas to process distorted audio signals and destructed images. This innovative\nimplementation required the revelation of a way to preprocess the distorted\nsignal at hand. The experimental results show very good performance in terms of\nrecovering audio signals and blurred images, both for an FIR and IIR distorting\nfilters.\n",
        "published": "2013-09-19T14:45:54Z",
        "pdf_link": "http://arxiv.org/pdf/1309.5004v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.5357v1",
        "title": "Development of Comprehensive Devnagari Numeral and Character Database\n  for Offline Handwritten Character Recognition",
        "summary": "  In handwritten character recognition, benchmark database plays an important\nrole in evaluating the performance of various algorithms and the results\nobtained by various researchers. In Devnagari script, there is lack of such\nofficial benchmark. This paper focuses on the generation of offline benchmark\ndatabase for Devnagari handwritten numerals and characters. The present work\ngenerated 5137 and 20305 isolated samples for numeral and character database,\nrespectively, from 750 writers of all ages, sex, education, and profession. The\noffline sample images are stored in TIFF image format as it occupies less\nmemory. Also, the data is presented in binary level so that memory requirement\nis further reduced. It will facilitate research on handwriting recognition of\nDevnagari script through free access to the researchers.\n",
        "published": "2013-08-17T03:09:50Z",
        "pdf_link": "http://arxiv.org/pdf/1309.5357v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.5594v2",
        "title": "Generic Image Classification Approaches Excel on Face Recognition",
        "summary": "  The main finding of this work is that the standard image classification\npipeline, which consists of dictionary learning, feature encoding, spatial\npyramid pooling and linear classification, outperforms all state-of-the-art\nface recognition methods on the tested benchmark datasets (we have tested on\nAR, Extended Yale B, the challenging FERET, and LFW-a datasets). This\nsurprising and prominent result suggests that those advances in generic image\nclassification can be directly applied to improve face recognition systems. In\nother words, face recognition may not need to be viewed as a separate object\nclassification problem.\n  While recently a large body of residual based face recognition methods focus\non developing complex dictionary learning algorithms, in this work we show that\na dictionary of randomly extracted patches (even from non-face images) can\nachieve very promising results using the image classification pipeline. That\nmeans, the choice of dictionary learning methods may not be important. Instead,\nwe find that learning multiple dictionaries using different low-level image\nfeatures often improve the final classification accuracy. Our proposed face\nrecognition approach offers the best reported results on the widely-used face\nrecognition benchmark datasets. In particular, on the challenging FERET and\nLFW-a datasets, we improve the best reported accuracies in the literature by\nabout 20% and 30% respectively.\n",
        "published": "2013-09-22T11:52:03Z",
        "pdf_link": "http://arxiv.org/pdf/1309.5594v2"
    },
    {
        "id": "http://arxiv.org/abs/1309.6195v1",
        "title": "Scan-based Compressed Terahertz Imaging and Real-Time Reconstruction via\n  the Complex-valued Fast Block Sparse Bayesian Learning Algorithm",
        "summary": "  Compressed Sensing based Terahertz imaging (CS-THz) is a computational\nimaging technique. It uses only one THz receiver to accumulate the random\nmodulated image measurements where the original THz image is reconstruct from\nthese measurements using compressed sensing solvers. The advantage of the\nCS-THz is its reduced acquisition time compared with the raster scan mode.\nHowever, when it applied to large-scale two-dimensional (2D) imaging, the\nincreased dimension resulted in both high computational complexity and\nexcessive memory usage. In this paper, we introduced a novel CS-based THz\nimaging system that progressively compressed the THz image column by column.\nTherefore, the CS-THz system could be simplified with a much smaller sized\nmodulator and reduced dimension. In order to utilize the block structure and\nthe correlation of adjacent columns of the THz image, a complex-valued block\nsparse Bayesian learning algorithm was proposed. We conducted systematic\nevaluation of state-of-the-art CS algorithms under the scan based CS-THz\narchitecture. The compression ratios and the choices of the sensing matrices\nwere analyzed in detail using both synthetic and real-life THz images.\nSimulation results showed that both the scan based architecture and the\nproposed recovery algorithm were superior and efficient for large scale CS-THz\napplications.\n",
        "published": "2013-09-20T23:08:27Z",
        "pdf_link": "http://arxiv.org/pdf/1309.6195v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.6379v1",
        "title": "Diffeomorphic Metric Mapping and Probabilistic Atlas Generation of\n  Hybrid Diffusion Imaging based on BFOR Signal Basis",
        "summary": "  We propose a large deformation diffeomorphic metric mapping algorithm to\nalign multiple b-value diffusion weighted imaging (mDWI) data, specifically\nacquired via hybrid diffusion imaging (HYDI), denoted as LDDMM-HYDI. We then\npropose a Bayesian model for estimating the white matter atlas from HYDIs. We\nadopt the work given in Hosseinbor et al. (2012) and represent the q-space\ndiffusion signal with the Bessel Fourier orientation reconstruction (BFOR)\nsignal basis. The BFOR framework provides the representation of mDWI in the\nq-space and thus reduces memory requirement. In addition, since the BFOR signal\nbasis is orthonormal, the L2 norm that quantifies the differences in the\nq-space signals of any two mDWI datasets can be easily computed as the sum of\nthe squared differences in the BFOR expansion coefficients. In this work, we\nshow that the reorientation of the $q$-space signal due to spatial\ntransformation can be easily defined on the BFOR signal basis. We incorporate\nthe BFOR signal basis into the LDDMM framework and derive the gradient descent\nalgorithm for LDDMM-HYDI with explicit orientation optimization. Additionally,\nwe extend the previous Bayesian atlas estimation framework for scalar-valued\nimages to HYDIs and derive the expectation-maximization algorithm for solving\nthe HYDI atlas estimation problem. Using real HYDI datasets, we show the\nBayesian model generates the white matter atlas with anatomical details.\nMoreover, we show that it is important to consider the variation of mDWI\nreorientation due to a small change in diffeomorphic transformation in the\nLDDMM-HYDI optimization and to incorporate the full information of HYDI for\naligning mDWI.\n",
        "published": "2013-09-25T01:57:50Z",
        "pdf_link": "http://arxiv.org/pdf/1309.6379v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.6390v1",
        "title": "Contextually learnt detection of unusual motion-based behaviour in\n  crowded public spaces",
        "summary": "  In this paper we are interested in analyzing behaviour in crowded public\nplaces at the level of holistic motion. Our aim is to learn, without user\ninput, strong scene priors or labelled data, the scope of \"normal behaviour\"\nfor a particular scene and thus alert to novelty in unseen footage. The first\ncontribution is a low-level motion model based on what we term tracklet\nprimitives, which are scene-specific elementary motions. We propose a\nclustering-based algorithm for tracklet estimation from local approximations to\ntracks of appearance features. This is followed by two methods for motion\nnovelty inference from tracklet primitives: (a) we describe an approach based\non a non-hierarchial ensemble of Markov chains as a means of capturing\nbehavioural characteristics at different scales, and (b) a more flexible\nalternative which exhibits a higher generalizing power by accounting for\nconstraints introduced by intentionality and goal-oriented planning of human\nmotion in a particular scene. Evaluated on a 2h long video of a busy city\nmarketplace, both algorithms are shown to be successful at inferring unusual\nbehaviour, the latter model achieving better performance for novelties at a\nlarger spatial scale.\n",
        "published": "2013-09-25T03:22:59Z",
        "pdf_link": "http://arxiv.org/pdf/1309.6390v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.6391v1",
        "title": "Multiple-object tracking in cluttered and crowded public spaces",
        "summary": "  This paper addresses the problem of tracking moving objects of variable\nappearance in challenging scenes rich with features and texture. Reliable\ntracking is of pivotal importance in surveillance applications. It is made\nparticularly difficult by the nature of objects encountered in such scenes:\nthese too change in appearance and scale, and are often articulated (e.g.\nhumans). We propose a method which uses fast motion detection and segmentation\nas a constraint for both building appearance models and their robust\npropagation (matching) in time. The appearance model is based on sets of local\nappearances automatically clustered using spatio-kinetic similarity, and is\nupdated with each new appearance seen. This integration of all seen appearances\nof a tracked object makes it extremely resilient to errors caused by occlusion\nand the lack of permanence of due to low data quality, appearance change or\nbackground clutter. These theoretical strengths of our algorithm are\nempirically demonstrated on two hour long video footage of a busy city\nmarketplace.\n",
        "published": "2013-09-25T03:34:01Z",
        "pdf_link": "http://arxiv.org/pdf/1309.6391v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.6691v1",
        "title": "Characterness: An Indicator of Text in the Wild",
        "summary": "  Text in an image provides vital information for interpreting its contents,\nand text in a scene can aide with a variety of tasks from navigation, to\nobstacle avoidance, and odometry. Despite its value, however, identifying\ngeneral text in images remains a challenging research problem. Motivated by the\nneed to consider the widely varying forms of natural text, we propose a\nbottom-up approach to the problem which reflects the `characterness' of an\nimage region. In this sense our approach mirrors the move from saliency\ndetection methods to measures of `objectness'. In order to measure the\ncharacterness we develop three novel cues that are tailored for character\ndetection, and a Bayesian method for their integration. Because text is made up\nof sets of characters, we then design a Markov random field (MRF) model so as\nto exploit the inherent dependencies between characters.\n  We experimentally demonstrate the effectiveness of our characterness cues as\nwell as the advantage of Bayesian multi-cue integration. The proposed text\ndetector outperforms state-of-the-art methods on a few benchmark scene text\ndetection datasets. We also show that our measurement of `characterness' is\nsuperior than state-of-the-art saliency detection models when applied to the\nsame task.\n",
        "published": "2013-09-25T23:30:18Z",
        "pdf_link": "http://arxiv.org/pdf/1309.6691v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.6964v4",
        "title": "Online Algorithms for Factorization-Based Structure from Motion",
        "summary": "  We present a family of online algorithms for real-time factorization-based\nstructure from motion, leveraging a relationship between incremental singular\nvalue decomposition and recently proposed methods for online matrix completion.\nOur methods are orders of magnitude faster than previous state of the art, can\nhandle missing data and a variable number of feature points, and are robust to\nnoise and sparse outliers. We demonstrate our methods on both real and\nsynthetic sequences and show that they perform well in both online and batch\nsettings. We also provide an implementation which is able to produce 3D models\nin real time using a laptop with a webcam.\n",
        "published": "2013-09-26T16:46:28Z",
        "pdf_link": "http://arxiv.org/pdf/1309.6964v4"
    },
    {
        "id": "http://arxiv.org/abs/1309.7276v1",
        "title": "Adopting level set theory based algorithms to segment human ear",
        "summary": "  Human identification has always been a topic that interested researchers\naround the world. Biometric methods are found to be more effective and much\neasier for the users than the traditional identification methods like keys,\nsmart cards and passwords. Unlike with the traditional methods, with biometric\nmethods the data acquisition is most of the times passive, which means the\nusers do not take active part in data acquisition. Data acquisition can be\nperformed using cameras, scanners or sensors. Human physiological biometrics\nsuch as face, eye and ear are good candidates for uniquely identifying an\nindividual. However, human ear scores over face and eye because of certain\nadvantages it has over face. The most challenging phase in human identification\nbased on ear biometric is the segmentation of the ear image from the captured\nimage which may contain many unwanted details. In this work, PDE based image\nprocessing techniques are used to segment out the ear image. Level Set Theory\nbased image processing is employed to obtain the contour of the ear image. A\nfew Level set algorithms are compared for their efficiency in segmenting test\near images.\n",
        "published": "2013-09-26T05:48:18Z",
        "pdf_link": "http://arxiv.org/pdf/1309.7276v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.7434v1",
        "title": "Face Verification Using Boosted Cross-Image Features",
        "summary": "  This paper proposes a new approach for face verification, where a pair of\nimages needs to be classified as belonging to the same person or not. This\nproblem is relatively new and not well-explored in the literature. Current\nmethods mostly adopt techniques borrowed from face recognition, and process\neach of the images in the pair independently, which is counter intuitive. In\ncontrast, we propose to extract cross-image features, i.e. features across the\npair of images, which, as we demonstrate, is more discriminative to the\nsimilarity and the dissimilarity of faces. Our features are derived from the\npopular Haar-like features, however, extended to handle the face verification\nproblem instead of face detection. We collect a large bank of cross-image\nfeatures using filters of different sizes, locations, and orientations.\nConsequently, we use AdaBoost to select and weight the most discriminative\nfeatures. We carried out extensive experiments on the proposed ideas using\nthree standard face verification datasets, and obtained promising results\noutperforming state-of-the-art.\n",
        "published": "2013-09-28T06:21:18Z",
        "pdf_link": "http://arxiv.org/pdf/1309.7434v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.7484v1",
        "title": "CSIFT Based Locality-constrained Linear Coding for Image Classification",
        "summary": "  In the past decade, SIFT descriptor has been witnessed as one of the most\nrobust local invariant feature descriptors and widely used in various vision\ntasks. Most traditional image classification systems depend on the\nluminance-based SIFT descriptors, which only analyze the gray level variations\nof the images. Misclassification may happen since their color contents are\nignored. In this article, we concentrate on improving the performance of\nexisting image classification algorithms by adding color information. To\nachieve this purpose, different kinds of colored SIFT descriptors are\nintroduced and implemented. Locality-constrained Linear Coding (LLC), a\nstate-of-the-art sparse coding technology, is employed to construct the image\nclassification system for the evaluation. The real experiments are carried out\non several benchmarks. With the enhancements of color SIFT, the proposed image\nclassification system obtains approximate 3% improvement of classification\naccuracy on the Caltech-101 dataset and approximate 4% improvement of\nclassification accuracy on the Caltech-256 dataset.\n",
        "published": "2013-09-28T18:05:12Z",
        "pdf_link": "http://arxiv.org/pdf/1309.7484v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.7609v1",
        "title": "Identificacin y Registro Catastral de Cuerpos de Agua mediante\n  Tcnicas de Procesamiento Digital de Imagenes",
        "summary": "  The effects of global climate change on Peruvian glaciers have brought about\nseveral processes of deglaciation during the last few years. The immediate\neffect is the change of size of lakes and rivers. Public institutions that\nmonitor water resources currently have only recent studies which make up less\nthan 10% of the total. The effects of climate change and the lack of updated\ninformation intensify social-economic problems related to water resources in\nPeru. The objective of this research is to develop a software application to\nautomate the Cadastral Registry of Water Bodies in Peru, using techniques of\ndigital image processing, which would provide tools for detection, record,\ntemporal analysis and visualization of water bodies. The images used are from\nthe satellite Landsat5, which undergo a pre-processing of calibration and\ncorrection of the satellite. Detection results are archived into a file that\ncontains location vectors and images of the segmentated bodies of water.\n",
        "published": "2013-09-29T15:36:43Z",
        "pdf_link": "http://arxiv.org/pdf/1309.7609v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.7615v1",
        "title": "Correcting Multi-focus Images via Simple Standard Deviation for Image\n  Fusion",
        "summary": "  Image fusion is one of the recent trends in image registration which is an\nessential field of image processing. The basic principle of this paper is to\nfuse multi-focus images using simple statistical standard deviation. Firstly,\nthe simple standard deviation for the k-by-k window inside each of the\nmulti-focus images was computed. The contribution in this paper came from the\nidea that the focused part inside an image had high details rather than the\nunfocused part. Hence, the dispersion between pixels inside the focused part is\nhigher than the dispersion inside the unfocused part. Secondly, a simple\ncomparison between the standard deviation for each k-by-k window in the\nmulti-focus images could be computed. The highest standard deviation between\nall the computed standard deviations for the multi-focus images could be\ntreated as the optimal that is to be placed in the fused image. The\nexperimental visual results show that the proposed method produces very\nsatisfactory results in spite of its simplicity.\n",
        "published": "2013-09-29T16:14:47Z",
        "pdf_link": "http://arxiv.org/pdf/1309.7615v1"
    },
    {
        "id": "http://arxiv.org/abs/1309.7912v1",
        "title": "An Image-Based Fluid Surface Pattern Model",
        "summary": "  This work aims at generating a model of the ocean surface and its dynamics\nfrom one or more video cameras. The idea is to model wave patterns from video\nas a first step towards a larger system of photogrammetric monitoring of marine\nconditions for use in offshore oil drilling platforms. The first part of the\nproposed approach consists in reducing the dimensionality of sensor data made\nup of the many pixels of each frame of the input video streams. This enables\nfinding a concise number of most relevant parameters to model the temporal\ndataset, yielding an efficient data-driven model of the evolution of the\nobserved surface. The second part proposes stochastic modeling to better\ncapture the patterns embedded in the data. One can then draw samples from the\nfinal model, which are expected to simulate the behavior of previously observed\nflow, in order to determine conditions that match new observations. In this\npaper we focus on proposing and discussing the overall approach and on\ncomparing two different techniques for dimensionality reduction in the first\nstage: principal component analysis and diffusion maps. Work is underway on the\nsecond stage of constructing better stochastic models of fluid surface dynamics\nas proposed here.\n",
        "published": "2013-09-30T16:39:21Z",
        "pdf_link": "http://arxiv.org/pdf/1309.7912v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0036v1",
        "title": "Personal Identification from Lip-Print Features using a Statistical\n  Model",
        "summary": "  This paper presents a novel approach towards identification of human beings\nfrom the statistical analysis of their lip prints. Lip features are extracted\nby studying the spatial orientations of the grooves present in lip prints of\nindividuals using standard edge detection techniques. Horizontal, vertical and\ndiagonal groove features are analysed using connected-component analysis to\ngenerate the region-specific edge datasets. Comparison between test and\nreference sample datasets against a threshold value to define a match yield\nsatisfactory results. FAR, FRR and ROC metrics have been used to gauge the\nperformance of the algorithm for real-world deployment in unimodal and\nmultimodal biometric verification systems.\n",
        "published": "2013-09-30T20:12:02Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0036v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0097v2",
        "title": "Analysis of Amoeba Active Contours",
        "summary": "  Subject of this paper is the theoretical analysis of structure-adaptive\nmedian filter algorithms that approximate curvature-based PDEs for image\nfiltering and segmentation. These so-called morphological amoeba filters are\nbased on a concept introduced by Lerallut et al. They achieve similar results\nas the well-known geodesic active contour and self-snakes PDEs. In the present\nwork, the PDE approximated by amoeba active contours is derived for a general\ngeometric situation and general amoeba metric. This PDE is structurally similar\nbut not identical to the geodesic active contour equation. It reproduces the\nprevious PDE approximation results for amoeba median filters as special cases.\nFurthermore, modifications of the basic amoeba active contour algorithm are\nanalysed that are related to the morphological force terms frequently used with\ngeodesic active contours. Experiments demonstrate the basic behaviour of amoeba\nactive contours and its similarity to geodesic active contours.\n",
        "published": "2013-09-30T23:57:08Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0097v2"
    },
    {
        "id": "http://arxiv.org/abs/1310.0171v1",
        "title": "Object Detection Using Keygraphs",
        "summary": "  We propose a new framework for object detection based on a generalization of\nthe keypoint correspondence framework. This framework is based on replacing\nkeypoints by keygraphs, i.e. isomorph directed graphs whose vertices are\nkeypoints, in order to explore relative and structural information. Unlike\nsimilar works in the literature, we deal directly with graphs in the entire\npipeline: we search for graph correspondences instead of searching for\nindividual point correspondences and then building graph correspondences from\nthem afterwards. We also estimate the pose from graph correspondences instead\nof falling back to point correspondences through a voting table. The\ncontributions of this paper are the proposed framework and an implementation\nthat properly handles its inherent issues of loss of locality and combinatorial\nexplosion, showing its viability for real-time applications. In particular, we\nintroduce the novel concept of keytuples to solve a running time issue. The\naccuracy of the implementation is shown by results of over 800 experiments with\na well-known database of images. The speed is illustrated by real-time tracking\nwith two different cameras in ordinary hardware.\n",
        "published": "2013-10-01T07:45:26Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0171v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0302v1",
        "title": "Surface Registration Using Genetic Algorithm in Reduced Search Space",
        "summary": "  Surface registration is a technique that is used in various areas such as\nobject recognition and 3D model reconstruction. Problem of surface registration\ncan be analyzed as an optimization problem of seeking a rigid motion between\ntwo different views. Genetic algorithms can be used for solving this\noptimization problem, both for obtaining the robust parameter estimation and\nfor its fine-tuning. The main drawback of genetic algorithms is that they are\ntime consuming which makes them unsuitable for online applications. Modern\nacquisition systems enable the implementation of the solutions that would\nimmediately give the information on the rotational angles between the different\nviews, thus reducing the dimension of the optimization problem. The paper gives\nan analysis of the genetic algorithm implemented in the conditions when the\nrotation matrix is known and a comparison of these results with results when\nthis information is not available.\n",
        "published": "2013-10-01T14:06:33Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0302v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0305v1",
        "title": "Filtering for More Accurate Dense Tissue Segmentation in Digitized\n  Mammograms",
        "summary": "  Breast tissue segmentation into dense and fat tissue is important for\ndetermining the breast density in mammograms. Knowing the breast density is\nimportant both in diagnostic and computer-aided detection applications. There\nare many different ways to express the density of a breast and good quality\nsegmentation should provide the possibility to perform accurate classification\nno matter which classification rule is being used. Knowing the right breast\ndensity and having the knowledge of changes in the breast density could give a\nhint of a process which started to happen within a patient. Mammograms\ngenerally suffer from a problem of different tissue overlapping which results\nin the possibility of inaccurate detection of tissue types. Fibroglandular\ntissue presents rather high attenuation of X-rays and is visible as brighter in\nthe resulting image but overlapping fibrous tissue and blood vessels could\neasily be replaced with fibroglandular tissue in automatic segmentation\nalgorithms. Small blood vessels and microcalcifications are also shown as\nbright objects with similar intensities as dense tissue but do have some\nproperties which makes possible to suppress them from the final results. In\nthis paper we try to divide dense and fat tissue by suppressing the scattered\nstructures which do not represent glandular or dense tissue in order to divide\nmammograms more accurately in the two major tissue types. For suppressing blood\nvessels and microcalcifications we have used Gabor filters of different size\nand orientation and a combination of morphological operations on filtered image\nwith enhanced contrast.\n",
        "published": "2013-10-01T14:09:21Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0305v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0306v1",
        "title": "Flexible Visual Quality Inspection in Discrete Manufacturing",
        "summary": "  Most visual quality inspections in discrete manufacturing are composed of\nlength, surface, angle or intensity measurements. Those are implemented as\nend-user configurable inspection tools that should not require an image\nprocessing expert to set up. Currently available software solutions providing\nsuch capability use a flowchart based programming environment, but do not fully\naddress an inspection flowchart robustness and can require a redefinition of\nthe flowchart if a small variation is introduced. In this paper we propose an\nacquire-register-analyze image processing pattern designed for discrete\nmanufacturing that aims to increase the robustness of the inspection flowchart\nby consistently addressing variations in product position, orientation and\nsize. A proposed pattern is transparent to the end-user and simplifies the\nflowchart. We describe a developed software solution that is a practical\nimplementation of the proposed pattern. We give an example of its real-life use\nin industrial production of electric components.\n",
        "published": "2013-10-01T14:12:01Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0306v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0307v2",
        "title": "Using the Random Sprays Retinex Algorithm for Global Illumination\n  Estimation",
        "summary": "  In this paper the use of Random Sprays Retinex (RSR) algorithm for global\nillumination estimation is proposed and its feasibility tested. Like other\nalgorithms based on the Retinex model, RSR also provides local illumination\nestimation and brightness adjustment for each pixel and it is faster than other\npath-wise Retinex algorithms. As the assumption of the uniform illumination\nholds in many cases, it should be possible to use the mean of local\nillumination estimations of RSR as a global illumination estimation for images\nwith (assumed) uniform illumination allowing also the accuracy to be easily\nmeasured. Therefore we propose a method for estimating global illumination\nestimation based on local RSR results. To our best knowledge this is the first\ntime that RSR algorithm is used to obtain global illumination estimation. For\nour tests we use a publicly available color constancy image database for\ntesting. The results are presented and discussed and it turns out that the\nproposed method outperforms many existing unsupervised color constancy\nalgorithms. The source code is available at\nhttp://www.fer.unizg.hr/ipg/resources/color_constancy/.\n",
        "published": "2013-10-01T14:13:24Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0307v2"
    },
    {
        "id": "http://arxiv.org/abs/1310.0308v1",
        "title": "Combining Spatio-Temporal Appearance Descriptors and Optical Flow for\n  Human Action Recognition in Video Data",
        "summary": "  This paper proposes combining spatio-temporal appearance (STA) descriptors\nwith optical flow for human action recognition. The STA descriptors are local\nhistogram-based descriptors of space-time, suitable for building a partial\nrepresentation of arbitrary spatio-temporal phenomena. Because of the\npossibility of iterative refinement, they are interesting in the context of\nonline human action recognition. We investigate the use of dense optical flow\nas the image function of the STA descriptor for human action recognition, using\ntwo different algorithms for computing the flow: the Farneb\\\"ack algorithm and\nthe TVL1 algorithm. We provide a detailed analysis of the influencing optical\nflow algorithm parameters on the produced optical flow fields. An extensive\nexperimental validation of optical flow-based STA descriptors in human action\nrecognition is performed on the KTH human action dataset. The encouraging\nexperimental results suggest the potential of our approach in online human\naction recognition.\n",
        "published": "2013-10-01T14:13:40Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0308v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0310v1",
        "title": "A Novel Georeferenced Dataset for Stereo Visual Odometry",
        "summary": "  In this work, we present a novel dataset for assessing the accuracy of stereo\nvisual odometry. The dataset has been acquired by a small-baseline stereo rig\nmounted on the top of a moving car. The groundtruth is supplied by a consumer\ngrade GPS device without IMU. Synchronization and alignment between GPS\nreadings and stereo frames are recovered after the acquisition. We show that\nthe attained groundtruth accuracy allows to draw useful conclusions in\npractice. The presented experiments address influence of camera calibration,\nbaseline distance and zero-disparity features to the achieved reconstruction\nperformance.\n",
        "published": "2013-10-01T14:15:48Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0310v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0311v1",
        "title": "Multiclass Road Sign Detection using Multiplicative Kernel",
        "summary": "  We consider the problem of multiclass road sign detection using a\nclassification function with multiplicative kernel comprised from two kernels.\nWe show that problems of detection and within-foreground classification can be\njointly solved by using one kernel to measure object-background differences and\nanother one to account for within-class variations. The main idea behind this\napproach is that road signs from different foreground variations can share\nfeatures that discriminate them from backgrounds. The classification function\ntraining is accomplished using SVM, thus feature sharing is obtained through\nsupport vector sharing. Training yields a family of linear detectors, where\neach detector corresponds to a specific foreground training sample. The\nredundancy among detectors is alleviated using k-medoids clustering. Finally,\nwe report detection and classification results on a set of road sign images\nobtained from a camera on a moving vehicle.\n",
        "published": "2013-10-01T14:16:06Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0311v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0314v1",
        "title": "Global Localization Based on 3D Planar Surface Segments",
        "summary": "  Global localization of a mobile robot using planar surface segments extracted\nfrom depth images is considered. The robot's environment is represented by a\ntopological map consisting of local models, each representing a particular\nlocation modeled by a set of planar surface segments. The discussed\nlocalization approach segments a depth image acquired by a 3D camera into\nplanar surface segments which are then matched to model surface segments. The\nrobot pose is estimated by the Extended Kalman Filter using surface segment\npairs as measurements. The reliability and accuracy of the considered approach\nare experimentally evaluated using a mobile robot equipped by a Microsoft\nKinect sensor.\n",
        "published": "2013-10-01T14:18:52Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0314v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0315v1",
        "title": "Computer Vision Systems in Road Vehicles: A Review",
        "summary": "  The number of road vehicles significantly increased in recent decades. This\ntrend accompanied a build-up of road infrastructure and development of various\ncontrol systems to increase road traffic safety, road capacity and travel\ncomfort. In traffic safety significant development has been made and today's\nsystems more and more include cameras and computer vision methods. Cameras are\nused as part of the road infrastructure or in vehicles. In this paper a review\non computer vision systems in vehicles from the stand point of traffic\nengineering is given. Safety problems of road vehicles are presented, current\nstate of the art in-vehicle vision systems is described and open problems with\nfuture research directions are discussed.\n",
        "published": "2013-10-01T14:19:11Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0315v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0316v1",
        "title": "Classifying Traffic Scenes Using The GIST Image Descriptor",
        "summary": "  This paper investigates classification of traffic scenes in a very low\nbandwidth scenario, where an image should be coded by a small number of\nfeatures. We introduce a novel dataset, called the FM1 dataset, consisting of\n5615 images of eight different traffic scenes: open highway, open road,\nsettlement, tunnel, tunnel exit, toll booth, heavy traffic and the overpass. We\nevaluate the suitability of the GIST descriptor as a representation of these\nimages, first by exploring the descriptor space using PCA and k-means\nclustering, and then by using an SVM classifier and recording its 10-fold\ncross-validation performance on the introduced FM1 dataset. The obtained\nrecognition rates are very encouraging, indicating that the use of the GIST\ndescriptor alone could be sufficiently descriptive even when very high\nperformance is required.\n",
        "published": "2013-10-01T14:19:26Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0316v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0317v1",
        "title": "An Overview and Evaluation of Various Face and Eyes Detection Algorithms\n  for Driver Fatigue Monitoring Systems",
        "summary": "  In this work various methods and algorithms for face and eyes detection are\nexamined in order to decide which of them are applicable for use in a driver\nfatigue monitoring system. In the case of face detection the standard\nViola-Jones face detector has shown best results, while the method of finding\nthe eye centers by means of gradients has proven to be most appropriate in the\ncase of eyes detection. The later method has also a potential for retrieving\nbehavioral parameters needed for estimation of the level of driver fatigue.\nThis possibility will be examined in future work.\n",
        "published": "2013-10-01T14:19:42Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0317v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.0319v3",
        "title": "Second Croatian Computer Vision Workshop (CCVW 2013)",
        "summary": "  Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013,\nhttp://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb,\nCroatia. Workshop was organized by the Center of Excellence for Computer Vision\nof the University of Zagreb.\n",
        "published": "2013-10-01T14:26:29Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0319v3"
    },
    {
        "id": "http://arxiv.org/abs/1310.0365v1",
        "title": "The complex-valued encoding for dicision-making based on aliasing data",
        "summary": "  It is proposed a complex valued channel encoding for multidimensional data.\nThe basic approach contains overlapping of complex nonlinear mappings. Its\ndevelopment leads to sparse representation of multi-channel data, increasing\ntheir dimensions and the distance between the images.\n",
        "published": "2013-10-01T16:06:00Z",
        "pdf_link": "http://arxiv.org/pdf/1310.0365v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.1257v1",
        "title": "Second order scattering descriptors predict fMRI activity due to visual\n  textures",
        "summary": "  Second layer scattering descriptors are known to provide good classification\nperformance on natural quasi-stationary processes such as visual textures due\nto their sensitivity to higher order moments and continuity with respect to\nsmall deformations. In a functional Magnetic Resonance Imaging (fMRI)\nexperiment we present visual textures to subjects and evaluate the predictive\npower of these descriptors with respect to the predictive power of simple\ncontour energy - the first scattering layer. We are able to conclude not only\nthat invariant second layer scattering coefficients better encode voxel\nactivity, but also that well predicted voxels need not necessarily lie in known\nretinotopic regions.\n",
        "published": "2013-08-10T13:00:39Z",
        "pdf_link": "http://arxiv.org/pdf/1310.1257v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.1531v1",
        "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual\n  Recognition",
        "summary": "  We evaluate whether features extracted from the activation of a deep\nconvolutional network trained in a fully supervised fashion on a large, fixed\nset of object recognition tasks can be re-purposed to novel generic tasks. Our\ngeneric tasks may differ significantly from the originally trained tasks and\nthere may be insufficient labeled or unlabeled data to conventionally train or\nadapt a deep architecture to the new tasks. We investigate and visualize the\nsemantic clustering of deep convolutional features with respect to a variety of\nsuch tasks, including scene recognition, domain adaptation, and fine-grained\nrecognition challenges. We compare the efficacy of relying on various network\nlevels to define a fixed feature, and report novel results that significantly\noutperform the state-of-the-art on several important vision challenges. We are\nreleasing DeCAF, an open-source implementation of these deep convolutional\nactivation features, along with all associated network parameters to enable\nvision researchers to be able to conduct experimentation with deep\nrepresentations across a range of visual concept learning paradigms.\n",
        "published": "2013-10-06T02:48:17Z",
        "pdf_link": "http://arxiv.org/pdf/1310.1531v1"
    },
    {
        "id": "http://arxiv.org/abs/1310.1690v1",
        "title": "Online Unsupervised Feature Learning for Visual Tracking",
        "summary": "  Feature encoding with respect to an over-complete dictionary learned by\nunsupervised methods, followed by spatial pyramid pooling, and linear\nclassification, has exhibited powerful strength in various vision applications.\nHere we propose to use the feature learning pipeline for visual tracking.\nTracking is implemented using tracking-by-detection and the resulted framework\nis very simple yet effective. First, online dictionary learning is used to\nbuild a dictionary, which captures the appearance changes of the tracking\ntarget as well as the background changes. Given a test image window, we extract\nlocal image patches from it and each local patch is encoded with respect to the\ndictionary. The encoded features are then pooled over a spatial pyramid to form\nan aggregated feature vector. Finally, a simple linear classifier is trained on\nthese features.\n  Our experiments show that the proposed powerful---albeit simple---tracker,\noutperforms all the state-of-the-art tracking methods that we have tested.\nMoreover, we evaluate the performance of different dictionary learning and\nfeature encoding methods in the proposed tracking framework, and analyse the\nimpact of each component in the tracking scenario. We also demonstrate the\nflexibility of feature learning by plugging it into Hare et al.'s tracking\nmethod. The outcome is, to our knowledge, the best tracker ever reported, which\nfacilitates the advantages of both feature learning and structured output\nprediction.\n",
        "published": "2013-10-07T07:32:17Z",
        "pdf_link": "http://arxiv.org/pdf/1310.1690v1"
    }
]